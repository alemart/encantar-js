{"config":{"lang":["en"],"separator":"[\\s\\-]+","pipeline":["stopWordFilter"]},"docs":[{"location":"contact/","title":"Contact","text":"<p>Please send your inquiries to support@this.domain.</p> <p>Also, see the FAQ.</p>"},{"location":"demos/","title":"Demos","text":""},{"location":"demos/#basics","title":"Basics","text":""},{"location":"demos/#webar-with-a-frame","title":"WebAR with A-Frame","text":"<p>Template based on A-Frame and encantar.js. Very easy to remix!</p> <p>Try it!</p>"},{"location":"demos/#webar-with-babylonjs","title":"WebAR with babylon.js","text":"<p>Template based on babylon.js and encantar.js.</p> <p>Try it!</p>"},{"location":"demos/#webar-with-threejs","title":"WebAR with three.js","text":"<p>Template based on three.js and encantar.js.</p> <p>Try it!</p>"},{"location":"demos/#webar-with-any-framework","title":"WebAR with any framework","text":"<p>Create WebAR experiences with encantar.js and any 3D framework.</p> <p>Try it!</p>"},{"location":"demos/#games-fun","title":"Games &amp; fun","text":""},{"location":"demos/#magic-ar-basketball","title":"Magic AR Basketball","text":"<p>Basketball game based on babylon.js. Play with your phone!</p> <p>Play now!</p>"},{"location":"demos/#street-art","title":"Street Art","text":"<p>WebAR template for art and entertainment. Based on A-Frame.</p> <p>Try it!</p>"},{"location":"demos/#extras","title":"Extras","text":""},{"location":"demos/#video-player-with-buttons","title":"Video Player with Buttons","text":"<p>Enchant your audience with video clips in Augmented Reality! (1)</p> <ol> <li>This demo is part of an Add-On.</li> </ol> <p>Explore</p>"},{"location":"demos/#take-photos","title":"Take Photos","text":"<p>Let your users take AR photos, as in a camera app. (1)</p> <ol> <li>This demo is part of an Add-On.</li> </ol> <p>Explore</p>"},{"location":"demos/#pure-webgl-madness","title":"Pure WebGL madness","text":"<p>WebAR with pure WebGL \u2013 for tough programmers!</p> <p>Try it!</p>"},{"location":"demos/#pointer-tracking","title":"Pointer tracking","text":"<p>Track touch and mouse input with encantar.js.</p> <p>Try it!</p>"},{"location":"faq/","title":"Questions &amp; Answers","text":""},{"location":"faq/#what-is-encantarjs","title":"What is encantar.js?","text":"<p>encantar.js is a standalone GPU-accelerated Augmented Reality engine for the web. The name is derived from the Portuguese and Spanish word encantar, which means: to enchant, to delight, to love, to fascinate, to put a magical spell on someone or something. </p>"},{"location":"faq/#what-about-its-compatibility","title":"What about its compatibility?","text":"<p>encantar.js runs in any device and is compatible with all major web browsers:</p> Chrome Edge Firefox Opera Safari* \u2714 \u2714 \u2714 \u2714 \u2714 <p>* use Safari 15.2 or later.</p> <p>encantar.js requires WebGL2 and WebAssembly, which are widely supported.</p>"},{"location":"faq/#is-this-webxr","title":"Is this WebXR?","text":"<p>No, encantar.js is not WebXR. It's WebAR. The WebXR API allows you to access functionalities of VR and AR-capable devices in web browsers. It relies on other technologies, such as Google's ARCore or Apple's ARKit, to run the show. Those technologies are great, though they are supported on specific devices, which may or may not match your users' devices. Also, at the time of this writing, WebXR is unsupported on iPhone except through unofficial workarounds. On the other hand, encantar.js is fully standalone and is built from scratch using standard web technologies such as WebGL2 and WebAssembly, which are widely supported. It works on mobile and even on Desktop computers. My intention is to give it broad compatibility.</p>"},{"location":"faq/#what-is-webar","title":"What is WebAR?","text":"<p>As explained in the concepts page, WebAR is a set of technologies used to create Augmented Reality experiences that run in web browsers. WebAR makes it easy for users to experience AR, because they can have immediate access to the AR experiences. All they have to do is open a web page. They are not tied to specific platforms and they also don't need to download apps.</p>"},{"location":"faq/#any-recommendations","title":"Any recommendations?","text":"<p>For a good experience:</p> <ul> <li>Don't move the camera nor the target image too quickly. This produces motion blur.</li> <li>The target image should appear clearly in the video.</li> <li>The physical environment should be properly illuminated.</li> <li>If you're scanning the image on a screen, make sure to adjust the brightness. If the screen is too bright (too dark), it will cause overexposure (underexposure) in the video and tracking difficulties - details of the images will be lost. Screen reflections are also undesirable.</li> <li>If you print the image, avoid shiny materials (e.g., glossy paper). They may generate artifacts in the image and interfere with the tracking. Prefer non-reflective materials.</li> <li>Avoid low-quality cameras. Cameras of common smartphones are okay.</li> </ul> <p>See also: Guidelines for Images.</p>"},{"location":"faq/#can-i-bundle-it-using-vite-webpack-etc","title":"Can I bundle it using Vite, Webpack, etc?","text":"<p>Static linking is not allowed according to the LGPL. The inclusion of encantar.js in a web page using a separate script tag does not constitute static linking provided that section 4 of the license is met:</p> <pre><code>&lt;script src=\"path/to/encantar.js\"&gt;&lt;/script&gt;\n&lt;script src=\"path/to/my-ar-experience.js\"&gt;&lt;/script&gt;\n</code></pre>"},{"location":"faq/#why-do-my-models-appear-laid-down-in-ar","title":"Why do my models appear \"laid down\" in AR?","text":"<p>encantar.js uses a right-handed coordinate system with the Z-axis pointing \"up\". The same convention is used in Blender. When exporting your own models, make sure that the Z-axis points \"up\" and that the ground plane is the XY-plane. If your models appear \"laid down\" in AR, this is probably the issue.</p> <p>Fix with code</p> <p>Fixing the orientation of the model is the preferred solution. However, you can also fix the issue with code: add a node (entity) to the scene graph and make it rotate its children by 90 degrees around the x-axis.</p>"},{"location":"faq/#can-i-increase-the-resolution-of-the-tracking","title":"Can I increase the resolution of the tracking?","text":"<p>Yes. You can increase the resolution of the tracker, as well as the resolution of the camera, using the API. You can also increase the resolution of the rendered virtual scene by setting the resolution of the viewport. Performance is affected by various factors such as upload times (GPU). Test your AR experience on your target devices to find a good balance between performance and increased resolution.</p>"},{"location":"faq/#how-do-i-know-which-image-is-detected","title":"How do I know which image is detected?","text":"<p>Add an event listener to the Image Tracker, as in the example:</p> <pre><code>const tracker = AR.Tracker.Image();\n\n// ...\n\ntracker.addEventListener('targetfound', event =&gt; {\n\n    // print the name of the Reference Image\n    console.log('Found target: ' + event.referenceImage.name);\n\n});\n</code></pre>"},{"location":"faq/#i-am-enchanted","title":"I am enchanted!","text":"<p>I know! </p>"},{"location":"guidelines-for-images/","title":"Guidelines for Images","text":"<p>Not all images are suitable for tracking. For best results, pick images that are distinct, asymmetric, detailed and that have little or no text.</p>"},{"location":"guidelines-for-images/#distinct","title":"Distinct","text":"<p>A distinct image has distinguishable areas - quite unlike a repetitive pattern!</p> Suitable  Unsuitable"},{"location":"guidelines-for-images/#asymmetric","title":"Asymmetric","text":"<p>Asymmetric images help the engine determine their orientation. When evaluating symmetry, you must not take colors into account.</p> Suitable  Unsuitable"},{"location":"guidelines-for-images/#detailed","title":"Detailed","text":"<p>A detailed image has lots of different details with sufficient contrast. There isn't much blank space!</p> Suitable  Unsuitable"},{"location":"guidelines-for-images/#little-or-no-text","title":"Little or no text","text":"<p>It follows from the other recommendations that images with too much text - particularly small text - are unsuitable for tracking. Feature points will tend to cluster around the letters and will not be distinct enough. A little bit of text is okay.</p> Suitable  Unsuitable"},{"location":"guidelines-for-images/#other-considerations","title":"Other considerations","text":""},{"location":"guidelines-for-images/#aspect-ratio","title":"Aspect ratio","text":"<p>Prefer images whose aspect ratio (the ratio width \u00f7 height) is somewhere between the aspect ratio of the target device (16:9 is a common aspect ratio) and 1:1 (a square). It's okay to use landscape or portrait mode - the engine will make the necessary adjustments.</p>"},{"location":"guidelines-for-images/#resolution","title":"Resolution","text":"<p>Using a Ultra HD image is of no benefit, because the engine will downscale it. A tiny image isn't desirable either, because some details may be lost and the engine will likely have to upscale it. Use an image that has its details preserved. It's even better if that image can be loaded quickly!</p>"},{"location":"guidelines-for-images/#physical-materials","title":"Physical materials","text":"<p>When printing your images, keep the following in mind:</p> <ul> <li>Prefer non-reflective materials. Avoid shiny materials such as glossy paper. Reflections may generate artifacts in the video and interfere with the tracking.</li> <li>Materials should be rigid. Don't use something that can be distorted too easily.</li> <li>Use quality materials.</li> </ul>"},{"location":"guidelines-for-images/#brightness-on-screens","title":"Brightness on screens","text":"<p>If you're using a screen to display your images, make sure to adjust its brightness. If the screen is too bright (too dark), it will cause overexposure (underexposure) in the video and tracking difficulties - details of the images will be lost. Screen reflections are also undesirable.</p>"},{"location":"guidelines-for-images/#test-it","title":"Test it!","text":"<p>In addition to the guidelines presented above, you should always experiment with your images and make sure it all works as intended. Keep in mind that proper lighting of the physical environment is also very important!</p> <p>See also: Recommendations for WebAR.</p>"},{"location":"license/","title":"GNU LESSER GENERAL PUBLIC LICENSE","text":"<p>Version 3, 29 June 2007</p> <p>Copyright (C) 2007 Free Software Foundation, Inc. https://fsf.org/</p> <p>Everyone is permitted to copy and distribute verbatim copies of this license document, but changing it is not allowed.</p> <p>This version of the GNU Lesser General Public License incorporates the terms and conditions of version 3 of the GNU General Public License, supplemented by the additional permissions listed below.</p>"},{"location":"license/#0-additional-definitions","title":"0. Additional Definitions.","text":"<p>As used herein, \"this License\" refers to version 3 of the GNU Lesser General Public License, and the \"GNU GPL\" refers to version 3 of the GNU General Public License.</p> <p>\"The Library\" refers to a covered work governed by this License, other than an Application or a Combined Work as defined below.</p> <p>An \"Application\" is any work that makes use of an interface provided by the Library, but which is not otherwise based on the Library. Defining a subclass of a class defined by the Library is deemed a mode of using an interface provided by the Library.</p> <p>A \"Combined Work\" is a work produced by combining or linking an Application with the Library. The particular version of the Library with which the Combined Work was made is also called the \"Linked Version\".</p> <p>The \"Minimal Corresponding Source\" for a Combined Work means the Corresponding Source for the Combined Work, excluding any source code for portions of the Combined Work that, considered in isolation, are based on the Application, and not on the Linked Version.</p> <p>The \"Corresponding Application Code\" for a Combined Work means the object code and/or source code for the Application, including any data and utility programs needed for reproducing the Combined Work from the Application, but excluding the System Libraries of the Combined Work.</p>"},{"location":"license/#1-exception-to-section-3-of-the-gnu-gpl","title":"1. Exception to Section 3 of the GNU GPL.","text":"<p>You may convey a covered work under sections 3 and 4 of this License without being bound by section 3 of the GNU GPL.</p>"},{"location":"license/#2-conveying-modified-versions","title":"2. Conveying Modified Versions.","text":"<p>If you modify a copy of the Library, and, in your modifications, a facility refers to a function or data to be supplied by an Application that uses the facility (other than as an argument passed when the facility is invoked), then you may convey a copy of the modified version:</p> <ul> <li>a) under this License, provided that you make a good faith effort     to ensure that, in the event an Application does not supply the     function or data, the facility still operates, and performs     whatever part of its purpose remains meaningful, or</li> <li>b) under the GNU GPL, with none of the additional permissions of     this License applicable to that copy.</li> </ul>"},{"location":"license/#3-object-code-incorporating-material-from-library-header-files","title":"3. Object Code Incorporating Material from Library Header Files.","text":"<p>The object code form of an Application may incorporate material from a header file that is part of the Library. You may convey such object code under terms of your choice, provided that, if the incorporated material is not limited to numerical parameters, data structure layouts and accessors, or small macros, inline functions and templates (ten or fewer lines in length), you do both of the following:</p> <ul> <li>a) Give prominent notice with each copy of the object code that     the Library is used in it and that the Library and its use are     covered by this License.</li> <li>b) Accompany the object code with a copy of the GNU GPL and this     license document.</li> </ul>"},{"location":"license/#4-combined-works","title":"4. Combined Works.","text":"<p>You may convey a Combined Work under terms of your choice that, taken together, effectively do not restrict modification of the portions of the Library contained in the Combined Work and reverse engineering for debugging such modifications, if you also do each of the following:</p> <ul> <li>a) Give prominent notice with each copy of the Combined Work that     the Library is used in it and that the Library and its use are     covered by this License.</li> <li>b) Accompany the Combined Work with a copy of the GNU GPL and this     license document.</li> <li>c) For a Combined Work that displays copyright notices during     execution, include the copyright notice for the Library among     these notices, as well as a reference directing the user to the     copies of the GNU GPL and this license document.</li> <li>d) Do one of the following:<ul> <li>0) Convey the Minimal Corresponding Source under the terms of     this License, and the Corresponding Application Code in a form     suitable for, and under terms that permit, the user to     recombine or relink the Application with a modified version of     the Linked Version to produce a modified Combined Work, in the     manner specified by section 6 of the GNU GPL for conveying     Corresponding Source.</li> <li>1) Use a suitable shared library mechanism for linking with     the Library. A suitable mechanism is one that (a) uses at run     time a copy of the Library already present on the user's     computer system, and (b) will operate properly with a modified     version of the Library that is interface-compatible with the     Linked Version.</li> </ul> </li> <li>e) Provide Installation Information, but only if you would     otherwise be required to provide such information under section 6     of the GNU GPL, and only to the extent that such information is     necessary to install and execute a modified version of the     Combined Work produced by recombining or relinking the Application     with a modified version of the Linked Version. (If you use option     4d0, the Installation Information must accompany the Minimal     Corresponding Source and Corresponding Application Code. If you     use option 4d1, you must provide the Installation Information in     the manner specified by section 6 of the GNU GPL for conveying     Corresponding Source.)</li> </ul>"},{"location":"license/#5-combined-libraries","title":"5. Combined Libraries.","text":"<p>You may place library facilities that are a work based on the Library side by side in a single library together with other library facilities that are not Applications and are not covered by this License, and convey such a combined library under terms of your choice, if you do both of the following:</p> <ul> <li>a) Accompany the combined library with a copy of the same work     based on the Library, uncombined with any other library     facilities, conveyed under the terms of this License.</li> <li>b) Give prominent notice with the combined library that part of it     is a work based on the Library, and explaining where to find the     accompanying uncombined form of the same work.</li> </ul>"},{"location":"license/#6-revised-versions-of-the-gnu-lesser-general-public-license","title":"6. Revised Versions of the GNU Lesser General Public License.","text":"<p>The Free Software Foundation may publish revised and/or new versions of the GNU Lesser General Public License from time to time. Such new versions will be similar in spirit to the present version, but may differ in detail to address new problems or concerns.</p> <p>Each version is given a distinguishing version number. If the Library as you received it specifies that a certain numbered version of the GNU Lesser General Public License \"or any later version\" applies to it, you have the option of following the terms and conditions either of that published version or of any later version published by the Free Software Foundation. If the Library as you received it does not specify a version number of the GNU Lesser General Public License, you may choose any version of the GNU Lesser General Public License ever published by the Free Software Foundation.</p> <p>If the Library as you received it specifies that a proxy can decide whether future versions of the GNU Lesser General Public License shall apply, that proxy's public statement of acceptance of any version is permanent authorization for you to choose that version for the Library.</p>"},{"location":"addons/","title":"Add-Ons","text":"<p>Add-Ons provide an enriched experience with additional features that enhance the core of encantar.js. They are provided as extra perks for supporters. Take a look at these enchanting features! \ud83d\ude0d</p> <p></p> <p></p> <p></p> <p></p>"},{"location":"addons/#video-player","title":"Video Player","text":"<p>Enchant your audience using this easy-to-use &amp; customizable Video Player! Videos in AR are suitable for: product marketing, AR business cards, educational materials, interactive art, and more!</p> <p>Tell me more</p>"},{"location":"addons/#take-photos","title":"Take Photos","text":"<p>Make your WebAR experiences memorable! Users can take photos with AR content just by tapping a button, as in a camera app. Photos can be downloaded, shared on social media, and more!</p> <p>Tell me more</p>"},{"location":"addons/#ar-buttons","title":"AR Buttons","text":"<p>Add interactivity to your scenes with easy-to-use buttons for AR! You can customize their images and colors. They're bundled with the Video Player.</p> <p>Tell me more</p>"},{"location":"addons/#ar-clickables","title":"AR Clickables","text":"<p>Turn 3D and 2D objects into \"clickables\" that respond to touch or mouse input. AR Clickables are based on the Pointer Tracker. They are the building blocks of AR Buttons and are included with them.</p> <p>Tell me more</p>"},{"location":"addons/#asset-manager","title":"Asset Manager","text":"<p>Framework-agnostic solution for preloading assets such as: 3D models, video clips, audio files and more. This Add-On is bundled with the core.</p> <p>Tell me more</p>"},{"location":"addons/ar-button/","title":"AR Button","text":"<p>An A-Frame component and primitive for creating buttons. Buttons respond to clicks and are used to perform some action. They're customizable and built on top of the ar-clickable component.</p> <p>Important</p> <p>AR Buttons require an ar-pointer-tracker in your scene!</p> <p></p> <p>I want this Add-On!</p>"},{"location":"addons/ar-button/#properties","title":"Properties","text":"Property Description Default <code>enabled</code> Whether or not the button is enabled. <code>true</code> <code>src</code> The graphic of the button. If none is provided, a default graphic is used. <code>\"\"</code> <code>width</code> The width of the button. <code>0.5</code> <code>height</code> The height of the button. <code>0.5</code> <code>color</code> The color tint of the button. <code>\"white\"</code> <code>pressed-color</code> The color tint of the button when pressed. <code>\"#ffd855\"</code> <code>disabled-color</code> The color tint of the button when disabled. <code>\"gray\"</code>"},{"location":"addons/ar-button/#look-and-feel","title":"Look and feel","text":""},{"location":"addons/ar-button/#setting-the-text","title":"Setting the text","text":"<p>You can set a text by attaching the <code>text</code> component to your <code>&lt;ar-button&gt;</code>:</p> <pre><code>&lt;ar-button\n    width=\"0.75\" height=\"0.25\"\n    text=\"value: Button; align: center; color: black; wrapCount: 15\"\n&gt;&lt;/ar-button&gt;\n</code></pre> <p>Refer to the documentation of the text component for more details.</p>"},{"location":"addons/ar-button/#changing-the-colors","title":"Changing the colors","text":"<p>Changing the colors is simple to do:</p> <pre><code>&lt;ar-button id=\"my-button\" color=\"lime\" pressed-color=\"tomato\"&gt;&lt;/ar-button&gt;\n</code></pre>"},{"location":"addons/ar-button/#customizing-the-graphic","title":"Customizing the graphic","text":"<p>You can also customize the graphic of your <code>&lt;ar-button&gt;</code> by changing its <code>src</code> property. You'll typically set it to a query selector that refers to an image:</p> <pre><code>&lt;ar-button id=\"my-button\" src=\"#my-button-image\"&gt;&lt;/ar-button&gt;\n\n&lt;!-- ... --&gt;\n\n&lt;a-assets&gt;\n  &lt;img id=\"my-button-image\" src=\"assets/my-button-image.png\"&gt;\n&lt;/a-assets&gt;\n</code></pre> <p>Tip: changing the graphic when pressed</p> <p>If you also want to change the graphic of the button when it's being pressed, set its <code>pressed-color</code> to white and employ <code>ar-onmousedown</code> and <code>ar-onmouseup</code> as follows:</p> <pre><code>&lt;ar-button pressed-color=\"white\"\n  src=\"#my-button-image\"\n  ar-onmouseup=\"ar-button.src: #my-button-image\"\n  ar-onmousedown=\"ar-button.src: #my-pressed-button-image\"\n&gt;&lt;/ar-button&gt;\n</code></pre>"},{"location":"addons/ar-button/#detecting-clicks","title":"Detecting clicks","text":""},{"location":"addons/ar-button/#using-ar-onclick","title":"Using ar-onclick","text":"<p>AR Buttons are built on top of AR Clickables and respond to the same events. In particular, the <code>\"click\"</code> event should be listened to in order to initiate an action. The <code>ar-onclick</code> component makes that really easy:</p> <pre><code>&lt;!-- Change the graphic of the button when it's clicked --&gt;\n&lt;ar-button src=\"#image-1\" ar-onclick=\"ar-button.src: #image-2\"&gt;&lt;/ar-button&gt;\n</code></pre> <p>Button clicks can also affect other entities:</p> <pre><code>&lt;!-- Make the sphere visible when clicking the button --&gt;\n&lt;ar-button ar-onclick=\"_target: #sphere; visible: true\"&gt;&lt;/ar-button&gt;\n&lt;a-sphere id=\"sphere\" position=\"1 0 0\" visible=\"false\"&gt;&lt;/a-sphere&gt;\n</code></pre> <p>Refer to the documentation of ar-clickable for details on <code>ar-onclick</code>.</p>"},{"location":"addons/ar-button/#using-javascript","title":"Using JavaScript","text":"<p>While <code>ar-onclick</code> is easy-to-use, it's limited to setting properties. For advanced usage, you need JavaScript. Write a component and listen to the <code>\"click\"</code> event as in the template below:</p> <pre><code>/*\n  Usage:\n  &lt;ar-button do-something-on-click&gt;&lt;/ar-button&gt;\n*/\nAFRAME.registerComponent('do-something-on-click', {\n\n    dependencies: [ 'ar-button' ],\n\n    init()\n    {\n        this._onclick = this._onclick.bind(this);\n    },\n\n    play()\n    {\n        this.el.addEventListener('click', this._onclick);\n    },\n\n    pause()\n    {\n        this.el.removeEventListener('click', this._onclick);\n    },\n\n    _onclick()\n    {\n        console.log('Do something! ;)');\n    },\n\n});\n</code></pre>"},{"location":"addons/ar-clickable/","title":"AR Clickable","text":"<p>An A-Frame component that turns 3D and 2D objects into \"clickables\" that respond to pointer input. Registered entities will receive certain events. You can add interactivity to them by employing easy-to-use declarative event handlers such as <code>ar-onclick</code>, or by writing your own event handlers in JavaScript.</p> <p>Important</p> <p>AR Clickables require an ar-pointer-tracker in your scene!</p> <p></p> <p>I want this Add-On!</p>"},{"location":"addons/ar-clickable/#properties","title":"Properties","text":"Property Description Default <code>enabled</code> Whether or not the entity will receive certain events. <code>true</code>"},{"location":"addons/ar-clickable/#declarative-handlers","title":"Declarative handlers","text":""},{"location":"addons/ar-clickable/#overview","title":"Overview","text":"<p>Declarative event handlers are components used to register event listeners that set properties. They provide an easy way to create interactivity within your HTML page. There is a component for each event:</p> Handler Description <code>ar-onclick</code> Triggered when the entity receives a <code>\"click\"</code> event. <code>ar-onmousedown</code> Triggered when the entity receives a <code>\"mousedown\"</code> event. <code>ar-onmouseup</code> Triggered when the entity receives a <code>\"mouseup\"</code> event. <p>Example</p> <pre><code>&lt;!-- Turn a yellow box into red when clicked --&gt;\n&lt;a-box color=\"yellow\" ar-onclick=\"material.color: red\"&gt;&lt;/a-box&gt;\n</code></pre> <p>Where is ar-clickable?</p> <p>Whenever using a declarative handler, <code>ar-clickable</code> is implied. There is no need to set it explicitly.</p>"},{"location":"addons/ar-clickable/#special-properties","title":"Special properties","text":"<p>The following special properties are used to further customize the declarative handlers:</p> Property Description <code>_target</code> Query selector to be used when setting properties on a different entity. <code>_delay</code> Delay, in milliseconds, before setting the properties. <p>What about event-set?</p> <p>Declarative handlers are similar to A-Frame's event-set in their usage, but there are differences behind the scenes. Whenever working with AR Clickables, usage of the declarative handlers presented in this page is recommended.</p>"},{"location":"addons/ar-clickable/#multiple-handlers","title":"Multiple handlers","text":"<p>Use double-underscores (<code>__</code>) to attach multiple handlers of the same type to a single entity:</p> <p>Example</p> <pre><code>&lt;!-- Turn a yellow box into red when clicked,\n     and then turn it back to yellow after a second --&gt;\n&lt;a-box color=\"yellow\"\n    ar-onclick__1=\"material.color: red\"\n    ar-onclick__2=\"_delay: 1000; material.color: yellow\"\n&gt;&lt;/a-box&gt;\n</code></pre>"},{"location":"addons/ar-clickable/#events","title":"Events","text":"<p>Entities with an attached <code>ar-clickable</code> receive events analogous to mouse events of the 2D web:</p> Event name Description <code>\"click\"</code> The entity was clicked. <code>\"mousedown\"</code> Fired whenever a pointing device button is pressed while the pointer is intersecting the entity. <code>\"mouseup\"</code> Triggered whenever a pointing device button is released after <code>\"mousedown\"</code> is fired. <p>Event details:</p> Detail Description <code>intersection</code> three.js intersection object, or <code>null</code> if that is unavailable. <code>pointer</code> The TrackablePointer associated with the event."},{"location":"addons/ar-clickable/#advanced-usage","title":"Advanced usage","text":"<p>You can also write your own event handlers in JavaScript as in the template below:</p> <pre><code>/*\n  Usage:\n  &lt;a-box alert-on-click&gt;&lt;/a-box&gt;\n*/\nAFRAME.registerComponent('alert-on-click', {\n\n    dependencies: [ 'ar-clickable' ],\n\n    init()\n    {\n        this._onclick = this._onclick.bind(this);\n    },\n\n    play()\n    {\n        this.el.addEventListener('click', this._onclick);\n    },\n\n    pause()\n    {\n        this.el.removeEventListener('click', this._onclick);\n    },\n\n    _onclick(event)\n    {\n        alert('You clicked me!');\n        console.log(event.detail);\n    },\n\n});\n</code></pre>"},{"location":"addons/ar-snapshot-button/","title":"Take Photos","text":"<p>Make your WebAR experiences memorable! Simply drop <code>&lt;ar-snapshot-button&gt;</code> into your web page, and your users will be able to take photos with AR content just by tapping a button, as in a camera app. Photos can be downloaded, shared among friends on social media, and more!</p> <p></p> <p></p> <p>I want this Add-On!</p>"},{"location":"addons/ar-snapshot-button/#overview","title":"Overview","text":"<p>The Add-On includes a working example, but here is how it works in a nutshell:</p> <pre><code>...\n&lt;ar-viewport&gt;\n    &lt;ar-hud&gt;\n\n        &lt;!-- Just plug &amp; play! --&gt;\n        &lt;ar-snapshot-button&gt;&lt;/ar-snapshot-button&gt;\n\n        ...\n\n    &lt;/ar-hud&gt;\n&lt;/ar-viewport&gt;\n...\n</code></pre>"},{"location":"addons/ar-snapshot-button/#properties","title":"Properties","text":"Property Description Default <code>action</code> The action to be performed when the button is pressed. <code>\"download\"</code> <code>filename</code> The desired filename of the snapshot. Valid extensions: png, jpg, jpeg. Browsers treat this name only as a suggestion. <code>\"snapshot.png\"</code> <code>resolution</code> The resolution of the snapshot. <code>\"720p\"</code>"},{"location":"addons/ar-snapshot-button/#actions","title":"Actions","text":"Action Description <code>\"download\"</code> Download snapshots to the device. See also: Dynamic filenames. <code>\"popup\"</code> Display snapshots in a new window or tab, without saving them. <code>\"none\"</code> Do nothing. This action may be useful when implementing custom behaviors with events."},{"location":"addons/ar-snapshot-button/#events","title":"Events","text":"Event name Description Fields of <code>event.custom</code> <code>\"arsnapshotready\"</code> A new snapshot is ready. <code>file</code>: the snapshot represented as a File object.  <code>ar</code>: a reference to the AR System."},{"location":"addons/ar-snapshot-button/#customization","title":"Customization","text":""},{"location":"addons/ar-snapshot-button/#changing-the-visuals","title":"Changing the visuals","text":"<p>The button is a circular graphic, a standard in camera apps. It may be customized by changing a CSS file that accompanies the demo.</p>"},{"location":"addons/ar-snapshot-button/#playing-sounds","title":"Playing sounds","text":"<p>Use the <code>sound</code> component of A-Frame to make your button play a sound when it's pressed:</p> <pre><code>&lt;ar-snapshot-button sound=\"src: #button-sound\"&gt;&lt;/ar-snapshot-button&gt;\n\n...\n\n&lt;a-assets&gt;\n    &lt;audio id=\"button-sound\" src=\"click.wav\" preload=\"auto\"&gt;&lt;/audio&gt;\n    ...\n&lt;/a-assets&gt;\n</code></pre>"},{"location":"addons/ar-snapshot-button/#troubleshooting","title":"Troubleshooting","text":""},{"location":"addons/ar-snapshot-button/#cors","title":"CORS","text":"<p>Make sure that the viewport canvas is not tainted due to cross-origin issues. If possible, load your page and your assets from the same origin.</p>"},{"location":"addons/ar-snapshot-button/#dynamic-filenames","title":"Dynamic filenames","text":"<p>When downloading photos to the device, you may want to avoid filename clashes. Downloads are treated differently across browsers. When a filename clash occurs, some browsers automatically rename the new file. Others do not, and ask if the user wants to replace the previous file. You may find this behavior undesirable for a camera app. We can avoid clashes by listening to events:</p> <pre><code>&lt;script&gt;(function () {\n\n// use localStorage for persistent IDs, or a Date for unique IDs\nlet nextId = 1; // Date.now();\n\n// dynamically change the filename\ndocument.addEventListener('arsnapshotready', function(event) {\n\n    const button = event.target;\n    const newFilename = generateFilename();\n\n    button.setAttribute('filename', newFilename);\n\n});\n\n// check out the docs of the A-Frame plugin for details on 'arready'\ndocument.addEventListener('arready', function() {\n\n    const button = document.querySelector('ar-snapshot-button');\n    const newFilename = generateFilename();\n\n    button.setAttribute('filename', newFilename);\n\n});\n\n// generate a new filename\nfunction generateFilename()\n{\n    const id = nextId++;\n    return `snapshot${id}.png`;\n}\n\n})();&lt;/script&gt;\n</code></pre>"},{"location":"addons/ar-video-player/","title":"Video Player","text":"<p>An A-Frame component and primitive for playing videos in AR. <code>&lt;ar-video-player&gt;</code> is tailored for encantar.js. Unlike the standard <code>&lt;a-video&gt;</code>, <code>&lt;ar-video-player&gt;</code> handles corner cases for AR and includes easy-to-use controls, so you can focus on your projects rather than dealing with technicalities and quirks of video playback in the browser.</p> <p>It's easy to use!</p> <p>The Video Player Add-On includes a working demo that you can easily modify. This page documents it in depth and is meant to be used as a reference.</p> <p></p> <p></p> <p>I want this Add-On!</p>"},{"location":"addons/ar-video-player/#properties","title":"Properties","text":"Property Description Default <code>src</code> Query selector of a <code>&lt;video&gt;</code> element. <code>\"\"</code> <code>autoplay</code> Whether or not the video should play as soon as the target is found. When enabling autoplay, your <code>&lt;video&gt;</code> element should be muted in order to comply with browser policies. Since: 1.1.0 <code>false</code> <code>width</code> Width of the player. <code>2</code> <code>height</code> Height of the player. <code>1.125</code> <p>Tip</p> <p>Place your <code>&lt;video&gt;</code> tag(s) inside <code>&lt;a-assets&gt;</code>:</p> <pre><code>&lt;ar-root&gt;\n    &lt;ar-video-player src=\"#my-video\"&gt;\n        &lt;!-- ... video controls ... --&gt;\n    &lt;/ar-video-player&gt;\n&lt;/ar-root&gt;\n\n&lt;!-- ... --&gt;\n\n&lt;a-assets&gt;\n    &lt;video id=\"my-video\" playsinline&gt;\n        &lt;source src=\"assets/my-video.mp4\" type=\"video/mp4\" /&gt;\n        &lt;source src=\"assets/my-video.webm\" type=\"video/webm\" /&gt;\n    &lt;/video&gt;\n&lt;/a-assets&gt;\n</code></pre> <p>Aspect ratio</p> <p>Make sure that the <code>width</code> and the <code>height</code> of your <code>&lt;ar-video-player&gt;</code> match the aspect ratio of your video. The default size is appropriate for the commonly used 16:9 widescreen ratio.</p>"},{"location":"addons/ar-video-player/#video-controls","title":"Video controls","text":""},{"location":"addons/ar-video-player/#overview","title":"Overview","text":"<p>You may attach the <code>ar-video-control</code> component to any AR Button (typically) or to any AR Clickable (in general) in order to let the user control the video with a click. What exactly happens with a click depends on the selected action.</p> <p>Add the <code>ar-video-control</code> component to a descendant of <code>&lt;ar-video-player&gt;</code> as in this example:</p> <pre><code>&lt;ar-video-player src=\"#my-video\"&gt;\n\n    &lt;!-- The play button is placed inside ar-video-player --&gt;\n    &lt;ar-button id=\"play-button\" position=\"0 -0.9 0\"\n        ar-video-control=\"action: play\"\n    &gt;&lt;/ar-button&gt;\n\n&lt;/ar-video-player&gt;\n</code></pre>"},{"location":"addons/ar-video-player/#properties_1","title":"Properties","text":"Property Description Default <code>action</code> The action to be performed. <code>\"\"</code>"},{"location":"addons/ar-video-player/#actions","title":"Actions","text":"Action Description <code>\"play\"</code> Play the video. <code>\"pause\"</code> Pause the video. <code>\"toggle\"</code> Toggle the video playback. <code>\"stop\"</code> Pause and rewind the video. <code>\"rewind\"</code> Rewind the video without pausing it. <code>\"mute\"</code> Mute the video. <code>\"unmute\"</code> Unmute the video. <code>\"toggleAudio\"</code> Toggle the audio. <code>\"\"</code> Do nothing."},{"location":"addons/ar-video-player/#multiple-videos","title":"Multiple videos","text":"<p>You may play different videos depending on the target that is being tracked. This can be accomplished by setting an <code>&lt;ar-video-player-source&gt;</code> for each reference image:</p> <pre><code>&lt;ar-root&gt;\n    &lt;ar-video-player width=\"2\" height=\"1.125\"&gt;\n\n        &lt;!-- Set different videos for different targets --&gt;\n        &lt;ar-video-player-source reference-image=\"mage\" src=\"#mage-video\"&gt;&lt;/ar-video-player-source&gt;\n        &lt;ar-video-player-source reference-image=\"cat\" src=\"#cat-video\"&gt;&lt;/ar-video-player-source&gt;\n\n    &lt;/ar-video-player&gt;\n&lt;/ar-root&gt;\n</code></pre> <p>Since: 1.1.0</p>"},{"location":"addons/ar-video-player/#properties_2","title":"Properties","text":"Property Description Default <code>reference-image</code> The name of a reference image. <code>\"\"</code> <code>src</code> Query selector of a <code>&lt;video&gt;</code> element. <code>\"\"</code>"},{"location":"addons/ar-video-player/#declarative-handlers","title":"Declarative handlers","text":""},{"location":"addons/ar-video-player/#overview_1","title":"Overview","text":"<p>Declarative event handlers are components used to register event listeners that set properties. They provide an easy way to create interactivity within your HTML page. There is a component for each event:</p> Handler Description <code>ar-onvideoplay</code> Triggered when the video is played. <code>ar-onvideopause</code> Triggered when the video is paused. <code>ar-onvideoended</code> Triggered when the video reaches its end. <p>These handlers can be added to <code>&lt;ar-video-player&gt;</code> itself or to any of its descendants:</p> <pre><code>&lt;!-- Make the video player translucent when not playing a video --&gt;\n&lt;ar-video-player src=\"#my-video\" transparent=\"true\" opacity=\"0.5\"\n    ar-onvideoplay=\"opacity: 1\"\n    ar-onvideopause=\"opacity: 0.5\"\n    ar-onvideoended=\"opacity: 0.5\"\n&gt;\n    &lt;!-- ... video controls ... --&gt;\n&lt;/ar-video-player&gt;\n</code></pre> <p>Video controls may be combined with declarative handlers for easy customization:</p> <pre><code>&lt;!-- Make the pause button appear when the video starts playing.\n     Make it disappear when the video ends or is paused. --&gt;\n&lt;ar-video-player src=\"#my-video\"&gt;\n\n    &lt;!-- The pause button is placed inside ar-video-player --&gt;\n    &lt;ar-button id=\"pause-button\" position=\"0 -0.9 0\"\n        visible=\"false\" enabled=\"false\"\n        ar-onvideoplay=\"visible: true; ar-button.enabled: true\"\n        ar-onvideopause=\"visible: false; ar-button.enabled: false\"\n        ar-onvideoended=\"visible: false; ar-button.enabled: false\"\n        ar-video-control=\"action: pause\"\n    &gt;&lt;/ar-button&gt;\n\n&lt;/ar-video-player&gt;\n</code></pre>"},{"location":"addons/ar-video-player/#special-properties","title":"Special properties","text":"<p>The following special properties are used to further customize the declarative handlers:</p> Property Description <code>_target</code> Query selector to be used when setting properties on a different entity. <code>_delay</code> Delay, in milliseconds, before setting the properties. <p>What about event-set?</p> <p>Declarative handlers are similar to A-Frame's event-set in their usage, but there are differences behind the scenes. Whenever working with the Video Player, usage of the declarative handlers presented in this page is recommended.</p>"},{"location":"addons/ar-video-player/#multiple-handlers","title":"Multiple handlers","text":"<p>Use double-underscores (<code>__</code>) to attach multiple handlers of the same type to a single entity:</p> <pre><code>&lt;!-- Make two animated characters show up as soon as the video reaches its end --&gt;\n&lt;ar-video-player src=\"#my-video\"\n    ar-onvideoended__1=\"_target: #animated-character-1; visible: true\"\n    ar-onvideoended__2=\"_target: #animated-character-2; visible: true\"\n&gt;\n    &lt;!-- ... video controls ... --&gt;\n&lt;/ar-video-player&gt;\n\n&lt;!-- ... --&gt;\n\n&lt;a-entity id=\"animated-character-1\" visible=\"false\" ... &gt;&lt;/a-entity&gt;\n&lt;a-entity id=\"animated-character-2\" visible=\"false\" ... &gt;&lt;/a-entity&gt;\n</code></pre>"},{"location":"addons/ar-video-player/#events","title":"Events","text":"<p>The <code>&lt;ar-video-player&gt;</code> emits the following events based on the state of the underlying <code>&lt;video&gt;</code> element:</p> Event name Description <code>\"videoplay\"</code> Triggered whenever the video is played. <code>\"videopause\"</code> Triggered whenever the video is paused. <code>\"videoended\"</code> Triggered whenever the video reaches its end."},{"location":"addons/ar-video-player/#methods","title":"Methods","text":"Method Description <code>invoke(action)</code> Perform an action."},{"location":"addons/ar-video-player/#autoplay","title":"Autoplay","text":"<p>Due to browser policies, there are restrictions to be aware of when using autoplay:</p> <ul> <li>Usage of the autoplay setting on <code>&lt;ar-video-player&gt;</code> should be accompanied by a <code>muted</code> attribute on the <code>&lt;video&gt;</code> tag. If the page receives no user interaction, then you may only play your video automatically if it's effectively muted.</li> <li>Usage of the <code>autoplay</code> attribute on the <code>&lt;video&gt;</code> tag is discouraged. Video playback may be blocked. In addition, the Video Player will not show up in AR at the exact moment the page is loaded.</li> <li>Ponder whether or not playing an initially muted video makes sense for your project. It may be better to wait for user input in order to initiate the playback, e.g., have the user click on a play button. If you decide to use autoplay, have a unmute button nearby.</li> </ul> <p>Example</p> <pre><code>&lt;ar-root&gt;\n    &lt;ar-video-player src=\"#my-video\" autoplay=\"true\"&gt;\n        &lt;!-- ... video controls ... --&gt;\n    &lt;/ar-video-player&gt;\n&lt;/ar-root&gt;\n\n&lt;!-- ... --&gt;\n\n&lt;a-assets&gt;\n    &lt;!-- Notice the muted attribute --&gt;\n    &lt;video id=\"my-video\" playsinline muted&gt;\n        &lt;source src=\"assets/my-video.mp4\" type=\"video/mp4\" /&gt;\n        &lt;source src=\"assets/my-video.webm\" type=\"video/webm\" /&gt;\n    &lt;/video&gt;\n&lt;/a-assets&gt;\n</code></pre>"},{"location":"addons/asset-manager/","title":"Asset Manager","text":"<p>A framework-agnostic solution for preloading assets such as: 3D models, video clips, audio files and more. Preloading assets is typically done in the <code>preload()</code> method when using the plugins for babylon.js or three.js. This Add-On is bundled with the core.</p>"},{"location":"addons/asset-manager/#methods","title":"Methods","text":""},{"location":"addons/asset-manager/#preload","title":"preload","text":"<p><code>assetManager.preload(url: string | string[], options?: object): Promise&lt;void&gt;</code></p> <p>Preload one or more assets.</p> <p>Arguments</p> <ul> <li><code>url: string | string[]</code>. Absolute or relative URL(s) of the asset(s).</li> <li><code>options: object, optional</code>. An object with the following keys (all are optional):<ul> <li><code>timeout: number</code>. Timeout value, in seconds. Defaults to infinity (i.e., no timeout).</li> </ul> </li> </ul> <p>Returns</p> <p>A promise that is resolved as soon as all assets are preloaded, or that is rejected on error.</p> <p>Example</p> <pre><code>class MyDemo exports ARDemo\n{\n    // ...\n\n    preload()\n    {\n        return this._assetManager.preload([\n            'assets/mage.glb',\n            'assets/cat.glb',\n            'assets/meow.wav',\n        ], { timeout: 30 });\n    }\n\n    // ...\n\n    constructor()\n    {\n        super();\n\n        // ...\n\n        this._assetManager = new AssetManager();\n\n        // ...\n    }\n}\n</code></pre>"},{"location":"addons/asset-manager/#url","title":"url","text":"<p><code>assetManager.url(filename: string): string</code></p> <p>Gets an object URL of a preloaded asset.</p> <p>Arguments</p> <ul> <li><code>filename: string</code>. The filename of the asset.</li> </ul> <p>Returns</p> <p>An object URL.</p> <p>Example</p> <pre><code>// If the asset is located at \"assets/mage.glb\",\n// then its filename is \"mage.glb\"\nconst mageURL = this._assetManager.url('mage.glb');\n</code></pre>"},{"location":"addons/asset-manager/#file","title":"file","text":"<p><code>assetManager.file(filename: string): File</code></p> <p>Gets a File corresponding to a preloaded asset.</p> <p>Arguments</p> <ul> <li><code>filename: string</code>. The filename of the asset.</li> </ul> <p>Returns</p> <p>A File object.</p>"},{"location":"addons/asset-manager/#has","title":"has","text":"<p><code>assetManager.has(filename: string): boolean</code></p> <p>Checks if an asset has been preloaded.</p> <p>Arguments</p> <ul> <li><code>filename: string</code>. The filename of the asset.</li> </ul> <p>Returns</p> <p>Returns <code>true</code> if an asset with the given <code>filename</code> has been preloaded.</p>"},{"location":"addons/more-addons/","title":"More Add-Ons","text":"<p>Documentation of A-Frame components bundled with the core.</p>"},{"location":"addons/more-addons/#ar-scan-gimmick","title":"ar-scan-gimmick","text":"<p>Use <code>ar-scan-gimmick</code> to display an image in the HUD while the physical scene is being scanned (i.e., before an image target is tracked). Make sure to add the entity to ar-hud.</p> <p>Example</p> <pre><code>&lt;ar-viewport&gt;\n  &lt;ar-hud&gt;\n\n    &lt;!-- ar-scan-gimmick is part of the HUD --&gt;\n    &lt;ar-scan-gimmick&gt;&lt;/ar-scan-gimmick&gt;\n\n  &lt;/ar-hud&gt;\n&lt;/ar-viewport&gt;\n</code></pre>"},{"location":"addons/more-addons/#properties","title":"Properties","text":"Property Description Default <code>opacity</code> Opacity value. <code>1</code> <code>src</code> URL of an image. If none is provided, a default image is used. <code>\"\"</code>"},{"location":"addons/more-addons/#gltf-anim","title":"gltf-anim","text":"<p>An easy-to-use component for animating 3D models.</p> <p>Example</p> <pre><code>&lt;!-- Animate a 3D model in AR --&gt;\n&lt;ar-root&gt;\n  &lt;a-entity gltf-model=\"#mage-model\" gltf-anim=\"clip: Idle\"&gt;&lt;/a-entity&gt;\n&lt;/ar-root&gt;\n</code></pre>"},{"location":"addons/more-addons/#properties_1","title":"Properties","text":"Property Description Default <code>clip</code> The name of an animation clip. <code>\"\"</code> <code>loop</code> Whether or not the animation should loop. <code>true</code> <code>speed</code> Multiplier of the playback speed. <code>1</code> <code>transitionDuration</code> Duration, in seconds, of transitions between clips. <code>0</code>"},{"location":"api/ar-event-listener/","title":"AREventListener","text":"<p>A function that is linked to an AREventTarget. It is called as soon as that AREventTarget receives an AREvent of a specific type. The event is passed as an argument.</p>"},{"location":"api/ar-event-target/","title":"AREventTarget","text":"<p>An AREventTarget is an object that is able to receive AREvents. You may add event listeners to it in order to listen to \"relevant changes\" in its state.</p>"},{"location":"api/ar-event-target/#methods","title":"Methods","text":""},{"location":"api/ar-event-target/#addeventlistener","title":"addEventListener","text":"<p><code>target.addEventListener(type: AREventType, listener: AREventListener): void</code></p> <p>Add an event listener to <code>target</code>.</p> <p>Arguments</p> <ul> <li><code>type: AREventType</code>. The type of event you intend to listen to.</li> <li><code>listener: AREventListener</code>. The event listener you intend to add.</li> </ul> <p>Example</p> <pre><code>session.addEventListener('end', event =&gt; {\n    console.log('The session has ended.');\n});\n</code></pre>"},{"location":"api/ar-event-target/#removeeventlistener","title":"removeEventListener","text":"<p><code>target.removeEventListener(type: AREventType, listener: AREventListener): void</code></p> <p>Remove an event listener from <code>target</code>.</p> <p>Arguments</p> <ul> <li><code>type: AREventType</code>. The type of event you are listening to.</li> <li><code>listener: AREventListener</code>. The event listener you intend to remove.</li> </ul>"},{"location":"api/ar-event-type/","title":"AREventType","text":"<p>An AREventType is a string representing the type of an AREvent. The documentation of the different AREventTargets (e.g., Session) specify which event types are valid for those targets.</p>"},{"location":"api/ar-event/","title":"AREvent","text":"<p>An AREvent is an <code>Event</code> sent to an AREventTarget. AREvents are used to notify AREventListeners about \"relevant changes\" in the state of AREventTargets.</p>"},{"location":"api/ar-event/#properties","title":"Properties","text":""},{"location":"api/ar-event/#type","title":"type","text":"<p><code>event.type: AREventType</code></p> <p>An AREventType representing the type of the event.</p>"},{"location":"api/ar/","title":"AR","text":"<p>The <code>AR</code> namespace is the entry point of the features and components of encantar.js.</p> <p>Tip</p> <p>If you're looking for a step-by-step introduction to encantar.js, take a look at the tutorial.</p>"},{"location":"api/ar/#properties","title":"Properties","text":""},{"location":"api/ar/#settings","title":"Settings","text":"<p><code>AR.Settings: Settings, read-only</code></p> <p>The settings of the engine.</p>"},{"location":"api/ar/#version","title":"version","text":"<p><code>AR.version: string, read-only</code></p> <p>The version of encantar.js.</p>"},{"location":"api/ar/#methods","title":"Methods","text":""},{"location":"api/ar/#issupported","title":"isSupported","text":"<p><code>AR.isSupported(): boolean</code></p> <p>Checks if the user agent is capable of running the engine.</p> <p>Returns</p> <p>Returns <code>true</code> if the user agent is compatible with the engine, or <code>false</code> otherwise.</p>"},{"location":"api/camera-source/","title":"CameraSource","text":"<p>A source of data linked to a webcam. This class extends VideoSource.</p>"},{"location":"api/camera-source/#instantiation","title":"Instantiation","text":""},{"location":"api/camera-source/#arsourcecamera","title":"AR.Source.Camera","text":"<p><code>AR.Source.Camera(settings: object): CameraSource</code></p> <p>Create a new webcam-based source of data with the specified <code>settings</code>.</p> <p>Arguments</p> <ul> <li><code>settings: object, optional</code>. An object with the following keys (all are optional):<ul> <li><code>resolution: Resolution</code>. The desired resolution of the video. The higher the resolution, the longer it takes for the video to be uploaded to the GPU, which impacts performance. The lower the resolution, the less accurate the tracking will be. Suggested values: <code>\"md+\"</code>, <code>\"md\"</code>, <code>\"sm+\"</code>, <code>\"sm\"</code>.</li> <li><code>aspectRatio: number</code>. A hint specifying the preferred aspect ratio of the video.</li> <li><code>constraints: MediaTrackConstraints</code>. Additional video constraints that will be passed to <code>navigator.mediaDevices.getUserMedia()</code>.</li> </ul> </li> </ul> <p>Landscape \u00d7 Portrait</p> <p>You generally do not need to specify an <code>aspectRatio</code>, as encantar.js uses a suitable default. When customizing this setting, pick standard values for landscape mode such as <code>16/9</code> or <code>4/3</code>. Pick such values even if mobile devices are expected to be in portrait mode. Using arbitrary numbers is discouraged and may produce unexpected results in different devices and browsers.</p> <p>Returns</p> <p>A new webcam-based source of data.</p> <p>Example</p> <pre><code>const webcam = AR.Source.Camera({\n    resolution: 'md+',\n    constraints: {\n        facingMode: 'environment' // will prefer the rear camera on mobile devices\n        //facingMode: 'user' // will prefer the front camera on mobile devices\n    }\n});\n</code></pre>"},{"location":"api/camera-source/#properties","title":"Properties","text":""},{"location":"api/camera-source/#resolution","title":"resolution","text":"<p><code>source.resolution: Resolution, read-only</code></p> <p>The resolution of this source of data. Set it when instantiating the object.</p>"},{"location":"api/canvas-source/","title":"CanvasSource","text":"<p>A source of data linked to a <code>&lt;canvas&gt;</code> element.</p>"},{"location":"api/canvas-source/#instantiation","title":"Instantiation","text":""},{"location":"api/canvas-source/#arsourcecanvas","title":"AR.Source.Canvas","text":"<p><code>AR.Source.Canvas(canvas: HTMLCanvasElement): CanvasSource</code></p> <p>Create a new source of data linked to the provided <code>canvas</code>.</p> <p>Arguments</p> <ul> <li><code>canvas: HTMLCanvasElement</code>. A <code>&lt;canvas&gt;</code> element.</li> </ul> <p>Returns</p> <p>A new source of data.</p>"},{"location":"api/canvas-source/#properties","title":"Properties","text":""},{"location":"api/canvas-source/#canvas","title":"canvas","text":"<p><code>source.canvas: HTMLCanvasElement, read-only</code></p> <p>The underlying <code>&lt;canvas&gt;</code> element.</p> <p>Since: 0.4.4</p>"},{"location":"api/frame/","title":"Frame","text":"<p>A <code>Frame</code> holds data for augmenting the physical scene with the virtual scene.</p>"},{"location":"api/frame/#properties","title":"Properties","text":""},{"location":"api/frame/#session","title":"session","text":"<p><code>frame.session: Session, read-only</code></p> <p>A reference to the session.</p>"},{"location":"api/frame/#results","title":"results","text":"<p><code>frame.results: Iterable&lt;TrackerResult&gt;, read-only</code></p> <p>Use this property to iterate through the results generated by the trackers.</p> <p>Example</p> <pre><code>function animate(time, frame)\n{\n    for(const result of frame.results) {\n        // ...\n    }\n\n    session.requestAnimationFrame(animate);\n}\n\nsession.requestAnimationFrame(animate);\n</code></pre>"},{"location":"api/gizmos/","title":"Gizmos","text":"<p>Gizmos provide visual cues about the state of the trackers. They are particularly useful during development.</p>"},{"location":"api/gizmos/#properties","title":"Properties","text":""},{"location":"api/gizmos/#visible","title":"visible","text":"<p><code>gizmos.visible: boolean</code></p> <p>Whether or not the gizmos are visible.</p>"},{"location":"api/hud/","title":"HUD","text":"<p>A HUD (Heads Up Display) is an overlay used to display 2D elements that do not correlate with the physical scene. It's part of a viewport and occupies its entire space. It appears in front of the augmented scene.</p>"},{"location":"api/hud/#properties","title":"Properties","text":""},{"location":"api/hud/#container","title":"container","text":"<p><code>hud.container: HTMLDivElement, read-only</code></p> <p>The container of the HUD.</p>"},{"location":"api/hud/#visible","title":"visible","text":"<p><code>hud.visible: boolean, read-only</code></p> <p>Whether or not the HUD is visible.</p> <p>Deprecated since: 0.4.3</p> <p>Note: this property is read-only since 0.4.3</p>"},{"location":"api/image-tracker-result/","title":"ImageTrackerResult","text":"<p>A result generated by an Image Tracker.</p>"},{"location":"api/image-tracker-result/#properties","title":"Properties","text":""},{"location":"api/image-tracker-result/#tracker","title":"tracker","text":"<p><code>result.tracker: ImageTracker, read-only</code></p> <p>A reference to the Image Tracker that generated this result.</p>"},{"location":"api/image-tracker-result/#trackables","title":"trackables","text":"<p><code>result.trackables: TrackableImage[], read-only</code></p> <p>An array of zero or one TrackableImage object(s).</p>"},{"location":"api/image-tracker-result/#viewer","title":"viewer","text":"<p><code>result.viewer: Viewer | undefined, read-only</code></p> <p>A viewer associated with the trackable. If there is no trackable, this property will be <code>undefined</code>.</p>"},{"location":"api/image-tracker/","title":"ImageTracker","text":"<p>A tracker that tracks images in a video. Images are tracked using templates known as reference images.</p> <p>Guidelines for Images</p> <p>Read Guidelines for Images for tips on how to design images that are suitable for tracking.</p>"},{"location":"api/image-tracker/#instantiation","title":"Instantiation","text":""},{"location":"api/image-tracker/#artrackerimage","title":"AR.Tracker.Image","text":"<p><code>AR.Tracker.Image(options: object): ImageTracker</code></p> <p>Instantiate an image tracker with the specified <code>options</code>.</p> <p>Since: 0.4.0</p> <p>Arguments</p> <ul> <li><code>options: object, optional</code>. An object with the following keys (all are optional):<ul> <li><code>resolution: Resolution</code>. The resolution of the tracker. Make sure that the resolution of the video is at least as high as this. Suggested values: <code>\"sm\"</code>, <code>\"sm+\"</code>, <code>\"md\"</code>, <code>\"md+\"</code>.</li> </ul> </li> </ul> <p>Returns</p> <p>A new image tracker.</p> <p>Example</p> <pre><code>const tracker = AR.Tracker.Image({\n    resolution: \"sm\"\n});\n</code></pre>"},{"location":"api/image-tracker/#artrackerimagetracker","title":"AR.Tracker.ImageTracker","text":"<p><code>AR.Tracker.ImageTracker(): ImageTracker</code></p> <p>Instantiate an image tracker with the default settings.</p> <p>Deprecated since: 0.4.0. Use <code>AR.Tracker.Image()</code> instead.</p> <p>Returns</p> <p>A new image tracker.</p>"},{"location":"api/image-tracker/#properties","title":"Properties","text":""},{"location":"api/image-tracker/#type","title":"type","text":"<p><code>tracker.type: string, read-only</code></p> <p>The string <code>\"image-tracker\"</code>.</p>"},{"location":"api/image-tracker/#state","title":"state","text":"<p><code>tracker.state: string, read-only</code></p> <p>The current state of the tracker.</p>"},{"location":"api/image-tracker/#database","title":"database","text":"<p><code>tracker.database: ReferenceImageDatabase, read-only</code></p> <p>A database of reference images.</p>"},{"location":"api/image-tracker/#resolution","title":"resolution","text":"<p><code>tracker.resolution: Resolution, read-only</code></p> <p>The resolution adopted by the computer vision algorithms implemented in the tracker. Higher resolutions improve the tracking quality, but are computationally more expensive. Note that this resolution is different from, and should not be larger than, the resolution of the camera!</p> <p>Note: this property is read-only since 0.4.0. Set the resolution when instantiating the tracker.</p>"},{"location":"api/image-tracker/#events","title":"Events","text":"<p>An ImageTracker is an AREventTarget. You can listen to the following events:</p>"},{"location":"api/image-tracker/#targetfound","title":"targetfound","text":"<p>A target has been found.</p> <p>Properties</p> <ul> <li><code>referenceImage: ReferenceImage</code>. The reference image that is linked to the target.</li> </ul> <p>Example</p> <pre><code>tracker.addEventListener('targetfound', event =&gt; {\n    console.log('Found target: ' + event.referenceImage.name);\n});\n</code></pre>"},{"location":"api/image-tracker/#targetlost","title":"targetlost","text":"<p>A target has been lost.</p> <p>Properties</p> <ul> <li><code>referenceImage: ReferenceImage</code>. The reference image that is linked to the target.</li> </ul>"},{"location":"api/perspective-view/","title":"PerspectiveView","text":"<p>A View that models a perspective projection.</p>"},{"location":"api/perspective-view/#properties","title":"Properties","text":""},{"location":"api/perspective-view/#aspect","title":"aspect","text":"<p><code>view.aspect: number, read-only</code></p> <p>Aspect ratio of the viewing frustum.</p>"},{"location":"api/perspective-view/#fovx","title":"fovx","text":"<p><code>view.fovx: number, read-only</code></p> <p>Horizontal field-of-view of the viewing frustum, measured in radians.</p> <p>Since: 0.3.0</p>"},{"location":"api/perspective-view/#fovy","title":"fovy","text":"<p><code>view.fovy: number, read-only</code></p> <p>Vertical field-of-view of the viewing frustum, measured in radians.</p>"},{"location":"api/perspective-view/#near","title":"near","text":"<p><code>view.near: number, read-only</code></p> <p>Distance of the near clipping plane of the viewing frustum to the Z = 0 plane in viewer space.</p>"},{"location":"api/perspective-view/#far","title":"far","text":"<p><code>view.far: number, read-only</code></p> <p>Distance of the far clipping plane of the viewing frustum to the Z = 0 plane in viewer space.</p>"},{"location":"api/plugin-aframe/","title":"A-Frame plugin","text":"<p>Documentation of the A-Frame plugin. Study the demos for elaborate examples.</p> <p>Since: 0.3.0</p>"},{"location":"api/plugin-aframe/#basics","title":"Basics","text":""},{"location":"api/plugin-aframe/#example","title":"Example","text":"<p>A basic augmented scene can be constructed as follows:</p> <pre><code>&lt;a-scene encantar=\"stats: true; gizmos: true\"&gt;\n\n    &lt;!-- Sources of data --&gt;\n    &lt;ar-sources&gt;\n        &lt;ar-camera-source&gt;&lt;/ar-camera-source&gt; &lt;!-- webcam --&gt;\n    &lt;/ar-sources&gt;\n\n    &lt;!-- Trackers --&gt;\n    &lt;ar-trackers&gt;\n        &lt;ar-image-tracker&gt;\n            &lt;ar-reference-image name=\"mage\" src=\"mage.png\"&gt;&lt;/ar-reference-image&gt;\n        &lt;/ar-image-tracker&gt;\n    &lt;/ar-trackers&gt;\n\n    &lt;!-- AR Viewport --&gt;\n    &lt;ar-viewport&gt;&lt;/ar-viewport&gt;\n\n    &lt;!-- Virtual camera for AR --&gt;\n    &lt;ar-camera&gt;&lt;/ar-camera&gt;\n\n    &lt;!-- Root node: this will be displayed in AR --&gt;\n    &lt;ar-root reference-image=\"mage\"&gt;\n        &lt;a-box color=\"yellow\" position=\"0 0 0.5\"&gt;&lt;/a-box&gt;\n    &lt;/ar-root&gt;\n\n&lt;/a-scene&gt;\n</code></pre> <p></p>"},{"location":"api/plugin-aframe/#encantar","title":"encantar","text":"<p>The <code>encantar</code> component enchants <code>&lt;a-scene&gt;</code>, so that it displays content in AR.</p> <p>Properties</p> <ul> <li><code>mode: string</code>. The session mode. Defaults to <code>\"immersive\"</code>.</li> <li><code>stats: boolean</code>. Whether or not to display the built-in stats panel. It's useful during development. Defaults to <code>false</code>.</li> <li><code>gizmos: boolean</code>. Whether or not to display the gizmos. Defaults to <code>false</code>.</li> <li><code>autoplay: boolean</code>. Whether or not to start the AR session automatically. Defaults to <code>true</code>.</li> </ul> <p>Example</p> <pre><code>&lt;a-scene encantar=\"stats: true; gizmos: true\"&gt;\n    ...\n&lt;/a-scene&gt;\n</code></pre>"},{"location":"api/plugin-aframe/#ar-root","title":"ar-root","text":"<p>The <code>&lt;ar-root&gt;</code> primitive sets up a node of the virtual scene that is automatically aligned to the physical scene. Simply put, children of this node will augment physical reality. <code>&lt;ar-root&gt;</code> must be a direct child of <code>&lt;a-scene&gt;</code>. It does not have to be unique. See also: ar-camera.</p> <p>Properties</p> <ul> <li><code>reference-image: string</code>. The name of a reference image or the empty string. This node will be matched to the specified reference image, or to any reference image if this property is the empty string. Defaults to the empty string. See also: ar-reference-image.</li> </ul> <p>Example</p> <pre><code>&lt;a-scene encantar&gt;\n\n    ...\n\n    &lt;!-- Matches only the specified reference image --&gt;\n    &lt;ar-root reference-image=\"mage\"&gt;\n        ...\n    &lt;/ar-root&gt;\n\n    &lt;!-- Matches any reference image --&gt;\n    &lt;ar-root&gt;\n        ...\n    &lt;/ar-root&gt;\n\n    ...\n\n&lt;/a-scene&gt;\n</code></pre>"},{"location":"api/plugin-aframe/#visualization","title":"Visualization","text":""},{"location":"api/plugin-aframe/#ar-viewport","title":"ar-viewport","text":"<p>The <code>&lt;ar-viewport&gt;</code> primitive sets up the viewport that will be linked to the AR session. It must be unique and a direct child of <code>&lt;a-scene&gt;</code>. See also: ar-hud.</p> <p>Properties</p> <ul> <li><code>resolution: string</code>. The resolution of the viewport, which corresponds to the resolution of the virtual scene. See also: Resolution.</li> <li><code>style: string</code>. The style of the viewport.</li> <li><code>fullscreen-ui: component</code>. A component that controls the built-in fullscreen button. This button included as a convenience if the fullscreen mode is available on the target platform. The following properties are available:<ul> <li><code>enabled: boolean</code>. Whether or not to display the fullscreen button. Defaults to <code>true</code>.</li> </ul> </li> </ul> <p>Example</p> <pre><code>&lt;a-scene encantar&gt;\n\n    ...\n\n    &lt;ar-viewport resolution=\"lg\"&gt;\n        ...\n    &lt;/ar-viewport&gt;\n\n    ...\n\n&lt;/a-scene&gt;\n</code></pre>"},{"location":"api/plugin-aframe/#ar-hud","title":"ar-hud","text":"<p>The <code>&lt;ar-hud&gt;</code> primitive sets up a Heads Up Display, a 2D overlay that is displayed in front of the augmented scene. It's meant to contain HTML elements. Additionally, it must be a direct child of <code>&lt;ar-viewport&gt;</code>. See also: ar-viewport.</p> <p>Example</p> <pre><code>&lt;ar-viewport&gt;\n    &lt;ar-hud&gt;\n\n        &lt;!-- This will be displayed in front of the augmented scene --&gt;\n        &lt;button id=\"example-button\"&gt;Tap me&lt;/button&gt;\n\n    &lt;/ar-hud&gt;\n&lt;/ar-viewport&gt;\n</code></pre>"},{"location":"api/plugin-aframe/#ar-camera","title":"ar-camera","text":"<p><code>&lt;ar-camera&gt;</code> sets up a virtual camera that is ready for AR. It should be unique and a direct child of <code>&lt;a-scene&gt;</code>. Do not confuse it with <code>&lt;a-camera&gt;</code>, the standard camera from A-Frame. See also: ar-root.</p> <p>Example</p> <pre><code>&lt;a-scene encantar&gt;\n\n    ...\n\n    &lt;ar-camera&gt;&lt;/ar-camera&gt;\n\n    ...\n\n&lt;/a-scene&gt;\n</code></pre>"},{"location":"api/plugin-aframe/#sources","title":"Sources","text":""},{"location":"api/plugin-aframe/#ar-sources","title":"ar-sources","text":"<p>The <code>&lt;ar-sources&gt;</code> primitive is used to specify the sources of data that will be linked to the AR session. It must be unique and a direct child of <code>&lt;a-scene&gt;</code>.</p> <p>Example</p> <pre><code>&lt;a-scene encantar&gt;\n\n    ...\n\n    &lt;ar-sources&gt;\n        ...\n    &lt;/ar-sources&gt;\n\n    ...\n\n&lt;/a-scene&gt;\n</code></pre>"},{"location":"api/plugin-aframe/#ar-camera-source","title":"ar-camera-source","text":"<p><code>&lt;ar-camera-source&gt;</code> sets up a CameraSource, which is source of data linked to a webcam. It must be a direct child of <code>&lt;ar-sources&gt;</code>.</p> <p>Properties</p> <ul> <li><code>resolution: string</code>. The preferred resolution of the camera. See also: Resolution.</li> <li><code>facing-mode: string</code>. The preferred camera on mobile devices. Typically <code>\"environment\"</code> (rear camera) or <code>\"user\"</code> (front camera). Defaults to <code>\"environment\"</code>.</li> </ul> <p>Example</p> <pre><code>&lt;ar-sources&gt;\n    &lt;ar-camera-source resolution=\"360p\"&gt;&lt;/ar-camera-source&gt;\n&lt;/ar-sources&gt;\n</code></pre>"},{"location":"api/plugin-aframe/#ar-video-source","title":"ar-video-source","text":"<p><code>&lt;ar-video-source&gt;</code> sets up a VideoSource, which is a source of data linked to a <code>&lt;video&gt;</code> element. It must be a direct child of <code>&lt;ar-sources&gt;</code>.</p> <p>Properties</p> <ul> <li><code>video: selector</code>. A selector of a <code>&lt;video&gt;</code> element.</li> </ul> <p>Example</p> <pre><code>&lt;ar-sources&gt;\n    &lt;ar-video-source video=\"#my-video\"&gt;&lt;/ar-video-source&gt;\n&lt;/ar-sources&gt;\n\n...\n\n&lt;!-- External assets --&gt;\n&lt;video id=\"my-video\" hidden muted loop playsinline autoplay&gt;\n    &lt;source src=\"my-video.webm\" type=\"video/webm\" /&gt;\n    &lt;source src=\"my-video.mp4\" type=\"video/mp4\" /&gt;\n&lt;/video&gt;\n</code></pre>"},{"location":"api/plugin-aframe/#ar-canvas-source","title":"ar-canvas-source","text":"<p><code>&lt;ar-canvas-source&gt;</code> sets up a CanvasSource, which is a source of data linked to a <code>&lt;canvas&gt;</code> element. It must be a direct child of <code>&lt;ar-sources&gt;</code>.</p> <p>Properties</p> <ul> <li><code>canvas: selector</code>. A selector of a <code>&lt;canvas&gt;</code> element.</li> </ul>"},{"location":"api/plugin-aframe/#ar-pointer-source","title":"ar-pointer-source","text":"<p><code>&lt;ar-pointer-source&gt;</code> sets up a PointerSource, a source of pointer-based input. It must be a direct child of <code>&lt;ar-sources&gt;</code>. See also: ar-pointer-tracker.</p> <p>Since: 0.4.0</p> <p>Example</p> <pre><code>&lt;ar-sources&gt;\n    ...\n    &lt;ar-pointer-source&gt;&lt;/ar-pointer-source&gt;\n&lt;/ar-sources&gt;\n</code></pre>"},{"location":"api/plugin-aframe/#trackers","title":"Trackers","text":""},{"location":"api/plugin-aframe/#ar-trackers","title":"ar-trackers","text":"<p>The <code>&lt;ar-trackers&gt;</code> primitive is used to specify the trackers that will be linked to the AR session. It must be unique and a direct child of <code>&lt;a-scene&gt;</code>.</p> <p>Example</p> <pre><code>&lt;a-scene encantar&gt;\n\n    ...\n\n    &lt;ar-trackers&gt;\n        ...\n    &lt;/ar-trackers&gt;\n\n    ...\n\n&lt;/a-scene&gt;\n</code></pre>"},{"location":"api/plugin-aframe/#ar-image-tracker","title":"ar-image-tracker","text":"<p><code>&lt;ar-image-tracker&gt;</code> sets up an ImageTracker, which is used to track images in a video. You must include at least one <code>&lt;ar-reference-image&gt;</code> as a direct child. See also: ar-reference-image, ar-camera-source, ar-video-source.</p> <p>Properties</p> <ul> <li><code>resolution: string</code>. The resolution of the tracker. See also: Resolution.</li> </ul> <p>Example</p> <pre><code>&lt;ar-trackers&gt;\n    &lt;ar-image-tracker resolution=\"md\"&gt;\n        &lt;ar-reference-image name=\"mage\" src=\"mage.png\"&gt;&lt;/ar-reference-image&gt;\n        &lt;ar-reference-image name=\"magic\" src=\"magic.png\"&gt;&lt;/ar-reference-image&gt;\n    &lt;/ar-image-tracker&gt;\n&lt;/ar-trackers&gt;\n</code></pre>"},{"location":"api/plugin-aframe/#ar-reference-image","title":"ar-reference-image","text":"<p><code>&lt;ar-reference-image&gt;</code> defines a ReferenceImage to be used by an image tracker. It must be a direct child of <code>&lt;ar-image-tracker&gt;</code>. See also: ar-image-tracker.</p> <p>Properties</p> <ul> <li><code>name: string</code>. The name of the reference image. You may link it with <code>&lt;ar-root&gt;</code>. Names must be unique. See also: ar-root.</li> <li><code>src: string</code>. Path to the image.</li> </ul> <p>Example</p> <pre><code>&lt;ar-image-tracker&gt;\n    &lt;ar-reference-image name=\"mage\" src=\"mage.png\"&gt;&lt;/ar-reference-image&gt;\n&lt;/ar-image-tracker&gt;\n</code></pre>"},{"location":"api/plugin-aframe/#ar-pointer-tracker","title":"ar-pointer-tracker","text":"<p><code>&lt;ar-pointer-tracker&gt;</code> sets up a PointerTracker, which is used to track pointer-based input. It must be a direct child of <code>&lt;ar-trackers&gt;</code>. See also: ar-pointer-source, pointers.</p> <p>Since: 0.4.0</p> <p>Properties</p> <ul> <li><code>space: string</code>. The space in which pointers will be located. Since: 0.4.1</li> </ul> <p>Example</p> <pre><code>&lt;ar-trackers&gt;\n    ...\n    &lt;ar-pointer-tracker&gt;&lt;/ar-pointer-tracker&gt;\n&lt;/ar-trackers&gt;\n</code></pre>"},{"location":"api/plugin-aframe/#ar-system","title":"AR System","text":""},{"location":"api/plugin-aframe/#ar","title":"ar","text":"<p>The <code>ar</code> system conveniently exposes useful objects and methods in JavaScript. It may be accessed from any component by writing <code>this.el.sceneEl.systems.ar</code>.</p> <p>Example</p> <pre><code>AFRAME.registerComponent('my-component', {\n\n    // ...\n\n    tick()\n    {\n        const scene = this.el.sceneEl;\n        const ar = scene.systems.ar;\n        const session = ar.session;\n\n        // ...\n    },\n\n    // ...\n\n});\n</code></pre>"},{"location":"api/plugin-aframe/#session","title":"session","text":"<p><code>ar.session: Session | null</code></p> <p>The AR Session. If the AR session hasn't been started, this will be <code>null</code>.</p>"},{"location":"api/plugin-aframe/#frame","title":"frame","text":"<p><code>ar.frame: Frame | null</code></p> <p>The current Frame. If the AR scene isn't initialized, this will be <code>null</code>.</p>"},{"location":"api/plugin-aframe/#viewer","title":"viewer","text":"<p><code>ar.viewer: Viewer | null</code></p> <p>A reference to the Viewer of the current frame, if any.</p> <p>Since: 0.4.0</p>"},{"location":"api/plugin-aframe/#pointers","title":"pointers","text":"<p><code>ar.pointers: TrackablePointer[]</code></p> <p>The TrackablePointers of the current frame, if any. Make sure to add a <code>&lt;ar-pointer-tracker&gt;</code> in order to use these. See also: ar-pointer-tracker.</p> <p>Since: 0.4.0</p>"},{"location":"api/plugin-aframe/#utils","title":"utils","text":"<p><code>ar.utils: object</code></p> <p>Utilities for AR.</p> <p>Since: 0.4.0</p>"},{"location":"api/plugin-aframe/#utilities","title":"Utilities","text":""},{"location":"api/plugin-aframe/#convertvector2","title":"convertVector2","text":"<p><code>ar.utils.convertVector2(v: Vector2): THREE.Vector2</code></p> <p>Convert a Vector2 into a <code>THREE.Vector2</code>.</p> <p>Since: 0.4.0</p> <p>Arguments</p> <ul> <li><code>v: Vector2</code>. A 2D vector.</li> </ul> <p>Returns</p> <p>A corresponding <code>THREE.Vector2</code>.</p>"},{"location":"api/plugin-aframe/#convertvector3","title":"convertVector3","text":"<p><code>ar.utils.convertVector3(v: Vector3): THREE.Vector3</code></p> <p>Convert a Vector3 into a <code>THREE.Vector3</code>.</p> <p>Since: 0.4.0</p> <p>Arguments</p> <ul> <li><code>v: Vector3</code>. A 3D vector.</li> </ul> <p>Returns</p> <p>A corresponding <code>THREE.Vector3</code>.</p>"},{"location":"api/plugin-aframe/#convertquaternion","title":"convertQuaternion","text":"<p><code>ar.utils.convertQuaternion(q: Quaternion): THREE.Quaternion</code></p> <p>Convert a Quaternion into a <code>THREE.Quaternion</code>.</p> <p>Since: 0.4.0</p> <p>Arguments</p> <ul> <li><code>q: Quaternion</code>. A quaternion.</li> </ul> <p>Returns</p> <p>A corresponding <code>THREE.Quaternion</code>.</p>"},{"location":"api/plugin-aframe/#convertray","title":"convertRay","text":"<p><code>ar.utils.convertRay(r: Ray): THREE.Ray</code></p> <p>Convert a Ray into a <code>THREE.Ray</code>.</p> <p>Since: 0.4.0</p> <p>Arguments</p> <ul> <li><code>r: Ray</code>. A ray.</li> </ul> <p>Returns</p> <p>A corresponding <code>THREE.Ray</code>.</p>"},{"location":"api/plugin-aframe/#events","title":"Events","text":"<p>The events below are emitted on the scene.</p>"},{"location":"api/plugin-aframe/#arready","title":"arready","text":"<p>The main loop of the AR scene has been set up. This takes place just after the AR session starts.</p> <p>Since: 0.4.2. Previously, this event was called ar-started.</p> <p>Details</p> <ul> <li><code>ar: object</code>. The ar system.</li> </ul>"},{"location":"api/plugin-aframe/#arsessionended","title":"arsessionended","text":"<p>The AR session has ended.</p> <p>Since: 0.4.2</p> <p>Details</p> <ul> <li><code>ar: object</code>. The ar system.</li> </ul>"},{"location":"api/plugin-aframe/#artargetfound","title":"artargetfound","text":"<p>An image target has been found.</p> <p>Since: 0.4.2</p> <p>Details</p> <ul> <li><code>referenceImage: ReferenceImage</code>. The reference image that is linked to the target.</li> <li><code>ar: object</code>. The ar system.</li> </ul>"},{"location":"api/plugin-aframe/#artargetlost","title":"artargetlost","text":"<p>An image target has been lost.</p> <p>Since: 0.4.2</p> <p>Details</p> <ul> <li><code>referenceImage: ReferenceImage</code>. The reference image that is linked to the target.</li> <li><code>ar: object</code>. The ar system.</li> </ul>"},{"location":"api/plugin-babylon/","title":"Babylon.js plugin","text":"<p>Documentation of the babylon.js plugin. Study the demos for practical examples.</p> <p>Since: 0.3.0</p>"},{"location":"api/plugin-babylon/#basics","title":"Basics","text":""},{"location":"api/plugin-babylon/#lifecycle","title":"Lifecycle","text":"<p>The following diagram shows, in a simplified manner, the lifecycle of an AR experience. The rectangular blocks represent methods of your ARDemo. Function encantar starts the magic.</p> <p></p> <p>Tip</p> <p>Use event listeners to detect events such as finding an image in a camera feed.</p>"},{"location":"api/plugin-babylon/#encantar","title":"encantar","text":"<p><code>encantar(demo: ARDemo): Promise&lt;ARSystem&gt;</code></p> <p>The <code>encantar</code> function enchants a <code>demo</code>, meaning: it starts the lifecycle of the AR experience.</p> <p>Arguments</p> <ul> <li><code>demo: ARDemo</code>. Your demo. See also: ARDemo</li> </ul> <p>Returns</p> <p>A promise that resolves to an ARSystem when the demo starts.</p> <p>Example</p> <pre><code>function main()\n{\n    const demo = new MyDemo(); // class MyDemo extends ARDemo\n\n    encantar(demo).catch(error =&gt; {\n        alert(error.message);\n    });\n}\n\ndocument.addEventListener('DOMContentLoaded', main);\n</code></pre> <p>Note</p> <p>You should not call session.requestAnimationFrame() when using this plugin. The plugin already calls it.</p>"},{"location":"api/plugin-babylon/#ardemo","title":"ARDemo","text":"<p><code>ARDemo</code> is the base class for Augmented Reality experiences. It's an abstract class, meaning that you must extend it. It operates within the lifecycle of your AR experience. The plugin will call its methods and control the flow of the program. Simply call encantar to start the magic!</p>"},{"location":"api/plugin-babylon/#ar","title":"ar","text":"<p><code>demo.ar: ARSystem | null, read-only</code></p> <p>A reference to the ARSystem, or <code>null</code> if the demo hasn't been started yet. See also: lifecycle</p> <p>Since: 0.4.0</p>"},{"location":"api/plugin-babylon/#startsession","title":"startSession","text":"<p><code>startSession(): Promise&lt;Session&gt; | SpeedyPromise&lt;Session&gt;</code></p> <p>Start the AR Session. This method receives no arguments. It's supposed to call AR.startSession with the desired settings.</p> <p>Returns</p> <p>A promise that resolves to a Session.</p> <p>Important</p> <p>This is an abstract method. You must implement it.</p> <p>Fact</p> <p>The tracking begins when the session is started.</p>"},{"location":"api/plugin-babylon/#init","title":"init","text":"<p><code>init(): void | Promise&lt;void&gt;</code></p> <p>Use this method to initialize your 3D scene. See also: ar, preload</p> <p>Returns</p> <p><code>undefined</code>, or a promise that resolves to <code>undefined</code>.</p> <p>Example</p> <pre><code>class MyDemo extends ARDemo\n{\n    // ...\n\n    init()\n    {\n        const ar = this.ar;\n        const scene = ar.scene;\n\n        // initialize the scene\n        // ...\n    }\n\n    // ...\n}\n</code></pre> <p>Important</p> <p>Load external assets in preload. <code>init</code> shouldn't take too long to run because the session has already started, and the user is about to begin to interact with the software. See also: lifecycle</p>"},{"location":"api/plugin-babylon/#update","title":"update","text":"<p><code>update(): void</code></p> <p>Animation step, called during the animation loop. You may want to do something with ar.session or ar.frame.</p> <p>Example</p> <pre><code>class MyDemo extends ARDemo\n{\n    // ...\n\n    update()\n    {\n        const ar = this.ar;\n        const session = ar.session;\n        const deltaTime = session.time.delta; // given in seconds\n\n        // ...\n    }\n\n    // ...\n}\n</code></pre>"},{"location":"api/plugin-babylon/#release","title":"release","text":"<p><code>release(): void</code></p> <p>Release resources soon after the AR session is ended.</p>"},{"location":"api/plugin-babylon/#preload","title":"preload","text":"<p><code>preload(): Promise&lt;void&gt;</code></p> <p>Preload resources before starting the AR session. See also: init, startSession</p> <p>Since: 0.4.0</p> <p>Returns</p> <p>A promise that resolves to <code>undefined</code>.</p> <p>Note</p> <p>The babylon.js scene and engine will only be available during preload if you provide your own canvas.</p>"},{"location":"api/plugin-babylon/#canvas","title":"canvas","text":"<p><code>get canvas(): HTMLCanvasElement | null</code></p> <p>Optional user-provided canvas. If specified, use it in your viewport when starting the session.</p> <p>Since: 0.4.6</p> <p>Returns</p> <p>The canvas in which the virtual scene will be drawn.</p> <p>Example</p> <pre><code>get canvas()\n{\n    const canvas = document.getElementById('ar-canvas');\n\n    if(!canvas)\n        throw new Error('Missing ar-canvas');\n\n    return canvas;\n}\n</code></pre>"},{"location":"api/plugin-babylon/#arsystem","title":"ARSystem","text":"<p><code>ARSystem</code> is a helper for creating Augmented Reality experiences. Access it via ARDemo.ar.</p>"},{"location":"api/plugin-babylon/#session","title":"session","text":"<p><code>ar.session: Session, read-only</code></p> <p>A reference to the AR Session.</p>"},{"location":"api/plugin-babylon/#frame","title":"frame","text":"<p><code>ar.frame: Frame | null, read-only</code></p> <p>A reference to the current Frame. This will be <code>null</code> if the demo hasn't been started yet, or if the session has been ended. See also: lifecycle</p>"},{"location":"api/plugin-babylon/#viewer","title":"viewer","text":"<p><code>ar.viewer: Viewer | null, read-only</code></p> <p>A reference to the Viewer. This will be <code>null</code> if the frame is <code>null</code>.</p> <p>Since: 0.4.0</p>"},{"location":"api/plugin-babylon/#pointers","title":"pointers","text":"<p><code>ar.pointers: TrackablePointer[], read-only</code></p> <p>An array of TrackablePointers.</p> <p>Since: 0.4.0</p> <p>Tip</p> <p>Make sure to add a PointerTracker to your session in order to use these.</p>"},{"location":"api/plugin-babylon/#root","title":"root","text":"<p><code>ar.root: BABYLON.TransformNode, read-only</code></p> <p>A node that is automatically aligned to the physical scene.</p> <p>Important</p> <p>In most cases, objects of your virtual scene should be descendants of this node!</p>"},{"location":"api/plugin-babylon/#camera","title":"camera","text":"<p><code>ar.camera: BABYLON.Camera, read-only</code></p> <p>A camera that is automatically adjusted for AR.</p>"},{"location":"api/plugin-babylon/#scene","title":"scene","text":"<p><code>ar.scene: BABYLON.Scene, read-only</code></p> <p>The babylon.js scene.</p>"},{"location":"api/plugin-babylon/#engine","title":"engine","text":"<p><code>ar.engine: BABYLON.Engine, read-only</code></p> <p>The babylon.js engine.</p>"},{"location":"api/plugin-babylon/#utils","title":"utils","text":"<p><code>ar.utils: ARUtils, read-only</code></p> <p>Utilities object.</p> <p>Since: 0.4.0</p>"},{"location":"api/plugin-babylon/#arutils","title":"ARUtils","text":"<p>Utilities object.</p>"},{"location":"api/plugin-babylon/#convertvector2","title":"convertVector2","text":"<p><code>ar.utils.convertVector2(v: Vector2): BABYLON.Vector2</code></p> <p>Convert a Vector2 into a <code>BABYLON.Vector2</code>.</p> <p>Since: 0.4.0</p> <p>Arguments</p> <ul> <li><code>v: Vector2</code>. A 2D vector.</li> </ul> <p>Returns</p> <p>A corresponding <code>BABYLON.Vector2</code>.</p>"},{"location":"api/plugin-babylon/#convertvector3","title":"convertVector3","text":"<p><code>ar.utils.convertVector3(v: Vector3): BABYLON.Vector3</code></p> <p>Convert a Vector3 into a <code>BABYLON.Vector3</code>.</p> <p>Since: 0.4.0</p> <p>Arguments</p> <ul> <li><code>v: Vector3</code>. A 3D vector.</li> </ul> <p>Returns</p> <p>A corresponding <code>BABYLON.Vector3</code>.</p>"},{"location":"api/plugin-babylon/#convertquaternion","title":"convertQuaternion","text":"<p><code>ar.utils.convertQuaternion(q: Quaternion): BABYLON.Quaternion</code></p> <p>Convert a Quaternion into a <code>BABYLON.Quaternion</code>.</p> <p>Since: 0.4.0</p> <p>Arguments</p> <ul> <li><code>q: Quaternion</code>. A quaternion.</li> </ul> <p>Returns</p> <p>A corresponding <code>BABYLON.Quaternion</code>.</p>"},{"location":"api/plugin-babylon/#convertray","title":"convertRay","text":"<p><code>ar.utils.convertRay(r: Ray): BABYLON.Ray</code></p> <p>Convert a Ray into a <code>BABYLON.Ray</code>.</p> <p>Since: 0.4.0</p> <p>Arguments</p> <ul> <li><code>r: Ray</code>. A ray.</li> </ul> <p>Returns</p> <p>A corresponding <code>BABYLON.Ray</code>.</p>"},{"location":"api/plugin-three/","title":"Three.js plugin","text":"<p>Documentation of the three.js plugin. Study the demos for practical examples.</p>"},{"location":"api/plugin-three/#basics","title":"Basics","text":""},{"location":"api/plugin-three/#lifecycle","title":"Lifecycle","text":"<p>The following diagram shows, in a simplified manner, the lifecycle of an AR experience. The rectangular blocks represent methods of your ARDemo. Function encantar starts the magic.</p> <p></p> <pre>\nmermaid\nflowchart TD\n    _((start)) --&gt;|encantar called| A[preload]\n    A --&gt; B[startSession]\n    B --&gt;|session started| C[init]\n    C --&gt;|demo started| D[update]\n    ? --&gt;|animation loop| D\n    D --&gt; ?{{Session active?}}\n    ? --&gt;|session ended| E[release]\n    E --&gt;|demo ended| Z((end))\n</pre> <p>Tip</p> <p>Use event listeners to detect events such as finding an image in a camera feed.</p>"},{"location":"api/plugin-three/#encantar","title":"encantar","text":"<p><code>encantar(demo: ARDemo): Promise&lt;ARSystem&gt;</code></p> <p>The <code>encantar</code> function enchants a <code>demo</code>, meaning: it starts the lifecycle of the AR experience.</p> <p>Since: 0.3.0</p> <p>Arguments</p> <ul> <li><code>demo: ARDemo</code>. Your demo. See also: ARDemo</li> </ul> <p>Returns</p> <p>A promise that resolves to an ARSystem when the demo starts.</p> <p>Example</p> <pre><code>function main()\n{\n    const demo = new MyDemo(); // class MyDemo extends ARDemo\n\n    encantar(demo).catch(error =&gt; {\n        alert(error.message);\n    });\n}\n\ndocument.addEventListener('DOMContentLoaded', main);\n</code></pre> <p>Note</p> <p>You should not call session.requestAnimationFrame() when using this plugin. The plugin already calls it.</p>"},{"location":"api/plugin-three/#ardemo","title":"ARDemo","text":"<p><code>ARDemo</code> is the base class for Augmented Reality experiences. It's an abstract class, meaning that you must extend it. It operates within the lifecycle of your AR experience. The plugin will call its methods and control the flow of the program. Simply call encantar to start the magic!</p>"},{"location":"api/plugin-three/#ar","title":"ar","text":"<p><code>demo.ar: ARSystem | null, read-only</code></p> <p>A reference to the ARSystem, or <code>null</code> if the demo hasn't been started yet. See also: lifecycle</p> <p>Since: 0.4.0</p>"},{"location":"api/plugin-three/#startsession","title":"startSession","text":"<p><code>startSession(): Promise&lt;Session&gt; | SpeedyPromise&lt;Session&gt;</code></p> <p>Start the AR Session. This method receives no arguments. It's supposed to call AR.startSession with the desired settings.</p> <p>Returns</p> <p>A promise that resolves to a Session.</p> <p>Important</p> <p>This is an abstract method. You must implement it.</p> <p>Fact</p> <p>The tracking begins when the session is started.</p>"},{"location":"api/plugin-three/#init","title":"init","text":"<p><code>init(): void | Promise&lt;void&gt;</code></p> <p>Use this method to initialize your 3D scene. See also: ar, preload</p> <p>Returns</p> <p><code>undefined</code>, or a promise that resolves to <code>undefined</code>.</p> <p>Example</p> <pre><code>class MyDemo extends ARDemo\n{\n    // ...\n\n    init()\n    {\n        const ar = this.ar;\n        const scene = ar.scene;\n\n        // initialize the scene\n        // ...\n    }\n\n    // ...\n}\n</code></pre> <p>Important</p> <p>Load external assets in preload. <code>init</code> shouldn't take too long to run because the session has already started, and the user is about to begin to interact with the software. See also: lifecycle</p>"},{"location":"api/plugin-three/#update","title":"update","text":"<p><code>update(): void</code></p> <p>Animation step, called during the animation loop. You may want to do something with ar.session or ar.frame.</p> <p>Example</p> <pre><code>class MyDemo extends ARDemo\n{\n    // ...\n\n    update()\n    {\n        const ar = this.ar;\n        const session = ar.session;\n        const deltaTime = session.time.delta; // given in seconds\n\n        // ...\n    }\n\n    // ...\n}\n</code></pre>"},{"location":"api/plugin-three/#release","title":"release","text":"<p><code>release(): void</code></p> <p>Release resources soon after the AR session is ended.</p>"},{"location":"api/plugin-three/#preload","title":"preload","text":"<p><code>preload(): Promise&lt;void&gt;</code></p> <p>Preload resources before starting the AR session. See also: init, startSession</p> <p>Since: 0.4.0</p> <p>Returns</p> <p>A promise that resolves to <code>undefined</code>.</p>"},{"location":"api/plugin-three/#canvas","title":"canvas","text":"<p><code>get canvas(): HTMLCanvasElement | null</code></p> <p>Optional user-provided canvas. If specified, use it in your viewport when starting the session.</p> <p>Since: 0.4.6</p> <p>Returns</p> <p>The canvas in which the virtual scene will be drawn.</p> <p>Example</p> <pre><code>get canvas()\n{\n    const canvas = document.getElementById('ar-canvas');\n\n    if(!canvas)\n        throw new Error('Missing ar-canvas');\n\n    return canvas;\n}\n</code></pre>"},{"location":"api/plugin-three/#arsystem","title":"ARSystem","text":"<p><code>ARSystem</code> is a helper for creating Augmented Reality experiences. Access it via ARDemo.ar.</p>"},{"location":"api/plugin-three/#session","title":"session","text":"<p><code>ar.session: Session, read-only</code></p> <p>A reference to the AR Session.</p>"},{"location":"api/plugin-three/#frame","title":"frame","text":"<p><code>ar.frame: Frame | null, read-only</code></p> <p>A reference to the current Frame. This will be <code>null</code> if the demo hasn't been started yet, or if the session has been ended. See also: lifecycle</p>"},{"location":"api/plugin-three/#viewer","title":"viewer","text":"<p><code>ar.viewer: Viewer | null, read-only</code></p> <p>A reference to the Viewer. This will be <code>null</code> if the frame is <code>null</code>.</p> <p>Since: 0.4.0</p>"},{"location":"api/plugin-three/#pointers","title":"pointers","text":"<p><code>ar.pointers: TrackablePointer[], read-only</code></p> <p>An array of TrackablePointers.</p> <p>Since: 0.4.0</p> <p>Tip</p> <p>Make sure to add a PointerTracker to your session in order to use these.</p>"},{"location":"api/plugin-three/#root","title":"root","text":"<p><code>ar.root: THREE.Group, read-only</code></p> <p>A node that is automatically aligned to the physical scene.</p> <p>Important</p> <p>In most cases, objects of your virtual scene should be descendants of this node!</p>"},{"location":"api/plugin-three/#camera","title":"camera","text":"<p><code>ar.camera: THREE.Camera, read-only</code></p> <p>A camera that is automatically adjusted for AR.</p>"},{"location":"api/plugin-three/#scene","title":"scene","text":"<p><code>ar.scene: THREE.Scene, read-only</code></p> <p>The three.js scene.</p>"},{"location":"api/plugin-three/#renderer","title":"renderer","text":"<p><code>ar.renderer: THREE.WebGLRenderer, read-only</code></p> <p>The three.js renderer.</p>"},{"location":"api/plugin-three/#utils","title":"utils","text":"<p><code>ar.utils: ARUtils, read-only</code></p> <p>Utilities object.</p> <p>Since: 0.4.0</p>"},{"location":"api/plugin-three/#arutils","title":"ARUtils","text":"<p>Utilities object.</p>"},{"location":"api/plugin-three/#convertvector2","title":"convertVector2","text":"<p><code>ar.utils.convertVector2(v: Vector2): THREE.Vector2</code></p> <p>Convert a Vector2 into a <code>THREE.Vector2</code>.</p> <p>Since: 0.4.0</p> <p>Arguments</p> <ul> <li><code>v: Vector2</code>. A 2D vector.</li> </ul> <p>Returns</p> <p>A corresponding <code>THREE.Vector2</code>.</p>"},{"location":"api/plugin-three/#convertvector3","title":"convertVector3","text":"<p><code>ar.utils.convertVector3(v: Vector3): THREE.Vector3</code></p> <p>Convert a Vector3 into a <code>THREE.Vector3</code>.</p> <p>Since: 0.4.0</p> <p>Arguments</p> <ul> <li><code>v: Vector3</code>. A 3D vector.</li> </ul> <p>Returns</p> <p>A corresponding <code>THREE.Vector3</code>.</p>"},{"location":"api/plugin-three/#convertquaternion","title":"convertQuaternion","text":"<p><code>ar.utils.convertQuaternion(q: Quaternion): THREE.Quaternion</code></p> <p>Convert a Quaternion into a <code>THREE.Quaternion</code>.</p> <p>Since: 0.4.0</p> <p>Arguments</p> <ul> <li><code>q: Quaternion</code>. A quaternion.</li> </ul> <p>Returns</p> <p>A corresponding <code>THREE.Quaternion</code>.</p>"},{"location":"api/plugin-three/#convertray","title":"convertRay","text":"<p><code>ar.utils.convertRay(r: Ray): THREE.Ray</code></p> <p>Convert a Ray into a <code>THREE.Ray</code>.</p> <p>Since: 0.4.0</p> <p>Arguments</p> <ul> <li><code>r: Ray</code>. A ray.</li> </ul> <p>Returns</p> <p>A corresponding <code>THREE.Ray</code>.</p>"},{"location":"api/pointer-source/","title":"PointerSource","text":"<p>A source of pointer-based input. It feeds a PointerTracker.</p> <p>Since: 0.4.0</p>"},{"location":"api/pointer-source/#instantiation","title":"Instantiation","text":""},{"location":"api/pointer-source/#arsourcepointer","title":"AR.Source.Pointer","text":"<p><code>AR.Source.Pointer(): PointerSource</code></p> <p>Create a new <code>PointerSource</code>.</p> <p>Returns</p> <p>A new <code>PointerSource</code>.</p> <p>Example</p> <pre><code>const pointerSource = AR.Source.Pointer();\n</code></pre>"},{"location":"api/pointer-tracker-result/","title":"PointerTrackerResult","text":"<p>A result generated by a PointerTracker.</p> <p>Since: 0.4.0</p>"},{"location":"api/pointer-tracker-result/#properties","title":"Properties","text":""},{"location":"api/pointer-tracker-result/#tracker","title":"tracker","text":"<p><code>result.tracker: PointerTracker, read-only</code></p> <p>A reference to the PointerTracker that generated this result.</p>"},{"location":"api/pointer-tracker-result/#trackables","title":"trackables","text":"<p><code>result.trackables: TrackablePointer[], read-only</code></p> <p>An array of TrackablePointers.</p>"},{"location":"api/pointer-tracker/","title":"PointerTracker","text":"<p>A tracker of pointers. It consumes data from a PointerSource and produces PointerTrackerResults.</p> <p>Since: 0.4.0</p>"},{"location":"api/pointer-tracker/#instantiation","title":"Instantiation","text":""},{"location":"api/pointer-tracker/#artrackerpointer","title":"AR.Tracker.Pointer","text":"<p><code>AR.Tracker.Pointer(options: object): PointerTracker</code></p> <p>Create a new <code>PointerTracker</code> with the specified <code>options</code>.</p> <p>Arguments</p> <ul> <li><code>options: object, optional</code>. An object with the following keys (all are optional):<ul> <li><code>space: string</code>. The space in which pointers will be located. Defaults to <code>\"normalized\"</code>.</li> </ul> </li> </ul> <p>Returns</p> <p>A new <code>PointerTracker</code>.</p> <p>Example</p> <pre><code>// Use the default settings\nconst pointerTracker = AR.Tracker.Pointer();\n\n// Track pointers in adjusted space\nconst pointerTracker = AR.Tracker.Pointer({ space: 'adjusted' });\n</code></pre>"},{"location":"api/pointer-tracker/#properties","title":"Properties","text":""},{"location":"api/pointer-tracker/#type","title":"type","text":"<p><code>tracker.type: string, read-only</code></p> <p>The string <code>\"pointer-tracker\"</code>.</p>"},{"location":"api/pointer-tracker/#space","title":"space","text":"<p><code>tracker.space: string, read-only</code></p> <p>The space in which pointers are located. You may set it when instantiating the tracker. Possible values: <code>\"normalized\"</code> or <code>\"adjusted\"</code>.</p> <ul> <li> <p>In <code>\"normalized\"</code> space, pointers are located in [-1,1]x[-1,1]. The origin of the space is at the center of the viewport. The x-axis points to the right and the y-axis points up. This is the default space.</p> <ul> <li>Point (0,0) is at the center of the viewport</li> <li>The top-right corner of the viewport is at (+1,+1)</li> <li>The bottom-left corner of the viewport is at (-1,-1)</li> </ul> </li> <li> <p>The <code>\"adjusted\"</code> space is similar to the normalized space, except that it is scaled so that it matches the aspect ratio of the viewport.</p> <p>Pointers in adjusted space are contained in normalized space, but unless the viewport is a square, one of their coordinates, x or y, will no longer range from -1 to +1. It will range from -s to +s, where s = min(a, 1/a). In this expression, a is the aspect ratio of the viewport and s is less than or equal to 1.</p> <p>Selecting the adjusted space is useful for making sure that pointer speeds are equivalent in both axes and for preserving movement curves. Speeds are not equivalent and movement curves are not preserved by default because the normalized space is a square, whereas the viewport is a rectangle.</p> <p>In summary, prefer the adjusted space when working with velocities and movement curves.</p> </li> </ul>"},{"location":"api/pose/","title":"Pose","text":"<p>A pose represents a position and an orientation in 3D space.</p>"},{"location":"api/pose/#properties","title":"Properties","text":""},{"location":"api/pose/#transform","title":"transform","text":"<p><code>pose.transform: Transform, read-only</code></p> <p>The underlying transform.</p>"},{"location":"api/quaternion/","title":"Quaternion","text":"<p>A number system used in encantar.js to represent rotations in 3D space.</p> <p>Since: 0.4.0</p>"},{"location":"api/quaternion/#properties","title":"Properties","text":""},{"location":"api/quaternion/#x","title":"x","text":"<p><code>quaternion.x: number, read-only</code></p> <p>The x coordinate of the quaternion (imaginary).</p>"},{"location":"api/quaternion/#y","title":"y","text":"<p><code>quaternion.y: number, read-only</code></p> <p>The y coordinate of the quaternion (imaginary).</p>"},{"location":"api/quaternion/#z","title":"z","text":"<p><code>quaternion.z: number, read-only</code></p> <p>The z coordinate of the quaternion (imaginary).</p>"},{"location":"api/quaternion/#w","title":"w","text":"<p><code>quaternion.w: number, read-only</code></p> <p>The w coordinate of the quaternion (real).</p>"},{"location":"api/quaternion/#methods","title":"Methods","text":""},{"location":"api/quaternion/#length","title":"length","text":"<p><code>quaternion.length(): number</code></p> <p>Compute the magnitude of the quaternion.</p> <p>Returns</p> <p>The magnitude of the quaternion.</p>"},{"location":"api/quaternion/#equals","title":"equals","text":"<p><code>quaternion.equals(q: Quaternion): boolean</code></p> <p>Check if <code>this</code> and <code>q</code> have the same coordinates.</p> <p>Arguments</p> <ul> <li><code>q: Quaternion</code>. A quaternion.</li> </ul> <p>Returns</p> <p><code>true</code> if <code>this</code> and <code>q</code> have the same coordinates.</p>"},{"location":"api/quaternion/#tostring","title":"toString","text":"<p><code>quaternion.toString(): string</code></p> <p>Generate a string representation of the quaternion.</p> <p>Returns</p> <p>A string representation of the quaternion.</p>"},{"location":"api/ray/","title":"Ray","text":"<p>A ray with origin and direction.</p> <p>Since: 0.4.0</p>"},{"location":"api/ray/#properties","title":"Properties","text":""},{"location":"api/ray/#origin","title":"origin","text":"<p><code>ray.origin: Vector3</code></p> <p>The origin point of the ray.</p>"},{"location":"api/ray/#direction","title":"direction","text":"<p><code>ray.direction: Vector3</code></p> <p>The direction of the ray, a unit vector.</p>"},{"location":"api/reference-image-database/","title":"ReferenceImageDatabase","text":"<p>A database of reference images that belongs to an Image Tracker.</p>"},{"location":"api/reference-image-database/#properties","title":"Properties","text":""},{"location":"api/reference-image-database/#count","title":"count","text":"<p><code>database.count: number, read-only</code></p> <p>The number of reference images stored in this database.</p>"},{"location":"api/reference-image-database/#capacity","title":"capacity","text":"<p><code>database.capacity: number</code></p> <p>The maximum number of reference images that can be stored in this database.</p> <p>Note: this property is writable since version 0.3.0 (experimental).</p>"},{"location":"api/reference-image-database/#methods","title":"Methods","text":""},{"location":"api/reference-image-database/#add","title":"add","text":"<p><code>database.add(referenceImages: ReferenceImage[]): SpeedyPromise&lt;void&gt;</code></p> <p>Add reference image(s) to the database.</p> <p>Arguments</p> <ul> <li><code>referenceImages: ReferenceImage[]</code>. The reference image(s) you want to add.</li> </ul> <p>Returns</p> <p>A promise that resolves as soon as the provided reference images are loaded and added to the database.</p> <p>Example</p> <pre><code>const referenceImages = [{\n    name: 'my-first-image',\n    image: document.getElementById('my-first-image')\n}, {\n    name: 'my-second-image',\n    image: document.getElementById('my-second-image')\n}];\n\ntracker.database.add(referenceImages).then(() =&gt; {\n    console.log('The images have been added to the database');\n});\n</code></pre>"},{"location":"api/reference-image-database/#iterator","title":"@@iterator","text":"<p><code>database[Symbol.iterator](): Iterator&lt;ReferenceImage&gt;</code></p> <p>This is used to iterate over the reference images stored in the database.</p> <p>Returns</p> <p>An iterator.</p> <p>Example</p> <pre><code>for(const referenceImage of tracker.database) {\n    console.log(referenceImage.name);\n}\n</code></pre>"},{"location":"api/reference-image/","title":"ReferenceImage","text":"<p>An interface specifying an image template that is fed to an Image Tracker.</p> <p>Guidelines for Images</p> <p>Read Guidelines for Images for tips on how to design images that are suitable for tracking.</p>"},{"location":"api/reference-image/#properties","title":"Properties","text":""},{"location":"api/reference-image/#name","title":"name","text":"<p><code>referenceImage.name: string, read-only</code></p> <p>A name used to identify this reference image in a database.</p>"},{"location":"api/reference-image/#image","title":"image","text":"<p><code>referenceImage.image: HTMLImageElement | ImageBitmap | ImageData, read-only</code></p> <p>Image template with pixel data.</p> <p>Note: <code>ImageData</code> is acceptable since version 0.4.0.</p>"},{"location":"api/resolution/","title":"Resolution","text":"<p>A <code>Resolution</code> is a setting defined by a string. It is mapped to a size measured in pixels according to special rules. You may use it, for example, to set the resolution of the camera, to adjust the resolution of the tracker, or to set the rendering resolution of the virtual scene.</p> <p>The table below shows examples of how resolution strings are converted to pixels:</p> Resolution Alias 16:9 16:10 4:3 Notes <code>\"120p\"</code> <code>\"xs\"</code> 214x120 192x120 160x120 <code>\"144p\"</code> <code>\"xs+\"</code> 256x144 230x144 192x144 <code>\"240p\"</code> <code>\"sm\"</code> 426x240 384x240 320x240 SD <code>\"288p\"</code> <code>\"sm+\"</code> 512x288 460x288 384x288 <code>\"320p\"</code> <code>\"md\"</code> 568x320 512x320 426x320 <code>\"360p\"</code> <code>\"md+\"</code> 640x360 576x360 480x360 SD <code>\"480p\"</code> <code>\"lg\"</code> 854x480 768x480 640x480 SD <code>\"600p\"</code> <code>\"lg+\"</code> 1066x600 960x600 800x600 <code>\"720p\"</code> <code>\"xl\"</code> 1280x720 1152x720 960x720 HD <code>\"768p\"</code> 1366x768 1228x768 1024x768 <code>\"900p\"</code> <code>\"xl+\"</code> 1600x900 1440x900 1200x900 <code>\"960p\"</code> 1706x960 1536x960 1280x960 <code>\"1080p\"</code> <code>\"xxl\"</code> 1920x1080 1728x1080 1440x1080 Full HD"},{"location":"api/session/","title":"Session","text":"<p>A central component of a WebAR experience. Read the concepts for more information.</p>"},{"location":"api/session/#instantiation","title":"Instantiation","text":""},{"location":"api/session/#arstartsession","title":"AR.startSession","text":"<p><code>AR.startSession(options: object): SpeedyPromise&lt;Session&gt;</code></p> <p>Start a new session.</p> <p>Arguments</p> <ul> <li><code>options: object</code>. Options object with the following keys:<ul> <li><code>trackers: Tracker[]</code>. The trackers to be attached to the session.</li> <li><code>sources: Source[]</code>. The sources of data to be linked to the session.</li> <li><code>viewport: Viewport</code>. The viewport to be linked to the session.</li> <li><code>mode: string, optional</code>. Either <code>\"immersive\"</code> or <code>\"inline\"</code>. Defaults to <code>\"immersive\"</code>.</li> <li><code>gizmos: boolean, optional</code>. Whether or not to display the gizmos. Defaults to <code>false</code>.</li> <li><code>stats: boolean, optional</code>. Whether or not to display the stats panel. It's useful during development. Defaults to <code>false</code>.</li> </ul> </li> </ul> <p>Returns</p> <p>A promise that resolves to a new Session object.</p>"},{"location":"api/session/#properties","title":"Properties","text":""},{"location":"api/session/#mode","title":"mode","text":"<p><code>session.mode: string, read-only</code></p> <p>Session mode: either <code>\"immersive\"</code> or <code>\"inline\"</code>.</p>"},{"location":"api/session/#ended","title":"ended","text":"<p><code>session.ended: boolean, read-only</code></p> <p>Whether or not the session has been ended. See also: end.</p> <p>Since: 0.3.0</p>"},{"location":"api/session/#time","title":"time","text":"<p><code>session.time: TimeManager, read-only</code></p> <p>A reference to the TimeManager of this session.</p>"},{"location":"api/session/#gizmos","title":"gizmos","text":"<p><code>session.gizmos: Gizmos, read-only</code></p> <p>A reference to the Gizmos object.</p>"},{"location":"api/session/#viewport","title":"viewport","text":"<p><code>session.viewport: Viewport, read-only</code></p> <p>A reference to the Viewport linked to this session.</p>"},{"location":"api/session/#trackers","title":"trackers","text":"<p><code>session.trackers: Iterable&lt;Tracker&gt;, read-only</code></p> <p>The trackers that are attached to the session.</p> <p>Since: 0.3.0</p>"},{"location":"api/session/#sources","title":"sources","text":"<p><code>session.sources: Iterable&lt;Source&gt;, read-only</code></p> <p>The sources of data that are linked to the session.</p> <p>Since: 0.3.0</p>"},{"location":"api/session/#methods","title":"Methods","text":""},{"location":"api/session/#requestanimationframe","title":"requestAnimationFrame","text":"<p><code>session.requestAnimationFrame(callback: function): SessionRequestAnimationFrameHandle</code></p> <p>Schedules a call to the <code>callback</code> function, which is intended to update and render the virtual scene. Your <code>callback</code> function must itself call <code>session.requestAnimationFrame()</code> again in order to continue to update and render the virtual scene.</p> <p>Notes</p> <p><code>session.requestAnimationFrame()</code> is analogous to <code>window.requestAnimationFrame()</code>, but they are not the same! The former is a call to the WebAR engine, whereas the latter is a standard call to the web browser.</p> <p>This call will be ignored and an invalid handle will be returned if the session has been ended (since 0.3.0). Previously, it would raise an exception.</p> <p>Arguments</p> <ul> <li><code>callback: function</code>. A function that receives two parameters:<ul> <li><code>time: DOMHighResTimeStamp</code>. Elapsed time, in milliseconds, since an arbitrary reference. This parameter is kept to mimic web standards, but its usage is discouraged. Prefer using <code>frame.session.time.elapsed</code> and <code>frame.session.time.delta</code> instead. These are especially useful for creating animations. See also: TimeManager.</li> <li><code>frame: Frame</code>. A Frame holding the data you need to create the augmented scene.</li> </ul> </li> </ul> <p>Returns</p> <p>A handle.</p> <p>Example</p> <pre><code>//\n// This is the animation loop:\n//\n\nfunction animate(time, frame)\n{\n    // update and render the virtual scene\n    // ...\n\n    // repeat\n    session.requestAnimationFrame(animate);\n}\n\n// start the animation loop\nsession.requestAnimationFrame(animate);\n</code></pre>"},{"location":"api/session/#cancelanimationframe","title":"cancelAnimationFrame","text":"<p><code>session.cancelAnimationFrame(handle: SessionRequestAnimationFrameHandle): void</code></p> <p>Cancels an animation frame request.</p> <p>Arguments</p> <ul> <li><code>handle: SessionRequestAnimationFrameHandle</code>. A handle returned by <code>session.requestAnimationFrame()</code>. If the handle is invalid, this method does nothing.</li> </ul>"},{"location":"api/session/#end","title":"end","text":"<p><code>session.end(): SpeedyPromise&lt;void&gt;</code></p> <p>Ends the session.</p> <p>Returns</p> <p>A promise that resolves as soon as the session is terminated.</p>"},{"location":"api/session/#events","title":"Events","text":"<p>A session is an AREventTarget. You can listen to the following events:</p>"},{"location":"api/session/#end_1","title":"end","text":"<p>The session has ended.</p> <p>Example</p> <pre><code>session.addEventListener('end', event =&gt; {\n    console.log('The session has ended.');\n});\n</code></pre>"},{"location":"api/settings/","title":"Settings","text":"<p>Engine settings.</p>"},{"location":"api/settings/#properties","title":"Properties","text":""},{"location":"api/settings/#powerpreference","title":"powerPreference","text":"<p><code>AR.Settings.powerPreference: string</code></p> <p>Power profile. One of the following: <code>\"default\"</code>, <code>\"low-power\"</code>, <code>\"high-performance\"</code>.</p> Profile Description <code>\"default\"</code> Default settings. <code>\"low-power\"</code> Reduce performance in order to reduce power consumption. <code>\"high-performance\"</code> High performance mode."},{"location":"api/source/","title":"Source","text":"<p>An abstraction representing a source of data that is meant to be linked to a session. A video is a typical source of data. Sources of data feed the trackers. Refer to the concepts for more information.</p>"},{"location":"api/speedy-matrix/","title":"SpeedyMatrix","text":"<p>Speedy includes its own fast implementation of matrices. They are used extensively in encantar.js.</p>"},{"location":"api/speedy-matrix/#properties","title":"Properties","text":""},{"location":"api/speedy-matrix/#rows","title":"rows","text":"<p><code>matrix.rows: number, read-only</code></p> <p>Number of rows of the matrix.</p>"},{"location":"api/speedy-matrix/#columns","title":"columns","text":"<p><code>matrix.columns: number, read-only</code></p> <p>Number of columns of the matrix.</p>"},{"location":"api/speedy-matrix/#methods","title":"Methods","text":""},{"location":"api/speedy-matrix/#read","title":"read","text":"<p><code>matrix.read(): number[]</code></p> <p>Read the entries of the matrix in column-major format.</p> <p>Returns</p> <p>The entries of the matrix in column-major format.</p> <p>Example</p> <pre><code>/*\n\nSuppose that you are given this matrix:\n\n         [ 1  4  7 ]\nmatrix = [ 2  5  8 ]\n         [ 3  6  9 ]\n\nIts entries in column-major format are: [1,2,3,   4,5,6,   7,8,9]\n\n*/\n\nconst entries = matrix.read();\n</code></pre>"},{"location":"api/speedy-matrix/#tostring","title":"toString","text":"<p><code>matrix.toString(): string</code></p> <p>Convert to string.</p> <p>Returns</p> <p>A human-readable representation of the matrix.</p> <p>Example</p> <pre><code>console.log(matrix.toString());\n</code></pre>"},{"location":"api/speedy-promise/","title":"SpeedyPromise","text":"<p>Speedy includes its own implementation of promises. A <code>SpeedyPromise</code> works just like a standard promise. SpeedyPromises are designed for real-time applications. There are some subtle differences behind the scenes, but you need not be concerned with those.</p>"},{"location":"api/speedy-promise/#instantiation","title":"Instantiation","text":""},{"location":"api/speedy-promise/#speedypromise_1","title":"Speedy.Promise","text":"<p><code>new Speedy.Promise(executor: function): SpeedyPromise</code></p> <p>Creates a new <code>SpeedyPromise</code>. This works just like the constructor of a standard promise.</p> <p>Arguments</p> <ul> <li><code>executor: function</code>. A function that takes two functions as arguments:<ul> <li><code>resolve: function</code>. To be called when the promise is resolved.</li> <li><code>reject: function</code>. To be called when the promise is rejected.</li> </ul> </li> </ul> <p>Returns</p> <p>A new <code>SpeedyPromise</code>.</p> <p>Example</p> <pre><code>function sleep(ms)\n{\n    return new Speedy.Promise((resolve, reject) =&gt; {\n        if(ms &gt;= 0)\n            setTimeout(resolve, ms);\n        else\n            reject(new Error('Invalid time'));\n    });\n}\n\nsleep(2000).then(() =&gt; {\n    console.log('2 seconds have passed');\n}).catch(error =&gt; {\n    console.error(error.message);\n}).finally(() =&gt; {\n    console.log('Done!');\n});\n</code></pre>"},{"location":"api/speedy-size/","title":"SpeedySize","text":"<p>Represents the size of a rectangle.</p>"},{"location":"api/speedy-size/#properties","title":"Properties","text":""},{"location":"api/speedy-size/#width","title":"width","text":"<p><code>size.width: number, read-only</code></p> <p>Width of the rectangle.</p>"},{"location":"api/speedy-size/#height","title":"height","text":"<p><code>size.height: number, read-only</code></p> <p>Height of the rectangle.</p>"},{"location":"api/speedy/","title":"Speedy","text":"<p>encantar.js is built using Speedy Vision, a GPU-accelerated Computer Vision library which is another project of mine.</p> <p>Many features provided by Speedy Vision are very useful (e.g., matrices). I have decided to include some of them in parts of the encantar.js API for convenience.</p> <p>In this documentation, I provide a quick reference of some of the classes used in Speedy Vision. This reference is minimal. For a more complete reference, please visit the website of the project.</p>"},{"location":"api/speedy/#properties","title":"Properties","text":""},{"location":"api/speedy/#speedy_1","title":"Speedy","text":"<p><code>Speedy: Speedy, read-only</code></p> <p>The <code>Speedy</code> namespace is provided in global scope. It's also available as <code>AR.Speedy</code>.</p>"},{"location":"api/time-manager/","title":"TimeManager","text":"<p>Time-related utilities. They are useful for animating virtual scenes.</p>"},{"location":"api/time-manager/#properties","title":"Properties","text":""},{"location":"api/time-manager/#elapsed","title":"elapsed","text":"<p><code>time.elapsed: number, read-only</code></p> <p>Elapsed time since the start of the session, measured at the beginning of the current animation frame and given in seconds.</p>"},{"location":"api/time-manager/#delta","title":"delta","text":"<p><code>time.delta: number, read-only</code></p> <p>Elapsed time between the current and the previous animation frame, given in seconds. Use this value to produce animations that are independent of the framerate.</p>"},{"location":"api/time-manager/#scale","title":"scale","text":"<p><code>time.scale: number</code></p> <p>Time scale. Use it to accelerate, slowdown or pause the passage of time. Defaults to 1.</p>"},{"location":"api/time-manager/#unscaled","title":"unscaled","text":"<p><code>time.unscaled: number, read-only</code></p> <p>Time scale independent seconds since the start of the session, measured at the beginning of the current animation frame.</p>"},{"location":"api/trackable-image/","title":"TrackableImage","text":"<p>A trackable that represents an image target tracked by an Image Tracker.</p>"},{"location":"api/trackable-image/#properties","title":"Properties","text":""},{"location":"api/trackable-image/#pose","title":"pose","text":"<p><code>trackable.pose: Pose, read-only</code></p> <p>The pose of the trackable.</p>"},{"location":"api/trackable-image/#referenceimage","title":"referenceImage","text":"<p><code>trackable.referenceImage: ReferenceImage, read-only</code></p> <p>The reference image associated with the trackable.</p>"},{"location":"api/trackable-pointer/","title":"TrackablePointer","text":"<p>A trackable that represents a pointer tracked by a PointerTracker.</p> <p>A pointer is an abstraction that represents an instance of user input that targets one or more coordinates on a screen. For example, each point of contact between fingers and a multitouch screen generate a pointer. Devices such as a mouse and a pen/stylus also generate pointers.</p> <p>Pointers are located in the viewport. Their positions are given in space units. By default, space units are normalized units, which range from -1 to +1. In normalized space, the center of the viewport is at (0,0). The top right corner is at (1,1). The bottom left corner is at (-1,-1).</p> <p>Since: 0.4.0</p>"},{"location":"api/trackable-pointer/#properties","title":"Properties","text":""},{"location":"api/trackable-pointer/#id","title":"id","text":"<p><code>pointer.id: number, read-only</code></p> <p>A unique identifier assigned to this pointer.</p>"},{"location":"api/trackable-pointer/#phase","title":"phase","text":"<p><code>pointer.phase: string, read-only</code></p> <p>The phase of the pointer. It's one of the following strings:</p> <ul> <li><code>\"began\"</code>: the tracking began in this frame (e.g., a finger has just touched the screen)</li> <li><code>\"stationary\"</code>: the user did not move the pointer in this frame</li> <li><code>\"moved\"</code>: the user moved the pointer in this frame</li> <li><code>\"ended\"</code>: the tracking ended in this frame (e.g., a finger has just been lifted from the screen)</li> <li><code>\"canceled\"</code>: the tracking was canceled in this frame (e.g., the page has just lost focus)</li> </ul>"},{"location":"api/trackable-pointer/#position","title":"position","text":"<p><code>pointer.position: Vector2, read-only</code></p> <p>The current position of the pointer, given in space units. See also: PointerTracker.space, Viewer.raycast, Viewport.convertToPixels.</p>"},{"location":"api/trackable-pointer/#initialposition","title":"initialPosition","text":"<p><code>pointer.initialPosition: Vector2, read-only</code></p> <p>The position of the pointer when its tracking began.</p>"},{"location":"api/trackable-pointer/#deltaposition","title":"deltaPosition","text":"<p><code>pointer.deltaPosition: Vector2, read-only</code></p> <p>The difference between the position of the pointer in this and in the previous frame.</p>"},{"location":"api/trackable-pointer/#velocity","title":"velocity","text":"<p><code>pointer.velocity: Vector2, read-only</code></p> <p>The current velocity of the pointer, given in space units per second. You can get the current speed of motion by calculating the magnitude of this vector.</p>"},{"location":"api/trackable-pointer/#duration","title":"duration","text":"<p><code>pointer.duration: number, read-only</code></p> <p>The elapsed time, in seconds, since the tracking of this pointer began. You can check if this pointer represents a tap by comparing its duration to a threshold at the <code>\"ended\"</code> phase. Example: <code>isTap = pointer.phase == \"ended\" &amp;&amp; pointer.duration &lt; 0.25</code>.</p>"},{"location":"api/trackable-pointer/#movementlength","title":"movementLength","text":"<p><code>pointer.movementLength: number, read-only</code></p> <p>How much this pointer has moved, in space units, since its tracking began. You can get the average speed of motion by calculating the ratio <code>movementLength / duration</code>.</p>"},{"location":"api/trackable-pointer/#movementduration","title":"movementDuration","text":"<p><code>pointer.movementDuration: number, read-only</code></p> <p>The total time, in seconds, in which this pointer has moved. You can get the average speed of motion, excluding the times in which this pointer remained stationary, by calculating the ratio <code>movementLength / movementDuration</code>.</p>"},{"location":"api/trackable-pointer/#isprimary","title":"isPrimary","text":"<p><code>pointer.isPrimary: boolean, read-only</code></p> <p>Whether or not this is the primary pointer among all pointers of this kind. A typical primary pointer is that of a finger that touches the screen when no other fingers are touching it.</p>"},{"location":"api/trackable-pointer/#kind","title":"kind","text":"<p><code>pointer.kind: string, read-only</code></p> <p>The kind of device that originated this pointer. Typically <code>\"touch\"</code>, <code>\"mouse\"</code> or <code>\"pen\"</code>.</p>"},{"location":"api/trackable/","title":"Trackable","text":"<p>A Trackable is an interface that represents something that is tracked by a Tracker.</p>"},{"location":"api/trackable/#properties","title":"Properties","text":""},{"location":"api/trackable/#tracker","title":"tracker","text":"<p><code>trackable.tracker: Tracker, read-only</code></p> <p>A reference to the Tracker that generated this trackable.</p> <p>Since: 0.4.0</p>"},{"location":"api/tracker-result/","title":"TrackerResult","text":"<p>An interface that represents the result generated by a tracker at a specific time. It is part of a frame.</p>"},{"location":"api/tracker-result/#properties","title":"Properties","text":""},{"location":"api/tracker-result/#tracker","title":"tracker","text":"<p><code>result.tracker: Tracker, read-only</code></p> <p>A reference to the tracker that generated this result.</p>"},{"location":"api/tracker-result/#trackables","title":"trackables","text":"<p><code>result.trackables: Trackable[], read-only</code></p> <p>An array of zero or more trackables.</p>"},{"location":"api/tracker-result/#methods","title":"Methods","text":""},{"location":"api/tracker-result/#of","title":"of","text":"<p><code>result.of(trackerType: string): boolean</code></p> <p>Checks if <code>this</code> result was generated by tracker of a certain <code>trackerType</code>. This is a convenient type guard for TypeScript users. See also: Tracker.is.</p> <p>Since: 0.4.4</p> <p>Returns</p> <p>The same as <code>tracker.is(trackerType)</code>.</p> <p>Example</p> <pre><code>let result: TrackerResult;\n\n// ...\n\nif(result.of('image-tracker')) {\n    // result is inferred to be an ImageTrackerResult\n    // ...\n}\nelse if(result.of('pointer-tracker')) {\n    // result is inferred to be a PointerTrackerResult\n    // ...\n}\nelse {\n    // ...\n}\n</code></pre>"},{"location":"api/tracker/","title":"Tracker","text":"<p>An interface that represents a generic tracker. Trackers analyze input data in some way and are meant to be attached to a session. Refer to the concepts for more information.</p> <p>An Image Tracker is an implementation of a tracker, and so is a PointerTracker.</p>"},{"location":"api/tracker/#properties","title":"Properties","text":""},{"location":"api/tracker/#type","title":"type","text":"<p><code>tracker.type: string, read-only</code></p> <p>A string representing the type of the tracker.</p> <p>Deprecated since: 0.4.4. Use <code>tracker.is()</code> instead.</p>"},{"location":"api/tracker/#methods","title":"Methods","text":""},{"location":"api/tracker/#is","title":"is","text":"<p><code>tracker.is(type: string): boolean</code></p> <p>Checks if <code>this</code> tracker is of a certain <code>type</code>. This is a convenient type guard for TypeScript users. See also: TrackerResult.of.</p> <p>Since: 0.4.4</p> <p>Returns</p> <p><code>true</code> if and only if <code>type === tracker.type</code></p> <p>Example</p> <pre><code>let tracker: Tracker;\n\n// ...\n\nif(tracker.is('image-tracker')) {\n    // tracker is inferred to be an ImageTracker\n    // ...\n}\nelse if(tracker.is('pointer-tracker')) {\n    // tracker is inferred to be a PointerTracker\n    // ...\n}\nelse {\n    // ...\n}\n</code></pre>"},{"location":"api/transform/","title":"Transform","text":"<p>A Transform represents a position, a rotation and a scale in 3D space.</p>"},{"location":"api/transform/#properties","title":"Properties","text":""},{"location":"api/transform/#position","title":"position","text":"<p><code>transform.position: Vector3, read-only</code></p> <p>The 3D position encoded by the transform.</p> <p>Since: 0.4.0</p>"},{"location":"api/transform/#orientation","title":"orientation","text":"<p><code>transform.orientation: Quaternion, read-only</code></p> <p>A unit quaternion describing the rotational component of the transform.</p> <p>Since: 0.4.0</p>"},{"location":"api/transform/#scale","title":"scale","text":"<p><code>transform.scale: Vector3, read-only</code></p> <p>The scale encoded by the transform.</p> <p>Since: 0.4.0</p>"},{"location":"api/transform/#right","title":"right","text":"<p><code>transform.right: Vector3, read-only</code></p> <p>The unit right vector of the local space.</p> <p>Since: 0.4.0</p>"},{"location":"api/transform/#up","title":"up","text":"<p><code>transform.up: Vector3, read-only</code></p> <p>The unit up vector of the local space.</p> <p>Since: 0.4.0</p>"},{"location":"api/transform/#forward","title":"forward","text":"<p><code>transform.forward: Vector3, read-only</code></p> <p>The unit forward vector of the local space.</p> <p>Since: 0.4.0</p>"},{"location":"api/transform/#matrix","title":"matrix","text":"<p><code>transform.matrix: SpeedyMatrix, read-only</code></p> <p>A 4x4 matrix encoding the transform.</p>"},{"location":"api/transform/#inverse","title":"inverse","text":"<p><code>transform.inverse: Transform, read-only</code></p> <p>The inverse transform.</p>"},{"location":"api/vector2/","title":"Vector2","text":"<p>A vector in 2D space.</p> <p>Since: 0.4.0</p>"},{"location":"api/vector2/#instantiation","title":"Instantiation","text":""},{"location":"api/vector2/#arvector2","title":"AR.Vector2","text":"<p><code>AR.Vector2(x: number, y: number): Vector2</code></p> <p>Create a new vector with the provided coordinates.</p> <p>Arguments</p> <ul> <li><code>x: number</code>. x coordinate.</li> <li><code>y: number</code>. y coordinate.</li> </ul> <p>Returns</p> <p>A new vector.</p> <p>Example</p> <pre><code>const zero = AR.Vector2(0, 0);\n</code></pre>"},{"location":"api/vector2/#properties","title":"Properties","text":""},{"location":"api/vector2/#x","title":"x","text":"<p><code>vector.x: number, read-only</code></p> <p>The x coordinate of the vector.</p>"},{"location":"api/vector2/#y","title":"y","text":"<p><code>vector.y: number, read-only</code></p> <p>The y coordinate of the vector.</p>"},{"location":"api/vector2/#methods","title":"Methods","text":""},{"location":"api/vector2/#length","title":"length","text":"<p><code>vector.length(): number</code></p> <p>Compute the magnitude of the vector.</p> <p>Returns</p> <p>The magnitude of the vector.</p>"},{"location":"api/vector2/#dot","title":"dot","text":"<p><code>vector.dot(v: Vector2): number</code></p> <p>Compute the dot product of <code>this</code> and <code>v</code>.</p> <p>Arguments</p> <ul> <li><code>v: Vector2</code>. A vector.</li> </ul> <p>Returns</p> <p>The dot product of the vectors.</p>"},{"location":"api/vector2/#distanceto","title":"distanceTo","text":"<p><code>vector.distanceTo(v: Vector2): number</code></p> <p>Compute the distance between points <code>this</code> and <code>v</code>.</p> <p>Arguments</p> <ul> <li><code>v: Vector2</code>. A vector / point.</li> </ul> <p>Returns</p> <p>The distance between the points.</p>"},{"location":"api/vector2/#directionto","title":"directionTo","text":"<p><code>vector.directionTo(v: Vector2): Vector2</code></p> <p>Compute a unit vector pointing to <code>v</code> from <code>this</code>.</p> <p>Arguments</p> <ul> <li><code>v: Vector2</code>. A vector.</li> </ul> <p>Returns</p> <p>A new unit vector pointing to <code>v</code> from <code>this</code>.</p>"},{"location":"api/vector2/#normalized","title":"normalized","text":"<p><code>vector.normalized(): Vector2</code></p> <p>Compute a unit vector with the same direction as <code>this</code>.</p> <p>Returns</p> <p>A new unit vector with the same direction as <code>this</code>.</p>"},{"location":"api/vector2/#plus","title":"plus","text":"<p><code>vector.plus(v: Vector2): Vector2</code></p> <p>Compute the sum between <code>this</code> vector and <code>v</code>.</p> <p>Arguments</p> <ul> <li><code>v: Vector2</code>. A vector.</li> </ul> <p>Returns</p> <p>A new vector equal to the sum between <code>this</code> and <code>v</code>.</p>"},{"location":"api/vector2/#minus","title":"minus","text":"<p><code>vector.minus(v: Vector2): Vector2</code></p> <p>Compute the difference between <code>this</code> vector and <code>v</code>.</p> <p>Arguments</p> <ul> <li><code>v: Vector2</code>. A vector.</li> </ul> <p>Returns</p> <p>A new vector equal to the difference <code>this</code> - <code>v</code>.</p>"},{"location":"api/vector2/#times","title":"times","text":"<p><code>vector.times(scale: number): Vector2</code></p> <p>Compute <code>this</code> vector multiplied by a scale factor.</p> <p>Arguments</p> <ul> <li><code>scale: number</code>. A scale factor.</li> </ul> <p>Returns</p> <p>A new vector equal to the multiplication between <code>this</code> and the scale factor.</p>"},{"location":"api/vector2/#equals","title":"equals","text":"<p><code>vector.equals(v: Vector2): boolean</code></p> <p>Check if <code>this</code> and <code>v</code> have the same coordinates.</p> <p>Arguments</p> <ul> <li><code>v: Vector2</code>. A vector.</li> </ul> <p>Returns</p> <p><code>true</code> if <code>this</code> and <code>v</code> have the same coordinates.</p>"},{"location":"api/vector2/#tostring","title":"toString","text":"<p><code>vector.toString(): string</code></p> <p>Generate a string representation of the vector.</p> <p>Returns</p> <p>A string representation of the vector.</p>"},{"location":"api/vector3/","title":"Vector3","text":"<p>A vector in 3D space.</p> <p>Since: 0.4.0</p>"},{"location":"api/vector3/#instantiation","title":"Instantiation","text":""},{"location":"api/vector3/#arvector3","title":"AR.Vector3","text":"<p><code>AR.Vector3(x: number, y: number, z: number): Vector3</code></p> <p>Create a new vector with the provided coordinates.</p> <p>Arguments</p> <ul> <li><code>x: number</code>. x coordinate.</li> <li><code>y: number</code>. y coordinate.</li> <li><code>z: number</code>. z coordinate.</li> </ul> <p>Returns</p> <p>A new vector.</p> <p>Example</p> <pre><code>const zero = AR.Vector3(0, 0, 0);\n</code></pre>"},{"location":"api/vector3/#properties","title":"Properties","text":""},{"location":"api/vector3/#x","title":"x","text":"<p><code>vector.x: number, read-only</code></p> <p>The x coordinate of the vector.</p>"},{"location":"api/vector3/#y","title":"y","text":"<p><code>vector.y: number, read-only</code></p> <p>The y coordinate of the vector.</p>"},{"location":"api/vector3/#z","title":"z","text":"<p><code>vector.z: number, read-only</code></p> <p>The z coordinate of the vector.</p>"},{"location":"api/vector3/#methods","title":"Methods","text":""},{"location":"api/vector3/#length","title":"length","text":"<p><code>vector.length(): number</code></p> <p>Compute the magnitude of the vector.</p> <p>Returns</p> <p>The magnitude of the vector.</p>"},{"location":"api/vector3/#dot","title":"dot","text":"<p><code>vector.dot(v: Vector3): number</code></p> <p>Compute the dot product of <code>this</code> and <code>v</code>.</p> <p>Arguments</p> <ul> <li><code>v: Vector3</code>. A vector.</li> </ul> <p>Returns</p> <p>The dot product of the vectors.</p>"},{"location":"api/vector3/#distanceto","title":"distanceTo","text":"<p><code>vector.distanceTo(v: Vector3): number</code></p> <p>Compute the distance between points <code>this</code> and <code>v</code>.</p> <p>Arguments</p> <ul> <li><code>v: Vector3</code>. A vector / point.</li> </ul> <p>Returns</p> <p>The distance between the points.</p>"},{"location":"api/vector3/#directionto","title":"directionTo","text":"<p><code>vector.directionTo(v: Vector3): Vector3</code></p> <p>Compute a unit vector pointing to <code>v</code> from <code>this</code>.</p> <p>Arguments</p> <ul> <li><code>v: Vector3</code>. A vector.</li> </ul> <p>Returns</p> <p>A new unit vector pointing to <code>v</code> from <code>this</code>.</p>"},{"location":"api/vector3/#cross","title":"cross","text":"<p><code>vector.cross(v: Vector3): Vector3</code></p> <p>Compute the cross product of <code>this</code> and <code>v</code>.</p> <p>Arguments</p> <ul> <li><code>v: Vector3</code>. A vector.</li> </ul> <p>Returns</p> <p>The cross product <code>this</code> x <code>v</code>.</p>"},{"location":"api/vector3/#normalized","title":"normalized","text":"<p><code>vector.normalized(): Vector3</code></p> <p>Compute a unit vector with the same direction as <code>this</code>.</p> <p>Returns</p> <p>A new unit vector with the same direction as <code>this</code>.</p>"},{"location":"api/vector3/#plus","title":"plus","text":"<p><code>vector.plus(v: Vector3): Vector3</code></p> <p>Compute the sum between <code>this</code> vector and <code>v</code>.</p> <p>Arguments</p> <ul> <li><code>v: Vector3</code>. A vector.</li> </ul> <p>Returns</p> <p>A new vector equal to the sum between <code>this</code> and <code>v</code>.</p>"},{"location":"api/vector3/#minus","title":"minus","text":"<p><code>vector.minus(v: Vector3): Vector3</code></p> <p>Compute the difference between <code>this</code> vector and <code>v</code>.</p> <p>Arguments</p> <ul> <li><code>v: Vector3</code>. A vector.</li> </ul> <p>Returns</p> <p>A new vector equal to the difference <code>this</code> - <code>v</code>.</p>"},{"location":"api/vector3/#times","title":"times","text":"<p><code>vector.times(scale: number): Vector3</code></p> <p>Compute <code>this</code> vector multiplied by a scale factor.</p> <p>Arguments</p> <ul> <li><code>scale: number</code>. A scale factor.</li> </ul> <p>Returns</p> <p>A new vector equal to the multiplication between <code>this</code> and the scale factor.</p>"},{"location":"api/vector3/#equals","title":"equals","text":"<p><code>vector.equals(v: Vector3): boolean</code></p> <p>Check if <code>this</code> and <code>v</code> have the same coordinates.</p> <p>Arguments</p> <ul> <li><code>v: Vector3</code>. A vector.</li> </ul> <p>Returns</p> <p><code>true</code> if <code>this</code> and <code>v</code> have the same coordinates.</p>"},{"location":"api/vector3/#tostring","title":"toString","text":"<p><code>vector.toString(): string</code></p> <p>Generate a string representation of the vector.</p> <p>Returns</p> <p>A string representation of the vector.</p>"},{"location":"api/video-source/","title":"VideoSource","text":"<p>A source of data linked to a <code>&lt;video&gt;</code> element.</p>"},{"location":"api/video-source/#instantiation","title":"Instantiation","text":""},{"location":"api/video-source/#arsourcevideo","title":"AR.Source.Video","text":"<p><code>AR.Source.Video(video: HTMLVideoElement): VideoSource</code></p> <p>Create a new source of data linked to the provided <code>video</code>.</p> <p>Arguments</p> <ul> <li><code>video: HTMLVideoElement</code>. A <code>&lt;video&gt;</code> element.</li> </ul> <p>Returns</p> <p>A new source of data.</p>"},{"location":"api/video-source/#properties","title":"Properties","text":""},{"location":"api/video-source/#video","title":"video","text":"<p><code>source.video: HTMLVideoElement, read-only</code></p> <p>The underlying <code>&lt;video&gt;</code> element.</p> <p>Since: 0.4.1</p>"},{"location":"api/view/","title":"View","text":"<p>An interface that represents a view of the 3D world at a moment in time. A PerspectiveView is an implementation of a View.</p>"},{"location":"api/view/#properties","title":"Properties","text":""},{"location":"api/view/#projectionmatrix","title":"projectionMatrix","text":"<p><code>view.projectionMatrix: SpeedyMatrix, read-only</code></p> <p>A 4x4 matrix that projects viewer space onto clip space.</p>"},{"location":"api/viewer-pose/","title":"ViewerPose","text":"<p>The pose of a Viewer.</p>"},{"location":"api/viewer-pose/#properties","title":"Properties","text":""},{"location":"api/viewer-pose/#viewmatrix","title":"viewMatrix","text":"<p><code>pose.viewMatrix: SpeedyMatrix, read-only</code></p> <p>A 4x4 matrix that converts points from world space to viewer space.</p>"},{"location":"api/viewer/","title":"Viewer","text":"<p>A virtual camera in 3D world space.</p>"},{"location":"api/viewer/#properties","title":"Properties","text":""},{"location":"api/viewer/#pose","title":"pose","text":"<p><code>viewer.pose: ViewerPose, read-only</code></p> <p>The pose of the viewer.</p>"},{"location":"api/viewer/#view","title":"view","text":"<p><code>viewer.view: View, read-only</code></p> <p>A view of the viewer (monoscopic rendering).</p>"},{"location":"api/viewer/#methods","title":"Methods","text":""},{"location":"api/viewer/#converttoviewerspace","title":"convertToViewerSpace","text":"<p><code>viewer.convertToViewerSpace(pose: Pose): Pose</code></p> <p>Convert a <code>pose</code> from world space to viewer space.</p> <p>Arguments</p> <ul> <li><code>pose: Pose</code>. A pose in world space.</li> </ul> <p>Returns</p> <p>The input <code>pose</code> converted to viewer space.</p> <p>Example</p> <pre><code>const modelViewMatrix = viewer.convertToViewerSpace(pose).transform.matrix;\n</code></pre>"},{"location":"api/viewer/#raycast","title":"raycast","text":"<p><code>viewer.raycast(position: Vector2): Ray</code></p> <p>Cast a ray from a point in the image space associated with this viewer.</p> <p>Since: 0.4.0</p> <p>Arguments</p> <ul> <li><code>position: Vector2</code>. A point in image space, given in normalized units.</li> </ul> <p>Returns</p> <p>A ray in world space that corresponds to the given point.</p>"},{"location":"api/viewer/#forwardray","title":"forwardRay","text":"<p><code>viewer.forwardRay(): Ray</code></p> <p>Compute a ray in the forward direction from the viewer.</p> <p>Since: 0.4.0</p> <p>Returns</p> <p>A new ray in world space.</p>"},{"location":"api/viewport/","title":"Viewport","text":"<p>The viewport is the area of the web page in which the augmented scene is displayed.</p>"},{"location":"api/viewport/#instantiation","title":"Instantiation","text":""},{"location":"api/viewport/#arviewport","title":"AR.Viewport","text":"<p><code>AR.Viewport(settings: object): Viewport</code></p> <p>Create a new viewport with the specified <code>settings</code>.</p> <p>Arguments</p> <ul> <li><code>settings: object</code>. An object with the following keys:<ul> <li><code>container: HTMLDivElement</code>. A <code>&lt;div&gt;</code> that will contain the augmented scene.</li> <li><code>hudContainer: HTMLDivElement, optional</code>. An overlay that will be displayed in front of the augmented scene. It must be a direct child of <code>container</code> in the DOM tree.</li> <li><code>resolution: Resolution, optional</code>. The resolution of the virtual scene.</li> <li><code>canvas: HTMLCanvasElement, optional</code>. A canvas on which the virtual scene will be drawn. If unspecified, the engine will automatically creates a canvas for you.</li> <li><code>style: string, optional</code>. The viewport style. Since: 0.3.0</li> <li><code>fullscreenUI: boolean, optional</code>. Whether or not to include, as a convenience, the built-in fullscreen button on platforms in which the fullscreen mode is available. Defaults to <code>true</code>. Since: 0.3.0</li> </ul> </li> </ul> <p>Returns</p> <p>A new viewport.</p> <p>Example</p> <pre><code>const viewport = AR.Viewport({\n    container: document.getElementById('ar-viewport'),\n    resolution: 'lg'\n});\n</code></pre>"},{"location":"api/viewport/#properties","title":"Properties","text":""},{"location":"api/viewport/#container","title":"container","text":"<p><code>viewport.container: HTMLDivElement, read-only</code></p> <p>The container of the viewport.</p>"},{"location":"api/viewport/#hud","title":"hud","text":"<p><code>viewport.hud: HUD, read-only</code></p> <p>The HUD.</p>"},{"location":"api/viewport/#resolution","title":"resolution","text":"<p><code>viewport.resolution: Resolution, read-only</code></p> <p>The resolution of the virtual scene. You may set it when instantiating the viewport.</p>"},{"location":"api/viewport/#aspectratio","title":"aspectRatio","text":"<p><code>viewport.aspectRatio: number, read-only</code></p> <p>The aspect ratio of the viewport.</p> <p>Since: 0.4.0</p>"},{"location":"api/viewport/#virtualsize","title":"virtualSize","text":"<p><code>viewport.virtualSize: SpeedySize, read-only</code></p> <p>The size in pixels that matches the resolution of the virtual scene.</p>"},{"location":"api/viewport/#canvas","title":"canvas","text":"<p><code>viewport.canvas: HTMLCanvasElement, read-only</code></p> <p>The <code>&lt;canvas&gt;</code> on which the virtual scene is drawn.</p>"},{"location":"api/viewport/#style","title":"style","text":"<p><code>viewport.style: string, read-only</code></p> <p>The style determines the way the viewport appears on the screen. Different styles are applicable to different session modes. The following are valid styles:</p> <ul> <li><code>\"best-fit\"</code>: an immersive viewport that is scaled in a way that covers the page while preserving the aspect ratio of the augmented scene. This is known as letterboxing or pillarboxing.</li> <li><code>\"stretch\"</code>: an immersive viewport that is scaled in a way that fills the entire page, stretching the augmented scene if necessary.</li> <li><code>\"crop\"</code>: an immersive viewport that is scaled in a way that fills the entire page, cropping the augmented scene if necessary to maintain its aspect ratio. Since: 0.4.4</li> <li><code>\"inline\"</code>: an inline viewport that follows the typical flow of a web page.</li> </ul> <p>The default style is <code>\"best-fit\"</code> in immersive mode, or <code>\"inline\"</code> in inline mode.</p> <p>Since: 0.3.0</p>"},{"location":"api/viewport/#fullscreen","title":"fullscreen","text":"<p><code>viewport.fullscreen: boolean, read-only</code></p> <p>Whether or not the viewport container is being displayed in fullscreen mode. See also: requestFullscreen.</p> <p>Since: 0.3.0</p>"},{"location":"api/viewport/#fullscreenavailable","title":"fullscreenAvailable","text":"<p><code>viewport.fullscreenAvailable: boolean, read-only</code></p> <p>Used to check the availability of the fullscreen mode on the current platform and page.</p> <p>Since: 0.3.0</p>"},{"location":"api/viewport/#methods","title":"Methods","text":""},{"location":"api/viewport/#requestfullscreen","title":"requestFullscreen","text":"<p><code>viewport.requestFullscreen(): SpeedyPromise&lt;void&gt;</code></p> <p>Make a request to the user agent so that the viewport container is displayed in fullscreen mode. The user must interact with the page (e.g., tap on a button) in order to comply with browser policies, otherwise the request will not succeed.</p> <p>iPhone support</p> <p>At the time of this writing, the fullscreen mode is not supported on iPhone. An alternative way to create a fullscreen experience is to set the viewport style to <code>\"stretch\"</code> in a web app.</p> <p>Since: 0.3.0</p> <p>Returns</p> <p>A promise that is resolved when the fullscreen mode is activated, or rejected on error.</p> <p>Example</p> <pre><code>function toggleFullscreen()\n{\n    if(!viewport.fullscreen) {\n        viewport.requestFullscreen().catch(err =&gt; {\n            alert(`Can't enable fullscreen mode. ` + err.toString());\n        });\n    }\n    else {\n        viewport.exitFullscreen();\n    }\n}\n\n// require user interaction\nbutton.addEventListener('click', toggleFullscreen);\n</code></pre>"},{"location":"api/viewport/#exitfullscreen","title":"exitFullscreen","text":"<p><code>viewport.exitFullscreen(): SpeedyPromise&lt;void&gt;</code></p> <p>Exit fullscreen mode.</p> <p>Since: 0.3.0</p> <p>Returns</p> <p>A promise that is resolved once the fullscreen mode is no longer active, or rejected on error. The promise will be rejected if the method is called when not in fullscreen mode.</p>"},{"location":"api/viewport/#converttopixels","title":"convertToPixels","text":"<p><code>viewport.convertToPixels(position: Vector2, space: string): Vector2</code></p> <p>Convert a <code>position</code> given in space units to a corresponding pixel position in canvas space. See also: convertFromPixels().</p> <p>Since: 0.4.0</p> <p>Arguments</p> <ul> <li><code>position: Vector2</code>. A position in space units.</li> <li><code>space: string, optional</code>. The space to convert from. Possible values: <code>\"normalized\"</code> (default) or <code>\"adjusted\"</code>. See also: PointerTracker.space.</li> </ul> <p>Returns</p> <p>An equivalent pixel position in canvas space.</p>"},{"location":"api/viewport/#convertfrompixels","title":"convertFromPixels","text":"<p><code>viewport.convertFromPixels(position: Vector2, space: string): Vector2</code></p> <p>Convert a pixel <code>position</code> given in canvas space to a corresponding position in space units. See also: convertToPixels().</p> <p>Since: 0.4.0</p> <p>Arguments</p> <ul> <li><code>position: Vector2</code>. A pixel position in canvas space.</li> <li><code>space: string, optional</code>. The space to convert to. Possible values: <code>\"normalized\"</code> (default) or <code>\"adjusted\"</code>. See also: PointerTracker.space.</li> </ul> <p>Returns</p> <p>An equivalent position in space units.</p>"},{"location":"api/viewport/#takesnapshot","title":"takeSnapshot","text":"<p><code>viewport.takeSnapshot(resolution: Resolution): SpeedyPromise&lt;ImageBitmap&gt;</code></p> <p>Take a snapshot of the AR scene.</p> <p>Since: 0.4.5</p> <p>Tip</p> <p>If your virtual objects do not show up in the snapshot, redraw your scene just before calling this method (either inside or outside your render loop).</p> <p>Arguments</p> <ul> <li><code>resolution: Resolution, optional</code>. The resolution of the snapshot. If unspecified, the resolution of the viewport will be used.</li> </ul> <p>Returns</p> <p>A promise that resolves to an <code>ImageBitmap</code> featuring the snapshot.</p> <p>Warning</p> <p>The returned promise will be rejected if a canvas is tainted due to cross-origin issues.</p>"},{"location":"api/viewport/#events","title":"Events","text":"<p>A viewport is an AREventTarget. You can listen to the following events:</p>"},{"location":"api/viewport/#resize","title":"resize","text":"<p>The viewport has been resized. This will happen when the user resizes the window of the web browser or when the mobile device is flipped.</p> <p>Example</p> <pre><code>viewport.addEventListener('resize', () =&gt; {\n    console.log('The viewport has been resized.');\n});\n</code></pre>"},{"location":"api/viewport/#fullscreenchange","title":"fullscreenchange","text":"<p>The viewport has been switched to or out of fullscreen mode.</p> <p>Since: 0.3.0</p> <p>Example</p> <pre><code>viewport.addEventListener('fullscreenchange', () =&gt; {\n    if(viewport.fullscreen)\n        console.log('Switched to fullscreen mode');\n    else\n        console.log('Switched out of fullscreen mode');\n});\n</code></pre>"},{"location":"tutorial/","title":"Introduction","text":"<p>Augmented Reality (AR) has applications in many fields, including: games, marketing, commerce, education, arts, tourism, sports, healthcare, and so on. AR brings many exciting possibilities for creative projects - and you too can get into it!</p> <p>Traditionally, users were required to download (sometimes large) apps to experience AR. That was an obstacle for adoption. What if we dropped the need for apps and just required a web browser instead? Users already have web browsers! That's where WebAR comes in.</p>"},{"location":"tutorial/#what-to-expect-from-this-guide","title":"What to expect from this guide","text":"<p>We will create together an Augmented Reality experience that runs in web browsers. You will learn how to track an image in real-time. This is a common use case of Augmented Reality technology.</p> <p>No matter if you are a beginner, an expert, or somewhere in-between, set yourself at ease: this step-by-step guide can be followed by you.</p> <p>Get started</p> <p>In a hurry?</p> <p>This guide is an in-depth introduction to web-based Augmented Reality with encantar.js. If you're in a hurry, skip straight to the Demos section.</p>"},{"location":"tutorial/activate-your-webcam/","title":"Activate your webcam","text":"<p>In this section we're going to learn how to use your webcam to capture the video. We're also going to polish our work and make it presentable to users.</p>"},{"location":"tutorial/activate-your-webcam/#change-the-source-of-data","title":"Change the source of data","text":"<p>Instead of using a video file, we're going to use your webcam. We simply need to change the source of data and instruct encantar.js to use your webcam. We'll do it with one new line of code!</p> ar-demo.js<pre><code>async function startARSession()\n{\n    if(!AR.isSupported()) {\n        throw new Error(\n            'This device is not compatible with this AR experience.\\n\\n' +\n            'User agent: ' + navigator.userAgent\n        );\n    }\n\n    const tracker = AR.Tracker.Image();\n    await tracker.database.add([{\n        name: 'my-reference-image',\n        image: document.getElementById('my-reference-image')\n    }]);\n\n    const viewport = AR.Viewport({\n        container: document.getElementById('ar-viewport')\n    });\n\n    //const video = document.getElementById('my-video'); // comment this line\n    //const source = AR.Source.Video(video); // comment this line\n    const source = AR.Source.Camera();\n\n    const session = await AR.startSession({\n        mode: 'immersive',\n        viewport: viewport,\n        trackers: [ tracker ],\n        sources: [ source ],\n        stats: true,\n        gizmos: true,\n    });\n\n    return session;\n}\n</code></pre> <p>Let's also comment (or remove) the <code>&lt;video&gt;</code> tag from the HTML file - we no longer need it:</p> index.html<pre><code>&lt;!doctype html&gt;\n&lt;html&gt;\n    &lt;head&gt;\n        &lt;meta charset=\"utf-8\"&gt;\n        &lt;meta name=\"viewport\" content=\"width=device-width, user-scalable=no, minimum-scale=1, maximum-scale=1\"&gt;\n        &lt;title&gt;encantar.js WebAR demo&lt;/title&gt;\n        &lt;script src=\"encantar.js\"&gt;&lt;/script&gt;\n        &lt;script src=\"ar-demo.js\"&gt;&lt;/script&gt;\n        &lt;style&gt;body { background-color: #3d5afe; }&lt;/style&gt;\n    &lt;/head&gt;\n    &lt;body&gt;\n        &lt;div id=\"ar-viewport\"&gt;&lt;/div&gt;\n        &lt;img id=\"my-reference-image\" src=\"my-reference-image.webp\" hidden&gt;\n        &lt;!--\n        &lt;video id=\"my-video\" hidden muted loop playsinline autoplay&gt;\n            &lt;source src=\"my-video.webm\" type=\"video/webm\" /&gt;\n            &lt;source src=\"my-video.mp4\" type=\"video/mp4\" /&gt;\n        &lt;/video&gt;\n        --&gt;\n    &lt;/body&gt;\n&lt;/html&gt;\n</code></pre> <p>Open http://localhost:8000 and... ta-da! The web browser will ask for your permission to access the camera. Have fun. </p> <p>Before using a webcam</p> <p>Pay attention to the following:</p> <ol> <li>Low-quality cameras should be avoided. A camera of a typical smartphone is probably good enough.</li> <li>Don't move the camera / the target image too quickly, as quick movements produce motion blur.</li> <li>Ensure good lighting conditions (see below).</li> </ol> <p>Check your physical scene</p> <p>Good lighting conditions are important for a good user experience. Even though the encantar.js can handle various lighting conditions, you should get your physical scene appropriately illuminated.</p> <p>When developing your own WebAR experiences, ask yourself:</p> <ul> <li>Will my users experience AR indoors? If so, make sure that the room is sufficiently illuminated.</li> <li>Will my users experience AR outdoors? In this case, make sure that users interact with your AR experience during the day, or have that interaction happen in a place with sufficient artificial lighting.</li> </ul> <p>When printing your reference images, avoid shiny materials (e.g., glossy paper). They may generate artifacts in the image and interfere with the tracking. Prefer non-reflective materials.</p> <p>If you're using a screen to display the reference image, make sure to adjust the brightness. Too much brightness causes overexposure and loss of detail, leading to tracking difficulties. Not enough brightness is also undesirable, because it makes the reference image look too dark in the video. Screen reflections are also undesirable.</p> <p>Use HTTPS</p> <p>When distributing your WebAR experiences over the internet, make sure to use HTTPS. Web browsers will only allow access to the webcam in secure contexts.</p> <p>Here is the reference image in case you need it again:</p> <p></p> Reference Image"},{"location":"tutorial/activate-your-webcam/#create-a-scan-gimmick","title":"Create a scan gimmick","text":"<p>Let's polish our work. When the tracker is scanning the physical scene, we'll display a visual cue suggesting the user to frame the target image. I'll call that a scan gimmick.</p> <p>Save the image below as scan.png:</p> <p> </p> Scan gimmick <p>In order to display that scan gimmick, we need to create a HUD (Heads-Up Display). A HUD is an overlay used to display 2D content in front of the augmented scene. It's part of the viewport. Modify <code>index.html</code> and <code>ar-demo.js</code> as follows:</p> index.html<pre><code>&lt;!doctype html&gt;\n&lt;html&gt;\n    &lt;head&gt;\n        &lt;meta charset=\"utf-8\"&gt;\n        &lt;meta name=\"viewport\" content=\"width=device-width, user-scalable=no, minimum-scale=1, maximum-scale=1\"&gt;\n        &lt;title&gt;encantar.js WebAR demo&lt;/title&gt;\n        &lt;script src=\"encantar.js\"&gt;&lt;/script&gt;\n        &lt;script src=\"ar-demo.js\"&gt;&lt;/script&gt;\n        &lt;style&gt;\n        body { background-color: #3d5afe; }\n        #scan { width: 100%; height: 100%; object-fit: contain; opacity: 0.75; }\n        &lt;/style&gt;\n    &lt;/head&gt;\n    &lt;body&gt;\n        &lt;div id=\"ar-viewport\"&gt;\n            &lt;div id=\"ar-hud\" hidden&gt;\n                &lt;img id=\"scan\" src=\"scan.png\" draggable=\"false\"&gt;\n            &lt;/div&gt;\n        &lt;/div&gt;\n        &lt;img id=\"my-reference-image\" src=\"my-reference-image.webp\" hidden&gt;\n        &lt;!--\n        &lt;video id=\"my-video\" hidden muted loop playsinline autoplay&gt;\n            &lt;source src=\"my-video.webm\" type=\"video/webm\" /&gt;\n            &lt;source src=\"my-video.mp4\" type=\"video/mp4\" /&gt;\n        &lt;/video&gt;\n        --&gt;\n    &lt;/body&gt;\n&lt;/html&gt;\n</code></pre> ar-demo.js<pre><code>async function startARSession()\n{\n    if(!AR.isSupported()) {\n        throw new Error(\n            'This device is not compatible with this AR experience.\\n\\n' +\n            'User agent: ' + navigator.userAgent\n        );\n    }\n\n    const tracker = AR.Tracker.Image();\n    await tracker.database.add([{\n        name: 'my-reference-image',\n        image: document.getElementById('my-reference-image')\n    }]);\n\n    const viewport = AR.Viewport({\n        container: document.getElementById('ar-viewport'),\n        hudContainer: document.getElementById('ar-hud')\n    });\n\n    //const video = document.getElementById('my-video');\n    //const source = AR.Source.Video(video);\n    const source = AR.Source.Camera();\n\n    const session = await AR.startSession({\n        mode: 'immersive',\n        viewport: viewport,\n        trackers: [ tracker ],\n        sources: [ source ],\n        stats: true,\n        gizmos: true,\n    });\n\n    return session;\n}\n</code></pre> <p>Open http://localhost:8000. Now you can see the scan gimmick being displayed... all the time?!</p>"},{"location":"tutorial/activate-your-webcam/#configure-the-scan-gimmick","title":"Configure the scan gimmick","text":"<p>The scan gimmick should only be displayed when the tracker is scanning the physical scene. We should hide it as soon as a target image is recognized. If the tracking is lost, then we need to display it again because we're back in scanning mode.</p> <p>A simple way to know whether or not we're tracking a target image is to use events. We're going to add two event listeners to our tracker. If a  <code>targetfound</code> event happens, we hide the scan gimmick. If a <code>targetlost</code> event happens, we show the scan gimmick again.</p> ar-demo.js<pre><code>async function startARSession()\n{\n    if(!AR.isSupported()) {\n        throw new Error(\n            'This device is not compatible with this AR experience.\\n\\n' +\n            'User agent: ' + navigator.userAgent\n        );\n    }\n\n    const tracker = AR.Tracker.Image();\n    await tracker.database.add([{\n        name: 'my-reference-image',\n        image: document.getElementById('my-reference-image')\n    }]);\n\n    const viewport = AR.Viewport({\n        container: document.getElementById('ar-viewport'),\n        hudContainer: document.getElementById('ar-hud')\n    });\n\n    //const video = document.getElementById('my-video');\n    //const source = AR.Source.Video(video);\n    const source = AR.Source.Camera();\n\n    const session = await AR.startSession({\n        mode: 'immersive',\n        viewport: viewport,\n        trackers: [ tracker ],\n        sources: [ source ],\n        stats: true,\n        gizmos: true,\n    });\n\n    const scan = document.getElementById('scan');\n\n    tracker.addEventListener('targetfound', event =&gt; {\n        scan.hidden = true;\n    });\n\n    tracker.addEventListener('targetlost', event =&gt; {\n        scan.hidden = false;\n    });\n\n    return session;\n}\n</code></pre>"},{"location":"tutorial/activate-your-webcam/#hide-the-gizmos","title":"Hide the gizmos","text":"<p>Let's polish our work even more by hiding the gizmos. You may just set <code>gizmos</code> to <code>false</code> in <code>AR.startSession()</code> and there will be no more gizmos. Do the same to hide the stats panel.</p> <p>Let me show you a different approach. Instead of getting rid of the gizmos completely, we're going to hide them partially. They will be displayed when the tracker is scanning the physical scene, but not when the physical scene is being augmented. That's easy to do with the event listeners we have just set up:</p> ar-demo.js<pre><code>async function startARSession()\n{\n    if(!AR.isSupported()) {\n        throw new Error(\n            'This device is not compatible with this AR experience.\\n\\n' +\n            'User agent: ' + navigator.userAgent\n        );\n    }\n\n    const tracker = AR.Tracker.Image();\n    await tracker.database.add([{\n        name: 'my-reference-image',\n        image: document.getElementById('my-reference-image')\n    }]);\n\n    const viewport = AR.Viewport({\n        container: document.getElementById('ar-viewport'),\n        hudContainer: document.getElementById('ar-hud')\n    });\n\n    //const video = document.getElementById('my-video');\n    //const source = AR.Source.Video(video);\n    const source = AR.Source.Camera();\n\n    const session = await AR.startSession({\n        mode: 'immersive',\n        viewport: viewport,\n        trackers: [ tracker ],\n        sources: [ source ],\n        stats: true,\n        gizmos: true,\n    });\n\n    const scan = document.getElementById('scan');\n\n    tracker.addEventListener('targetfound', event =&gt; {\n        scan.hidden = true;\n        session.gizmos.visible = false;\n    });\n\n    tracker.addEventListener('targetlost', event =&gt; {\n        scan.hidden = false;\n        session.gizmos.visible = true;\n    });\n\n    return session;\n}\n</code></pre> <p>Open http://localhost:8000 again. Now we're ready to create the augmented scene! </p>"},{"location":"tutorial/augment-the-scene/","title":"Augment the scene","text":"<p>We're already tracking an image of the physical world. The next step is to augment it with computer graphics. You'll use a different technology to render the graphics.</p>"},{"location":"tutorial/augment-the-scene/#pick-a-3d-rendering-technology","title":"Pick a 3D rendering technology","text":"<p>encantar.js is not a 3D rendering technology. It is an Augmented Reality technology that provides the data you need in order to augment your physical scenes. There are free and open-source 3D rendering technologies that you can use with encantar.js. Popular solutions include: A-Frame, Babylon.js and Three.js. You can also use other solutions. encantar.js lets you pick any web-based 3D rendering technology.</p> <p>Once you pick a 3D rendering technology, you need to integrate it with encantar.js. There is a code that is responsible for that integration. I call it a plugin. Among other things, a plugin transports the tracking results from encantar.js to the 3D rendering technology of your choice.</p>"},{"location":"tutorial/augment-the-scene/#use-a-plugin","title":"Use a plugin","text":"<p>Writing a plugin is a task of moderate complexity. It requires dealing with maths and with some idiosyncrasies of the 3D rendering technologies in order to make sure that it all works as intended. I provide easy-to-use plugins that work with different 3D rendering technologies, so that you don't need to deal with that complexity yourself. Plugins are shipped as JavaScript (.js) files. You just need to add a plugin to your web page, and then the integration will be done for you!</p> <p>Get the plugins in the demos</p>"},{"location":"tutorial/augment-the-scene/#create-the-virtual-scene","title":"Create the virtual scene","text":"<p>You will create the virtual scene using the 3D rendering technology of your choice. As soon as you combine it with an appropriate plugin, the physical scene will be automagically augmented with the virtual scene, thus creating the augmented scene.</p> <p>Let me tell you more about the 3D rendering technologies I just mentioned.</p>"},{"location":"tutorial/augment-the-scene/#a-frame","title":"A-Frame","text":"<p>A-Frame is an open-source framework used to build virtual reality (VR) experiences for the web. When you combine it with encantar.js, you become able to use it to create AR experiences too - without the need of special hardware or software.</p> <p>A-Frame is built on top of Three.js and extends it in powerful ways. It introduces a HTML-based declarative approach for scene graphs, empowering them with the Entity-Component-System, a software pattern commonly used in game development. A-Frame is easy for beginners and pleasing for experts. In many cases, writing JavaScript code is not needed.</p> <p>See how easy it is to construct a basic augmented scene:</p> <pre><code>&lt;a-scene encantar=\"stats: true; gizmos: true\"&gt;\n\n    &lt;!-- Sources of data --&gt;\n    &lt;ar-sources&gt;\n        &lt;ar-camera-source&gt;&lt;/ar-camera-source&gt; &lt;!-- webcam --&gt;\n    &lt;/ar-sources&gt;\n\n    &lt;!-- Trackers --&gt;\n    &lt;ar-trackers&gt;\n        &lt;ar-image-tracker&gt;\n            &lt;ar-reference-image name=\"mage\" src=\"mage.png\"&gt;&lt;/ar-reference-image&gt;\n        &lt;/ar-image-tracker&gt;\n    &lt;/ar-trackers&gt;\n\n    &lt;!-- AR Viewport --&gt;\n    &lt;ar-viewport&gt;&lt;/ar-viewport&gt;\n\n    &lt;!-- Virtual camera for AR --&gt;\n    &lt;ar-camera&gt;&lt;/ar-camera&gt;\n\n    &lt;!-- Root node: this will be displayed in AR --&gt;\n    &lt;ar-root reference-image=\"mage\"&gt;\n        &lt;a-box color=\"yellow\" position=\"0 0 0.5\"&gt;&lt;/a-box&gt;\n    &lt;/ar-root&gt;\n\n&lt;/a-scene&gt;\n</code></pre> <p></p> <p>Tell me more!</p>"},{"location":"tutorial/augment-the-scene/#babylonjs","title":"Babylon.js","text":"<p>Babylon.js is a powerful open-source game and 3D rendering engine for the web. It includes pretty much all features you commonly find in 3D rendering engines (scene graphs, lights, materials, meshes, animations, etc.), plus systems that are specific to game engines (audio engine, collision system, physics system, support for sprites, etc.), plus all kinds of sophisticated features for various applications.</p> <p>Babylon.js has an amazing documentation with plenty of learning resources, as well as a helpful and friendly community! Even though it can be used by beginners, it's recommended to have experience with JavaScript before creating projects with it.</p> <p>Tell me more!</p>"},{"location":"tutorial/augment-the-scene/#threejs","title":"Three.js","text":"<p>Three.js is a popular open-source JavaScript library used to render 3D graphics in web browsers. It has many features, including: scene graphs, cameras, animations, lights, materials, loading of 3D models, mathematical utilities, special effects, and more. It has an active and vibrant community. Many community-made extensions are available.</p> <p>Using Three.js requires more JavaScript experience than using A-Frame in most cases, but it's also a great choice if you're comfortable with coding. Compared to A-Frame, Three.js offers you additional freedom on how you can organize your code, because it's a library, not a framework.</p> <p>Tell me more!</p>"},{"location":"tutorial/concepts/","title":"Concepts","text":"<p>Before diving into AR with you, I need to introduce a few concepts. Please take the time to read them all. Feel free to come back to this page at any time.</p>"},{"location":"tutorial/concepts/#what-is-augmented-reality","title":"What is Augmented Reality?","text":"<p>Let me clarify what I mean by terms such as Augmented Reality and WebAR:</p> <ol> <li> <p>Augmented Reality is the augmentation of physical reality with virtual elements. We typically augment physical reality with imagery generated by computer graphics. In this context, the word augment means: to blend the physical and the virtual imagery in a visually correlated manner.</p> <p>1.1. AR is an abbreviation of Augmented Reality.</p> </li> <li> <p>An Augmented Reality experience, or Augmented Reality program, is a computer program designed to let users experience Augmented Reality<sup>1</sup>. Augmented Reality experiences come in different shapes. Some are designed for smartphones and tablets, others for special headsets, and so on.</p> </li> <li> <p>WebAR is a set of technologies used to create Augmented Reality experiences that run in web browsers. WebAR makes it easy for users to experience AR, because they can have immediate access to the AR experiences. All they have to do is open a web page. They are not tied to specific platforms and they also don't need to download apps.</p> </li> <li> <p>A WebAR experience is an Augmented Reality experience developed using WebAR technology.</p> </li> <li> <p>encantar.js is a WebAR technology. I also call it a WebAR engine. Lots of computations have to be performed behind the scenes in order to make an Augmented Reality experience possible. encantar.js uses the GPU<sup>2</sup> to accelerate many of those computations. In fact, the GPU and the CPU<sup>3</sup> are used together. This approach improves the performance of the WebAR experience and ultimately leads to a better user experience.</p> </li> </ol> <p>You can use encantar.js to create amazing WebAR experiences! </p>"},{"location":"tutorial/concepts/#basic-concepts","title":"Basic concepts","text":"<p>Let me explain some concepts that you'll see over and over again when developing WebAR experiences with encantar.js:</p> <ol> <li> <p>An Augmented Reality experience augments a physical scene with a virtual scene.</p> <p>1.1. The physical scene is a scene of the physical world.</p> <p>1.2. The virtual scene is a scene generated by computer graphics.</p> <p>1.3. The augmented scene is the physical scene augmented with the virtual scene.</p> </li> <li> <p>A session is a central component of a WebAR experience. It handles the main loop. The main loop performs two central tasks: it analyzes the input data and then passes the result of that analysis to the user callback.</p> <p>2.1. The user callback is a function that updates and renders the virtual scene. It is repeated in an animation loop, which is part of the main loop.</p> <p>2.2. The main loop is repeated until the session ends. The session ends when the user closes the web page, or by deliberate command.</p> </li> <li> <p>A session has one or more sources of data linked to it. A typical source of data is a video stream. Such a stream usually comes from a webcam or from a video file.</p> <p>3.1. A source of data produces input data.</p> </li> <li> <p>A tracker is a subsystem of the WebAR engine that analyzes input data in some way. Trackers are meant to be attached to a session. Example: an image tracker is a type of tracker. If we attach an image tracker to a session, then we will be able to track images in that session.</p> </li> <li> <p>The user callback receives a frame. A frame is an object that holds data for rendering the virtual scene in a way that is consistent with the input data at a particular moment in time. Simply put, frames help us augment the physical scene with the virtual scene.</p> <p>5.1. The data held by a frame is computed by the trackers that are attached to the session.</p> </li> <li> <p>A session is linked to a viewport. The viewport is the area in which we'll display the augmented scene. It's represented by a container defined by a suitable HTML element, typically a <code>&lt;div&gt;</code>.</p> </li> <li> <p>A session has a mode. The mode can be either immersive or inline.</p> <p>7.1. In immersive mode, the augmented scene is displayed in such a way that it occupies the entire area of the screen in which the web page is shown. Think of it as a kind of fullscreen. The immersive mode is what is typically wanted.</p> <p>7.2. In inline mode, the augmented scene is displayed in a way that is consistent with the typical flow of a web page. We can display the augmented scene in a web page such as this one - in the middle of text, links and other elements.</p> </li> </ol> <p>Now let's create our first WebAR experience! It gets to be fun, I promise! </p> <ol> <li> <p>An experience of AR is an event in consciousness in which AR is experienced. I sometimes use the latter definition.\u00a0\u21a9</p> </li> <li> <p>Graphics Processing Unit\u00a0\u21a9</p> </li> <li> <p>Central Processing Unit\u00a0\u21a9</p> </li> </ol>"},{"location":"tutorial/next-steps/","title":"Next steps","text":"<p>Congratulations! You have created your first WebAR experience with encantar.js! </p> <p>Let me tell you some of the steps you can take from now on.</p>"},{"location":"tutorial/next-steps/#change-the-power-preference","title":"Change the power preference","text":"<p>Image tracking is no trivial task: lots of computations are being performed behind the scenes. The WebAR engine prioritizes processing performance over power consumption by default. You may reduce power consumption by reducing processing performance. This is simple to do: just set <code>AR.Settings.powerPreference</code> to <code>\"low-power\"</code>.</p> ar-demo.js<pre><code>async function startARSession()\n{\n    if(!AR.isSupported()) {\n        throw new Error(\n            'This device is not compatible with this AR experience.\\n\\n' +\n            'User agent: ' + navigator.userAgent\n        );\n    }\n\n    AR.Settings.powerPreference = 'low-power'; // optional\n\n    const tracker = AR.Tracker.Image();\n    await tracker.database.add([{\n        name: 'my-reference-image',\n        image: document.getElementById('my-reference-image')\n    }]);\n\n    // ...\n}\n</code></pre> <p>When you enable low-power mode, the WebAR engine will target a framerate of 30. In many cases, this is still acceptable for a good user experience. I suggest you test both ways!</p> <p>I emphasize that you are not required to enable low-power mode. Enable it if power consumption is an issue for you. If it isn't, you may also experiment with the <code>\"high-performance\"</code> mode.</p> <p>When should I use low-power mode?</p> <p>If you're targeting mobile devices, test your WebAR experiences with low-power mode. If you decide that the lower framerate is still acceptable, keep the low-power mode in order to save battery life.</p>"},{"location":"tutorial/next-steps/#add-multiple-virtual-scenes","title":"Add multiple virtual scenes","text":"<p>You can add multiple reference images to the reference image database. Each of those images can correspond to a different virtual scene. The virtual scene that shows up depends on the target image that is being tracked.</p> <p>Explore the API to see how you can have multiple virtual scenes in a single web page. Don't go overboard with this, though: the web page should load fast. Too much content may impact loading times. Keep your media files small and load your content asynchronously if possible.</p>"},{"location":"tutorial/next-steps/#publish-your-webar-experiences","title":"Publish your WebAR experiences","text":"<p>So far we've just created a static HTML page. The next step is to make your page available on the web. Your pages must be served over HTTPS - that's important for webcam access!</p> <p>Tip: use a QR code</p> <p>If you intend to print your reference images, consider adding a QR code nearby. The QR code should point to your web page. Users can then just scan your QR code to open your WebAR experience. Easy! </p> <p>Use the minified code</p> <p>When deploying your WebAR experiences, make sure to include the minified <code>encantar.min.js</code> file instead of the regular <code>encantar.js</code>. The latter is suitable for development. The former, for production.</p>"},{"location":"tutorial/next-steps/#support-my-work","title":"Support my work","text":"<p>If you came this far in the guide, WebAR probably excites you. It is definitely something you want. I know, it is awesome! The possibilities are endless. Even better than getting your creative juices boiling with enthusiasm is the feeling of joy I have for sharing this work with you.</p> <p>I develop encantar.js independently. Creating this WebAR engine requires a lot of time, effort, skill and specialized knowledge. Please support my work today, so that I can make it even more awesome!</p> <p> </p>"},{"location":"tutorial/set-up-a-web-server/","title":"Set up a web server","text":"<p>Let's prepare our local environment in order to create our first WebAR experience.</p>"},{"location":"tutorial/set-up-a-web-server/#create-a-file-structure","title":"Create a file structure","text":"<p>Let's create a file structure for our AR experience:</p> <ol> <li>Create a new folder called <code>ar-demo</code> in your filesystem</li> <li>Download the latest release of encantar.js and extract <code>dist/encantar.js</code> to <code>ar-demo/</code></li> <li>Create a new empty file called <code>index.html</code> and store it in <code>ar-demo/</code></li> </ol> <p>You will have the following file structure:</p> <pre><code>ar-demo/\n\u251c\u2500\u2500 index.html\n\u2514\u2500\u2500 encantar.js\n</code></pre>"},{"location":"tutorial/set-up-a-web-server/#add-boilerplate-code","title":"Add boilerplate code","text":"<p>Use the code editor of your choice to write the following content to <code>index.html</code>:</p> index.html<pre><code>&lt;!doctype html&gt;\n&lt;html&gt;\n    &lt;head&gt;\n        &lt;meta charset=\"utf-8\"&gt;\n        &lt;meta name=\"viewport\" content=\"width=device-width, user-scalable=no, minimum-scale=1, maximum-scale=1\"&gt;\n        &lt;title&gt;encantar.js WebAR demo&lt;/title&gt;\n        &lt;script src=\"encantar.js\"&gt;&lt;/script&gt;\n        &lt;style&gt;body { background-color: #3d5afe; }&lt;/style&gt;\n    &lt;/head&gt;\n    &lt;body&gt;\n    &lt;/body&gt;\n&lt;/html&gt;\n</code></pre>"},{"location":"tutorial/set-up-a-web-server/#set-up-a-local-web-server","title":"Set up a local web server","text":"<p>Let's set up a local web server in your machine for development purposes. I'll be showing you an easy-to-follow approach. Feel free to use a different approach if you're an experienced web developer.</p> Graphical interfaceCommand line <p>This is an easy solution that works on Windows, Linux and macOS:</p> <ol> <li>Download and run Servez, a simple web server for local web development.</li> <li>In Folder to Serve, specify the <code>ar-demo</code> folder we have just created.</li> <li>Change the Port to 8000.</li> <li>Click on Start to launch the local web server.</li> <li>Click on Launch Browser to open a web browser at http://localhost:8000.</li> </ol> <p> Setting up Servez: make sure that Folder to Serve points to the correct path in your filesystem! </p> <p>If you're familiar with the command line, you can use programs such as <code>python</code>, <code>node</code> or <code>php</code> to launch a local web server. Navigate to the <code>ar-demo</code> directory and then run:</p> Python 2Python 3Node.jsPHP <pre><code>python -m SimpleHTTPServer 8000\n</code></pre> <pre><code>python3 -m http.server 8000\n</code></pre> <pre><code>npx http-server -p 8000\n</code></pre> <pre><code>php -S localhost:8000\n</code></pre> <p>Next, open your web browser and go to http://localhost:8000.</p> <p>You should see a blue screen in your web browser:</p> <p></p> <p>If you see that blue screen, you're ready to proceed. If not, review your settings.</p> <p>Why port 8000?</p> <p>Port 8000 is commonly used in web development. Although you may use a different port, I suggest that you stick to this convention throughout this guide.</p>"},{"location":"tutorial/set-up-the-session/","title":"Set up the session","text":"<p>Now we're going to track our reference image for the first time! </p>"},{"location":"tutorial/set-up-the-session/#create-the-viewport","title":"Create the viewport","text":"<p>We begin by creating the viewport. Remember that the viewport is the area in which we'll display the augmented scene. Add the following to <code>index.html</code> and to <code>ar-demo.js</code>:</p> index.html<pre><code>&lt;!doctype html&gt;\n&lt;html&gt;\n    &lt;head&gt;\n        &lt;meta charset=\"utf-8\"&gt;\n        &lt;meta name=\"viewport\" content=\"width=device-width, user-scalable=no, minimum-scale=1, maximum-scale=1\"&gt;\n        &lt;title&gt;encantar.js WebAR demo&lt;/title&gt;\n        &lt;script src=\"encantar.js\"&gt;&lt;/script&gt;\n        &lt;script src=\"ar-demo.js\"&gt;&lt;/script&gt;\n        &lt;style&gt;body { background-color: #3d5afe; }&lt;/style&gt;\n    &lt;/head&gt;\n    &lt;body&gt;\n        &lt;div id=\"ar-viewport\"&gt;&lt;/div&gt;\n        &lt;img id=\"my-reference-image\" src=\"my-reference-image.webp\" hidden&gt;\n        &lt;video id=\"my-video\" hidden muted loop playsinline autoplay&gt;\n            &lt;source src=\"my-video.webm\" type=\"video/webm\" /&gt;\n            &lt;source src=\"my-video.mp4\" type=\"video/mp4\" /&gt;\n        &lt;/video&gt;\n    &lt;/body&gt;\n&lt;/html&gt;\n</code></pre> ar-demo.js<pre><code>window.onload = async function()\n{\n    try {\n        if(!AR.isSupported()) {\n            throw new Error(\n                'This device is not compatible with this AR experience.\\n\\n' +\n                'User agent: ' + navigator.userAgent\n            );\n        }\n\n        const tracker = AR.Tracker.Image();\n        await tracker.database.add([{\n            name: 'my-reference-image',\n            image: document.getElementById('my-reference-image')\n        }]);\n\n        const viewport = AR.Viewport({\n            container: document.getElementById('ar-viewport')\n        });\n    }\n    catch(error) {\n        alert(error.message);\n    }\n};\n</code></pre>"},{"location":"tutorial/set-up-the-session/#create-the-source-of-data","title":"Create the source of data","text":"<p>Let's set up our source of data. We get the <code>HTMLVideoElement</code> corresponding to the test video and then we use it to instantiate a video source of data. Write the following to <code>ar-demo.js</code>:</p> ar-demo.js<pre><code>window.onload = async function()\n{\n    try {\n        if(!AR.isSupported()) {\n            throw new Error(\n                'This device is not compatible with this AR experience.\\n\\n' +\n                'User agent: ' + navigator.userAgent\n            );\n        }\n\n        const tracker = AR.Tracker.Image();\n        await tracker.database.add([{\n            name: 'my-reference-image',\n            image: document.getElementById('my-reference-image')\n        }]);\n\n        const viewport = AR.Viewport({\n            container: document.getElementById('ar-viewport')\n        });\n\n        const video = document.getElementById('my-video');\n        const source = AR.Source.Video(video);\n    }\n    catch(error) {\n        alert(error.message);\n    }\n};\n</code></pre>"},{"location":"tutorial/set-up-the-session/#start-the-session","title":"Start the session","text":"<p>The session is a central component of a WebAR experience. The <code>AR</code> namespace has a very special method called <code>startSession</code>. It receives a settings dictionary that lets us configure the new session in different ways. Add the following code to <code>ar-demo.js</code>:</p> ar-demo.js<pre><code>window.onload = async function()\n{\n    try {\n        if(!AR.isSupported()) {\n            throw new Error(\n                'This device is not compatible with this AR experience.\\n\\n' +\n                'User agent: ' + navigator.userAgent\n            );\n        }\n\n        const tracker = AR.Tracker.Image();\n        await tracker.database.add([{\n            name: 'my-reference-image',\n            image: document.getElementById('my-reference-image')\n        }]);\n\n        const viewport = AR.Viewport({\n            container: document.getElementById('ar-viewport')\n        });\n\n        const video = document.getElementById('my-video');\n        const source = AR.Source.Video(video);\n\n        const session = await AR.startSession({\n            mode: 'immersive',\n            viewport: viewport,\n            trackers: [ tracker ],\n            sources: [ source ],\n            stats: true,\n            gizmos: true,\n        });\n    }\n    catch(error) {\n        alert(error.message);\n    }\n};\n</code></pre> <p>Most of the settings passed to <code>startSession</code> correspond directly to the concepts we saw earlier. We're starting a new session in immersive mode, with the tracker, source of data and viewport that we have just configured. Let me explain what <code>stats</code> and <code>gizmos</code> mean:</p> <ol> <li> <p>When you set <code>stats: true</code>, you're asking the engine to display a stats panel that shows useful data such as the current framerate. This is useful when developing WebAR experiences, but you should disable it in production.</p> </li> <li> <p>The option <code>gizmos: true</code> enables the gizmos. Gizmos are visual artifacts that help you visualize the current state of the tracker. They too are useful in development. In production, you may disable them or enable them partially (more on that later).</p> </li> </ol> <p>Open http://localhost:8000. You should see the tracking in action. Even though there is no virtual scene yet, the gizmos will show you the image being tracked.</p> <p></p> Image tracking in action! <p>The code I have just presented is, in essence, what you need to start a session. I'm going to move it to a new function called <code>startARSession</code> for convenience:</p> ar-demo.js<pre><code>window.onload = async function()\n{\n    try {\n        const session = await startARSession();\n    }\n    catch(error) {\n        alert(error.message);\n    }\n};\n\nasync function startARSession()\n{\n    if(!AR.isSupported()) {\n        throw new Error(\n            'This device is not compatible with this AR experience.\\n\\n' +\n            'User agent: ' + navigator.userAgent\n        );\n    }\n\n    const tracker = AR.Tracker.Image();\n    await tracker.database.add([{\n        name: 'my-reference-image',\n        image: document.getElementById('my-reference-image')\n    }]);\n\n    const viewport = AR.Viewport({\n        container: document.getElementById('ar-viewport')\n    });\n\n    const video = document.getElementById('my-video');\n    const source = AR.Source.Video(video);\n\n    const session = await AR.startSession({\n        mode: 'immersive',\n        viewport: viewport,\n        trackers: [ tracker ],\n        sources: [ source ],\n        stats: true,\n        gizmos: true,\n    });\n\n    return session;\n}\n</code></pre> <p>Now all you have to do to start a new session is call <code>startARSession()</code>!</p>"},{"location":"tutorial/set-up-the-session/#start-the-animation-loop","title":"Start the animation loop","text":"<p>The animation loop repeatedly calls the user callback. The user callback is a function responsible for updating and rendering the virtual scene. We have no virtual scene at the moment, but we'll already set up that function. Let's call <code>session.requestAnimationFrame()</code> and pass the user callback as an argument:</p> ar-demo.js<pre><code>window.onload = async function()\n{\n    try {\n        const session = await startARSession();\n\n        function animate(time, frame)\n        {\n            session.requestAnimationFrame(animate);\n        }\n\n        session.requestAnimationFrame(animate);\n    }\n    catch(error) {\n        alert(error.message);\n    }\n};\n\nasync function startARSession()\n{\n    // ...\n}\n</code></pre> <p>Calling <code>session.requestAnimationFrame()</code> inside the user callback, <code>animate()</code> in this example, makes it loop until the session ends. Making that call outside the user callback starts the loop.</p> <p>requestAnimationFrame</p> <p>Note that <code>session.requestAnimationFrame()</code> is different from <code>window.requestAnimationFrame()</code>. The former is a call to the WebAR engine, whereas the latter is a standard call to the web browser.</p>"},{"location":"tutorial/set-up-the-tracker/","title":"Set up the tracker","text":"<p>In this section we'll learn how to set up the tracker. Later on we'll see how to use the tracker to track an image in a video, with its position and orientation in 3D.</p>"},{"location":"tutorial/set-up-the-tracker/#add-a-reference-image","title":"Add a reference image","text":"<p>The first thing we need to do is add the image we want to track to our web page. We'll be calling that a reference image. We simply pick a suitable image and add an <code>&lt;img&gt;</code> tag to the page. Let's use the image below:</p> <p></p> Reference Image <p>What is a suitable image?</p> <p>Not all images are suitable for tracking. Images should be distinct, detailed and asymmetrical. I discuss this in detail in Guidelines for Images.</p> <p>Download the image to the <code>ar-demo/</code> folder. Save it as my-reference-image.webp.</p> <p>Next, let's add the reference image to our web page. Add an <code>&lt;img&gt;</code> tag to the <code>&lt;body&gt;</code> of the page as follows:</p> index.html<pre><code>&lt;!doctype html&gt;\n&lt;html&gt;\n    &lt;head&gt;\n        &lt;meta charset=\"utf-8\"&gt;\n        &lt;meta name=\"viewport\" content=\"width=device-width, user-scalable=no, minimum-scale=1, maximum-scale=1\"&gt;\n        &lt;title&gt;encantar.js WebAR demo&lt;/title&gt;\n        &lt;script src=\"encantar.js\"&gt;&lt;/script&gt;\n        &lt;style&gt;body { background-color: #3d5afe; }&lt;/style&gt;\n    &lt;/head&gt;\n    &lt;body&gt;\n        &lt;img id=\"my-reference-image\" src=\"my-reference-image.webp\"&gt;\n    &lt;/body&gt;\n&lt;/html&gt;\n</code></pre> <p>Reload the page. You should see the reference image:</p> <p></p> Reference image in a web page <p>If you don't see the image, make sure that there are no errors in the filename.</p> <p>Once you see that the image is being properly loaded, there is no need to keep it visible. Let's add the <code>hidden</code> attribute to the <code>&lt;img&gt;</code> tag:</p> index.html<pre><code>&lt;!doctype html&gt;\n&lt;html&gt;\n    &lt;head&gt;\n        &lt;meta charset=\"utf-8\"&gt;\n        &lt;meta name=\"viewport\" content=\"width=device-width, user-scalable=no, minimum-scale=1, maximum-scale=1\"&gt;\n        &lt;title&gt;encantar.js WebAR demo&lt;/title&gt;\n        &lt;script src=\"encantar.js\"&gt;&lt;/script&gt;\n        &lt;style&gt;body { background-color: #3d5afe; }&lt;/style&gt;\n    &lt;/head&gt;\n    &lt;body&gt;\n        &lt;img id=\"my-reference-image\" src=\"my-reference-image.webp\" hidden&gt;\n    &lt;/body&gt;\n&lt;/html&gt;\n</code></pre>"},{"location":"tutorial/set-up-the-tracker/#add-a-test-video","title":"Add a test video","text":"<p>We're going to be tracking that reference image in a test video. Please save the following video as my-video.webm and my-video.mp4 in <code>ar-demo/</code>. Later on I'll tell you how to use your webcam instead.</p> <p>This is the expected directory structure at this point:</p> <pre><code>ar-demo/\n\u251c\u2500\u2500 index.html\n\u251c\u2500\u2500 encantar.js\n\u251c\u2500\u2500 my-reference-image.webp\n\u251c\u2500\u2500 my-video.mp4\n\u2514\u2500\u2500 my-video.webm\n</code></pre> <p>Let's include the test video in our page. Add a <code>&lt;video&gt;</code> tag as follows:</p> index.html<pre><code>&lt;!doctype html&gt;\n&lt;html&gt;\n    &lt;head&gt;\n        &lt;meta charset=\"utf-8\"&gt;\n        &lt;meta name=\"viewport\" content=\"width=device-width, user-scalable=no, minimum-scale=1, maximum-scale=1\"&gt;\n        &lt;title&gt;encantar.js WebAR demo&lt;/title&gt;\n        &lt;script src=\"encantar.js\"&gt;&lt;/script&gt;\n        &lt;style&gt;body { background-color: #3d5afe; }&lt;/style&gt;\n    &lt;/head&gt;\n    &lt;body&gt;\n        &lt;img id=\"my-reference-image\" src=\"my-reference-image.webp\" hidden&gt;\n        &lt;video id=\"my-video\" hidden muted loop playsinline autoplay&gt;\n            &lt;source src=\"my-video.webm\" type=\"video/webm\" /&gt;\n            &lt;source src=\"my-video.mp4\" type=\"video/mp4\" /&gt;\n        &lt;/video&gt;\n    &lt;/body&gt;\n&lt;/html&gt;\n</code></pre>"},{"location":"tutorial/set-up-the-tracker/#instantiate-an-image-tracker","title":"Instantiate an Image Tracker","text":"<p>In order to track the reference image in our video, we need an Image Tracker. Remember that a tracker is a subsystem of the WebAR engine that analyzes input data in some way. An Image Tracker is a tracker that finds and tracks reference images in a video stream.</p> <p>Before we track anything with an Image Tracker, we must tell it what to track. There are two steps to this: first, we instantiate an Image Tracker. Next, we link our reference image to it.</p> <p>We'll be writing a little bit of JavaScript code now. In order to keep our code clean, we'll be writing the JavaScript code to a new file. Let's add a <code>&lt;script&gt;</code> tag below <code>encantar.js</code> as follows:</p> index.html<pre><code>&lt;!doctype html&gt;\n&lt;html&gt;\n    &lt;head&gt;\n        &lt;meta charset=\"utf-8\"&gt;\n        &lt;meta name=\"viewport\" content=\"width=device-width, user-scalable=no, minimum-scale=1, maximum-scale=1\"&gt;\n        &lt;title&gt;encantar.js WebAR demo&lt;/title&gt;\n        &lt;script src=\"encantar.js\"&gt;&lt;/script&gt;\n        &lt;script src=\"ar-demo.js\"&gt;&lt;/script&gt;\n        &lt;style&gt;body { background-color: #3d5afe; }&lt;/style&gt;\n    &lt;/head&gt;\n    &lt;body&gt;\n        &lt;img id=\"my-reference-image\" src=\"my-reference-image.webp\" hidden&gt;\n        &lt;video id=\"my-video\" hidden muted loop playsinline autoplay&gt;\n            &lt;source src=\"my-video.webm\" type=\"video/webm\" /&gt;\n            &lt;source src=\"my-video.mp4\" type=\"video/mp4\" /&gt;\n        &lt;/video&gt;\n    &lt;/body&gt;\n&lt;/html&gt;\n</code></pre> <p>Create a new file called <code>ar-demo.js</code> and store it in the <code>ar-demo/</code> folder. Write the following contents to it:</p> ar-demo.js<pre><code>window.onload = async function()\n{\n    try {\n        if(!AR.isSupported()) {\n            throw new Error(\n                'This device is not compatible with this AR experience.\\n\\n' +\n                'User agent: ' + navigator.userAgent\n            );\n        }\n\n        const tracker = AR.Tracker.Image();\n    }\n    catch(error) {\n        alert(error.message);\n    }\n};\n</code></pre> <p>The <code>AR</code> namespace holds the various elements featured by the engine. We'll be using it extensively.</p> <p>encantar.js only requires standard web technologies that have been around for a while. Still, it's a good practice to check if those technologies are supported by the target system. If they are not, we display a message and quit. If they are, we instantiate an Image Tracker.</p> <p>Before moving on, make sure that you have the following directory structure at this point:</p> <pre><code>ar-demo/\n\u251c\u2500\u2500 ar-demo.js\n\u251c\u2500\u2500 index.html\n\u251c\u2500\u2500 encantar.js\n\u251c\u2500\u2500 my-reference-image.webp\n\u251c\u2500\u2500 my-video.mp4\n\u2514\u2500\u2500 my-video.webm\n</code></pre>"},{"location":"tutorial/set-up-the-tracker/#link-the-image-to-the-tracker","title":"Link the image to the tracker","text":"<p>Our Image Tracker has an internal database of reference images that it's capable of tracking. We call it a reference image database. To link a reference image to the tracker means to add that image to the database.</p> <p>When linking a reference image to the tracker, the appropriate <code>HTMLImageElement</code> must be provided to the database. You may optionally assign a name to the image, so that you can identify it later on. If you don't, an automatically generated name will be assigned for you.</p> <p>Let's link the image to the tracker. Add the following code to <code>ar-demo.js</code>:</p> ar-demo.js<pre><code>window.onload = async function()\n{\n    try {\n        if(!AR.isSupported()) {\n            throw new Error(\n                'This device is not compatible with this AR experience.\\n\\n' +\n                'User agent: ' + navigator.userAgent\n            );\n        }\n\n        const tracker = AR.Tracker.Image();\n        await tracker.database.add([{\n            name: 'my-reference-image',\n            image: document.getElementById('my-reference-image')\n        }]);\n    }\n    catch(error) {\n        alert(error.message);\n    }\n};\n</code></pre> <p>Reload the page. If you see no errors popping up, it means that the image is linked to the tracker. You're ready to proceed!</p>"}]}