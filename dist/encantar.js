/*!
 * encantar.js version 0.4.1
 * GPU-accelerated Augmented Reality for the web
 * Copyright 2022-2025 Alexandre Martins <alemartf(at)gmail.com> (https://github.com/alemart)
 * https://encantar.dev
 *
 * @license LGPL-3.0-or-later
 * Date: 2025-01-21T02:37:34.737Z
*/
var AR = (() => {
  var __create = Object.create;
  var __defProp = Object.defineProperty;
  var __getOwnPropDesc = Object.getOwnPropertyDescriptor;
  var __getOwnPropNames = Object.getOwnPropertyNames;
  var __getProtoOf = Object.getPrototypeOf;
  var __hasOwnProp = Object.prototype.hasOwnProperty;
  var __esm = (fn, res) => function __init() {
    return fn && (res = (0, fn[__getOwnPropNames(fn)[0]])(fn = 0)), res;
  };
  var __commonJS = (cb, mod) => function __require() {
    return mod || (0, cb[__getOwnPropNames(cb)[0]])((mod = { exports: {} }).exports, mod), mod.exports;
  };
  var __copyProps = (to, from, except, desc) => {
    if (from && typeof from === "object" || typeof from === "function") {
      for (let key of __getOwnPropNames(from))
        if (!__hasOwnProp.call(to, key) && key !== except)
          __defProp(to, key, { get: () => from[key], enumerable: !(desc = __getOwnPropDesc(from, key)) || desc.enumerable });
    }
    return to;
  };
  var __toESM = (mod, isNodeMode, target) => (target = mod != null ? __create(__getProtoOf(mod)) : {}, __copyProps(
    // If the importer is in node compatibility mode or this is not an ESM
    // file that has been converted to a CommonJS file using a Babel-
    // compatible transform (i.e. "__esModule" has not been set), then set
    // "default" to the CommonJS "module.exports" for node compatibility.
    isNodeMode || !mod || !mod.__esModule ? __defProp(target, "default", { value: mod, enumerable: true }) : target,
    mod
  ));

  // node_modules/speedy-vision/dist/speedy-vision.js
  var require_speedy_vision = __commonJS({
    "node_modules/speedy-vision/dist/speedy-vision.js"(exports, module) {
      /*!
       * Speedy Vision version 0.9.1
       * GPU-accelerated Computer Vision for JavaScript
       * Copyright 2020-2024 Alexandre Martins <alemartf(at)gmail.com> (https://github.com/alemart)
       * https://github.com/alemart/speedy-vision
       *
       * @license Apache-2.0
       * Date: 2024-07-03T02:16:25.769Z
       */
      (function webpackUniversalModuleDefinition(root, factory) {
        if (typeof exports === "object" && typeof module === "object")
          module.exports = factory();
        else if (typeof define === "function" && define.amd)
          define([], factory);
        else if (typeof exports === "object")
          exports["Speedy"] = factory();
        else
          root["Speedy"] = factory();
      })(self, () => {
        return (
          /******/
          (() => {
            var __webpack_modules__ = {
              /***/
              2199: (
                /***/
                (__unused_webpack_module, __webpack_exports__2, __webpack_require__2) => {
                  "use strict";
                  __webpack_require__2.d(__webpack_exports__2, {
                    /* harmony export */
                    w: () => (
                      /* binding */
                      Settings2
                    )
                    /* harmony export */
                  });
                  var _speedy_namespace__WEBPACK_IMPORTED_MODULE_0__ = __webpack_require__2(6634);
                  var _gpu_speedy_gl__WEBPACK_IMPORTED_MODULE_1__ = __webpack_require__2(1001);
                  var _utils_utils__WEBPACK_IMPORTED_MODULE_2__ = __webpack_require__2(9037);
                  var _utils_errors__WEBPACK_IMPORTED_MODULE_3__ = __webpack_require__2(8581);
                  const DEFAULT_GPU_POLLING_MODE = "raf";
                  let gpuPollingMode = DEFAULT_GPU_POLLING_MODE;
                  let loggingMode = "default";
                  class Settings2 extends _speedy_namespace__WEBPACK_IMPORTED_MODULE_0__.Q {
                    /**
                     * Power preference of the WebGL context
                     * @returns {PowerPreference}
                     */
                    static get powerPreference() {
                      return _gpu_speedy_gl__WEBPACK_IMPORTED_MODULE_1__.c.powerPreference;
                    }
                    /**
                     * Power preference of the WebGL context
                     * @param {PowerPreference} value
                     */
                    static set powerPreference(value) {
                      _gpu_speedy_gl__WEBPACK_IMPORTED_MODULE_1__.c.powerPreference = value;
                    }
                    /**
                     * GPU polling mode
                     * @returns {GPUPollingMode}
                     */
                    static get gpuPollingMode() {
                      return gpuPollingMode;
                    }
                    /**
                     * GPU polling mode
                     * @param {GPUPollingMode} value
                     */
                    static set gpuPollingMode(value) {
                      if (value !== "raf" && value !== "asap") throw new _utils_errors__WEBPACK_IMPORTED_MODULE_3__.qw(`Invalid GPU polling mode: "${value}"`);
                      gpuPollingMode = value;
                    }
                    /**
                     * Logging mode
                     * @returns {LoggingMode}
                     */
                    static get logging() {
                      return loggingMode;
                    }
                    /**
                     * Logging mode
                     * @param {LoggingMode} mode
                     */
                    static set logging(mode) {
                      if (mode !== "default" && mode !== "none" && mode !== "diagnostic") throw new _utils_errors__WEBPACK_IMPORTED_MODULE_3__.qw(`Invalid logging mode: "${mode}"`);
                      else if (mode === "diagnostic") _utils_utils__WEBPACK_IMPORTED_MODULE_2__.A.log("%c DIAGNOSTIC MODE ", "background:red;color:white;font-size:36pt;font-weight:bold");
                      loggingMode = mode;
                    }
                  }
                }
              ),
              /***/
              6306: (
                /***/
                (__unused_webpack_module, __webpack_exports__2, __webpack_require__2) => {
                  "use strict";
                  __webpack_require__2.d(__webpack_exports__2, {
                    /* harmony export */
                    r: () => (
                      /* binding */
                      SpeedyMatrixExpr
                    )
                    /* harmony export */
                  });
                  var _speedy_matrix_wasm__WEBPACK_IMPORTED_MODULE_0__ = __webpack_require__2(6465);
                  var _utils_utils__WEBPACK_IMPORTED_MODULE_1__ = __webpack_require__2(9037);
                  var _utils_errors__WEBPACK_IMPORTED_MODULE_2__ = __webpack_require__2(8581);
                  const DTYPE_TO_BUFFER_TYPE = Object.freeze({
                    "float32": Float32Array
                  });
                  class SpeedyMatrixExpr {
                    /**
                     * Constructor
                     * @param {number} rows
                     * @param {number} columns
                     * @param {SpeedyMatrixDtype} dtype
                     */
                    constructor(rows, columns, dtype) {
                      _utils_utils__WEBPACK_IMPORTED_MODULE_1__.A.assert(rows > 0 && columns > 0);
                      _utils_utils__WEBPACK_IMPORTED_MODULE_1__.A.assert(dtype === SpeedyMatrixExpr.DEFAULT_DTYPE);
                      this._rows = rows | 0;
                      this._columns = columns | 0;
                      this._dtype = dtype;
                    }
                    /**
                     * Number of rows
                     * @returns {number}
                     */
                    get rows() {
                      return this._rows;
                    }
                    /**
                     * Number of columns
                     * @returns {number}
                     */
                    get columns() {
                      return this._columns;
                    }
                    /**
                     * Data type
                     * @returns {SpeedyMatrixDtype}
                     */
                    get dtype() {
                      return this._dtype;
                    }
                    /**
                     * Default data type
                     * @returns {SpeedyMatrixDtype}
                     */
                    static get DEFAULT_DTYPE() {
                      return "float32";
                    }
                    /**
                     * Buffer types
                     * @returns {Dtype2BufferType}
                     */
                    static get BUFFER_TYPE() {
                      return DTYPE_TO_BUFFER_TYPE;
                    }
                    /**
                     * Matrix addition
                     * @param {SpeedyMatrixExpr} expr
                     * @returns {SpeedyMatrixExpr}
                     */
                    plus(expr) {
                      return new SpeedyMatrixAddExpr(this, expr);
                    }
                    /**
                     * Matrix subtraction
                     * @param {SpeedyMatrixExpr} expr
                     * @returns {SpeedyMatrixExpr}
                     */
                    minus(expr) {
                      return new SpeedyMatrixSubtractExpr(this, expr);
                    }
                    /**
                     * Matrix multiplication
                     * @param {SpeedyMatrixExpr|number} expr
                     * @returns {SpeedyMatrixExpr}
                     */
                    times(expr) {
                      if (typeof expr === "number") return new SpeedyMatrixScaleExpr(this, expr);
                      else return new SpeedyMatrixMultiplyExpr(this, expr);
                    }
                    /**
                     * Matrix transposition
                     * @returns {SpeedyMatrixExpr}
                     */
                    transpose() {
                      return new SpeedyMatrixTransposeExpr(this);
                    }
                    /**
                     * Matrix inversion
                     * @returns {SpeedyMatrixExpr}
                     */
                    inverse() {
                      return new SpeedyMatrixInvertExpr(this);
                    }
                    /**
                     * Component-wise multiplication
                     * @param {SpeedyMatrixExpr} expr
                     * @returns {SpeedyMatrixExpr}
                     */
                    compMult(expr) {
                      return new SpeedyMatrixCompMultExpr(this, expr);
                    }
                    /**
                     * Left division: A \ b, which is equivalent to (pseudo-)inverse(A) * b
                     * @param {SpeedyMatrixExpr} expr
                     * @returns {SpeedyMatrixExpr}
                     */
                    ldiv(expr) {
                      return new SpeedyMatrixLdivExpr(this, expr);
                    }
                    /**
                     * Returns a human-readable string representation of the matrix expression
                     * @returns {string}
                     */
                    toString() {
                      return `SpeedyMatrixExpr(rows=${this.rows}, columns=${this.columns})`;
                    }
                    /**
                     * Evaluate this expression
                     * @abstract
                     * @param {WebAssembly.Instance} wasm
                     * @param {SpeedyMatrixWASMMemory} memory
                     * @returns {SpeedyMatrix}
                     */
                    _evaluate(wasm, memory) {
                      throw new _utils_errors__WEBPACK_IMPORTED_MODULE_2__.aQ();
                    }
                  }
                  const {
                    SpeedyMatrix
                  } = __webpack_require__2(4188);
                  class SpeedyMatrixTempExpr extends SpeedyMatrixExpr {
                    /**
                     * Constructor
                     * @param {number} rows
                     * @param {number} columns
                     * @param {SpeedyMatrixDtype} dtype
                     */
                    constructor(rows, columns, dtype) {
                      super(rows, columns, dtype);
                      this._tempMatrix = SpeedyMatrix.Zeros(this.rows, this.columns, this.dtype);
                    }
                  }
                  class SpeedyMatrixUnaryOperationExpr extends SpeedyMatrixTempExpr {
                    /**
                     * Constructor
                     * @param {number} rows rows of the output matrix
                     * @param {number} columns columns of the output matrix
                     * @param {SpeedyMatrixExpr} operand
                     */
                    constructor(rows, columns, operand) {
                      super(rows, columns, operand.dtype);
                      this._operand = operand;
                    }
                    /**
                     * Evaluate this expression
                     * @param {WebAssembly.Instance} wasm
                     * @param {SpeedyMatrixWASMMemory} memory
                     * @returns {SpeedyMatrix}
                     */
                    _evaluate(wasm, memory) {
                      const operand = this._operand._evaluate(wasm, memory);
                      const result = this._tempMatrix;
                      const resultptr = _speedy_matrix_wasm__WEBPACK_IMPORTED_MODULE_0__.U.allocateMat32(wasm, memory, result);
                      const operandptr = _speedy_matrix_wasm__WEBPACK_IMPORTED_MODULE_0__.U.allocateMat32(wasm, memory, operand);
                      _speedy_matrix_wasm__WEBPACK_IMPORTED_MODULE_0__.U.copyToMat32(wasm, memory, operandptr, operand);
                      this._compute(wasm, memory, resultptr, operandptr);
                      _speedy_matrix_wasm__WEBPACK_IMPORTED_MODULE_0__.U.copyFromMat32(wasm, memory, resultptr, result);
                      _speedy_matrix_wasm__WEBPACK_IMPORTED_MODULE_0__.U.deallocateMat32(wasm, memory, operandptr);
                      _speedy_matrix_wasm__WEBPACK_IMPORTED_MODULE_0__.U.deallocateMat32(wasm, memory, resultptr);
                      return result;
                    }
                    /**
                     * Compute the result of this operation
                     * @abstract
                     * @param {WebAssembly.Instance} wasm
                     * @param {SpeedyMatrixWASMMemory} memory
                     * @param {number} resultptr pointer to Mat32
                     * @param {number} operandptr pointer to Mat32
                     */
                    _compute(wasm, memory, resultptr, operandptr) {
                      throw new _utils_errors__WEBPACK_IMPORTED_MODULE_2__.aQ();
                    }
                  }
                  class SpeedyMatrixBinaryOperationExpr extends SpeedyMatrixTempExpr {
                    /**
                     * Constructor
                     * @param {number} rows rows of the output matrix
                     * @param {number} columns columns of the output matrix
                     * @param {SpeedyMatrixExpr} left left operand
                     * @param {SpeedyMatrixExpr} right right operand
                     */
                    constructor(rows, columns, left, right) {
                      _utils_utils__WEBPACK_IMPORTED_MODULE_1__.A.assert(left.dtype === right.dtype);
                      super(rows, columns, left.dtype);
                      this._left = left;
                      this._right = right;
                    }
                    /**
                     * Evaluate this expression
                     * @param {WebAssembly.Instance} wasm
                     * @param {SpeedyMatrixWASMMemory} memory
                     * @returns {SpeedyMatrix}
                     */
                    _evaluate(wasm, memory) {
                      const left = this._left._evaluate(wasm, memory);
                      const right = this._right._evaluate(wasm, memory);
                      const result = this._tempMatrix;
                      const resultptr = _speedy_matrix_wasm__WEBPACK_IMPORTED_MODULE_0__.U.allocateMat32(wasm, memory, result);
                      const leftptr = _speedy_matrix_wasm__WEBPACK_IMPORTED_MODULE_0__.U.allocateMat32(wasm, memory, left);
                      const rightptr = _speedy_matrix_wasm__WEBPACK_IMPORTED_MODULE_0__.U.allocateMat32(wasm, memory, right);
                      _speedy_matrix_wasm__WEBPACK_IMPORTED_MODULE_0__.U.copyToMat32(wasm, memory, leftptr, left);
                      _speedy_matrix_wasm__WEBPACK_IMPORTED_MODULE_0__.U.copyToMat32(wasm, memory, rightptr, right);
                      this._compute(wasm, memory, resultptr, leftptr, rightptr);
                      _speedy_matrix_wasm__WEBPACK_IMPORTED_MODULE_0__.U.copyFromMat32(wasm, memory, resultptr, result);
                      _speedy_matrix_wasm__WEBPACK_IMPORTED_MODULE_0__.U.deallocateMat32(wasm, memory, rightptr);
                      _speedy_matrix_wasm__WEBPACK_IMPORTED_MODULE_0__.U.deallocateMat32(wasm, memory, leftptr);
                      _speedy_matrix_wasm__WEBPACK_IMPORTED_MODULE_0__.U.deallocateMat32(wasm, memory, resultptr);
                      return result;
                    }
                    /**
                     * Compute the result of this operation
                     * @abstract
                     * @param {WebAssembly.Instance} wasm
                     * @param {SpeedyMatrixWASMMemory} memory
                     * @param {number} resultptr pointer to Mat32
                     * @param {number} leftptr pointer to Mat32
                     * @param {number} rightptr pointer to Mat32
                     */
                    _compute(wasm, memory, resultptr, leftptr, rightptr) {
                      throw new _utils_errors__WEBPACK_IMPORTED_MODULE_2__.aQ();
                    }
                  }
                  class SpeedyMatrixTransposeExpr extends SpeedyMatrixUnaryOperationExpr {
                    /**
                     * Constructor
                     * @param {SpeedyMatrixExpr} operand
                     */
                    constructor(operand) {
                      super(operand.columns, operand.rows, operand);
                    }
                    /**
                     * Compute result = operand^T
                     * @param {WebAssembly.Instance} wasm
                     * @param {SpeedyMatrixWASMMemory} memory
                     * @param {number} resultptr pointer to Mat32
                     * @param {number} operandptr pointer to Mat32
                     */
                    _compute(wasm, memory, resultptr, operandptr) {
                      wasm.exports.Mat32_transpose(resultptr, operandptr);
                    }
                  }
                  class SpeedyMatrixInvertExpr extends SpeedyMatrixUnaryOperationExpr {
                    /**
                     * Constructor
                     * @param {SpeedyMatrixExpr} operand
                     */
                    constructor(operand) {
                      _utils_utils__WEBPACK_IMPORTED_MODULE_1__.A.assert(operand.rows === operand.columns);
                      super(operand.rows, operand.columns, operand);
                      this._size = operand.rows;
                    }
                    /**
                     * Compute result = operand ^ (-1)
                     * @param {WebAssembly.Instance} wasm
                     * @param {SpeedyMatrixWASMMemory} memory
                     * @param {number} resultptr pointer to Mat32
                     * @param {number} operandptr pointer to Mat32
                     */
                    _compute(wasm, memory, resultptr, operandptr) {
                      switch (this._size) {
                        case 0:
                          break;
                        case 1:
                          wasm.exports.Mat32_inverse1(resultptr, operandptr);
                          break;
                        case 2:
                          wasm.exports.Mat32_inverse2(resultptr, operandptr);
                          break;
                        case 3:
                          wasm.exports.Mat32_inverse3(resultptr, operandptr);
                          break;
                        default:
                          wasm.exports.Mat32_qr_inverse(resultptr, operandptr);
                          break;
                      }
                    }
                  }
                  class SpeedyMatrixScaleExpr extends SpeedyMatrixUnaryOperationExpr {
                    /**
                     * Constructor
                     * @param {SpeedyMatrixExpr} operand
                     * @param {number} scalar
                     */
                    constructor(operand, scalar) {
                      super(operand.rows, operand.columns, operand);
                      this._scalar = +scalar;
                    }
                    /**
                     * Compute result = scalar * operand
                     * @param {WebAssembly.Instance} wasm
                     * @param {SpeedyMatrixWASMMemory} memory
                     * @param {number} resultptr pointer to Mat32
                     * @param {number} operandptr pointer to Mat32
                     */
                    _compute(wasm, memory, resultptr, operandptr) {
                      wasm.exports.Mat32_scale(resultptr, operandptr, this._scalar);
                    }
                  }
                  class SpeedyMatrixAddExpr extends SpeedyMatrixBinaryOperationExpr {
                    /**
                     * Constructor
                     * @param {SpeedyMatrixExpr} left left operand
                     * @param {SpeedyMatrixExpr} right right operand
                     */
                    constructor(left, right) {
                      _utils_utils__WEBPACK_IMPORTED_MODULE_1__.A.assert(left.rows === right.rows && left.columns === right.columns);
                      super(left.rows, left.columns, left, right);
                    }
                    /**
                     * Compute result = left + right
                     * @param {WebAssembly.Instance} wasm
                     * @param {SpeedyMatrixWASMMemory} memory
                     * @param {number} resultptr pointer to Mat32
                     * @param {number} leftptr pointer to Mat32
                     * @param {number} rightptr pointer to Mat32
                     */
                    _compute(wasm, memory, resultptr, leftptr, rightptr) {
                      wasm.exports.Mat32_add(resultptr, leftptr, rightptr);
                    }
                  }
                  class SpeedyMatrixSubtractExpr extends SpeedyMatrixBinaryOperationExpr {
                    /**
                     * Constructor
                     * @param {SpeedyMatrixExpr} left left operand
                     * @param {SpeedyMatrixExpr} right right operand
                     */
                    constructor(left, right) {
                      _utils_utils__WEBPACK_IMPORTED_MODULE_1__.A.assert(left.rows === right.rows && left.columns === right.columns);
                      super(left.rows, left.columns, left, right);
                    }
                    /**
                     * Compute result = left - right
                     * @param {WebAssembly.Instance} wasm
                     * @param {SpeedyMatrixWASMMemory} memory
                     * @param {number} resultptr pointer to Mat32
                     * @param {number} leftptr pointer to Mat32
                     * @param {number} rightptr pointer to Mat32
                     */
                    _compute(wasm, memory, resultptr, leftptr, rightptr) {
                      wasm.exports.Mat32_subtract(resultptr, leftptr, rightptr);
                    }
                  }
                  class SpeedyMatrixMultiplyExpr extends SpeedyMatrixBinaryOperationExpr {
                    /**
                     * Constructor
                     * @param {SpeedyMatrixExpr} left left operand
                     * @param {SpeedyMatrixExpr} right right operand
                     */
                    constructor(left, right) {
                      _utils_utils__WEBPACK_IMPORTED_MODULE_1__.A.assert(left.columns === right.rows);
                      super(left.rows, right.columns, left, right);
                    }
                    /**
                     * Compute result = left * right
                     * @param {WebAssembly.Instance} wasm
                     * @param {SpeedyMatrixWASMMemory} memory
                     * @param {number} resultptr pointer to Mat32
                     * @param {number} leftptr pointer to Mat32
                     * @param {number} rightptr pointer to Mat32
                     */
                    _compute(wasm, memory, resultptr, leftptr, rightptr) {
                      wasm.exports.Mat32_multiply(resultptr, leftptr, rightptr);
                    }
                  }
                  class SpeedyMatrixCompMultExpr extends SpeedyMatrixBinaryOperationExpr {
                    /**
                     * Constructor
                     * @param {SpeedyMatrixExpr} left left operand
                     * @param {SpeedyMatrixExpr} right right operand
                     */
                    constructor(left, right) {
                      _utils_utils__WEBPACK_IMPORTED_MODULE_1__.A.assert(left.rows === right.rows && left.columns === right.columns);
                      super(right.rows, right.columns, left, right);
                    }
                    /**
                     * Compute result = left <compMult> right
                     * @param {WebAssembly.Instance} wasm
                     * @param {SpeedyMatrixWASMMemory} memory
                     * @param {number} resultptr pointer to Mat32
                     * @param {number} leftptr pointer to Mat32
                     * @param {number} rightptr pointer to Mat32
                     */
                    _compute(wasm, memory, resultptr, leftptr, rightptr) {
                      wasm.exports.Mat32_compmult(resultptr, leftptr, rightptr);
                    }
                  }
                  class SpeedyMatrixLdivExpr extends SpeedyMatrixBinaryOperationExpr {
                    /**
                     * Constructor
                     * @param {SpeedyMatrixExpr} left left operand
                     * @param {SpeedyMatrixExpr} right right operand
                     */
                    constructor(left, right) {
                      const m = left.rows, n = left.columns;
                      _utils_utils__WEBPACK_IMPORTED_MODULE_1__.A.assert(m >= n && right.rows === m && right.columns === 1);
                      super(n, 1, left, right);
                    }
                    /**
                     * Compute result = left \ right
                     * @param {WebAssembly.Instance} wasm
                     * @param {SpeedyMatrixWASMMemory} memory
                     * @param {number} resultptr pointer to Mat32
                     * @param {number} leftptr pointer to Mat32
                     * @param {number} rightptr pointer to Mat32
                     */
                    _compute(wasm, memory, resultptr, leftptr, rightptr) {
                      wasm.exports.Mat32_qr_ols(resultptr, leftptr, rightptr, 2);
                    }
                  }
                }
              ),
              /***/
              6465: (
                /***/
                (__unused_webpack_module, __webpack_exports__2, __webpack_require__2) => {
                  "use strict";
                  __webpack_require__2.d(__webpack_exports__2, {
                    /* harmony export */
                    U: () => (
                      /* binding */
                      SpeedyMatrixWASM
                    )
                    /* harmony export */
                  });
                  var _speedy_promise__WEBPACK_IMPORTED_MODULE_0__ = __webpack_require__2(9192);
                  var _utils_errors__WEBPACK_IMPORTED_MODULE_1__ = __webpack_require__2(8581);
                  var _utils_utils__WEBPACK_IMPORTED_MODULE_2__ = __webpack_require__2(9037);
                  var _utils_globals__WEBPACK_IMPORTED_MODULE_3__ = __webpack_require__2(3816);
                  const WASM_BINARY = __webpack_require__2(3575);
                  let _instance = null;
                  let _module = null;
                  const _memory = ((mem) => ({
                    as: {
                      object: mem,
                      uint8: new Uint8Array(mem.buffer),
                      int32: new Int32Array(mem.buffer),
                      uint32: new Uint32Array(mem.buffer),
                      float32: new Float32Array(mem.buffer),
                      float64: new Float64Array(mem.buffer)
                    }
                  }))(typeof WebAssembly === "undefined" ? new Uint8Array(1024) : (
                    // use a filler
                    new WebAssembly.Memory({
                      initial: 16,
                      // 1 MB
                      maximum: 256
                    })
                  ));
                  class SpeedyMatrixWASM {
                    /**
                     * Gets you the WASM instance, augmented memory & module
                     * @returns {SpeedyPromise<SpeedyMatrixWASMHandle>}
                     */
                    static ready() {
                      if (typeof WebAssembly === "undefined") return _speedy_promise__WEBPACK_IMPORTED_MODULE_0__.i.reject(new _utils_errors__WEBPACK_IMPORTED_MODULE_1__.EM("This application requires WebAssembly. Please update your system."));
                      if (!_utils_globals__WEBPACK_IMPORTED_MODULE_3__.LITTLE_ENDIAN) return _speedy_promise__WEBPACK_IMPORTED_MODULE_0__.i.reject(new _utils_errors__WEBPACK_IMPORTED_MODULE_1__.EM(`Can't run WebAssembly code: not in a little-endian machine!`));
                      return new _speedy_promise__WEBPACK_IMPORTED_MODULE_0__.i((resolve, reject) => {
                        SpeedyMatrixWASM._ready(resolve, reject);
                      });
                    }
                    /**
                     * Synchronously gets you the WASM instance, augmented memory & module
                     * @returns {SpeedyMatrixWASMHandle}
                     */
                    static get handle() {
                      if (!_instance || !_module) throw new _utils_errors__WEBPACK_IMPORTED_MODULE_1__.NO(`Can't get WASM handle: routines not yet loaded`);
                      return {
                        wasm: _instance,
                        memory: _memory,
                        module: _module
                      };
                    }
                    /**
                     * Gets you the WASM imports bound to a memory object
                     * @param {SpeedyMatrixWASMMemory} memory
                     * @returns {Object<string,Function>}
                     */
                    static imports(memory) {
                      const obj = new SpeedyMatrixWASMImports(memory);
                      return Object.getOwnPropertyNames(SpeedyMatrixWASMImports.prototype).filter((property) => typeof obj[property] === "function" && property !== "constructor").reduce((imports, methodName) => (imports[methodName] = obj[methodName], imports), /* @__PURE__ */ Object.create(null));
                    }
                    /**
                     * Allocate a Mat32 in WebAssembly memory without copying any data
                     * @param {WebAssembly.Instance} wasm
                     * @param {SpeedyMatrixWASMMemory} memory
                     * @param {SpeedyMatrix} matrix
                     * @returns {number} pointer to the new Mat32
                     */
                    static allocateMat32(wasm, memory, matrix) {
                      const dataptr = wasm.exports.malloc(matrix.data.byteLength);
                      const matptr = wasm.exports.Mat32_create(matrix.rows, matrix.columns, matrix.step0, matrix.step1, matrix._data.length, dataptr);
                      return matptr;
                    }
                    /**
                     * Deallocate a Mat32 in WebAssembly
                     * @param {WebAssembly.Instance} wasm
                     * @param {SpeedyMatrixWASMMemory} memory
                     * @param {number} matptr pointer to the allocated Mat32
                     * @returns {number} NULL
                     */
                    static deallocateMat32(wasm, memory, matptr) {
                      const dataptr = wasm.exports.Mat32_data(matptr);
                      wasm.exports.free(matptr);
                      wasm.exports.free(dataptr);
                      return 0;
                    }
                    /**
                     * Copy the data of a matrix to a WebAssembly Mat32
                     * @param {WebAssembly.Instance} wasm
                     * @param {SpeedyMatrixWASMMemory} memory
                     * @param {number} matptr pointer to a Mat32
                     * @param {SpeedyMatrix} matrix
                     * @returns {number} matptr
                     */
                    static copyToMat32(wasm, memory, matptr, matrix) {
                      _utils_utils__WEBPACK_IMPORTED_MODULE_2__.A.assert(
                        //matrix.dtype === 'float32' &&
                        matrix.data.byteLength === wasm.exports.Mat32_dataSize(matptr)
                      );
                      const dataptr = wasm.exports.Mat32_data(matptr);
                      memory.as.float32.set(matrix.data, dataptr / Float32Array.BYTES_PER_ELEMENT);
                      return matptr;
                    }
                    /**
                     * Copy the data of a WebAssembly Mat32 to a matrix
                     * @param {WebAssembly.Instance} wasm
                     * @param {SpeedyMatrixWASMMemory} memory
                     * @param {number} matptr pointer to a Mat32
                     * @param {SpeedyMatrix} matrix
                     * @returns {number} matptr
                     */
                    static copyFromMat32(wasm, memory, matptr, matrix) {
                      _utils_utils__WEBPACK_IMPORTED_MODULE_2__.A.assert(
                        //matrix.dtype === 'float32' &&
                        matrix.data.byteLength === wasm.exports.Mat32_dataSize(matptr)
                      );
                      const base = wasm.exports.Mat32_data(matptr) / Float32Array.BYTES_PER_ELEMENT;
                      for (let offset = matrix.data.length - 1; offset >= 0; offset--) matrix.data[offset] = memory.as.float32[base + offset];
                      return matptr;
                    }
                    /**
                     * Polls the WebAssembly instance until it's ready
                     * @param {function(SpeedyMatrixWASMHandle): void} resolve
                     * @param {function(Error): void} reject
                     * @param {number} [counter]
                     */
                    static _ready(resolve, reject, counter = 1e3) {
                      if (_instance !== null && _module !== null) resolve({
                        wasm: _instance,
                        memory: _memory,
                        module: _module
                      });
                      else if (counter <= 0) reject(new _utils_errors__WEBPACK_IMPORTED_MODULE_1__.MU(`Can't load WASM routines`));
                      else setTimeout(SpeedyMatrixWASM._ready, 0, resolve, reject, counter - 1);
                    }
                  }
                  class SpeedyMatrixWASMImports {
                    /**
                     * Constructor
                     * @param {SpeedyMatrixWASMMemory} memory will be bound to this object
                     */
                    constructor(memory) {
                      const methodNames = Object.getOwnPropertyNames(this.constructor.prototype).filter((property) => typeof this[property] === "function").filter((property) => property !== "constructor");
                      methodNames.forEach((methodName) => {
                        this[methodName] = this[methodName].bind(this);
                      });
                      this.memory = memory;
                      this.cstring = new CStringUtils(memory);
                      return Object.freeze(this);
                    }
                    /**
                     * Prints a message
                     * @param {number} ptr pointer to char
                     */
                    print(ptr) {
                      _utils_utils__WEBPACK_IMPORTED_MODULE_2__.A.log(this.cstring.get(ptr));
                    }
                    /**
                     * Throws an error
                     * @param {number} ptr pointer to char
                     */
                    fatal(ptr) {
                      throw new _utils_errors__WEBPACK_IMPORTED_MODULE_1__.NO(this.cstring.get(ptr));
                    }
                    /**
                     * Fills a memory segment with a byte
                     * @param {number} value byte
                     * @param {number} start memory address, inclusive
                     * @param {number} end memory address greater than start, exclusive
                     */
                    bytefill(value, start, end) {
                      this.memory.as.uint8.fill(value, start, end);
                    }
                    /**
                     * Copy a memory segment to another segment
                     * @param {number} target memory address, where we'll start writing
                     * @param {number} start memory address, where we'll start copying (inclusive)
                     * @param {number} end memory address, where we'll end the copy (exclusive)
                     */
                    copyWithin(target, start, end) {
                      this.memory.as.uint8.copyWithin(target, start, end);
                    }
                  }
                  class CStringUtils {
                    /**
                     * Constructor
                     * @param {SpeedyMatrixWASMMemory} memory
                     */
                    constructor(memory) {
                      this._decoder = new TextDecoder("utf-8");
                      this._memory = memory;
                    }
                    /**
                     * Convert a C string to a JavaScript string
                     * @param {number} ptr pointer to char
                     * @returns {string}
                     */
                    get(ptr) {
                      const byte = this._memory.as.uint8;
                      const size = this._memory.as.uint8.byteLength;
                      let p = ptr;
                      while (p < size && 0 !== byte[p]) ++p;
                      return this._decoder.decode(byte.subarray(ptr, p));
                    }
                  }
                  (function loadWASM(memory) {
                    const base64decode = (data) => Uint8Array.from(atob(data), (v) => v.charCodeAt(0));
                    if (typeof WebAssembly === "undefined") return;
                    _speedy_promise__WEBPACK_IMPORTED_MODULE_0__.i.resolve(WASM_BINARY).then((data) => base64decode(data)).then((bytes) => WebAssembly.instantiate(bytes, {
                      env: Object.assign({
                        memory: memory.as.object
                      }, SpeedyMatrixWASM.imports(memory))
                    })).then((wasm) => {
                      _instance = wasm.instance;
                      _module = wasm.module;
                      wasm.instance.exports.srand(Date.now() * 1e-3 & 4294967295);
                      _utils_utils__WEBPACK_IMPORTED_MODULE_2__.A.log(`The WebAssembly routines have been loaded!`);
                    }).catch((err) => {
                      throw new _utils_errors__WEBPACK_IMPORTED_MODULE_1__.NO(`Can't load the WebAssembly routines: ${err}`, err);
                    });
                  })(_memory);
                }
              ),
              /***/
              4188: (
                /***/
                (__unused_webpack_module, __webpack_exports__2, __webpack_require__2) => {
                  "use strict";
                  __webpack_require__2.r(__webpack_exports__2);
                  __webpack_require__2.d(__webpack_exports__2, {
                    /* harmony export */
                    SpeedyMatrix: () => (
                      /* binding */
                      SpeedyMatrix
                    )
                    /* harmony export */
                  });
                  var _speedy_matrix_expr__WEBPACK_IMPORTED_MODULE_0__ = __webpack_require__2(6306);
                  var _speedy_matrix_wasm__WEBPACK_IMPORTED_MODULE_1__ = __webpack_require__2(6465);
                  var _speedy_promise__WEBPACK_IMPORTED_MODULE_2__ = __webpack_require__2(9192);
                  var _utils_utils__WEBPACK_IMPORTED_MODULE_3__ = __webpack_require__2(9037);
                  class SpeedyMatrix extends _speedy_matrix_expr__WEBPACK_IMPORTED_MODULE_0__.r {
                    /**
                     * @private
                     * 
                     * Low-level constructor
                     * @param {number} rows number of rows
                     * @param {number} columns number of columns
                     * @param {number} step0 step size between two consecutive elements (e.g., 1)
                     * @param {number} step1 step size between two consecutive columns (e.g., rows)
                     * @param {SpeedyMatrixBufferType} data entries in column-major format
                     */
                    constructor(rows, columns, step0, step1, data) {
                      super(rows, columns, _speedy_matrix_expr__WEBPACK_IMPORTED_MODULE_0__.r.DEFAULT_DTYPE);
                      _utils_utils__WEBPACK_IMPORTED_MODULE_3__.A.assert(data.constructor === _speedy_matrix_expr__WEBPACK_IMPORTED_MODULE_0__.r.BUFFER_TYPE[this.dtype]);
                      _utils_utils__WEBPACK_IMPORTED_MODULE_3__.A.assert(step0 > 0 && step1 >= step0);
                      _utils_utils__WEBPACK_IMPORTED_MODULE_3__.A.assert(
                        data.length + rows * columns === 0 || // empty matrix and empty buffer, or
                        data.length === 1 + step0 * (rows - 1) + step1 * (columns - 1)
                        // correctly sized buffer
                      );
                      this._step0 = step0 | 0;
                      this._step1 = step1 | 0;
                      this._data = data;
                    }
                    /**
                     * Create a new matrix with the specified size and entries
                     * @param {number} rows number of rows
                     * @param {number} columns number of columns
                     * @param {number[]} entries in column-major format
                     * @param {SpeedyMatrixDtype} [dtype] data type
                     * @returns {SpeedyMatrix}
                     */
                    static Create(rows, columns, entries, dtype = _speedy_matrix_expr__WEBPACK_IMPORTED_MODULE_0__.r.DEFAULT_DTYPE) {
                      _utils_utils__WEBPACK_IMPORTED_MODULE_3__.A.assert(rows * columns > 0, `Can't create a matrix without a shape`);
                      _utils_utils__WEBPACK_IMPORTED_MODULE_3__.A.assert(rows * columns === entries.length, `Can't create matrix: expected ${rows * columns} entries, but found ${entries.length}`);
                      _utils_utils__WEBPACK_IMPORTED_MODULE_3__.A.assert(Object.prototype.hasOwnProperty.call(_speedy_matrix_expr__WEBPACK_IMPORTED_MODULE_0__.r.BUFFER_TYPE, dtype), `Invalid dtype: "${dtype}"`);
                      return new SpeedyMatrix(rows, columns, 1, rows, Reflect.construct(_speedy_matrix_expr__WEBPACK_IMPORTED_MODULE_0__.r.BUFFER_TYPE[dtype], [entries]));
                    }
                    /**
                     * Create a new matrix filled with zeros with the specified size
                     * @param {number} rows number of rows
                     * @param {number} [columns] number of columns
                     * @param {SpeedyMatrixDtype} [dtype] data type
                     * @returns {SpeedyMatrix}
                     */
                    static Zeros(rows, columns = rows, dtype = _speedy_matrix_expr__WEBPACK_IMPORTED_MODULE_0__.r.DEFAULT_DTYPE) {
                      _utils_utils__WEBPACK_IMPORTED_MODULE_3__.A.assert(rows * columns > 0, `Can't create a matrix without a shape`);
                      _utils_utils__WEBPACK_IMPORTED_MODULE_3__.A.assert(Object.prototype.hasOwnProperty.call(_speedy_matrix_expr__WEBPACK_IMPORTED_MODULE_0__.r.BUFFER_TYPE, dtype), `Invalid dtype: "${dtype}"`);
                      return new SpeedyMatrix(rows, columns, 1, rows, Reflect.construct(_speedy_matrix_expr__WEBPACK_IMPORTED_MODULE_0__.r.BUFFER_TYPE[dtype], [rows * columns]));
                    }
                    /**
                     * Create a new matrix filled with ones with the specified size
                     * @param {number} rows number of rows
                     * @param {number} [columns] number of columns
                     * @param {SpeedyMatrixDtype} [dtype] data type
                     * @returns {SpeedyMatrix}
                     */
                    static Ones(rows, columns = rows, dtype = _speedy_matrix_expr__WEBPACK_IMPORTED_MODULE_0__.r.DEFAULT_DTYPE) {
                      _utils_utils__WEBPACK_IMPORTED_MODULE_3__.A.assert(rows * columns > 0, `Can't create a matrix without a shape`);
                      _utils_utils__WEBPACK_IMPORTED_MODULE_3__.A.assert(Object.prototype.hasOwnProperty.call(_speedy_matrix_expr__WEBPACK_IMPORTED_MODULE_0__.r.BUFFER_TYPE, dtype), `Invalid dtype: "${dtype}"`);
                      return new SpeedyMatrix(rows, columns, 1, rows, Reflect.construct(_speedy_matrix_expr__WEBPACK_IMPORTED_MODULE_0__.r.BUFFER_TYPE[dtype], [rows * columns]).fill(1));
                    }
                    /**
                     * Create a new identity matrix with the specified size
                     * @param {number} rows number of rows
                     * @param {number} [columns] number of columns
                     * @param {SpeedyMatrixDtype} [dtype] data type
                     * @returns {SpeedyMatrix}
                     */
                    static Eye(rows, columns = rows, dtype = _speedy_matrix_expr__WEBPACK_IMPORTED_MODULE_0__.r.DEFAULT_DTYPE) {
                      _utils_utils__WEBPACK_IMPORTED_MODULE_3__.A.assert(rows * columns > 0, `Can't create a matrix without a shape`);
                      _utils_utils__WEBPACK_IMPORTED_MODULE_3__.A.assert(Object.prototype.hasOwnProperty.call(_speedy_matrix_expr__WEBPACK_IMPORTED_MODULE_0__.r.BUFFER_TYPE, dtype), `Invalid dtype: "${dtype}"`);
                      const data = Reflect.construct(_speedy_matrix_expr__WEBPACK_IMPORTED_MODULE_0__.r.BUFFER_TYPE[dtype], [rows * columns]);
                      for (let j = Math.min(rows, columns) - 1; j >= 0; j--) data[j * rows + j] = 1;
                      return new SpeedyMatrix(rows, columns, 1, rows, data);
                    }
                    /**
                     * Evaluate an expression synchronously and store the result in a new matrix
                     * @param {SpeedyMatrixExpr} expr matrix expression
                     * @returns {SpeedyMatrix}
                     */
                    static From(expr) {
                      return SpeedyMatrix.Zeros(expr.rows, expr.columns, expr.dtype).setToSync(expr);
                    }
                    /**
                     * Returns a promise that resolves immediately if the WebAssembly routines
                     * are ready to be used, or as soon as they do become ready
                     * @returns {SpeedyPromise<void>}
                     */
                    static ready() {
                      return _speedy_matrix_wasm__WEBPACK_IMPORTED_MODULE_1__.U.ready().then((_) => void 0);
                    }
                    /**
                     * Get the underlying buffer
                     * @returns {SpeedyMatrixBufferType}
                     */
                    get data() {
                      return this._data;
                    }
                    /**
                     * Row-step
                     * @returns {number} defaults to 1
                     */
                    get step0() {
                      return this._step0;
                    }
                    /**
                     * Column-step
                     * @returns {number} defaults to this.rows
                     */
                    get step1() {
                      return this._step1;
                    }
                    /**
                     * Extract a block from this matrix. Use a shared underlying buffer
                     * @param {number} firstRow
                     * @param {number} lastRow
                     * @param {number} firstColumn
                     * @param {number} lastColumn
                     * @returns {SpeedyMatrix}
                     */
                    block(firstRow, lastRow, firstColumn, lastColumn) {
                      _utils_utils__WEBPACK_IMPORTED_MODULE_3__.A.assert(firstRow <= lastRow && firstColumn <= lastColumn, `Invalid indices: [${firstRow}:${lastRow},${firstColumn}:${lastColumn}]`);
                      firstRow = Math.max(firstRow, 0);
                      lastRow = Math.min(lastRow, this._rows - 1);
                      firstColumn = Math.max(firstColumn, 0);
                      lastColumn = Math.min(lastColumn, this._columns - 1);
                      const rows = lastRow - firstRow + 1;
                      const columns = lastColumn - firstColumn + 1;
                      const step0 = this._step0, step1 = this._step1;
                      const begin = firstRow * step0 + firstColumn * step1;
                      const end = 1 + lastRow * step0 + lastColumn * step1;
                      return new SpeedyMatrix(rows, columns, step0, step1, this._data.subarray(begin, end));
                    }
                    /**
                     * Extract a row from this matrix
                     * @param {number} index 0-based
                     * @returns {SpeedyMatrix}
                     */
                    row(index) {
                      return this.block(index, index, 0, this._columns - 1);
                    }
                    /**
                     * Extract a column from this matrix
                     * @param {number} index 0-based
                     * @returns {SpeedyMatrix}
                     */
                    column(index) {
                      return this.block(0, this._rows - 1, index, index);
                    }
                    /**
                     * Extract the main diagonal from this matrix
                     * @returns {SpeedyMatrix} as a column-vector
                     */
                    diagonal() {
                      const diagsize = Math.min(this._rows, this._columns);
                      const rows = diagsize;
                      const columns = 1;
                      const diagstep = this._step0 + this._step1;
                      const begin = 0;
                      const end = 1 + (diagsize - 1) * diagstep;
                      return new SpeedyMatrix(rows, columns, diagstep, diagstep, this._data.subarray(begin, end));
                    }
                    /**
                     * Read a single entry of this matrix
                     * @param {number} row 0-based index
                     * @param {number} column 0-based index
                     * @returns {number}
                     */
                    at(row, column) {
                      if (row >= 0 && row < this._rows && column >= 0 && column < this._columns) return this._data[this._step0 * row + this._step1 * column];
                      else return Number.NaN;
                    }
                    /**
                     * Read the entries of the matrix in column-major format
                     * @returns {number[]}
                     */
                    read() {
                      const entries = new Array(this._rows * this._columns);
                      const step0 = this._step0, step1 = this._step1;
                      let i = 0;
                      for (let column = 0; column < this._columns; column++) {
                        for (let row = 0; row < this._rows; row++) entries[i++] = this._data[row * step0 + column * step1];
                      }
                      return entries;
                    }
                    /**
                     * Returns a human-readable string representation of the matrix
                     * @returns {string}
                     */
                    toString() {
                      const DECIMALS = 5;
                      const rows = this.rows, columns = this.columns;
                      const entries = this.read();
                      const mat = (
                        /** @type {number[][]} */
                        new Array(rows)
                      );
                      for (let i = 0; i < rows; i++) {
                        mat[i] = new Array(columns);
                        for (let j = 0; j < columns; j++) mat[i][j] = entries[j * rows + i];
                      }
                      const fix = (x) => x.toFixed(DECIMALS);
                      const fmt = mat.map((row) => "    " + row.map(fix).join(", ")).join(",\n");
                      const str = `SpeedyMatrix(rows=${rows}, columns=${columns}, data=[
${fmt}
])`;
                      return str;
                    }
                    /**
                     * Set the contents of this matrix to the result of an expression
                     * @param {SpeedyMatrixExpr} expr matrix expression
                     * @returns {SpeedyPromise<SpeedyMatrix>} resolves to this
                     */
                    setTo(expr) {
                      return _speedy_matrix_wasm__WEBPACK_IMPORTED_MODULE_1__.U.ready().then((_) => {
                        return this.setToSync(expr);
                      });
                    }
                    /**
                     * Synchronously set the contents of this matrix to the result of an expression
                     * @param {SpeedyMatrixExpr} expr matrix expression
                     * @returns {SpeedyMatrix} this
                     */
                    setToSync(expr) {
                      const {
                        wasm,
                        memory
                      } = _speedy_matrix_wasm__WEBPACK_IMPORTED_MODULE_1__.U.handle;
                      const result = expr._evaluate(wasm, memory);
                      _utils_utils__WEBPACK_IMPORTED_MODULE_3__.A.assert(this._rows === result._rows && this._columns === result._columns && this.dtype === result.dtype, `Can't set the values of a ${this.rows} x ${this.columns} ${this.dtype} matrix to those of a ${result.rows} x ${result.columns} ${result.dtype} matrix`);
                      const step0 = this._step0, step1 = this._step1, rstep0 = result._step0, rstep1 = result._step1;
                      if (step0 === rstep0 && step1 === rstep1 && this._data.length === result._data.length) {
                        this._data.set(result._data);
                      } else {
                        for (let column = this._columns - 1; column >= 0; column--) {
                          for (let row = this._rows - 1; row >= 0; row--) this._data[row * step0 + column * step1] = result._data[row * rstep0 + column * rstep1];
                        }
                      }
                      return this;
                    }
                    /**
                     * Fill this matrix with a scalar value
                     * @param {number} value
                     * @returns {SpeedyPromise<SpeedyMatrix>} resolves to this
                     */
                    fill(value) {
                      this.fillSync(value);
                      return _speedy_promise__WEBPACK_IMPORTED_MODULE_2__.i.resolve(this);
                    }
                    /**
                     * Synchronously fill this matrix with a scalar value
                     * @param {number} value
                     * @returns {SpeedyMatrix} this
                     */
                    fillSync(value) {
                      value = +value;
                      if (this._rows * this._columns === this._data.length) {
                        this._data.fill(value);
                        return this;
                      }
                      for (let column = 0; column < this._columns; column++) {
                        for (let row = 0; row < this._rows; row++) {
                          this._data[row * this._step0 + column * this._step1] = value;
                        }
                      }
                      return this;
                    }
                    /**
                     * Evaluate this expression
                     * @param {WebAssembly.Instance} wasm
                     * @param {SpeedyMatrixWASMMemory} memory
                     * @returns {SpeedyMatrix}
                     */
                    _evaluate(wasm, memory) {
                      return this;
                    }
                  }
                }
              ),
              /***/
              6634: (
                /***/
                (__unused_webpack_module, __webpack_exports__2, __webpack_require__2) => {
                  "use strict";
                  __webpack_require__2.d(__webpack_exports__2, {
                    /* harmony export */
                    Q: () => (
                      /* binding */
                      SpeedyNamespace
                    )
                    /* harmony export */
                  });
                  var _utils_errors__WEBPACK_IMPORTED_MODULE_0__ = __webpack_require__2(8581);
                  class SpeedyNamespace {
                    /**
                     * Namespaces can't be instantiated.
                     * Only static methods are allowed.
                     * @abstract
                     * @throws SpeedyError
                     */
                    constructor() {
                      throw new _utils_errors__WEBPACK_IMPORTED_MODULE_0__.aQ(`Namespaces can't be instantiated`);
                    }
                  }
                }
              ),
              /***/
              9192: (
                /***/
                (__unused_webpack_module, __webpack_exports__2, __webpack_require__2) => {
                  "use strict";
                  __webpack_require__2.d(__webpack_exports__2, {
                    /* harmony export */
                    i: () => (
                      /* binding */
                      SpeedyPromise
                    )
                    /* harmony export */
                  });
                  const PENDING = 0;
                  const FULFILLED = 1;
                  const REJECTED = 2;
                  const SUSPEND_ASYNC = 1;
                  const asap2 = typeof queueMicrotask !== "undefined" && queueMicrotask || // browsers
                  typeof process !== "undefined" && process.nextTick || // node.js
                  ((f) => Promise.resolve().then(() => f()));
                  class SpeedyPromise {
                    /**
                     * Constructor
                     * @param {function(function(T=): void, function(Error): void): void} callback
                     */
                    constructor(callback) {
                      this._state = PENDING;
                      this._value = void 0;
                      this._onFulfillment = null;
                      this._onRejection = null;
                      this._children = 0;
                      this[0] = this;
                      this._parent = void 0;
                      this._flags = 0;
                      this._fulfill = this._fulfill.bind(this);
                      this._reject = this._reject.bind(this);
                      this._resolve = this._resolve.bind(this);
                      this._broadcastIfAsync = this._broadcastIfAsync.bind(this);
                      callback(this._fulfill, this._reject);
                    }
                    /**
                     * Setup handlers
                     * @template U, V=never
                     * @param {null|undefined|(function(T): U|PromiseLike<U>|SpeedyPromise<U>)} onFulfillment called when the SpeedyPromise is fulfilled
                     * @param {null|undefined|(function(Error): V|PromiseLike<V>|SpeedyPromise<V>)} [onRejection] called when the SpeedyPromise is rejected
                     * @returns {SpeedyPromise<U>}
                     */
                    then(onFulfillment, onRejection = null) {
                      const child = new SpeedyPromise(this._nop);
                      child._onFulfillment = typeof onFulfillment === "function" && onFulfillment;
                      child._onRejection = typeof onRejection === "function" && onRejection;
                      child._parent = this;
                      this[this._children++] = child;
                      this._flags &= ~SUSPEND_ASYNC;
                      this._notify();
                      return child;
                    }
                    /**
                     * Setup rejection handler
                     * @template U, V=never
                     * @param {null|undefined|(function(Error): V|PromiseLike<V>|SpeedyPromise<V>)} [onRejection] called when the SpeedyPromise is rejected
                     * @returns {SpeedyPromise<V>}
                     */
                    catch(onRejection) {
                      return this.then(null, onRejection);
                    }
                    /**
                     * Execute a callback when the promise is settled
                     * (i.e., fulfilled or rejected)
                     * @param {function(): void} onFinally
                     * @returns {SpeedyPromise<T>}
                     */
                    finally(onFinally) {
                      const fn = (val) => {
                        onFinally();
                        return val;
                      };
                      return this.then(fn, fn);
                    }
                    /**
                     * Start the computation immediately, synchronously.
                     * Can't afford to spend any time at all waiting for micro-tasks, etc.
                     * @returns {SpeedyPromise<T>} this
                     */
                    turbocharge() {
                      let my = this;
                      this._flags |= SUSPEND_ASYNC;
                      while (my._parent !== void 0) {
                        my = my._parent;
                        my._flags |= SUSPEND_ASYNC;
                      }
                      my._notify();
                      return this;
                    }
                    /**
                     * Convert to string
                     * @returns {string}
                     */
                    toString() {
                      switch (this._state) {
                        case PENDING:
                          return `SpeedyPromise { <pending> }`;
                        case FULFILLED:
                          return `SpeedyPromise { <fulfilled> ${this._value} }`;
                        case REJECTED:
                          return `SpeedyPromise { <rejected> ${this._value} }`;
                        default:
                          return "";
                      }
                    }
                    /**
                     * Symbol.toStringTag
                     * @returns {string}
                     */
                    get [Symbol.toStringTag]() {
                      return "SpeedyPromise";
                    }
                    /**
                     * Creates a resolved SpeedyPromise
                     * @template U
                     * @param {U} [value]
                     * @returns {SpeedyPromise<U>}
                     */
                    static resolve(value) {
                      const promise = new SpeedyPromise(this._snop);
                      if (typeof value === "object" && value !== null && "then" in value || typeof value === "function" && "then" in value) {
                        promise._resolve(value);
                      } else {
                        promise._value = value;
                        promise._state = FULFILLED;
                      }
                      return promise;
                    }
                    /**
                     * Creates a rejected SpeedyPromise
                     * @template U
                     * @param {Error} reason
                     * @returns {SpeedyPromise<U>}
                     */
                    static reject(reason) {
                      const promise = new SpeedyPromise(this._snop);
                      promise._value = reason;
                      promise._state = REJECTED;
                      return promise;
                    }
                    /**
                     * Returns a SpeedyPromise that resolves to an array
                     * containing the results of the input promises/values,
                     * in their given order. The returned SpeedyPromise will
                     * resolve if all input promises resolve, or reject if
                     * any input promise rejects.
                     * @template U
                     * @param {Iterable<U>|Iterable<SpeedyPromise<U>>|Iterable<Promise<U>>} iterable e.g., a SpeedyPromise[], a thenable[]
                     * @returns {SpeedyPromise<U[]>}
                     *
                     * FIXME iterables need not be all <U>
                     */
                    static all(iterable) {
                      return new SpeedyPromise((resolve, reject) => {
                        const input = [];
                        for (const element of iterable) input.push(element);
                        const length = input.length;
                        if (length == 0) {
                          resolve([]);
                          return;
                        }
                        let counter = length;
                        const output = new Array(length);
                        const partialResolve = (i) => (val) => {
                          output[i] = val;
                          if (0 == --counter) resolve(output);
                        };
                        for (let i = 0; i < length; i++) {
                          const element = input[i];
                          if (element.__proto__ === SpeedyPromise.prototype || element.__proto__ === Promise.prototype) element.then(partialResolve(i), reject);
                          else SpeedyPromise.resolve(element).then(partialResolve(i), reject);
                        }
                      });
                    }
                    /**
                     * Returns a promise that gets fulfilled or rejected as soon
                     * as the first promise in the iterable gets fulfilled or
                     * rejected (with its value/reason).
                     * @template U
                     * @param {Iterable<U>|Iterable<SpeedyPromise<U>>|Iterable<Promise<U>>} iterable e.g., a SpeedyPromise[], a thenable[]
                     * @returns {SpeedyPromise<U>}
                     */
                    static race(iterable) {
                      return new SpeedyPromise((resolve, reject) => {
                        const input = [];
                        for (const element of iterable) input.push(element);
                        const length = input.length;
                        for (let i = 0; i < length; i++) {
                          const element = input[i];
                          if (element.__proto__ === SpeedyPromise.prototype || element.__proto__ === Promise.prototype) element.then(resolve, reject);
                          else SpeedyPromise.resolve(element).then(resolve, reject);
                        }
                      });
                    }
                    /**
                     * Fulfill this promise with a value
                     * @param {T} value
                     */
                    _fulfill(value) {
                      this._setState(FULFILLED, value);
                    }
                    /**
                     * Reject this promise with a reason
                     * @param {Error} reason
                     */
                    _reject(reason) {
                      this._setState(REJECTED, reason);
                    }
                    /**
                     * Set the state and the value of this promise
                     * @param {number} state
                     * @param {T|Error} value
                     */
                    _setState(state, value) {
                      if (this._state != PENDING) return;
                      this._state = state;
                      this._value = value;
                      this._notify();
                    }
                    /**
                     * Notify my children that this promise is no
                     * longer pending. This is an async operation:
                     * my childen will be notified "as soon
                     * as possible" (it will be scheduled).
                     * We may force this to be synchronous, though
                     */
                    _notify() {
                      if (this._state == PENDING) return;
                      if (this._flags & SUSPEND_ASYNC) {
                        this._broadcast();
                        return;
                      }
                      asap2(this._broadcastIfAsync);
                    }
                    /**
                     * Helper method
                     */
                    _broadcastIfAsync() {
                      if (!(this._flags & SUSPEND_ASYNC)) this._broadcast();
                    }
                    /**
                     * Tell my children that this promise
                     * is either fulfilled or rejected.
                     * This is a synchronous operation
                     */
                    _broadcast() {
                      const children = this._children;
                      const state = this._state;
                      if (state === FULFILLED) {
                        for (let i = 0; i < children; i++) {
                          const child = this[i];
                          const callback = child._onFulfillment;
                          try {
                            if (callback) {
                              if (callback !== child._nop) {
                                child._resolve(callback(this._value));
                                child._onFulfillment = child._nop;
                              }
                            } else child._fulfill(this._value);
                          } catch (e) {
                            child._reject(e);
                          }
                        }
                      } else if (state === REJECTED) {
                        for (let i = 0; i < children; i++) {
                          const child = this[i];
                          const callback = child._onRejection;
                          try {
                            if (callback) {
                              if (callback !== child._nop) {
                                child._resolve(callback(this._value));
                                child._onRejection = child._nop;
                              }
                            } else child._reject(this._value);
                          } catch (e) {
                            child._reject(e);
                          }
                        }
                      }
                    }
                    /**
                     * Promise Resolution Procedure
                     * based on the Promises/A+ spec
                     * @param {T} x
                     */
                    _resolve(x) {
                      if (typeof x !== "object" && typeof x !== "function" || x === null) {
                        this._fulfill(x);
                        return;
                      }
                      if (x === this) throw new TypeError();
                      if (x.__proto__ === SpeedyPromise.prototype || x.__proto__ === Promise.prototype) {
                        x.then(this._resolve, this._reject);
                        return;
                      }
                      try {
                        const then = x.then;
                        if (typeof then === "function") {
                          let resolve = this._resolve, reject = this._reject;
                          try {
                            then.call(x, (y) => {
                              resolve(y);
                              resolve = reject = this._nop;
                            }, (r) => {
                              reject(r);
                              resolve = reject = this._nop;
                            });
                          } catch (e) {
                            if (resolve !== this._nop && reject !== this._nop) this._reject(e);
                          }
                        } else {
                          this._fulfill(x);
                        }
                      } catch (e) {
                        this._reject(e);
                      }
                    }
                    /**
                     * No-operation
                     */
                    _nop() {
                    }
                    /**
                     * Static no-operation
                     */
                    static _snop() {
                    }
                  }
                }
              ),
              /***/
              9420: (
                /***/
                (__unused_webpack_module, __webpack_exports__2, __webpack_require__2) => {
                  "use strict";
                  __webpack_require__2.d(__webpack_exports__2, {
                    gx: () => (
                      /* binding */
                      createShader
                    ),
                    bf: () => (
                      /* binding */
                      importShader
                    )
                  });
                  var speedy_gl = __webpack_require__2(1001);
                  var utils = __webpack_require__2(9037);
                  var types = __webpack_require__2(6049);
                  var errors = __webpack_require__2(8581);
                  ;
                  function _wrapRegExp() {
                    _wrapRegExp = function(e2, r2) {
                      return new BabelRegExp(e2, void 0, r2);
                    };
                    var e = RegExp.prototype, r = /* @__PURE__ */ new WeakMap();
                    function BabelRegExp(e2, t, p) {
                      var o = RegExp(e2, t);
                      return r.set(o, p || r.get(e2)), _setPrototypeOf(o, BabelRegExp.prototype);
                    }
                    function buildGroups(e2, t) {
                      var p = r.get(t);
                      return Object.keys(p).reduce(function(r2, t2) {
                        var o = p[t2];
                        if ("number" == typeof o) r2[t2] = e2[o];
                        else {
                          for (var i = 0; void 0 === e2[o[i]] && i + 1 < o.length; ) i++;
                          r2[t2] = e2[o[i]];
                        }
                        return r2;
                      }, /* @__PURE__ */ Object.create(null));
                    }
                    return _inherits(BabelRegExp, RegExp), BabelRegExp.prototype.exec = function(r2) {
                      var t = e.exec.call(this, r2);
                      if (t) {
                        t.groups = buildGroups(t, this);
                        var p = t.indices;
                        p && (p.groups = buildGroups(p, this));
                      }
                      return t;
                    }, BabelRegExp.prototype[Symbol.replace] = function(t, p) {
                      if ("string" == typeof p) {
                        var o = r.get(this);
                        return e[Symbol.replace].call(this, t, p.replace(/\$<([^>]+)>/g, function(e2, r2) {
                          var t2 = o[r2];
                          return "$" + (Array.isArray(t2) ? t2.join("$") : t2);
                        }));
                      }
                      if ("function" == typeof p) {
                        var i = this;
                        return e[Symbol.replace].call(this, t, function() {
                          var e2 = arguments;
                          return "object" != typeof e2[e2.length - 1] && (e2 = [].slice.call(e2)).push(buildGroups(e2, i)), p.apply(this, e2);
                        });
                      }
                      return e[Symbol.replace].call(this, t, p);
                    }, _wrapRegExp.apply(this, arguments);
                  }
                  function _inherits(t, e) {
                    if ("function" != typeof e && null !== e) throw new TypeError("Super expression must either be null or a function");
                    t.prototype = Object.create(e && e.prototype, { constructor: { value: t, writable: true, configurable: true } }), Object.defineProperty(t, "prototype", { writable: false }), e && _setPrototypeOf(t, e);
                  }
                  function _setPrototypeOf(t, e) {
                    return _setPrototypeOf = Object.setPrototypeOf ? Object.setPrototypeOf.bind() : function(t2, e2) {
                      return t2.__proto__ = e2, t2;
                    }, _setPrototypeOf(t, e);
                  }
                  const globals = __webpack_require__2(3816);
                  const numericGlobals = (
                    /** @type {ShaderPreprocessorTemplateOfConstants} */
                    Object.keys(globals).filter((key) => typeof globals[key] == "number").reduce((obj, key) => (obj[key] = globals[key], obj), {})
                  );
                  const basicConstants = Object.freeze(Object.assign(Object.assign({}, numericGlobals), {}, {
                    // fragment shader
                    "FS_USE_CUSTOM_PRECISION": 0,
                    // use default precision settings
                    "FS_OUTPUT_TYPE": 0,
                    // normalized RGBA
                    // colors
                    "PIXELCOMPONENT_RED": types.kQ.RED,
                    "PIXELCOMPONENT_GREEN": types.kQ.GREEN,
                    "PIXELCOMPONENT_BLUE": types.kQ.BLUE,
                    "PIXELCOMPONENT_ALPHA": types.kQ.ALPHA
                  }));
                  const platformConstants = (platform, glRenderer) => Object.freeze({
                    "APPLE": /(Mac|iOS|iPhone|iPad|iPod)/i.test(platform) | 0,
                    // "MacIntel", "macOS", "iOS", "iPhone", "iPad"...
                    "APPLE_GPU": /Apple/.test(glRenderer) | 0,
                    // the renderer is always "Apple GPU" on Safari and on Epiphany at the time of this writing; on Chrome, it may be "Apple M1" for example...
                    "INTEL_GRAPHICS": /Intel.*Graphics/.test(glRenderer) | 0
                    // Intel[(R)] ... [HD] Graphics xyz ...
                  });
                  const commentsRegex = [/\/\*(.|\s)*?\*\//g, /\/\/.*$/gm];
                  const includeRegex = /^\s*@\s*include\s+"(.*?)"/gm;
                  const constantRegex = /@(\w+)@/g;
                  const unrollRegex = [/* @__PURE__ */ _wrapRegExp(/@\s*unroll\s+?for\s*\(\s*(int|)\s*(\w+)\s*=\s*(\x2D?\d+|\w+)\s*;\s*\2\s*(<=?)\s*(\x2D?\d+|\w+)\s*;\s*\2\s*\+\+()\s*\)\s*\{\s*([\s\S]+?)\s*\}/g, {
                    counter: 2
                  }), /* @__PURE__ */ _wrapRegExp(/@\s*unroll\s+?for\s*\(\s*(int|)\s*(\w+)\s*=\s*(\x2D?\d+|\w+)\s*;\s*\2\s*(<=?)\s*(\x2D?\d+|\w+)\s*;\s*\2\s*\+=\s*(\x2D?\d+)\s*\)\s*\{\s*([\s\S]+?)\s*\}/g, {
                    counter: 2
                  })];
                  class ShaderPreprocessor {
                    /**
                     * Runs the preprocessor and generates GLSL code
                     * @param {ShaderPreprocessorConstants} defines user-provided preprocessor constants for this shader
                     * @param {string} infix annotated GLSL code
                     * @param {string} [prefix]
                     * @param {string} [suffix]
                     * @returns {string} preprocessed GLSL code
                     */
                    static generateGLSL(defines, infix, prefix = null, suffix = null) {
                      const errors2 = [];
                      const constants = generateConstants(defines);
                      const annotatedGLSL = generateUnprocessedGLSL(defines, infix, prefix, suffix);
                      return unrollLoops(annotatedGLSL.replace(commentsRegex[0], "").replace(commentsRegex[1], "").replace(constantRegex, (_, name) => String(
                        // Replace preprocessor @CONSTANTS@ by their numeric values
                        constants.has(name) ? Number(constants.get(name)) : (errors2.push(`Undefined constant ${name}`), 0)
                      )).replace(includeRegex, (_, filename) => (
                        // Included files may include other files.
                        // XXX no cycle detection!
                        ShaderPreprocessor.generateGLSL(defines, readfileSync(filename))
                      )), defines) + errors2.map((msg) => `
#error ${msg}
`).join("");
                    }
                  }
                  function generateUnprocessedGLSL(defines, infix, prefix = null, suffix = null) {
                    const parts = [];
                    if (prefix !== null) parts.push(prefix);
                    for (const [key, value] of defines) parts.push(`#define ${key} ${Number(value)}`);
                    parts.push(infix);
                    if (suffix !== null) parts.push(suffix);
                    return parts.join("\n");
                  }
                  function generateConstants(defines) {
                    utils.A.assert(speedy_gl.c.isInitialized());
                    const myConstants = (
                      /** @type {ShaderPreprocessorConstants} */
                      /* @__PURE__ */ new Map()
                    );
                    const globalConstants = Object.assign(/* @__PURE__ */ Object.create(null), basicConstants, platformConstants(utils.A.platformString(), speedy_gl.c.instance.renderer));
                    for (const key in globalConstants) {
                      myConstants.set(key, globalConstants[key]);
                    }
                    for (const [key, value] of defines) myConstants.set(key, value);
                    return myConstants;
                  }
                  function readfileSync(filename) {
                    if (String(filename).match(/^[a-zA-Z0-9_-]+\.glsl$/)) return __webpack_require__2(5235)("./" + filename);
                    throw new errors.kG(`Shader preprocessor: can't read file "${filename}"`);
                  }
                  function unrollLoops(code, defines) {
                    const fn = unroll.bind(defines);
                    const n = unrollRegex.length;
                    for (let i = 0; i < n; i++) code = code.replace(unrollRegex[i], fn);
                    return code;
                  }
                  function unroll(match, type, counter, start, cmp, end, step, loopcode) {
                    const defines = (
                      /** @type {ShaderPreprocessorConstants} */
                      this
                    );
                    const hasStart = Number.isFinite(+start) || defines.has(start);
                    const hasEnd = Number.isFinite(+end) || defines.has(end);
                    if (!hasStart || !hasEnd) {
                      if (defines.size > 0) throw new errors.mB(`Can't unroll loop: unknown limits (start=${start}, end=${end}). Code:

${match}`);
                      else return match;
                    }
                    let istart = defines.has(start) ? defines.get(start) : parseInt(start);
                    let iend = defines.has(end) ? defines.get(end) : parseInt(end);
                    let istep = step.length == 0 ? 1 : parseInt(step);
                    utils.A.assert(istart <= iend && istep > 0);
                    const hasBreak = loopcode.match(/\bbreak\s*;/) !== null;
                    let unrolledCode = hasBreak ? "switch(1) { default:\n" : "{\n";
                    unrolledCode += `${type} ${counter};
`;
                    iend += cmp == "<=" ? 1 : 0;
                    for (let i = istart; i < iend; i += istep) unrolledCode += `{
${counter} = ${i};
${loopcode}
}
`;
                    unrolledCode += "}\n";
                    return unrolledCode;
                  }
                  ;
                  const DEFAULT_ATTRIBUTES = Object.freeze({
                    position: "a_position",
                    texCoord: "a_texCoord"
                  });
                  const DEFAULT_ATTRIBUTES_LOCATION = Object.freeze({
                    position: 0,
                    // use location 0; see https://developer.mozilla.org/en-US/docs/Web/API/WebGL_API/WebGL_best_practices
                    texCoord: 1
                  });
                  const DEFAULT_VERTEX_SHADER_PREFIX = `#version 300 es
precision highp float;
precision highp int;

layout (location=${DEFAULT_ATTRIBUTES_LOCATION.position}) in vec2 ${DEFAULT_ATTRIBUTES.position};
layout (location=${DEFAULT_ATTRIBUTES_LOCATION.texCoord}) in vec2 ${DEFAULT_ATTRIBUTES.texCoord};
out highp vec2 texCoord;
uniform highp vec2 texSize;

#define vsinit() gl_Position = vec4(${DEFAULT_ATTRIBUTES.position}, 0.0f, 1.0f); texCoord = ${DEFAULT_ATTRIBUTES.texCoord};


`;
                  const DEFAULT_VERTEX_SHADER = `#define vsmain() ;`;
                  const DEFAULT_VERTEX_SHADER_SUFFIX = `

void main() { vsinit(); vsmain(); }
`;
                  const DEFAULT_FRAGMENT_SHADER_PREFIX = `#version 300 es

#if @FS_USE_CUSTOM_PRECISION@ == 0
precision mediump float; // ~float16
precision mediump sampler2D;
precision highp int; // int32
#endif

#if @FS_OUTPUT_TYPE@ == 0
#define OUT_TYPE mediump vec4
#elif @FS_OUTPUT_TYPE@ == 1
#define OUT_TYPE mediump ivec4
#elif @FS_OUTPUT_TYPE@ == 2
#define OUT_TYPE mediump uvec4
#else
#error Unknown FS_OUTPUT_TYPE
#endif

out OUT_TYPE color;
in highp vec2 texCoord;
uniform highp vec2 texSize;

@include "global.glsl"

`;
                  const PRIVATE_TOKEN = Symbol();
                  class ShaderDeclaration {
                    /**
                     * @private Constructor
                     * @param {Symbol} privateToken
                     * @param {ShaderDeclarationArgumentList} argumentList
                     * @param {ShaderDeclarationPreprocessorConstants} defines
                     * @param {ShaderDeclarationUnprocessedGLSL} fsSource unprocessed GLSL code of the fragment shader
                     * @param {ShaderDeclarationUnprocessedGLSL} vsSource unprocessed GLSL code of the vertex shader
                     */
                    constructor(privateToken, argumentList, defines, fsSource, vsSource) {
                      if (privateToken !== PRIVATE_TOKEN) throw new errors.Er();
                      this._arguments = [...argumentList];
                      this._defines = new Map(defines);
                      this._fragmentSource = ShaderPreprocessor.generateGLSL(this._defines, fsSource, DEFAULT_FRAGMENT_SHADER_PREFIX);
                      this._vertexSource = ShaderPreprocessor.generateGLSL(this._defines, vsSource, DEFAULT_VERTEX_SHADER_PREFIX, DEFAULT_VERTEX_SHADER_SUFFIX);
                      this._uniforms = this._autodetectUniforms(this._fragmentSource + "\n" + this._vertexSource);
                      this._validateArguments(this._arguments, this._uniforms);
                    }
                    /**
                     * Return the preprocessed GLSL source code of the fragment shader
                     * @returns {string}
                     */
                    get fragmentSource() {
                      return this._fragmentSource;
                    }
                    /**
                     * Return the preprocessed GLSL source code of the vertex shader
                     * @returns {string}
                     */
                    get vertexSource() {
                      return this._vertexSource;
                    }
                    /**
                     * Get the names of the vertex shader attributes
                     * @returns {typeof DEFAULT_ATTRIBUTES}
                     */
                    get attributes() {
                      return DEFAULT_ATTRIBUTES;
                    }
                    /**
                     * Get the pre-defined locations of the vertex shader attributes
                     * @returns {typeof DEFAULT_ATTRIBUTES_LOCATION}
                     */
                    get locationOfAttributes() {
                      return DEFAULT_ATTRIBUTES_LOCATION;
                    }
                    /**
                     * Names of the arguments that will be passed to the Shader,
                     * corresponding to GLSL uniforms, in the order they will be passed
                     * @returns {string[]}
                     */
                    get arguments() {
                      return [].concat(this._arguments);
                    }
                    /**
                     * Names of the uniforms declared in the shader
                     * @returns {string[]}
                     */
                    get uniforms() {
                      return Array.from(this._uniforms.keys());
                    }
                    /**
                     * The GLSL type of a uniform variable declared in the shader
                     * @param {string} name
                     * @returns {string}
                     */
                    uniformType(name) {
                      if (!this._uniforms.has(name)) throw new errors.qw(`Unrecognized uniform variable: "${name}"`);
                      return this._uniforms.get(name);
                    }
                    /**
                     * The value of an externally defined constant, i.e., via withDefines()
                     * @param {string} name 
                     * @returns {number}
                     */
                    definedConstant(name) {
                      if (!this._defines.has(name)) throw new errors.qw(`Unrecognized externally defined constant: "${name}"`);
                      return this._defines.get(name);
                    }
                    /**
                     * Parses a GLSL source and detects the uniform variables,
                     * as well as their types
                     * @param {string} preprocessedSource 
                     * @returns {ShaderDeclarationUniformTypes} specifies the types of all uniforms
                     */
                    _autodetectUniforms(preprocessedSource) {
                      const sourceWithoutComments = preprocessedSource;
                      const regex = /^\s*uniform\s+(highp\s+|mediump\s+|lowp\s+)?(\w+)\s+([^;]+)/gm;
                      const uniforms = (
                        /** @type {ShaderDeclarationUniformTypes} */
                        /* @__PURE__ */ new Map()
                      );
                      let match;
                      while ((match = regex.exec(sourceWithoutComments)) !== null) {
                        const type = match[2];
                        const names = match[3].split(",").map((name) => name.trim()).filter((name) => name);
                        for (const name of names) {
                          if (name.endsWith("]")) {
                            if (!(match = name.match(/(\w+)\s*\[\s*(\d+)\s*\]$/))) throw new errors.mB(`Unspecified array length for uniform "${name}" in the shader`);
                            const [array, size] = [match[1], Number(match[2])];
                            for (let i = 0; i < size; i++) uniforms.set(`${array}[${i}]`, type);
                          } else {
                            if (!uniforms.has(name) || uniforms.get(name) === type) uniforms.set(name, type);
                            else throw new errors.Er(`Redefinition of uniform "${name}" in the shader`);
                          }
                        }
                      }
                      return uniforms;
                    }
                    /**
                     * Checks if all the arguments of the shader declaration are backed by a
                     * uniform variable in GLSL code
                     * @param {ShaderDeclarationArgumentList} argumentList
                     * @param {ShaderDeclarationUniformTypes} uniforms
                     * @throws {IllegalArgumentError}
                     */
                    _validateArguments(argumentList, uniforms) {
                      for (const argname of argumentList) {
                        if (!uniforms.has(argname)) {
                          if (!uniforms.has(argname + "[0]")) throw new errors.qw(`Argument "${argname}" has not been declared in the shader`);
                        }
                      }
                    }
                  }
                  class MemoryShaderDeclaration extends ShaderDeclaration {
                    /**
                     * @private Constructor
                     * @param {Symbol} privateToken
                     * @param {ShaderDeclarationArgumentList} argumentList
                     * @param {ShaderDeclarationPreprocessorConstants} defines
                     * @param {ShaderDeclarationUnprocessedGLSL} fsSource unprocessed GLSL code of the fragment shader
                     * @param {ShaderDeclarationUnprocessedGLSL} [vsSource] unprocessed GLSL code of the vertex shader
                     */
                    constructor(privateToken, argumentList, defines, fsSource, vsSource = DEFAULT_VERTEX_SHADER) {
                      super(privateToken, argumentList, defines, fsSource, vsSource);
                      this._fsUnprocessedSource = String(fsSource);
                      this._vsUnprocessedSource = String(vsSource);
                    }
                  }
                  class FileShaderDeclaration extends ShaderDeclaration {
                    /**
                     * @private Constructor
                     * @param {Symbol} privateToken
                     * @param {ShaderDeclarationArgumentList} argumentList
                     * @param {ShaderDeclarationPreprocessorConstants} defines
                     * @param {string} fsFilepath path to the file of the unprocessed GLSL code of the fragment shader
                     * @param {string} [vsFilepath] path to the file of the unprocessed GLSL code of the vertex shader
                     */
                    constructor(privateToken, argumentList, defines, fsFilepath, vsFilepath = "") {
                      if (!String(fsFilepath).match(/^[a-zA-Z0-9_\-/]+\.glsl$/)) throw new errors.kG(`Can't import fragment shader at "${fsFilepath}"`);
                      else if (vsFilepath != "" && !String(vsFilepath).match(/^[a-zA-Z0-9_\-/]+\.vs\.glsl$/)) throw new errors.kG(`Can't import vertex shader at "${vsFilepath}"`);
                      const fsSource = __webpack_require__2(4606)("./" + String(fsFilepath));
                      const vsSource = vsFilepath != "" ? __webpack_require__2(4606)("./" + String(vsFilepath)) : DEFAULT_VERTEX_SHADER;
                      super(privateToken, argumentList, defines, fsSource, vsSource);
                      this._fsFilepath = String(fsFilepath);
                      this._vsFilepath = String(vsFilepath);
                    }
                    /**
                     * Return the preprocessed GLSL source code of the fragment shader
                     * @returns {string}
                     */
                    get fragmentSource() {
                      return this._addHeader("// File: " + this._fsFilepath, super.fragmentSource);
                    }
                    /**
                     * Return the preprocessed GLSL source code of the vertex shader
                     * @returns {string}
                     */
                    get vertexSource() {
                      return this._addHeader("// File: " + (this._vsFilepath != "" ? this._vsFilepath : "(default-vs) " + this._fsFilepath), super.vertexSource);
                    }
                    /**
                     * Add a header to a GLSL code
                     * @param {string} header code to be added
                     * @param {string} src pre-processed GLSL code
                     * @returns {string} src with an added header
                     */
                    _addHeader(header, src) {
                      utils.A.assert(header.startsWith("//") && !header.includes("\n"));
                      const j = src.indexOf("\n");
                      const versionDirective = src.substr(0, j);
                      const body = src.substr(j);
                      utils.A.assert(versionDirective.startsWith("#version "));
                      const head = versionDirective + "\n" + header;
                      return head + body;
                    }
                  }
                  class ShaderDeclarationBuilder {
                    /**
                     * @private Constructor
                     * @param {Symbol} privateToken
                     */
                    constructor(privateToken) {
                      if (privateToken !== PRIVATE_TOKEN) throw new errors.Er();
                      this._arguments = [];
                      this._defines = /* @__PURE__ */ new Map();
                    }
                    /**
                     * Specify the list & order of arguments to be
                     * passed to the shader
                     * @param  {string[]} args argument names
                     * @returns {this}
                     */
                    withArguments(...args2) {
                      if (this._arguments.length > 0) throw new errors.Er(`Redefinition of shader arguments`);
                      for (let j = 0; j < args2.length; j++) this._arguments.push(String(args2[j]));
                      return this;
                    }
                    /**
                     * Specify a set of #defines to be prepended to the shader
                     * @param {Object<string,number>} defines key-value pairs
                     * @returns {this}
                     */
                    withDefines(defines) {
                      if (this._defines.size > 0) throw new errors.Er(`Redefinition of externally defined constants of a shader`);
                      const keys = Object.keys(defines);
                      for (const key of keys) {
                        const value = Number(defines[key]);
                        this._defines.set(key, value);
                      }
                      return this;
                    }
                    /**
                     * Build a ShaderDeclaration
                     * @returns {ShaderDeclaration}
                     */
                    build() {
                      throw new errors.aQ();
                    }
                  }
                  class MemoryShaderDeclarationBuilder extends ShaderDeclarationBuilder {
                    /**
                     * @private Constructor
                     * @param {Symbol} privateToken
                     * @param {ShaderDeclarationUnprocessedGLSL} fsSource
                     * @param {ShaderDeclarationUnprocessedGLSL} [vsSource]
                     */
                    constructor(privateToken, fsSource, vsSource) {
                      super(privateToken);
                      this._fsSource = String(fsSource);
                      this._vsSource = vsSource !== void 0 ? String(vsSource) : void 0;
                    }
                    /**
                     * Build a MemoryShaderDeclaration
                     * @returns {ShaderDeclaration}
                     */
                    build() {
                      return new MemoryShaderDeclaration(PRIVATE_TOKEN, this._arguments, this._defines, this._fsSource, this._vsSource);
                    }
                  }
                  class FileShaderDeclarationBuilder extends ShaderDeclarationBuilder {
                    /**
                     * @private Constructor
                     * @param {Symbol} privateToken
                     * @param {string} fsFilepath
                     * @param {string} [vsFilepath]
                     */
                    constructor(privateToken, fsFilepath, vsFilepath) {
                      super(privateToken);
                      this._fsFilepath = String(fsFilepath);
                      this._vsFilepath = vsFilepath !== void 0 ? String(vsFilepath) : void 0;
                    }
                    /**
                     * Build a FileShaderDeclaration
                     * @returns {ShaderDeclaration}
                     */
                    build() {
                      return new FileShaderDeclaration(PRIVATE_TOKEN, this._arguments, this._defines, this._fsFilepath, this._vsFilepath);
                    }
                  }
                  function importShader(filepath, vsfilepath = void 0) {
                    return new FileShaderDeclarationBuilder(PRIVATE_TOKEN, filepath, vsfilepath);
                  }
                  function createShader(source, vssource = void 0) {
                    return new MemoryShaderDeclarationBuilder(PRIVATE_TOKEN, source, vssource);
                  }
                }
              ),
              /***/
              1672: (
                /***/
                (__unused_webpack_module, __webpack_exports__2, __webpack_require__2) => {
                  "use strict";
                  __webpack_require__2.r(__webpack_exports__2);
                  __webpack_require__2.d(__webpack_exports__2, {
                    /* harmony export */
                    conv2D: () => (
                      /* binding */
                      conv2D
                    ),
                    /* harmony export */
                    convX: () => (
                      /* binding */
                      convX
                    ),
                    /* harmony export */
                    convY: () => (
                      /* binding */
                      convY
                    )
                    /* harmony export */
                  });
                  var _shader_declaration__WEBPACK_IMPORTED_MODULE_0__ = __webpack_require__2(9420);
                  var _utils_utils__WEBPACK_IMPORTED_MODULE_1__ = __webpack_require__2(9037);
                  var _utils_errors__WEBPACK_IMPORTED_MODULE_2__ = __webpack_require__2(8581);
                  function conv2D(kernel, normalizationConstant = 1) {
                    const kernel32 = new Float32Array(kernel.map((x) => +x * +normalizationConstant));
                    const kSize = Math.sqrt(kernel32.length) | 0;
                    const N = kSize >> 1;
                    if (kSize < 1 || kSize % 2 == 0) throw new _utils_errors__WEBPACK_IMPORTED_MODULE_2__.qw(`Can't perform a 2D convolution with an invalid kSize of ${kSize}`);
                    else if (kSize * kSize != kernel32.length) throw new _utils_errors__WEBPACK_IMPORTED_MODULE_2__.qw(`Invalid 2D convolution kernel of ${kernel32.length} elements (expected: square)`);
                    const pixelAtOffset = N <= 7 ? "pixelAtShortOffset" : "pixelAtLongOffset";
                    const foreachKernelElement = (fn) => _utils_utils__WEBPACK_IMPORTED_MODULE_1__.A.cartesian(_utils_utils__WEBPACK_IMPORTED_MODULE_1__.A.symmetricRange(N), _utils_utils__WEBPACK_IMPORTED_MODULE_1__.A.symmetricRange(N)).map((cur) => fn(kernel32[(cur[0] + N) * kSize + (cur[1] + N)], cur[0], cur[1])).join("\n");
                    const generateCode = (k, dy, dx) => `
        result += ${pixelAtOffset}(image, ivec2(${-dx | 0}, ${-dy | 0})) * float(${+k});
    `;
                    const source = `
    uniform sampler2D image;

    void main()
    {
        float alpha = threadPixel(image).a;
        vec4 result = vec4(0.0f);

        ${foreachKernelElement(generateCode)}

        color = vec4(result.rgb, alpha);
    }
    `;
                    return (0, _shader_declaration__WEBPACK_IMPORTED_MODULE_0__.gx)(source).withArguments("image");
                  }
                  function convX(kernel, normalizationConstant = 1) {
                    return conv1D("x", kernel, normalizationConstant);
                  }
                  function convY(kernel, normalizationConstant = 1) {
                    return conv1D("y", kernel, normalizationConstant);
                  }
                  function conv1D(axis, kernel, normalizationConstant = 1) {
                    const kernel32 = new Float32Array(kernel.map((x) => +x * +normalizationConstant));
                    const kSize = kernel32.length;
                    const N = kSize >> 1;
                    if (kSize < 1 || kSize % 2 == 0) throw new _utils_errors__WEBPACK_IMPORTED_MODULE_2__.qw(`Can't perform a 1D convolution with an invalid kSize of ${kSize}`);
                    else if (axis != "x" && axis != "y") throw new _utils_errors__WEBPACK_IMPORTED_MODULE_2__.qw(`Can't perform 1D convolution: invalid axis "${axis}"`);
                    const pixelAtOffset = N <= 7 ? "pixelAtShortOffset" : "pixelAtLongOffset";
                    const foreachKernelElement = (fn) => _utils_utils__WEBPACK_IMPORTED_MODULE_1__.A.symmetricRange(N).reduce((acc, cur) => acc + fn(kernel32[cur + N], cur), "");
                    const generateCode = (k, i) => axis == "x" ? `
        pixel += ${pixelAtOffset}(image, ivec2(${-i | 0}, 0)) * float(${+k});
    ` : `
        pixel += ${pixelAtOffset}(image, ivec2(0, ${-i | 0})) * float(${+k});
    `;
                    const source = `
    uniform sampler2D image;

    void main()
    {
        float alpha = threadPixel(image).a;
        vec4 pixel = vec4(0.0f);

        ${foreachKernelElement(generateCode)}

        color = vec4(pixel.rgb, alpha);
    }
    `;
                    return (0, _shader_declaration__WEBPACK_IMPORTED_MODULE_0__.gx)(source).withArguments("image");
                  }
                }
              ),
              /***/
              1001: (
                /***/
                (__unused_webpack_module, __webpack_exports__2, __webpack_require__2) => {
                  "use strict";
                  __webpack_require__2.d(__webpack_exports__2, {
                    /* harmony export */
                    c: () => (
                      /* binding */
                      SpeedyGL
                    )
                    /* harmony export */
                  });
                  var _utils_utils__WEBPACK_IMPORTED_MODULE_0__ = __webpack_require__2(9037);
                  var _core_settings__WEBPACK_IMPORTED_MODULE_1__ = __webpack_require__2(2199);
                  var _utils_observable__WEBPACK_IMPORTED_MODULE_4__ = __webpack_require__2(3211);
                  var _core_speedy_promise__WEBPACK_IMPORTED_MODULE_2__ = __webpack_require__2(9192);
                  var _utils_errors__WEBPACK_IMPORTED_MODULE_3__ = __webpack_require__2(8581);
                  const SINGLETON_KEY = Symbol();
                  const DEFAULT_POWER_PREFERENCE = "default";
                  const CANVAS_WIDTH = 16, CANVAS_HEIGHT = 16;
                  let instance = null;
                  let powerPreference = DEFAULT_POWER_PREFERENCE;
                  class SpeedyGL extends _utils_observable__WEBPACK_IMPORTED_MODULE_4__.c {
                    /**
                     * Constructor
                     * @param {Symbol} key
                     * @private
                     */
                    constructor(key) {
                      _utils_utils__WEBPACK_IMPORTED_MODULE_0__.A.assert(key === SINGLETON_KEY);
                      super();
                      this._reinitializeOnContextLoss = true;
                      this._canvas = this._createCanvas(this._reinitialize.bind(this));
                      this._gl = this._createContext(this._canvas);
                      this._vendor = "";
                      this._renderer = "";
                      this._readDriverInfo();
                      if (_core_settings__WEBPACK_IMPORTED_MODULE_1__.w.logging === "diagnostic") this._logDriverInfo();
                    }
                    /**
                     * Get Singleton
                     * @returns {SpeedyGL}
                     */
                    static get instance() {
                      return instance || (instance = new SpeedyGL(SINGLETON_KEY));
                    }
                    /**
                     * The WebGL Rendering Context
                     * Be careful not to cache this rendering context, as it may be lost!
                     * @returns {WebGL2RenderingContext}
                     */
                    get gl() {
                      return this._gl;
                    }
                    /**
                     * The internal canvas
                     * @returns {HTMLCanvasElement}
                     */
                    get canvas() {
                      return this._canvas;
                    }
                    /**
                     * Renderer string of the video driver
                     * @returns {string}
                     */
                    get renderer() {
                      return this._renderer;
                    }
                    /**
                     * Vendor string of the video driver
                     * @returns {string}
                     */
                    get vendor() {
                      return this._vendor;
                    }
                    /**
                     * Create a WebGL-capable canvas
                     * @param {Function} reinitialize to be called if we get a WebGL context loss event
                     * @returns {HTMLCanvasElement}
                     */
                    _createCanvas(reinitialize) {
                      const canvas = _utils_utils__WEBPACK_IMPORTED_MODULE_0__.A.createCanvas(CANVAS_WIDTH, CANVAS_HEIGHT);
                      canvas.addEventListener("webglcontextlost", (ev) => {
                        _utils_utils__WEBPACK_IMPORTED_MODULE_0__.A.warning(`Lost WebGL2 context`);
                        setTimeout(reinitialize, 0);
                        ev.preventDefault();
                      }, false);
                      return canvas;
                    }
                    /**
                     * Create a WebGL2 Rendering Context
                     * @param {HTMLCanvasElement} canvas
                     * @returns {WebGL2RenderingContext}
                     */
                    _createContext(canvas) {
                      _utils_utils__WEBPACK_IMPORTED_MODULE_0__.A.log(`Creating a ${powerPreference} WebGL2 rendering context...`);
                      if (typeof WebGL2RenderingContext === "undefined") throw new _utils_errors__WEBPACK_IMPORTED_MODULE_3__.EM(`This application requires WebGL2. Please update your system.`);
                      const gl = canvas.getContext("webgl2", {
                        premultipliedAlpha: false,
                        preserveDrawingBuffer: false,
                        powerPreference,
                        alpha: true,
                        // see https://developer.mozilla.org/en-US/docs/Web/API/WebGL_API/WebGL_best_practices#avoid_alphafalse_which_can_be_expensive
                        antialias: false,
                        depth: false,
                        stencil: false,
                        desynchronized: true
                      });
                      if (!gl) throw new _utils_errors__WEBPACK_IMPORTED_MODULE_3__.EM(`Can't create a WebGL2 Rendering Context. Try a different browser!`);
                      return gl;
                    }
                    /**
                     * Reinitialize WebGL
                     */
                    _reinitialize() {
                      if (!this._reinitializeOnContextLoss) return;
                      _utils_utils__WEBPACK_IMPORTED_MODULE_0__.A.warning(`Reinitializing WebGL2...`);
                      this._canvas.remove();
                      this._canvas = this._createCanvas(this._reinitialize.bind(this));
                      this._gl = this._createContext(this._canvas);
                      this._readDriverInfo();
                      this._notify();
                    }
                    /**
                     * Read debugging information about the video driver of the user
                     */
                    _readDriverInfo() {
                      const gl = this._gl;
                      let debugInfo = null;
                      if (navigator.userAgent.includes("Firefox")) {
                        this._vendor = "";
                        this._renderer = gl.getParameter(gl.RENDERER);
                      } else if (null != (debugInfo = gl.getExtension("WEBGL_debug_renderer_info"))) {
                        this._vendor = gl.getParameter(debugInfo.UNMASKED_VENDOR_WEBGL);
                        this._renderer = gl.getParameter(debugInfo.UNMASKED_RENDERER_WEBGL);
                      } else {
                        this._vendor = "";
                        this._renderer = "";
                      }
                    }
                    /**
                     * Log debugging information about the video driver and the platform
                     */
                    _logDriverInfo() {
                      _utils_utils__WEBPACK_IMPORTED_MODULE_0__.A.log("Platform: " + _utils_utils__WEBPACK_IMPORTED_MODULE_0__.A.platformString());
                      _utils_utils__WEBPACK_IMPORTED_MODULE_0__.A.log("GL vendor: " + this.vendor);
                      _utils_utils__WEBPACK_IMPORTED_MODULE_0__.A.log("GL renderer: " + this.renderer);
                    }
                    /**
                     * Lose the WebGL context. This is used to manually
                     * free resources, and also for purposes of testing
                     * @returns {WEBGL_lose_context}
                     */
                    loseContext() {
                      const gl = this._gl;
                      const ext = gl.getExtension("WEBGL_lose_context");
                      if (!ext) throw new _utils_errors__WEBPACK_IMPORTED_MODULE_3__.EM("WEBGL_lose_context extension is unavailable");
                      if (gl.isContextLost()) return ext;
                      this._reinitializeOnContextLoss = false;
                      ext.loseContext();
                      return ext;
                    }
                    /**
                     * Lose & restore the WebGL context
                     * @param {number} [secondsToRestore]
                     * @return {SpeedyPromise<WEBGL_lose_context>} resolves as soon as the context is restored
                     */
                    loseAndRestoreContext(secondsToRestore = 1) {
                      const ms = Math.max(secondsToRestore, 0) * 1e3;
                      const ext = this.loseContext();
                      return new _core_speedy_promise__WEBPACK_IMPORTED_MODULE_2__.i((resolve) => {
                        setTimeout(() => {
                          this._reinitializeOnContextLoss = true;
                          this._reinitialize();
                          setTimeout(() => resolve(ext), 0);
                        }, ms);
                      });
                    }
                    /**
                     * Power preference for the WebGL context
                     * @returns {PowerPreference}
                     */
                    static get powerPreference() {
                      return powerPreference;
                    }
                    /**
                     * Power preference for the WebGL context
                     * @param {PowerPreference} value
                     */
                    static set powerPreference(value) {
                      if (!(value === "default" || value === "low-power" || value === "high-performance")) throw new _utils_errors__WEBPACK_IMPORTED_MODULE_3__.qw(`Invalid powerPreference: "${value}"`);
                      if (instance == null || powerPreference !== value) {
                        powerPreference = value;
                        if (instance != null) instance.loseAndRestoreContext();
                      }
                    }
                    /**
                     * Check if an instance of SpeedyGL has already been created
                     * @returns {boolean}
                     */
                    static isInitialized() {
                      return instance != null;
                    }
                  }
                }
              ),
              /***/
              8581: (
                /***/
                (__unused_webpack_module, __webpack_exports__2, __webpack_require__2) => {
                  "use strict";
                  __webpack_require__2.d(__webpack_exports__2, {
                    /* harmony export */
                    EM: () => (
                      /* binding */
                      NotSupportedError2
                    ),
                    /* harmony export */
                    Er: () => (
                      /* binding */
                      IllegalOperationError5
                    ),
                    /* harmony export */
                    FJ: () => (
                      /* binding */
                      ResourceNotLoadedError
                    ),
                    /* harmony export */
                    MU: () => (
                      /* binding */
                      TimeoutError2
                    ),
                    /* harmony export */
                    NO: () => (
                      /* binding */
                      WebAssemblyError
                    ),
                    /* harmony export */
                    Uk: () => (
                      /* binding */
                      AccessDeniedError2
                    ),
                    /* harmony export */
                    aQ: () => (
                      /* binding */
                      AbstractMethodError
                    ),
                    /* harmony export */
                    kG: () => (
                      /* binding */
                      FileNotFoundError
                    ),
                    /* harmony export */
                    l: () => (
                      /* binding */
                      OutOfMemoryError
                    ),
                    /* harmony export */
                    mB: () => (
                      /* binding */
                      ParseError
                    ),
                    /* harmony export */
                    pf: () => (
                      /* binding */
                      AssertionError2
                    ),
                    /* harmony export */
                    qw: () => (
                      /* binding */
                      IllegalArgumentError5
                    ),
                    /* harmony export */
                    wB: () => (
                      /* binding */
                      GLError
                    ),
                    /* harmony export */
                    xB: () => (
                      /* binding */
                      SpeedyError
                    )
                    /* harmony export */
                  });
                  class SpeedyError extends Error {
                    /**
                     * Class constructor
                     * @param {string} message message text
                     * @param {SpeedyErrorCause} [cause] cause of the error
                     */
                    constructor(message, cause = null) {
                      super([message, cause ? cause.toString() : "[speedy-vision.js]"].join("\n-> "));
                      this._cause = cause;
                    }
                    /**
                     * Error name
                     * @returns {string}
                     */
                    get name() {
                      return this.constructor.name;
                    }
                    /**
                     * Set error name (ignored)
                     * @param {string} _ ignored
                     */
                    set name(_) {
                    }
                    /**
                     * Get the cause of the error. Available if
                     * it has been specified in the constructor
                     * @returns {SpeedyErrorCause}
                     */
                    get cause() {
                      return this._cause;
                    }
                  }
                  class NotSupportedError2 extends SpeedyError {
                    /**
                     * Class constructor
                     * @param {string} [message] additional text
                     * @param {SpeedyErrorCause} [cause] cause of the error
                     */
                    constructor(message = "", cause = null) {
                      super(`Unsupported operation. ${message}`, cause);
                    }
                  }
                  class NotImplementedError extends SpeedyError {
                    /**
                     * Class constructor
                     * @param {string} [message] additional text
                     * @param {SpeedyErrorCause} [cause] cause of the error
                     */
                    constructor(message = "", cause = null) {
                      super(`Method not implemented. ${message}`, cause);
                    }
                  }
                  class GLError extends SpeedyError {
                    /**
                     * Class constructor
                     * @param {string} [message] additional text
                     * @param {SpeedyErrorCause} [cause] cause of the error
                     */
                    constructor(message = "", cause = null) {
                      super(`WebGL error. ${message}`, cause);
                    }
                    /**
                     * Get an error object describing the latest WebGL error
                     * @param {WebGL2RenderingContext} gl
                     * @returns {GLError}
                     */
                    static from(gl) {
                      const recognizedErrors = ["NO_ERROR", "INVALID_ENUM", "INVALID_VALUE", "INVALID_OPERATION", "INVALID_FRAMEBUFFER_OPERATION", "OUT_OF_MEMORY", "CONTEXT_LOST_WEBGL"];
                      const glError = gl.getError();
                      const message = recognizedErrors.find((error) => gl[error] == glError) || "Unknown";
                      return new GLError(message);
                    }
                  }
                  class AbstractMethodError extends SpeedyError {
                    /**
                     * Class constructor
                     * @param {string} [message] additional text
                     * @param {SpeedyErrorCause} [cause] cause of the error
                     */
                    constructor(message = "", cause = null) {
                      super(`Can't call abstract method. ${message}`, cause);
                    }
                  }
                  class IllegalArgumentError5 extends SpeedyError {
                    /**
                     * Class constructor
                     * @param {string} [message] additional text
                     * @param {SpeedyErrorCause} [cause] cause of the error
                     */
                    constructor(message = "", cause = null) {
                      super(`Illegal argument. ${message}`, cause);
                    }
                  }
                  class IllegalOperationError5 extends SpeedyError {
                    /**
                     * Class constructor
                     * @param {string} [message] additional text
                     * @param {SpeedyErrorCause} [cause] cause of the error
                     */
                    constructor(message = "", cause = null) {
                      super(`Illegal operation. ${message}`, cause);
                    }
                  }
                  class OutOfMemoryError extends SpeedyError {
                    /**
                     * Class constructor
                     * @param {string} [message] additional text
                     * @param {SpeedyErrorCause} [cause] cause of the error
                     */
                    constructor(message = "", cause = null) {
                      super(`Out of memory. ${message}`, cause);
                    }
                  }
                  class FileNotFoundError extends SpeedyError {
                    /**
                     * Class constructor
                     * @param {string} [message] additional text
                     * @param {SpeedyErrorCause} [cause] cause of the error
                     */
                    constructor(message = "", cause = null) {
                      super(`File not found. ${message}`, cause);
                    }
                  }
                  class ResourceNotLoadedError extends SpeedyError {
                    /**
                     * Class constructor
                     * @param {string} [message] additional text
                     * @param {SpeedyErrorCause} [cause] cause of the error
                     */
                    constructor(message = "", cause = null) {
                      super(`Resource not loaded. ${message}`, cause);
                    }
                  }
                  class TimeoutError2 extends SpeedyError {
                    /**
                     * Class constructor
                     * @param {string} [message] additional text
                     * @param {SpeedyErrorCause} [cause] cause of the error
                     */
                    constructor(message = "", cause = null) {
                      super(`Timeout error. ${message}`, cause);
                    }
                  }
                  class ParseError extends SpeedyError {
                    /**
                     * Class constructor
                     * @param {string} [message] additional text
                     * @param {SpeedyErrorCause} [cause] cause of the error
                     */
                    constructor(message = "", cause = null) {
                      super(`Parse error. ${message}`, cause);
                    }
                  }
                  class AssertionError2 extends SpeedyError {
                    /**
                     * Class constructor
                     * @param {string} [message] additional text
                     * @param {SpeedyErrorCause} [cause] cause of the error
                     */
                    constructor(message = "", cause = null) {
                      super(`Assertion failed. ${message}`, cause);
                    }
                  }
                  class AccessDeniedError2 extends SpeedyError {
                    /**
                     * Class constructor
                     * @param {string} [message] additional text
                     * @param {SpeedyErrorCause} [cause] cause of the error
                     */
                    constructor(message = "", cause = null) {
                      super(`Access denied. ${message}`, cause);
                    }
                  }
                  class WebAssemblyError extends SpeedyError {
                    /**
                     * Class constructor
                     * @param {string} [message] additional text
                     * @param {SpeedyErrorCause} [cause] cause of the error
                     */
                    constructor(message = "", cause = null) {
                      super(`WebAssembly error. ${message}`, cause);
                    }
                  }
                }
              ),
              /***/
              3816: (
                /***/
                (__unused_webpack_module, __webpack_exports__2, __webpack_require__2) => {
                  "use strict";
                  __webpack_require__2.r(__webpack_exports__2);
                  __webpack_require__2.d(__webpack_exports__2, {
                    /* harmony export */
                    DEFAULT_ENCODER_CAPACITY: () => (
                      /* binding */
                      DEFAULT_ENCODER_CAPACITY
                    ),
                    /* harmony export */
                    FIX_BITS: () => (
                      /* binding */
                      FIX_BITS
                    ),
                    /* harmony export */
                    FIX_RESOLUTION: () => (
                      /* binding */
                      FIX_RESOLUTION
                    ),
                    /* harmony export */
                    LITTLE_ENDIAN: () => (
                      /* binding */
                      LITTLE_ENDIAN
                    ),
                    /* harmony export */
                    LOG2_MAX_DESCRIPTOR_SIZE: () => (
                      /* binding */
                      LOG2_MAX_DESCRIPTOR_SIZE
                    ),
                    /* harmony export */
                    LOG2_PYRAMID_MAX_SCALE: () => (
                      /* binding */
                      LOG2_PYRAMID_MAX_SCALE
                    ),
                    /* harmony export */
                    MATCH_INDEX_BITS: () => (
                      /* binding */
                      MATCH_INDEX_BITS
                    ),
                    /* harmony export */
                    MATCH_INDEX_MASK: () => (
                      /* binding */
                      MATCH_INDEX_MASK
                    ),
                    /* harmony export */
                    MATCH_MAX_DISTANCE: () => (
                      /* binding */
                      MATCH_MAX_DISTANCE
                    ),
                    /* harmony export */
                    MATCH_MAX_INDEX: () => (
                      /* binding */
                      MATCH_MAX_INDEX
                    ),
                    /* harmony export */
                    MAX_DESCRIPTOR_SIZE: () => (
                      /* binding */
                      MAX_DESCRIPTOR_SIZE
                    ),
                    /* harmony export */
                    MAX_ENCODER_CAPACITY: () => (
                      /* binding */
                      MAX_ENCODER_CAPACITY
                    ),
                    /* harmony export */
                    MAX_TEXTURE_LENGTH: () => (
                      /* binding */
                      MAX_TEXTURE_LENGTH
                    ),
                    /* harmony export */
                    MIN_ENCODER_LENGTH: () => (
                      /* binding */
                      MIN_ENCODER_LENGTH
                    ),
                    /* harmony export */
                    MIN_KEYPOINT_SIZE: () => (
                      /* binding */
                      MIN_KEYPOINT_SIZE
                    ),
                    /* harmony export */
                    PYRAMID_MAX_LEVELS: () => (
                      /* binding */
                      PYRAMID_MAX_LEVELS
                    ),
                    /* harmony export */
                    PYRAMID_MAX_SCALE: () => (
                      /* binding */
                      PYRAMID_MAX_SCALE
                    )
                    /* harmony export */
                  });
                  const PYRAMID_MAX_LEVELS = 8;
                  const LOG2_PYRAMID_MAX_SCALE = 0;
                  const PYRAMID_MAX_SCALE = 1 << LOG2_PYRAMID_MAX_SCALE;
                  const FIX_BITS = 3;
                  const FIX_RESOLUTION = 1 << FIX_BITS;
                  const MAX_TEXTURE_LENGTH = (1 << 16 - FIX_BITS) - 1;
                  const MIN_KEYPOINT_SIZE = 8;
                  const MIN_ENCODER_LENGTH = 2;
                  const MAX_ENCODER_CAPACITY = 8192;
                  const DEFAULT_ENCODER_CAPACITY = 2048;
                  const LOG2_MAX_DESCRIPTOR_SIZE = 6;
                  const MAX_DESCRIPTOR_SIZE = 1 << LOG2_MAX_DESCRIPTOR_SIZE;
                  const MATCH_INDEX_BITS = 32 - (LOG2_MAX_DESCRIPTOR_SIZE + 3);
                  const MATCH_INDEX_MASK = (1 << MATCH_INDEX_BITS) - 1;
                  const MATCH_MAX_INDEX = (1 << MATCH_INDEX_BITS) - 1;
                  const MATCH_MAX_DISTANCE = (1 << 32 - MATCH_INDEX_BITS) - 1;
                  const LITTLE_ENDIAN = function() {
                    return 51966 === new Uint16Array(new Uint8Array([254, 202]).buffer)[0];
                  }();
                }
              ),
              /***/
              3211: (
                /***/
                (__unused_webpack_module, __webpack_exports__2, __webpack_require__2) => {
                  "use strict";
                  __webpack_require__2.d(__webpack_exports__2, {
                    /* harmony export */
                    c: () => (
                      /* binding */
                      Observable
                    )
                    /* harmony export */
                  });
                  class Observable {
                    /**
                     * Constructor
                     */
                    constructor() {
                      this._subscribers = [];
                      this._thisptr = [];
                      this._args = [];
                    }
                    /**
                     * Add subscriber
                     * @param {Function} fn callback
                     * @param {object} [thisptr] "this" pointer to be used when invoking the callback
                     * @param {...any} args arguments to be passed to the callback
                     */
                    subscribe(fn, thisptr, ...args2) {
                      this._subscribers.push(fn);
                      this._thisptr.push(thisptr);
                      this._args.push(args2);
                    }
                    /**
                     * Remove subscriber
                     * @param {Function} fn previously added callback
                     * @param {object} [thisptr] "this" pointer
                     */
                    unsubscribe(fn, thisptr) {
                      for (let j = this._subscribers.length - 1; j >= 0; j--) {
                        if (this._subscribers[j] === fn && this._thisptr[j] === thisptr) {
                          this._subscribers.splice(j, 1);
                          this._thisptr.splice(j, 1);
                          this._args.splice(j, 1);
                          break;
                        }
                      }
                    }
                    /**
                     * Notify all subscribers about a state change
                     * @protected
                     */
                    _notify() {
                      for (let i = 0; i < this._subscribers.length; i++) this._subscribers[i].apply(this._thisptr[i], this._args[i]);
                    }
                  }
                }
              ),
              /***/
              6049: (
                /***/
                (__unused_webpack_module, __webpack_exports__2, __webpack_require__2) => {
                  "use strict";
                  __webpack_require__2.d(__webpack_exports__2, {
                    /* harmony export */
                    f5: () => (
                      /* binding */
                      ImageFormat
                    ),
                    /* harmony export */
                    kQ: () => (
                      /* binding */
                      PixelComponent
                    ),
                    /* harmony export */
                    kg: () => (
                      /* binding */
                      ColorComponentId
                    ),
                    /* harmony export */
                    zu: () => (
                      /* binding */
                      MediaType
                    )
                    /* harmony export */
                  });
                  const MediaType = Object.freeze({
                    Image: Symbol("Image"),
                    Video: Symbol("Video"),
                    Canvas: Symbol("Canvas"),
                    OffscreenCanvas: Symbol("OffscreenCanvas"),
                    Bitmap: Symbol("Bitmap"),
                    Data: Symbol("Data")
                  });
                  const ImageFormat = Object.freeze({
                    RGBA: Symbol("RGBA"),
                    GREY: Symbol("GREY")
                  });
                  const PixelComponent = Object.freeze({
                    RED: 1,
                    GREEN: 2,
                    BLUE: 4,
                    ALPHA: 8,
                    ALL: 15
                    // = RED | GREEN | BLUE | ALPHA
                  });
                  const ColorComponentId = Object.freeze({
                    [PixelComponent.RED]: 0,
                    [PixelComponent.GREEN]: 1,
                    [PixelComponent.BLUE]: 2,
                    [PixelComponent.ALPHA]: 3
                  });
                }
              ),
              /***/
              9037: (
                /***/
                (__unused_webpack_module, __webpack_exports__2, __webpack_require__2) => {
                  "use strict";
                  __webpack_require__2.d(__webpack_exports__2, {
                    /* harmony export */
                    A: () => (
                      /* binding */
                      Utils2
                    )
                    /* harmony export */
                  });
                  var _errors__WEBPACK_IMPORTED_MODULE_0__ = __webpack_require__2(8581);
                  var _core_speedy_promise__WEBPACK_IMPORTED_MODULE_1__ = __webpack_require__2(9192);
                  var _core_settings__WEBPACK_IMPORTED_MODULE_2__ = __webpack_require__2(2199);
                  class Utils2 {
                    /**
                     * Generates a warning
                     * @param {string} text message text
                     * @param  {...string} args optional text
                     */
                    static warning(text, ...args2) {
                      if (_core_settings__WEBPACK_IMPORTED_MODULE_2__.w.logging !== "none") console.warn("[speedy-vision] " + text, ...args2);
                    }
                    /**
                     * Logs a message
                     * @param {string} text message text
                     * @param  {...string} args optional text
                     */
                    static log(text, ...args2) {
                      if (_core_settings__WEBPACK_IMPORTED_MODULE_2__.w.logging !== "none") console.log("[speedy-vision] " + text, ...args2);
                    }
                    /**
                     * Assertion
                     * @param {boolean} expr expression
                     * @param {string} [text] error message
                     * @throws {AssertionError}
                     */
                    static assert(expr, text = "") {
                      if (!expr) throw new _errors__WEBPACK_IMPORTED_MODULE_0__.pf(text);
                    }
                    /**
                     * Gets the names of the arguments of the specified function
                     * @param {Function} fun 
                     * @returns {string[]}
                     */
                    static functionArguments(fun) {
                      const code = fun.toString();
                      const regex = code.startsWith("function") ? "function\\s.*\\(([^)]*)\\)" : code.startsWith("(") ? "\\(([^)]*)\\).*=>" : "([^=]+).*=>";
                      const match = new RegExp(regex).exec(code);
                      if (match !== null) {
                        const args2 = match[1].replace(/\/\*.*?\*\//g, "");
                        return args2.split(",").map(
                          (argname) => argname.replace(/=.*$/, "").trim()
                          // remove default params & trim
                        ).filter(
                          (argname) => argname
                          // handle trailing commas
                        );
                      } else throw new _errors__WEBPACK_IMPORTED_MODULE_0__.mB(`Can't detect function arguments of ${code}`);
                    }
                    /**
                     * Get all property descriptors from an object,
                     * traversing its entire prototype chain
                     * @param {object} obj 
                     * @returns {object}
                     */
                    static getAllPropertyDescriptors(obj) {
                      if (obj) {
                        const proto = Object.getPrototypeOf(obj);
                        return Object.assign(Object.assign({}, Utils2.getAllPropertyDescriptors(proto)), Object.getOwnPropertyDescriptors(obj));
                      } else return /* @__PURE__ */ Object.create(null);
                    }
                    /**
                     * Creates a HTMLCanvasElement with the given dimensions
                     * @param {number} width in pixels
                     * @param {number} height in pixels
                     * @returns {HTMLCanvasElement}
                     */
                    static createCanvas(width, height) {
                      const canvas = document.createElement("canvas");
                      canvas.width = width;
                      canvas.height = height;
                      return canvas;
                    }
                    /**
                     * Generate a 1D gaussian kernel with custom sigma
                     * Tip: use kernelSize >= (5 * sigma), kernelSize odd
                     * @param {number} sigma gaussian sigma
                     * @param {number} [kernelSize] kernel size, odd number
                     * @param {boolean} [normalized] normalize entries so that their sum is 1
                     * @returns {number[]}
                     */
                    static gaussianKernel(sigma, kernelSize = 0, normalized = true) {
                      if (kernelSize == 0) {
                        kernelSize = Math.ceil(5 * sigma) | 0;
                        kernelSize += 1 - kernelSize % 2;
                      }
                      kernelSize |= 0;
                      if (kernelSize < 1 || kernelSize % 2 == 0) throw new _errors__WEBPACK_IMPORTED_MODULE_0__.qw(`Invalid kernel size given to gaussianKernel: ${kernelSize} x 1`);
                      else if (sigma <= 0) throw new _errors__WEBPACK_IMPORTED_MODULE_0__.qw(`Invalid sigma given to gaussianKernel: ${sigma}`);
                      const kernel = new Array(kernelSize);
                      const N = kernelSize >> 1;
                      const c = +sigma * 1.4142135623730951;
                      const m = 0.3275911;
                      const a1 = 0.254829592;
                      const a2 = -0.284496736;
                      const a3 = 1.421413741;
                      const a4 = -1.453152027;
                      const a5 = 1.061405429;
                      let sum = 0;
                      for (let j = 0; j < kernelSize; j++) {
                        let xa = (j - N + 0.5) / c;
                        let xb = (j - N - 0.5) / c;
                        let sa = 1, sb = 1;
                        if (xa < 0) {
                          sa = -1;
                          xa = -xa;
                        }
                        if (xb < 0) {
                          sb = -1;
                          xb = -xb;
                        }
                        const ta = 1 / (1 + m * xa);
                        const tb = 1 / (1 + m * xb);
                        const pa = ((((a5 * ta + a4) * ta + a3) * ta + a2) * ta + a1) * ta;
                        const pb = ((((a5 * tb + a4) * tb + a3) * tb + a2) * tb + a1) * tb;
                        const ya = 1 - pa * Math.exp(-xa * xa);
                        const yb = 1 - pb * Math.exp(-xb * xb);
                        const erfa = sa * ya;
                        const erfb = sb * yb;
                        const fp = (erfa - erfb) / (2 * c);
                        kernel[j] = fp;
                        sum += fp;
                      }
                      if (normalized) {
                        for (let j = 0; j < kernelSize; j++) kernel[j] /= sum;
                      }
                      return kernel;
                    }
                    /**
                     * Generate a 2D kernel in column-major format using two separable 1D kernels
                     * @param {number[]} ka 1D kernel
                     * @param {number[]} [kb]
                     * @returns {number[]}
                     */
                    static kernel2d(ka, kb = ka) {
                      const ksize = ka.length;
                      Utils2.assert(ka.length == ka.length);
                      Utils2.assert(ksize >= 1 && ksize % 2 == 1);
                      let kernel2d = new Array(ksize * ksize), k = 0;
                      for (let col = 0; col < ksize; col++) {
                        for (let row = 0; row < ksize; row++) kernel2d[k++] = ka[row] * kb[col];
                      }
                      return kernel2d;
                    }
                    /**
                     * Cartesian product a x b: [ [ai, bj] for all i, j ]
                     * @param {number[]} a
                     * @param {number[]} b
                     * @returns {Array<[number,number]>}
                     */
                    static cartesian(a, b) {
                      return [].concat(...a.map((a2) => b.map((b2) => [a2, b2])));
                    }
                    /**
                     * Symmetric range
                     * @param {number} n non-negative integer
                     * @returns {number[]} [ -n, ..., n ]
                     */
                    static symmetricRange(n) {
                      if ((n |= 0) < 0) throw new _errors__WEBPACK_IMPORTED_MODULE_0__.qw(`Expected a non-negative integer as input`);
                      return [...Array(2 * n + 1).keys()].map((x) => x - n);
                    }
                    /**
                     * Compute the [0, n) range of integers
                     * @param {number} n positive integer
                     * @returns {number[]} [ 0, 1, ..., n-1 ]
                     */
                    static range(n) {
                      if ((n |= 0) <= 0) throw new _errors__WEBPACK_IMPORTED_MODULE_0__.qw(`Expected a positive integer as input`);
                      return [...Array(n).keys()];
                    }
                    /**
                     * Shuffle in-place
                     * @template T
                     * @param {T[]} arr
                     * @returns {T[]} arr
                     */
                    static shuffle(arr) {
                      const len = arr.length;
                      const m = len - 1;
                      for (let i = 0; i < m; i++) {
                        const j = i + (Math.random() * (len - i) | 0);
                        if (i !== j) {
                          const t = arr[i];
                          arr[i] = arr[j];
                          arr[j] = t;
                        }
                      }
                      return arr;
                    }
                    /**
                     * Flatten an array (1 level only)
                     * @template U
                     * @param {U[]} array
                     * @returns {U[]}
                     */
                    static flatten(array) {
                      const flat = [];
                      for (let i = 0, n = array.length; i < n; i++) {
                        const entry = array[i];
                        if (Array.isArray(entry)) {
                          for (let j = 0, m = entry.length; j < m; j++) flat.push(entry[j]);
                        } else flat.push(entry);
                      }
                      return flat;
                    }
                    /**
                     * Decode a 16-bit float from a
                     * unsigned 16-bit integer
                     * @param {number} uint16
                     * @returns {number}
                     */
                    static decodeFloat16(uint16) {
                      const s = (uint16 & 65535) >> 15;
                      const e = (uint16 & 32767) >> 10;
                      const m = uint16 & 1023;
                      const sign = 1 - 2 * s;
                      if (e == 0) return m == 0 ? sign * 0 : sign * m * 5960464477539063e-23;
                      else if (e == 31) return m == 0 ? sign * Number.POSITIVE_INFINITY : Number.NaN;
                      const f = e >= 15 ? 1 << e - 15 : 1 / (1 << 15 - e);
                      return sign * f * (1 + m * 9765625e-10);
                    }
                    /**
                     * Wrapper around getUserMedia()
                     * @param {MediaStreamConstraints} [constraints] will be passed to getUserMedia()
                     * @returns {SpeedyPromise<HTMLVideoElement>}
                     */
                    static requestCameraStream(constraints = {
                      audio: false,
                      video: true
                    }) {
                      Utils2.log("Accessing the webcam...");
                      if (!navigator.mediaDevices || !navigator.mediaDevices.getUserMedia) throw new _errors__WEBPACK_IMPORTED_MODULE_0__.EM("Unsupported browser: no mediaDevices.getUserMedia()");
                      return new _core_speedy_promise__WEBPACK_IMPORTED_MODULE_1__.i((resolve, reject) => {
                        navigator.mediaDevices.getUserMedia(constraints).then((stream) => {
                          const video = document.createElement("video");
                          video.onloadedmetadata = () => {
                            video.play();
                            Utils2.log(`The camera is on! Resolution: ${video.videoWidth} x ${video.videoHeight}`);
                            resolve(video);
                          };
                          video.setAttribute("playsinline", "");
                          video.setAttribute("autoplay", "");
                          if (constraints.audio === false || constraints.audio === void 0) video.setAttribute("muted", "");
                          video.srcObject = stream;
                        }).catch((err) => {
                          if (err.name === "NotAllowedError") {
                            reject(new _errors__WEBPACK_IMPORTED_MODULE_0__.Uk(`Please give access to the camera and reload the page.`, err));
                          } else if (err.name === "OverconstrainedError" || err.name === "NotFoundError") {
                            reject(new _errors__WEBPACK_IMPORTED_MODULE_0__.EM(`Can't access the webcam with the requested constraints: ${JSON.stringify(constraints)}.`, err));
                          } else {
                            reject(new _errors__WEBPACK_IMPORTED_MODULE_0__.xB(`Can't access the webcam.`, err));
                          }
                        });
                      });
                    }
                    /**
                     * Format binary data as a string with hex values
                     * @param {ArrayBuffer} bytes
                     * @returns {string}
                     */
                    static formatBinaryData(bytes) {
                      const uint8 = new Uint8Array(bytes);
                      const array = Array.from(uint8, (b) => b.toString(16).padStart(2, "0"));
                      return array.join(" ");
                    }
                    /**
                     * Returns a string containing platform brand information
                     * @returns {string}
                     */
                    static platformString() {
                      if (typeof navigator.userAgentData === "object") {
                        return navigator.userAgentData.platform;
                      }
                      return navigator.platform;
                    }
                  }
                }
              ),
              /***/
              5235: (
                /***/
                (module2, __unused_webpack_exports, __webpack_require__2) => {
                  var map = {
                    "./colors.glsl": 8609,
                    "./filters.glsl": 4672,
                    "./fixed-point.glsl": 9778,
                    "./float16.glsl": 8710,
                    "./global.glsl": 2434,
                    "./int32.glsl": 439,
                    "./keypoint-descriptors.glsl": 8545,
                    "./keypoint-matches.glsl": 6762,
                    "./keypoints.glsl": 7639,
                    "./math.glsl": 431,
                    "./platform.glsl": 6822,
                    "./pyramids.glsl": 2728,
                    "./subpixel.glsl": 6823
                  };
                  function webpackContext(req) {
                    var id = webpackContextResolve(req);
                    return __webpack_require__2(id);
                  }
                  function webpackContextResolve(req) {
                    if (!__webpack_require__2.o(map, req)) {
                      var e = new Error("Cannot find module '" + req + "'");
                      e.code = "MODULE_NOT_FOUND";
                      throw e;
                    }
                    return map[req];
                  }
                  webpackContext.keys = function webpackContextKeys() {
                    return Object.keys(map);
                  };
                  webpackContext.resolve = webpackContextResolve;
                  module2.exports = webpackContext;
                  webpackContext.id = 5235;
                }
              ),
              /***/
              4606: (
                /***/
                (module2, __unused_webpack_exports, __webpack_require__2) => {
                  var map = {
                    "./filters/convolution": 1672,
                    "./filters/convolution.js": 1672,
                    "./filters/convolution1d.glsl": 8211,
                    "./filters/convolution2d.glsl": 7360,
                    "./filters/fast-median.glsl": 8191,
                    "./filters/nightvision.glsl": 4438,
                    "./filters/normalize-image.glsl": 5867,
                    "./filters/rgb2grey.glsl": 9252,
                    "./include/colors.glsl": 8609,
                    "./include/filters.glsl": 4672,
                    "./include/fixed-point.glsl": 9778,
                    "./include/float16.glsl": 8710,
                    "./include/global.glsl": 2434,
                    "./include/int32.glsl": 439,
                    "./include/keypoint-descriptors.glsl": 8545,
                    "./include/keypoint-matches.glsl": 6762,
                    "./include/keypoints.glsl": 7639,
                    "./include/math.glsl": 431,
                    "./include/platform.glsl": 6822,
                    "./include/pyramids.glsl": 2728,
                    "./include/subpixel.glsl": 6823,
                    "./keypoints/allocate-descriptors.glsl": 1341,
                    "./keypoints/allocate-extra.glsl": 7833,
                    "./keypoints/apply-homography.glsl": 2352,
                    "./keypoints/bf-knn.glsl": 7541,
                    "./keypoints/clip-border.glsl": 4868,
                    "./keypoints/clip.glsl": 5591,
                    "./keypoints/distance-filter.glsl": 191,
                    "./keypoints/encode-keypoint-long-offsets.glsl": 5467,
                    "./keypoints/encode-keypoint-offsets.glsl": 336,
                    "./keypoints/encode-keypoint-positions.glsl": 8968,
                    "./keypoints/encode-keypoint-properties.glsl": 1733,
                    "./keypoints/encode-keypoints.glsl": 9674,
                    "./keypoints/encode-null-keypoints.glsl": 2090,
                    "./keypoints/fast.glsl": 1855,
                    "./keypoints/fast.vs.glsl": 4824,
                    "./keypoints/hamming-distance-filter.glsl": 2381,
                    "./keypoints/harris-cutoff.glsl": 6060,
                    "./keypoints/harris.glsl": 9974,
                    "./keypoints/knn-init.glsl": 3047,
                    "./keypoints/knn-transfer.glsl": 3266,
                    "./keypoints/laplacian.glsl": 8018,
                    "./keypoints/lk.glsl": 3168,
                    "./keypoints/lookup-of-locations.glsl": 3890,
                    "./keypoints/lookup-of-locations.vs.glsl": 8647,
                    "./keypoints/lsh-knn.glsl": 4776,
                    "./keypoints/mix-keypoints.glsl": 2648,
                    "./keypoints/nonmax-scale.glsl": 8825,
                    "./keypoints/nonmax-space.glsl": 5693,
                    "./keypoints/nonmax-suppression.glsl": 9280,
                    "./keypoints/orb-descriptor.glsl": 9108,
                    "./keypoints/orb-orientation.glsl": 7137,
                    "./keypoints/refine-scale.glsl": 9739,
                    "./keypoints/score-findmax.glsl": 8231,
                    "./keypoints/shuffle.glsl": 2518,
                    "./keypoints/sort-keypoints.glsl": 8096,
                    "./keypoints/subpixel-refinement.glsl": 5795,
                    "./keypoints/transfer-flow.glsl": 3169,
                    "./keypoints/transfer-orientation.glsl": 1337,
                    "./keypoints/transfer-to-extra.glsl": 6187,
                    "./keypoints/upload-keypoints.glsl": 477,
                    "./pyramids/downsample2.glsl": 4050,
                    "./pyramids/upsample2.glsl": 5545,
                    "./transforms/additive-mix.glsl": 7113,
                    "./transforms/resize.glsl": 1202,
                    "./transforms/warp-perspective.glsl": 7971,
                    "./utils/copy-components.glsl": 6122,
                    "./utils/copy-raster.glsl": 371,
                    "./utils/copy.glsl": 7307,
                    "./utils/fill-components.glsl": 8614,
                    "./utils/fill.glsl": 6271,
                    "./utils/flip-y.vs.glsl": 3016,
                    "./utils/scan-minmax2d.glsl": 3630,
                    "./utils/sobel-derivatives.glsl": 8508,
                    "./utils/sobel-derivatives.vs.glsl": 8073
                  };
                  function webpackContext(req) {
                    var id = webpackContextResolve(req);
                    return __webpack_require__2(id);
                  }
                  function webpackContextResolve(req) {
                    if (!__webpack_require__2.o(map, req)) {
                      var e = new Error("Cannot find module '" + req + "'");
                      e.code = "MODULE_NOT_FOUND";
                      throw e;
                    }
                    return map[req];
                  }
                  webpackContext.keys = function webpackContextKeys() {
                    return Object.keys(map);
                  };
                  webpackContext.resolve = webpackContextResolve;
                  module2.exports = webpackContext;
                  webpackContext.id = 4606;
                }
              ),
              /***/
              8211: (
                /***/
                (module2) => {
                  module2.exports = "#if !defined(KERNEL_SIZE) || !defined(AXIS) || (AXIS != 0 && AXIS != 1)\n#error Undefined KERNEL_SIZE / AXIS\n#endif\nuniform sampler2D image;\nuniform float kernel[@KERNEL_SIZE@];\nconst ivec2 axis = ivec2(1-AXIS, AXIS);\n#define S(x,k) result += pixelAtShortOffset(image, ivec2((x),(x)) * axis) * kernel[k]\nvoid main()\n{\nvec4 result = vec4(0.0f);\n#if KERNEL_SIZE == 3\nS(-1, 2);\nS( 0, 1);\nS( 1, 0);\n#elif KERNEL_SIZE == 5\nS(-2, 4);\nS(-1, 3);\nS( 0, 2);\nS( 1, 1);\nS( 2, 0);\n#elif KERNEL_SIZE == 7\nS(-3, 6);\nS(-2, 5);\nS(-1, 4);\nS( 0, 3);\nS( 1, 2);\nS( 2, 1);\nS( 3, 0);\n#elif KERNEL_SIZE == 9\nS(-4, 8);\nS(-3, 7);\nS(-2, 6);\nS(-1, 5);\nS( 0, 4);\nS( 1, 3);\nS( 2, 2);\nS( 3, 1);\nS( 4, 0);\n#elif KERNEL_SIZE == 11\nS(-5, 10);\nS(-4, 9);\nS(-3, 8);\nS(-2, 7);\nS(-1, 6);\nS( 0, 5);\nS( 1, 4);\nS( 2, 3);\nS( 3, 2);\nS( 4, 1);\nS( 5, 0);\n#elif KERNEL_SIZE == 13\nS(-6, 12);\nS(-5, 11);\nS(-4, 10);\nS(-3, 9);\nS(-2, 8);\nS(-1, 7);\nS( 0, 6);\nS( 1, 5);\nS( 2, 4);\nS( 3, 3);\nS( 4, 2);\nS( 5, 1);\nS( 6, 0);\n#elif KERNEL_SIZE == 15\nS(-7, 14);\nS(-6, 13);\nS(-5, 12);\nS(-4, 11);\nS(-3, 10);\nS(-2, 9);\nS(-1, 8);\nS( 0, 7);\nS( 1, 6);\nS( 2, 5);\nS( 3, 4);\nS( 4, 3);\nS( 5, 2);\nS( 6, 1);\nS( 7, 0);\n#else\n#error Invalid parameters\n#endif\ncolor = vec4(result.rgb, 1.0f);\n}";
                }
              ),
              /***/
              7360: (
                /***/
                (module2) => {
                  module2.exports = "#ifndef KERNEL_SIZE_SQUARED\n#error Must define KERNEL_SIZE_SQUARED\n#endif\nuniform sampler2D image;\nuniform float kernel[@KERNEL_SIZE_SQUARED@];\n#define S(x,y,k) result += pixelAtShortOffset(image, ivec2((x),(y))) * kernel[k]\nvoid main()\n{\nvec4 result = vec4(0.0f);\n#if KERNEL_SIZE_SQUARED == 9\nS(-1,-1, 8);\nS(-1, 0, 7);\nS(-1, 1, 6);\nS( 0,-1, 5);\nS( 0, 0, 4);\nS( 0, 1, 3);\nS( 1,-1, 2);\nS( 1, 0, 1);\nS( 1, 1, 0);\n#elif KERNEL_SIZE_SQUARED == 25\nS(-2,-2, 24);\nS(-2,-1, 23);\nS(-2, 0, 22);\nS(-2, 1, 21);\nS(-2, 2, 20);\nS(-1,-2, 19);\nS(-1,-1, 18);\nS(-1, 0, 17);\nS(-1, 1, 16);\nS(-1, 2, 15);\nS( 0,-2, 14);\nS( 0,-1, 13);\nS( 0, 0, 12);\nS( 0, 1, 11);\nS( 0, 2, 10);\nS( 1,-2, 9);\nS( 1,-1, 8);\nS( 1, 0, 7);\nS( 1, 1, 6);\nS( 1, 2, 5);\nS( 2,-2, 4);\nS( 2,-1, 3);\nS( 2, 0, 2);\nS( 2, 1, 1);\nS( 2, 2, 0);\n#elif KERNEL_SIZE_SQUARED == 49\nS(-3,-3, 48);\nS(-3,-2, 47);\nS(-3,-1, 46);\nS(-3, 0, 45);\nS(-3, 1, 44);\nS(-3, 2, 43);\nS(-3, 3, 42);\nS(-2,-3, 41);\nS(-2,-2, 40);\nS(-2,-1, 39);\nS(-2, 0, 38);\nS(-2, 1, 37);\nS(-2, 2, 36);\nS(-2, 3, 35);\nS(-1,-3, 34);\nS(-1,-2, 33);\nS(-1,-1, 32);\nS(-1, 0, 31);\nS(-1, 1, 30);\nS(-1, 2, 29);\nS(-1, 3, 28);\nS( 0,-3, 27);\nS( 0,-2, 26);\nS( 0,-1, 25);\nS( 0, 0, 24);\nS( 0, 1, 23);\nS( 0, 2, 22);\nS( 0, 3, 21);\nS( 1,-3, 20);\nS( 1,-2, 19);\nS( 1,-1, 18);\nS( 1, 0, 17);\nS( 1, 1, 16);\nS( 1, 2, 15);\nS( 1, 3, 14);\nS( 2,-3, 13);\nS( 2,-2, 12);\nS( 2,-1, 11);\nS( 2, 0, 10);\nS( 2, 1, 9);\nS( 2, 2, 8);\nS( 2, 3, 7);\nS( 3,-3, 6);\nS( 3,-2, 5);\nS( 3,-1, 4);\nS( 3, 0, 3);\nS( 3, 1, 2);\nS( 3, 2, 1);\nS( 3, 3, 0);\n#else\n#error Invalid KERNEL_SIZE_SQUARED\n#endif\ncolor = vec4(result.rgb, 1.0f);\n}";
                }
              ),
              /***/
              8191: (
                /***/
                (module2) => {
                  module2.exports = "uniform sampler2D image;\n#define X(i,j) t = vec2(min(p[i], p[j]), max(p[i], p[j])); p[i] = t.x; p[j] = t.y;\n#define S(i,x,y) p[i] = pixelAtShortOffset(image, ivec2((x),(y))).g\nvoid main()\n{\nfloat median;\nvec2 t;\n#if !defined(KERNEL_SIZE)\n#error Must define KERNEL_SIZE\n#elif KERNEL_SIZE == 3\nfloat p[9];\nS(0,-1,-1);\nS(1, 0,-1);\nS(2, 1,-1);\nS(3,-1, 0);\nS(4, 0, 0);\nS(5, 1, 0);\nS(6,-1, 1);\nS(7, 0, 1);\nS(8, 1, 1);\nX(1,2);X(4,5);X(7,8);X(0,1);X(3,4);X(6,7);X(1,2);X(4,5);X(7,8);X(0,3);X(5,8);X(4,7);X(3,6);X(1,4);X(2,5);X(4,7);X(4,2);X(6,4);X(4,2);\nmedian = p[4];\n#elif KERNEL_SIZE == 5\nfloat p[25];\nS( 0,-2,-2);\nS( 1,-1,-2);\nS( 2, 0,-2);\nS( 3, 1,-2);\nS( 4, 2,-2);\nS( 5,-2,-1);\nS( 6,-1,-1);\nS( 7, 0,-1);\nS( 8, 1,-1);\nS( 9, 2,-1);\nS(10,-2, 0);\nS(11,-1, 0);\nS(12, 0, 0);\nS(13, 1, 0);\nS(14, 2, 0);\nS(15,-2, 1);\nS(16,-1, 1);\nS(17, 0, 1);\nS(18, 1, 1);\nS(19, 2, 1);\nS(20,-2, 2);\nS(21,-1, 2);\nS(22, 0, 2);\nS(23, 1, 2);\nS(24, 2, 2);\nX(0,1);X(3,4);X(2,4);X(2,3);X(6,7);X(5,7);X(5,6);X(9,10);X(8,10);X(8,9);X(12,13);X(11,13);X(11,12);X(15,16);X(14,16);X(14,15);X(18,19);X(17,19);X(17,18);X(21,22);X(20,22);X(20,21);X(23,24);X(2,5);X(3,6);X(0,6);X(0,3);X(4,7);X(1,7);X(1,4);X(11,14);X(8,14);X(8,11);X(12,15);X(9,15);X(9,12);X(13,16);X(10,16);X(10,13);X(20,23);X(17,23);X(17,20);X(21,24);X(18,24);X(18,21);X(19,22);X(8,17);X(9,18);X(0,18);X(0,9);X(10,19);X(1,19);X(1,10);X(11,20);X(2,20);X(2,11);X(12,21);X(3,21);X(3,12);X(13,22);X(4,22);X(4,13);X(14,23);X(5,23);X(5,14);X(15,24);X(6,24);X(6,15);X(7,16);X(7,19);X(13,21);X(15,23);X(7,13);X(7,15);X(1,9);X(3,11);X(5,17);X(11,17);X(9,17);X(4,10);X(6,12);X(7,14);X(4,6);X(4,7);X(12,14);X(10,14);X(6,7);X(10,12);X(6,10);X(6,17);X(12,17);X(7,17);X(7,10);X(12,18);X(7,12);X(10,18);X(12,20);X(10,20);X(10,12);\nmedian = p[12];\n#elif KERNEL_SIZE == 7\nfloat p[49];\nS( 0,-3,-3);\nS( 1,-2,-3);\nS( 2,-1,-3);\nS( 3, 0,-3);\nS( 4, 1,-3);\nS( 5, 2,-3);\nS( 6, 3,-3);\nS( 7,-3,-2);\nS( 8,-2,-2);\nS( 9,-1,-2);\nS(10, 0,-2);\nS(11, 1,-2);\nS(12, 2,-2);\nS(13, 3,-2);\nS(14,-3,-1);\nS(15,-2,-1);\nS(16,-1,-1);\nS(17, 0,-1);\nS(18, 1,-1);\nS(19, 2,-1);\nS(20, 3,-1);\nS(21,-3, 0);\nS(22,-2, 0);\nS(23,-1, 0);\nS(24, 0, 0);\nS(25, 1, 0);\nS(26, 2, 0);\nS(27, 3, 0);\nS(28,-3, 1);\nS(29,-2, 1);\nS(30,-1, 1);\nS(31, 0, 1);\nS(32, 1, 1);\nS(33, 2, 1);\nS(34, 3, 1);\nS(35,-3, 2);\nS(36,-2, 2);\nS(37,-1, 2);\nS(38, 0, 2);\nS(39, 1, 2);\nS(40, 2, 2);\nS(41, 3, 2);\nS(42,-3, 3);\nS(43,-2, 3);\nS(44,-1, 3);\nS(45, 0, 3);\nS(46, 1, 3);\nS(47, 2, 3);\nS(48, 3, 3);\nX(0,1);X(2,3);X(0,2);X(1,3);X(1,2);X(4,5);X(6,7);X(4,6);X(5,7);X(5,6);X(0,4);X(2,6);X(2,4);X(1,5);X(3,7);X(3,5);X(1,2);X(3,4);X(5,6);X(8,9);X(10,11);X(8,10);X(9,11);X(9,10);X(12,13);X(14,15);X(12,14);X(13,15);X(13,14);X(8,12);X(10,14);X(10,12);X(9,13);X(11,15);X(11,13);X(9,10);X(11,12);X(13,14);X(0,8);X(4,12);X(4,8);X(2,10);X(6,14);X(6,10);X(2,4);X(6,8);X(10,12);X(1,9);X(5,13);X(5,9);X(3,11);X(7,15);X(7,11);X(3,5);X(7,9);X(11,13);X(1,2);X(3,4);X(5,6);X(7,8);X(9,10);X(11,12);X(13,14);X(16,17);X(18,19);X(16,18);X(17,19);X(17,18);X(20,21);X(22,23);X(20,22);X(21,23);X(21,22);X(16,20);X(18,22);X(18,20);X(17,21);X(19,23);X(19,21);X(17,18);X(19,20);X(21,22);X(24,25);X(26,27);X(24,26);X(25,27);X(25,26);X(28,29);X(30,31);X(28,30);X(29,31);X(29,30);X(24,28);X(26,30);X(26,28);X(25,29);X(27,31);X(27,29);X(25,26);X(27,28);X(29,30);X(16,24);X(20,28);X(20,24);X(18,26);X(22,30);X(22,26);X(18,20);X(22,24);X(26,28);X(17,25);X(21,29);X(21,25);X(19,27);X(23,31);X(23,27);X(19,21);X(23,25);X(27,29);X(17,18);X(19,20);X(21,22);X(23,24);X(25,26);X(27,28);X(29,30);X(0,16);X(8,24);X(8,16);X(4,20);X(12,28);X(12,20);X(4,8);X(12,16);X(20,24);X(2,18);X(10,26);X(10,18);X(6,22);X(14,30);X(14,22);X(6,10);X(14,18);X(22,26);X(2,4);X(6,8);X(10,12);X(14,16);X(18,20);X(22,24);X(26,28);X(1,17);X(9,25);X(9,17);X(5,21);X(13,29);X(13,21);X(5,9);X(13,17);X(21,25);X(3,19);X(11,27);X(11,19);X(7,23);X(15,31);X(15,23);X(7,11);X(15,19);X(23,27);X(3,5);X(7,9);X(11,13);X(15,17);X(19,21);X(23,25);X(27,29);X(1,2);X(3,4);X(5,6);X(7,8);X(9,10);X(11,12);X(13,14);X(15,16);X(17,18);X(19,20);X(21,22);X(23,24);X(25,26);X(27,28);X(29,30);X(32,33);X(34,35);X(32,34);X(33,35);X(33,34);X(36,37);X(38,39);X(36,38);X(37,39);X(37,38);X(32,36);X(34,38);X(34,36);X(33,37);X(35,39);X(35,37);X(33,34);X(35,36);X(37,38);X(40,41);X(42,43);X(40,42);X(41,43);X(41,42);X(44,45);X(46,47);X(44,46);X(45,47);X(45,46);X(40,44);X(42,46);X(42,44);X(41,45);X(43,47);X(43,45);X(41,42);X(43,44);X(45,46);X(32,40);X(36,44);X(36,40);X(34,42);X(38,46);X(38,42);X(34,36);X(38,40);X(42,44);X(33,41);X(37,45);X(37,41);X(35,43);X(39,47);X(39,43);X(35,37);X(39,41);X(43,45);X(33,34);X(35,36);X(37,38);X(39,40);X(41,42);X(43,44);X(45,46);X(32,48);X(40,48);X(36,40);X(44,48);X(38,42);X(34,36);X(38,40);X(42,44);X(46,48);X(37,41);X(39,43);X(35,37);X(39,41);X(43,45);X(33,34);X(35,36);X(37,38);X(39,40);X(41,42);X(43,44);X(45,46);X(47,48);X(0,32);X(16,48);X(16,32);X(8,40);X(24,40);X(8,16);X(24,32);X(40,48);X(4,36);X(20,36);X(12,44);X(28,44);X(12,20);X(28,36);X(4,8);X(12,16);X(20,24);X(28,32);X(36,40);X(44,48);X(2,34);X(18,34);X(10,42);X(26,42);X(10,18);X(26,34);X(6,38);X(22,38);X(14,46);X(30,46);X(14,22);X(30,38);X(6,10);X(14,18);X(22,26);X(30,34);X(38,42);X(2,4);X(6,8);X(10,12);X(14,16);X(18,20);X(22,24);X(26,28);X(30,32);X(34,36);X(38,40);X(42,44);X(46,48);X(1,33);X(17,33);X(9,41);X(25,41);X(9,17);X(25,33);X(5,37);X(21,37);X(13,45);X(29,45);X(13,21);X(29,37);X(5,9);X(13,17);X(21,25);X(29,33);X(37,41);X(3,35);X(19,35);X(11,43);X(27,43);X(11,19);X(27,35);X(7,39);X(23,39);X(15,47);X(31,47);X(15,23);X(31,39);X(7,11);X(15,19);X(23,27);X(31,35);X(39,43);X(3,5);X(7,9);X(11,13);X(15,17);X(19,21);X(23,25);X(27,29);X(31,33);X(35,37);X(39,41);X(43,45);X(1,2);X(3,4);X(5,6);X(7,8);X(9,10);X(11,12);X(13,14);X(15,16);X(17,18);X(19,20);X(21,22);X(23,24);\nmedian = p[24];\n#else\n#error Unsupported kernel size\n#endif\ncolor = vec4(median, median, median, 1.0f);\n}";
                }
              ),
              /***/
              4438: (
                /***/
                (module2) => {
                  module2.exports = "uniform sampler2D image;\nuniform sampler2D illuminationMap;\nuniform float gain;\nuniform float offset;\nuniform float decay;\n#ifndef GREYSCALE\n#error Must define GREYSCALE\n#endif\n#if GREYSCALE == 0\nconst mat3 rgb2yuv = mat3(\n0.299f, -0.14713f, 0.615f,\n0.587f, -0.28886f, -0.51499f,\n0.114f, 0.436f, -0.10001f\n);\nconst mat3 yuv2rgb = mat3(\n1.0f, 1.0f, 1.0f,\n0.0f, -0.39465f, 2.03211f,\n1.13983f, -0.58060f, 0.0f\n);\n#endif\nconst float eps = 0.0001f;\nconst float sqrt2 = 1.4142135623730951f;\nconst float magic = 20.0f;\nconst vec2 center = vec2(0.5f);\nvoid main()\n{\nvec4 pixel = threadPixel(image);\nvec4 imapPixel = threadPixel(illuminationMap);\nfloat lambda = -sqrt2 * log(max(1.0f - decay, eps));\nfloat dist = length(texCoord - center);\nfloat vgain = gain * exp(-lambda * dist);\nfloat normalizedGain = 2.0f * vgain;\nfloat normalizedOffset = 2.0f * offset - 1.0f;\n#if GREYSCALE != 0\nfloat luma = 1.0 / (1.0 + exp(-normalizedGain * magic * (pixel.g - imapPixel.g)));\nluma = clamp(luma + normalizedOffset, 0.0f, 1.0f);\ncolor = vec4(luma, luma, luma, 1.0f);\n#else\nvec3 yuvPixel = rgb2yuv * pixel.rgb;\nvec3 yuvImapPixel = rgb2yuv * imapPixel.rgb;\nfloat luma = 1.0 / (1.0 + exp(-normalizedGain * magic * (yuvPixel.r - yuvImapPixel.r)));\nluma += normalizedOffset;\nvec3 rgbCorrectedPixel = yuv2rgb * vec3(luma, yuvPixel.gb);\nrgbCorrectedPixel = clamp(rgbCorrectedPixel, 0.0f, 1.0f);\ncolor = vec4(rgbCorrectedPixel, 1.0f);\n#endif\n}";
                }
              ),
              /***/
              5867: (
                /***/
                (module2) => {
                  module2.exports = "#ifndef GREYSCALE\n#error Must define GREYSCALE\n#endif\n#if GREYSCALE != 0\nuniform sampler2D minmax2d;\n#else\nuniform sampler2D minmax2dRGB[3];\n#endif\nuniform float minValue;\nuniform float maxValue;\nconst float eps = 1.0f / 255.0f;\nvoid main()\n{\nvec2 minmax = clamp(vec2(minValue, maxValue), 0.0f, 255.0f) / 255.0f;\nvec4 newMin = vec4(minmax.x);\nvec4 newRange = vec4(minmax.y - minmax.x);\nvec4 alpha = vec4(1.0f, newMin.x, newRange.x, 1.0f);\n#if GREYSCALE != 0\nvec4 pixel = threadPixel(minmax2d);\nmat4 channel = mat4(pixel, pixel, pixel, alpha);\n#else\nmat4 channel = mat4(\nthreadPixel(minmax2dRGB[0]),\nthreadPixel(minmax2dRGB[1]),\nthreadPixel(minmax2dRGB[2]),\nalpha\n);\n#endif\nvec4 oldMin = vec4(channel[0].g, channel[1].g, channel[2].g, channel[3].g);\nvec4 oldRange = max(vec4(channel[0].b, channel[1].b, channel[2].b, channel[3].b), eps);\nvec4 oldIntensity = vec4(channel[0].a, channel[1].a, channel[2].a, channel[3].a);\nvec4 newIntensity = (oldIntensity - oldMin) * newRange / oldRange + newMin;\ncolor = newIntensity;\n}";
                }
              ),
              /***/
              9252: (
                /***/
                (module2) => {
                  module2.exports = "const vec4 grey = vec4(0.299f, 0.587f, 0.114f, 0.0f);\nuniform sampler2D image;\nvoid main()\n{\nvec4 pixel = threadPixel(image);\nfloat g = dot(pixel, grey);\ncolor = vec4(g, g, g, 1.0f);\n}";
                }
              ),
              /***/
              8609: (
                /***/
                (module2) => {
                  module2.exports = "#ifndef _COLORS_GLSL\n#define _COLORS_GLSL\n#define PIXELCOMPONENT_RED   @PIXELCOMPONENT_RED@\n#define PIXELCOMPONENT_GREEN @PIXELCOMPONENT_GREEN@\n#define PIXELCOMPONENT_BLUE  @PIXELCOMPONENT_BLUE@\n#define PIXELCOMPONENT_ALPHA @PIXELCOMPONENT_ALPHA@\n#endif";
                }
              ),
              /***/
              4672: (
                /***/
                (module2) => {
                  module2.exports = "#ifndef _FILTERS_GLSL\n#define _FILTERS_GLSL\nfloat laplacian(sampler2D pyramid, vec2 position, float lod)\n{\nfloat pot = exp2(lod);\nivec2 pyrBaseSize = textureSize(pyramid, 0);\nconst vec3 ones = vec3(1.0f);\nconst mat3 kernel = mat3(\n0,-1, 0,\n-1, 4,-1,\n0,-1, 0\n);\n#define LPC(x,y) pyrSubpixelAtExOffset(pyramid, position, lod, pot, ivec2((x),(y)), pyrBaseSize).g\nmat3 neighborhood = mat3(\n0.0f, LPC(0,-1), 0.0f,\nLPC(-1,0), LPC(0,0), LPC(1,0),\n0.0f, LPC(0,1), 0.0f\n);\nmat3 m = matrixCompMult(neighborhood, kernel);\nreturn dot(ones, vec3(\ndot(m[0], ones),\ndot(m[1], ones),\ndot(m[2], ones)\n)) * (1.0f + lod);\n}\n#endif";
                }
              ),
              /***/
              9778: (
                /***/
                (module2) => {
                  module2.exports = "#ifndef _FIXEDPOINT_GLSL\n#define _FIXEDPOINT_GLSL\n#define fixed_t int\n#define fixed2_t ivec2\nconst int FIX_BITS = int(@FIX_BITS@);\nconst float FIX_RESOLUTION = float(@FIX_RESOLUTION@);\n#define itofix(x) fixed_t((x) << FIX_BITS)\n#define fixtoi(f) int((x) >> FIX_BITS)\n#define ftofix(x) fixed_t((x) * FIX_RESOLUTION + 0.5f)\n#define fixtof(f) (float(f) / FIX_RESOLUTION)\n#define ivec2tofix(x) fixed2_t((x) << FIX_BITS)\n#define fixtoivec2(f) ivec2((f) >> FIX_BITS)\n#define vec2tofix(v) fixed2_t((v) * FIX_RESOLUTION + vec2(0.5f))\n#define fixtovec2(f) (vec2(f) / FIX_RESOLUTION)\n#endif";
                }
              ),
              /***/
              8710: (
                /***/
                (module2) => {
                  module2.exports = "#ifndef _FLOAT16_GLSL\n#define _FLOAT16_GLSL\n#define encodeFloat16(f) (vec2(packf16(f)) / 255.0f)\n#define decodeFloat16(v) unpackf16(uvec2((v) * 255.0f))\n#define encodePairOfFloat16(f) vec4(encodeFloat16((f).x), encodeFloat16((f).y))\n#define decodePairOfFloat16(v) vec2(decodeFloat16((v).rg), decodeFloat16((v).ba))\n#define encodeNullPairOfFloat16() vec4(1.0f)\n#define isNullPairOfFloat16(v) all(equal((v), encodeNullPairOfFloat16()))\n#define encodeDiscardedPairOfFloat16() vec4(0.0f, 1.0f, 0.0f, 1.0f)\n#define isDiscardedPairOfFloat16(v) all(equal((v), encodeDiscardedPairOfFloat16()))\n#define encodeFloat16NaN() vec2(0.5f, 1.0f)\n#define isEncodedFloat16NaN(v) all(equal((v), encodeFloat16NaN()))\nuvec2 packf16( float f)\n{\nuint y = packHalf2x16(vec2(f, 0.0f));\nreturn uvec2(y, y >> 8u) & 0xFFu;\n}\nfloat unpackf16(uvec2 v)\n{\nv &= 0xFFu;\nreturn unpackHalf2x16(v.x | (v.y << 8u)).x;\n}\nbool isEncodedFloat16Zero(vec2 v)\n{\nuvec2 w = uvec2(v * 255.0f);\nreturn 0u == w.x + w.y * (0x80u - w.y);\n}\n#endif";
                }
              ),
              /***/
              2434: (
                /***/
                (module2) => {
                  module2.exports = "#ifndef _GLOBAL_GLSL\n#define _GLOBAL_GLSL\n#define threadLocation() ivec2(texCoord * texSize)\n#define outputSize() ivec2(texSize)\n#define threadPixel(img) textureLod((img), texCoord, 0.0f)\n#define pixelAt(img, pos) texelFetch((img), (pos), 0)\n#define pixelAtShortOffset(img, offset) textureLodOffset((img), texCoord, 0.0f, (offset))\n#define pixelAtLongOffset(img, offset) textureLod((img), texCoord + vec2(offset) / texSize, 0.0f)\n#endif";
                }
              ),
              /***/
              439: (
                /***/
                (module2) => {
                  module2.exports = '#ifndef _INT32_GLSL\n#define _INT32_GLSL\n@include "platform.glsl"\nuint decodeUint32(vec4 rgba)\n{\nuvec4 v = uvec4(rgba * 255.0f) & 255u;\nreturn v.x | (v.y << 8u) | (v.z << 16u) | (v.w << 24u);\n}\nvec4 encodeUint32(uint value)\n{\n#if defined(APPLE_GPU) || (defined(APPLE) && defined(INTEL_GRAPHICS))\nuvec4 v = uvec4(value, value / 256u, value / 65536u, value / 16777216u) % 256u;\nreturn vec4(v) / 255.0f;\n#else\nuvec4 v = uvec4(value, value >> 8u, value >> 16u, value >> 24u) & 255u;\nreturn vec4(v) / 255.0f;\n#endif\n}\n#endif';
                }
              ),
              /***/
              8545: (
                /***/
                (module2) => {
                  module2.exports = "#ifndef _KEYPOINT_DESCRIPTORS_GLSL\n#define _KEYPOINT_DESCRIPTORS_GLSL\n#if !defined(DESCRIPTOR_SIZE)\n#error Must define DESCRIPTOR_SIZE\n#elif !defined(_KEYPOINTS_GLSL)\n#error Must include keypoints.glsl\n#endif\nuint[DESCRIPTOR_SIZE] readKeypointDescriptor(sampler2D encodedKeypoints, int descriptorSize, int extraSize, int encoderLength, KeypointAddress address)\n{\nint descriptorOffset = sizeofEncodedKeypoint(0, extraSize) / 4;\nKeypointAddress descriptorAddress = KeypointAddress(address.base, descriptorOffset);\nuint[DESCRIPTOR_SIZE] descriptor;\nvec4 pixel; uvec4 bytes;\n@unroll\nfor(int i = 0; i < DESCRIPTOR_SIZE; i += 4) {\npixel = readKeypointData(encodedKeypoints, encoderLength, descriptorAddress);\nbytes = uvec4(pixel * 255.0f);\ndescriptor[i]   = bytes.r;\ndescriptor[i+1] = bytes.g;\ndescriptor[i+2] = bytes.b;\ndescriptor[i+3] = bytes.a;\ndescriptorAddress.offset++;\n}\nreturn descriptor;\n}\nuint[DESCRIPTOR_SIZE] readKeypointDescriptorFromDB(sampler2D descriptorDB, int descriptorDBStride, int index)\n{\nuint[DESCRIPTOR_SIZE] descriptor;\nint rasterIndex = index * (DESCRIPTOR_SIZE / 4) * int(index >= 0);\nvec4 pixel; uvec4 bytes; ivec2 pos;\n@unroll\nfor(int i = 0; i < DESCRIPTOR_SIZE; i += 4) {\npos = ivec2(rasterIndex % descriptorDBStride, rasterIndex / descriptorDBStride);\npixel = (index >= 0) ? texelFetch(descriptorDB, pos, 0) : vec4(0.0f);\nbytes = uvec4(pixel * 255.0f);\ndescriptor[i]   = bytes.r;\ndescriptor[i+1] = bytes.g;\ndescriptor[i+2] = bytes.b;\ndescriptor[i+3] = bytes.a;\nrasterIndex++;\n}\nreturn descriptor;\n}\nint distanceBetweenKeypointDescriptors(uint[DESCRIPTOR_SIZE] a, uint[DESCRIPTOR_SIZE] b)\n{\nconst int[256] POPCNT = int[256](0,1,1,2,1,2,2,3,1,2,2,3,2,3,3,4,1,2,2,3,2,3,3,4,2,3,3,4,3,4,4,5,1,2,2,3,2,3,3,4,2,3,3,4,3,4,4,5,2,3,3,4,3,4,4,5,3,4,4,5,4,5,5,6,1,2,2,3,2,3,3,4,2,3,3,4,3,4,4,5,2,3,3,4,3,4,4,5,3,4,4,5,4,5,5,6,2,3,3,4,3,4,4,5,3,4,4,5,4,5,5,6,3,4,4,5,4,5,5,6,4,5,5,6,5,6,6,7,1,2,2,3,2,3,3,4,2,3,3,4,3,4,4,5,2,3,3,4,3,4,4,5,3,4,4,5,4,5,5,6,2,3,3,4,3,4,4,5,3,4,4,5,4,5,5,6,3,4,4,5,4,5,5,6,4,5,5,6,5,6,6,7,2,3,3,4,3,4,4,5,3,4,4,5,4,5,5,6,3,4,4,5,4,5,5,6,4,5,5,6,5,6,6,7,3,4,4,5,4,5,5,6,4,5,5,6,5,6,6,7,4,5,5,6,5,6,6,7,5,6,6,7,6,7,7,8);\nuvec4 xor, u, v;\nint dist = 0;\nivec4 bits;\n@unroll\nfor(int i = 0; i < DESCRIPTOR_SIZE; i += 4) {\nu = uvec4(a[i], a[i+1], a[i+2], a[i+3]);\nv = uvec4(b[i], b[i+1], b[i+2], b[i+3]);\nxor = (u ^ v) & 255u;\nbits = ivec4(POPCNT[xor.x], POPCNT[xor.y], POPCNT[xor.z], POPCNT[xor.w]);\ndist += bits.x + bits.y + bits.z + bits.w;\n}\nreturn dist;\n}\n#endif";
                }
              ),
              /***/
              6762: (
                /***/
                (module2) => {
                  module2.exports = '#ifndef _KEYPOINT_MATCHES_GLSL\n#define _KEYPOINT_MATCHES_GLSL\n@include "int32.glsl"\nconst int MATCH_INDEX_BITS = int(@MATCH_INDEX_BITS@);\nconst int MATCH_INDEX_MASK = int(@MATCH_INDEX_MASK@);\nconst int MATCH_MAX_INDEX = int(@MATCH_MAX_INDEX@);\nconst int MATCH_MAX_DISTANCE = int(@MATCH_MAX_DISTANCE@);\nstruct KeypointMatch\n{\nint index;\nint dist;\n};\nvec4 encodeKeypointMatch(KeypointMatch candidate)\n{\nuint index = uint(candidate.index) & uint(MATCH_INDEX_MASK);\nuint dist = uint(clamp(candidate.dist, 0, MATCH_MAX_DISTANCE));\nuint u32 = index | (dist << MATCH_INDEX_BITS);\nreturn encodeUint32(u32);\n}\nKeypointMatch decodeKeypointMatch(vec4 rgba)\n{\nuint u32 = decodeUint32(rgba);\nint dist = int(u32 >> MATCH_INDEX_BITS);\nint index = int(u32 & uint(MATCH_INDEX_MASK));\nreturn KeypointMatch(index, dist);\n}\nconst KeypointMatch MATCH_NOT_FOUND = KeypointMatch(MATCH_MAX_INDEX, MATCH_MAX_DISTANCE);\n#endif';
                }
              ),
              /***/
              7639: (
                /***/
                (module2) => {
                  module2.exports = '#ifndef _KEYPOINTS_GLSL\n#define _KEYPOINTS_GLSL\n@include "math.glsl"\n@include "fixed-point.glsl"\n@include "float16.glsl"\n@include "pyramids.glsl"\nstruct Keypoint\n{\nvec2 position;\nfloat lod;\nfloat orientation;\nfloat score;\nuint flags;\n};\nstruct KeypointAddress\n{\nint base;\nint offset;\n};\nconst int MIN_KEYPOINT_SIZE = int(@MIN_KEYPOINT_SIZE@);\nconst int MAX_DESCRIPTOR_SIZE = int(@MAX_DESCRIPTOR_SIZE@);\nconst uint KPF_NONE = 0u;\nconst uint KPF_NULL = 1u;\nconst uint KPF_DISCARDED = 2u;\n#define encodeKeypointScore(score) encodeFloat16(score)\n#define decodeKeypointScore(encodedScore) decodeFloat16(encodedScore)\n#define encodeKeypointOrientation(angle) ((angle) * INV_PI_OVER_2 + 0.5f)\n#define decodeKeypointOrientation(value) ((value) * TWO_PI - PI)\n#define encodeNullKeypoint() (vec4(1.0f))\n#define encodeDiscardedKeypoint() (vec4(0.0f))\n#define isNullKeypoint(keypoint) ((((keypoint).flags) & KPF_NULL) != 0u)\n#define isDiscardedKeypoint(keypoint) ((((keypoint).flags) & KPF_DISCARDED) != 0u)\n#define isBadKeypoint(keypoint) ((keypoint).score < 0.0f)\n#define sizeofEncodedKeypoint(descriptorSize, extraSize) (MIN_KEYPOINT_SIZE + (descriptorSize) + (extraSize))\n#define sizeofEncodedKeypointHeader() sizeofEncodedKeypoint(0,0)\n#define findKeypointIndex(address, descriptorSize, extraSize) ((address).base / ((sizeofEncodedKeypoint((descriptorSize), (extraSize))) / 4))\nvec4 readKeypointData(sampler2D encodedKeypoints, int encoderLength, KeypointAddress address)\n{\nint rasterIndex = address.base + address.offset;\nvec4 data = pixelAt(encodedKeypoints, ivec2(rasterIndex % encoderLength, rasterIndex / encoderLength));\nreturn rasterIndex < encoderLength * encoderLength ? data : encodeNullKeypoint();\n}\nKeypointAddress findKeypointAddress(ivec2 thread, int encoderLength, int descriptorSize, int extraSize)\n{\nint threadRaster = thread.y * encoderLength + thread.x;\nint pixelsPerKeypoint = sizeofEncodedKeypoint(descriptorSize, extraSize) / 4;\nint keypointIndex = int(threadRaster / pixelsPerKeypoint);\nKeypointAddress address = KeypointAddress(\nkeypointIndex * pixelsPerKeypoint,\nthreadRaster % pixelsPerKeypoint\n);\nreturn address;\n}\nKeypoint decodeKeypoint(sampler2D encodedKeypoints, int encoderLength, KeypointAddress address)\n{\nKeypoint keypoint;\nKeypointAddress positionAddress = KeypointAddress(address.base, 0);\nKeypointAddress propertiesAddress = KeypointAddress(address.base, 1);\nvec4 rawEncodedPosition = readKeypointData(encodedKeypoints, encoderLength, positionAddress);\nivec4 encodedPosition = ivec4(rawEncodedPosition * 255.0f);\nkeypoint.position = fixtovec2(fixed2_t(\nencodedPosition.r | (encodedPosition.g << 8),\nencodedPosition.b | (encodedPosition.a << 8)\n));\nvec4 rawEncodedProperties = readKeypointData(encodedKeypoints, encoderLength, propertiesAddress);\nkeypoint.lod = decodeLod(rawEncodedProperties.r);\nkeypoint.orientation = decodeKeypointOrientation(rawEncodedProperties.g);\nkeypoint.score = decodeKeypointScore(rawEncodedProperties.ba);\nbool isNull = all(equal(rawEncodedPosition, vec4(1)));\nbool isDiscarded = all(equal(rawEncodedPosition + rawEncodedProperties, vec4(0)));\nkeypoint.score = (isNull || isDiscarded) ? -1.0f : keypoint.score;\nkeypoint.flags = KPF_NONE;\nkeypoint.flags |= KPF_NULL * uint(isNull);\nkeypoint.flags |= KPF_DISCARDED * uint(isDiscarded);\nreturn keypoint;\n}\nvec4 encodeKeypointPosition(vec2 position)\n{\nconst vec2 zeros = vec2(0.0f);\nfixed2_t pos = vec2tofix(max(position, zeros));\nfixed2_t lo = pos & 255;\nfixed2_t hi = (pos >> 8) & 255;\nreturn vec4(lo.x, hi.x, lo.y, hi.y) / 255.0f;\n}\n#endif';
                }
              ),
              /***/
              431: (
                /***/
                (module2) => {
                  module2.exports = "#ifndef _MATH_GLSL\n#define _MATH_GLSL\n#define TWO_PI          6.28318530718f\n#define PI              3.14159265359f\n#define PI_OVER_2       1.57079632679f\n#define PI_OVER_4       0.78539816339f\n#define INV_PI          0.3183098861837907f\n#define INV_PI_OVER_2   0.15915494309189535f\nconst highp float INFINITY = 1.0f / 0.0f;\nfloat fastAtan(float x)\n{\nfloat w = 1.0f - abs(x);\nreturn (w >= 0.0f) ? ((PI_OVER_4 + 0.273f * w) * x) :\n(sign(x) * PI_OVER_2 - (PI_OVER_4 + 0.273f * (1.0f - abs(1.0f / x))) / x);\n}\nfloat fastAtan2(float y, float x)\n{\nreturn (x == 0.0f) ? PI_OVER_2 * sign(y) : fastAtan(y / x) + float(x < 0.0f) * PI * sign(y);\n}\n#endif";
                }
              ),
              /***/
              6822: (
                /***/
                (module2) => {
                  module2.exports = "#ifndef _PLATFORM_GLSL\n#define _PLATFORM_GLSL\n#if @APPLE@\n#define APPLE 1\n#endif\n#if @APPLE_GPU@\n#define APPLE_GPU 1\n#endif\n#if @INTEL_GRAPHICS@\n#define INTEL_GRAPHICS 1\n#endif\n#endif";
                }
              ),
              /***/
              2728: (
                /***/
                (module2) => {
                  module2.exports = "#ifndef _PYRAMIDS_GLSL\n#define _PYRAMIDS_GLSL\n#define pyrPixel(pyr, lod) textureLod((pyr), texCoord, (lod))\n#define pyrPixelAtOffset(pyr, lod, pot, offset) textureLod((pyr), texCoord + ((pot) * vec2(offset)) / texSize, (lod))\n#define pyrPixelAt(pyr, pos, lod) textureLod((pyr), (vec2(pos) + vec2(0.5f)) / texSize, (lod))\n#define pyrPixelAtEx(pyr, pos, lod, pyrBaseSize) textureLod((pyr), (vec2(pos) + vec2(0.5f)) / vec2(pyrBaseSize), (lod))\n#define pyrSubpixelAtEx(pyr, pos, lod, pyrBaseSize) textureLod((pyr), ((pos) + vec2(0.5f)) / vec2(pyrBaseSize), (lod))\n#define pyrSubpixelAtExOffset(pyr, pos, lod, pot, offset, pyrBaseSize) textureLod((pyr), (((pos) + vec2(0.5f)) + ((pot) * vec2(offset))) / vec2(pyrBaseSize), (lod))\nconst int PYRAMID_MAX_LEVELS = int(@PYRAMID_MAX_LEVELS@);\nconst float F_PYRAMID_MAX_LEVELS = float(@PYRAMID_MAX_LEVELS@);\nconst float LOG2_PYRAMID_MAX_SCALE = float(@LOG2_PYRAMID_MAX_SCALE@);\n#define encodeLod(lod) ((LOG2_PYRAMID_MAX_SCALE + (lod)) / (LOG2_PYRAMID_MAX_SCALE + F_PYRAMID_MAX_LEVELS))\nfloat decodeLod(float encodedLod)\n{\nfloat lod = encodedLod * (LOG2_PYRAMID_MAX_SCALE + F_PYRAMID_MAX_LEVELS) - LOG2_PYRAMID_MAX_SCALE;\nreturn lod - lod * step(1.0f, encodedLod);\n}\n#define LOD_EPS 0.0625f\nconst float ENCODED_LOD_EPS = (LOD_EPS / (LOG2_PYRAMID_MAX_SCALE + F_PYRAMID_MAX_LEVELS));\n#define isSameLod(lod1, lod2) (abs((lod1) - (lod2)) < LOD_EPS)\n#define isSameEncodedLod(alpha1, alpha2) (abs((alpha1) - (alpha2)) < ENCODED_LOD_EPS)\n#endif";
                }
              ),
              /***/
              6823: (
                /***/
                (module2) => {
                  module2.exports = "#ifndef _SUBPIXEL_GLSL\n#define _SUBPIXEL_GLSL\n#define subpixelAt(image, pos) textureLod((image), ((pos) + vec2(0.5f)) / texSize, 0.0f)\nvec4 subpixelAtBI(sampler2D image, vec2 pos)\n{\nvec2 frc = fract(pos);\nvec2 ifrc = vec2(1.0f) - frc;\nvec2 p = (floor(pos) + vec2(0.5f)) / vec2(textureSize(image, 0));\nvec4 pix00 = textureLod(image, p, 0.0f);\nvec4 pix10 = textureLodOffset(image, p, 0.0f, ivec2(1,0));\nvec4 pix01 = textureLodOffset(image, p, 0.0f, ivec2(0,1));\nvec4 pix11 = textureLodOffset(image, p, 0.0f, ivec2(1,1));\nmat4 pix = mat4(pix00, pix10, pix01, pix11);\nvec4 mul = vec4(ifrc.x * ifrc.y, frc.x * ifrc.y, ifrc.x * frc.y, frc.x * frc.y);\nreturn pix * mul;\n}\n#endif";
                }
              ),
              /***/
              1341: (
                /***/
                (module2) => {
                  module2.exports = '@include "keypoints.glsl"\nuniform sampler2D inputEncodedKeypoints;\nuniform int inputDescriptorSize;\nuniform int inputExtraSize;\nuniform int inputEncoderLength;\nuniform int outputDescriptorSize;\nuniform int outputExtraSize;\nuniform int outputEncoderLength;\nconst vec4 EMPTY_DESCRIPTOR = vec4(0.0f);\nvoid main()\n{\nivec2 thread = threadLocation();\nKeypointAddress myAddress = findKeypointAddress(thread, outputEncoderLength, outputDescriptorSize, outputExtraSize);\nint myIndex = findKeypointIndex(myAddress, outputDescriptorSize, outputExtraSize);\nint headerSize = sizeofEncodedKeypointHeader();\nbool isDescriptor = (myAddress.offset >= (headerSize + outputExtraSize) / 4);\nint addressOffset = myAddress.offset;\nint pixelsPerKeypoint = sizeofEncodedKeypoint(inputDescriptorSize, inputExtraSize) / 4;\nKeypointAddress otherAddress = KeypointAddress(myIndex * pixelsPerKeypoint, addressOffset);\ncolor = isDescriptor ? EMPTY_DESCRIPTOR : readKeypointData(inputEncodedKeypoints, inputEncoderLength, otherAddress);\n}';
                }
              ),
              /***/
              7833: (
                /***/
                (module2) => {
                  module2.exports = '@include "keypoints.glsl"\nuniform sampler2D inputEncodedKeypoints;\nuniform int inputDescriptorSize;\nuniform int inputExtraSize;\nuniform int inputEncoderLength;\nuniform int outputDescriptorSize;\nuniform int outputExtraSize;\nuniform int outputEncoderLength;\nvoid main()\n{\nivec2 thread = threadLocation();\nKeypointAddress myAddress = findKeypointAddress(thread, outputEncoderLength, outputDescriptorSize, outputExtraSize);\nint myIndex = findKeypointIndex(myAddress, outputDescriptorSize, outputExtraSize);\nint headerSize = sizeofEncodedKeypointHeader();\nbool isHead = (myAddress.offset < headerSize / 4);\nbool isDescriptor = (myAddress.offset >= (headerSize + outputExtraSize) / 4);\nbool isExtra = (!isHead && !isDescriptor);\nint numberOfExtraPixels = outputExtraSize / 4;\nint addressOffset = myAddress.offset - int(isDescriptor) * numberOfExtraPixels;\nint pixelsPerKeypoint = sizeofEncodedKeypoint(inputDescriptorSize, inputExtraSize) / 4;\nKeypointAddress otherAddress = KeypointAddress(myIndex * pixelsPerKeypoint, addressOffset);\ncolor = isExtra ? vec4(0.0f) : readKeypointData(inputEncodedKeypoints, inputEncoderLength, otherAddress);\n}';
                }
              ),
              /***/
              2352: (
                /***/
                (module2) => {
                  module2.exports = '@include "keypoints.glsl"\nuniform mat3 homography;\nuniform sampler2D encodedKeypoints;\nuniform int descriptorSize;\nuniform int extraSize;\nuniform int encoderLength;\nvoid main()\n{\nvec4 pixel = threadPixel(encodedKeypoints);\nivec2 thread = threadLocation();\nKeypointAddress address = findKeypointAddress(thread, encoderLength, descriptorSize, extraSize);\ncolor = pixel;\nif(address.offset != 0)\nreturn;\nKeypoint keypoint = decodeKeypoint(encodedKeypoints, encoderLength, address);\nif(isBadKeypoint(keypoint))\nreturn;\nvec3 pos3 = homography * vec3(keypoint.position, 1.0f);\ncolor = encodeKeypointPosition(pos3.xy / pos3.z);\n}';
                }
              ),
              /***/
              7541: (
                /***/
                (module2) => {
                  module2.exports = '@include "keypoints.glsl"\n@include "keypoint-descriptors.glsl"\n@include "keypoint-matches.glsl"\nuniform sampler2D encodedMatches;\nuniform sampler2D encodedFilters;\nuniform int matcherLength;\nuniform sampler2D dbEncodedKeypoints;\nuniform int dbDescriptorSize;\nuniform int dbExtraSize;\nuniform int dbEncoderLength;\nuniform sampler2D encodedKeypoints;\nuniform int descriptorSize;\nuniform int extraSize;\nuniform int encoderLength;\nuniform int passId;\n#ifndef NUMBER_OF_KEYPOINTS_PER_PASS\n#error Undefined NUMBER_OF_KEYPOINTS_PER_PASS\n#endif\nconst int INFINITE_DISTANCE = MATCH_MAX_DISTANCE + 1;\nvoid main()\n{\nivec2 thread = threadLocation();\nint keypointIndex = thread.x + thread.y * matcherLength;\nint pixelsPerKeypoint = sizeofEncodedKeypoint(descriptorSize, extraSize) / 4;\nKeypointAddress address = KeypointAddress(keypointIndex * pixelsPerKeypoint, 0);\nKeypoint keypoint = decodeKeypoint(encodedKeypoints, encoderLength, address);\ncolor = encodeKeypointMatch(MATCH_NOT_FOUND);\nif(isBadKeypoint(keypoint))\nreturn;\nKeypointMatch bestMatch = decodeKeypointMatch(threadPixel(encodedMatches));\nKeypointMatch filterMatch = decodeKeypointMatch(threadPixel(encodedFilters));\nuint[DESCRIPTOR_SIZE] descriptor = readKeypointDescriptor(encodedKeypoints, descriptorSize, extraSize, encoderLength, address);\nuint[DESCRIPTOR_SIZE] dbDescriptor;\nint dbPixelsPerKeypoint = sizeofEncodedKeypoint(dbDescriptorSize, dbExtraSize) / 4;\nfor(int i = 0; i < NUMBER_OF_KEYPOINTS_PER_PASS; i++) {\nint dbKeypointIndex = passId * NUMBER_OF_KEYPOINTS_PER_PASS + i;\nKeypointAddress dbAddress = KeypointAddress(dbKeypointIndex * dbPixelsPerKeypoint, 0);\nKeypoint dbKeypoint = decodeKeypoint(dbEncodedKeypoints, dbEncoderLength, dbAddress);\ndbDescriptor = readKeypointDescriptor(dbEncodedKeypoints, dbDescriptorSize, dbExtraSize, dbEncoderLength, dbAddress);\nint dist = !isBadKeypoint(dbKeypoint) ? distanceBetweenKeypointDescriptors(descriptor, dbDescriptor) : INFINITE_DISTANCE;\nbestMatch.index = all(bvec2(\ndist < bestMatch.dist || (dist == bestMatch.dist && dbKeypointIndex > bestMatch.index),\ndist > filterMatch.dist || (dist == filterMatch.dist && dbKeypointIndex < filterMatch.index)\n)) ? dbKeypointIndex : bestMatch.index;\nbestMatch.dist = dbKeypointIndex == bestMatch.index ? dist : bestMatch.dist;\n}\ncolor = encodeKeypointMatch(bestMatch);\n}';
                }
              ),
              /***/
              4868: (
                /***/
                (module2) => {
                  module2.exports = '@include "keypoints.glsl"\nuniform int imageWidth;\nuniform int imageHeight;\nuniform int borderTop;\nuniform int borderRight;\nuniform int borderBottom;\nuniform int borderLeft;\nuniform sampler2D encodedKeypoints;\nuniform int descriptorSize;\nuniform int extraSize;\nuniform int encoderLength;\nvoid main()\n{\nivec2 thread = threadLocation();\nKeypointAddress addr = findKeypointAddress(thread, encoderLength, descriptorSize, extraSize);\nKeypoint keypoint = decodeKeypoint(encodedKeypoints, encoderLength, addr);\nvec2 p = keypoint.position;\nbool withinBorder = any(lessThan(\nvec4(p.x, p.y, -p.x, -p.y),\nvec4(borderLeft, borderTop, borderRight - (imageWidth - 1), borderBottom - (imageHeight - 1))\n));\nvec4 pixel = threadPixel(encodedKeypoints);\nvec4 nullPixel = encodeNullKeypoint();\ncolor = withinBorder ? nullPixel : pixel;\n}';
                }
              ),
              /***/
              5591: (
                /***/
                (module2) => {
                  module2.exports = '@include "keypoints.glsl"\nuniform sampler2D encodedKeypoints;\nuniform int descriptorSize;\nuniform int extraSize;\nuniform int encoderLength;\nuniform int maxKeypoints;\nvoid main()\n{\nivec2 thread = threadLocation();\nint newEncoderLength = outputSize().x;\nKeypointAddress address = findKeypointAddress(thread, newEncoderLength, descriptorSize, extraSize);\nint index = findKeypointIndex(address, descriptorSize, extraSize);\nvec4 pixel = readKeypointData(encodedKeypoints, encoderLength, address);\ncolor = index < maxKeypoints ? pixel : encodeNullKeypoint();\n}';
                }
              ),
              /***/
              191: (
                /***/
                (module2) => {
                  module2.exports = '@include "keypoints.glsl"\nuniform sampler2D encodedKeypointsA;\nuniform int encoderLengthA;\nuniform sampler2D encodedKeypointsB;\nuniform int encoderLengthB;\nuniform int descriptorSize;\nuniform int extraSize;\nuniform int encoderLength;\nuniform float threshold;\nvoid main()\n{\nivec2 thread = threadLocation();\nKeypointAddress address = findKeypointAddress(thread, encoderLength, descriptorSize, extraSize);\nint index = findKeypointIndex(address, descriptorSize, extraSize);\nint pixelsPerKeypoint = sizeofEncodedKeypoint(descriptorSize, extraSize) / 4;\nvec4 data = readKeypointData(encodedKeypointsA, encoderLengthA, address);\ncolor = data;\nif(address.offset >= sizeofEncodedKeypointHeader() / 4)\nreturn;\nKeypoint keypointA = decodeKeypoint(encodedKeypointsA, encoderLengthA, address);\nKeypoint keypointB = decodeKeypoint(encodedKeypointsB, encoderLengthB, address);\ncolor = encodeNullKeypoint();\nif(isNullKeypoint(keypointA) && isNullKeypoint(keypointB))\nreturn;\ncolor = encodeDiscardedKeypoint();\nif(isDiscardedKeypoint(keypointA) || isDiscardedKeypoint(keypointB))\nreturn;\ncolor = encodeDiscardedKeypoint();\nif(isNullKeypoint(keypointA) || isNullKeypoint(keypointB))\nreturn;\nvec2 delta = keypointA.position - keypointB.position;\nbool shouldKeep = (dot(delta, delta) <= threshold * threshold);\ncolor = shouldKeep ? data : encodeDiscardedKeypoint();\n}';
                }
              ),
              /***/
              5467: (
                /***/
                (module2) => {
                  module2.exports = '@include "float16.glsl"\nuniform sampler2D offsetsImage;\nuniform ivec2 imageSize;\n#ifndef MAX_ITERATIONS\n#error Undefined MAX_ITERATIONS\n#endif\n#define decodeSkipOffset(pixel) (int((pixel).g * 255.0f) | (int((pixel).a * 255.0f) << 8))\n#define encodeSkipOffset(offset) (vec2((offset) & 255, (offset) >> 8) / 255.0f)\nvoid main()\n{\nvec4 pixel = threadPixel(offsetsImage);\nivec2 thread = threadLocation();\nint rasterIndex = thread.y * imageSize.x + thread.x;\nint offset = decodeSkipOffset(pixel);\nint totalOffset = offset;\nvec2 encodedScore = pixel.rb;\nivec2 pos = thread; int allow = 1;\n@unroll\nfor(int i = 0; i < MAX_ITERATIONS; i++) {\nallow *= int(pos.y < imageSize.y) * int(isEncodedFloat16Zero(pixel.rb));\nrasterIndex += allow * offset;\npos = ivec2(rasterIndex % imageSize.x, rasterIndex / imageSize.x);\npixel = pixelAt(offsetsImage, pos);\noffset = decodeSkipOffset(pixel);\ntotalOffset += allow * offset;\n}\ntotalOffset = min(totalOffset, 65535);\ncolor.rb = encodedScore;\ncolor.ga = encodeSkipOffset(totalOffset);\n}';
                }
              ),
              /***/
              336: (
                /***/
                (module2) => {
                  module2.exports = '@include "float16.glsl"\nuniform sampler2D corners;\nuniform ivec2 imageSize;\nvoid main()\n{\nvec4 pixel = threadPixel(corners);\nivec2 pos = threadLocation();\nvec2 encodedScore = pixel.rb;\nint offset = 0, allow = 1, jumped = 0;\n#define READ(j) ; \\\nallow *= int(pos.y < imageSize.y) * int(isEncodedFloat16Zero(pixel.rb)); \\\noffset += allow; \\\npos.x = (pos.x + 1) % imageSize.x; \\\npos.y += int(pos.x == 0); \\\npixel = (0 != (jumped |= int(pos.x == 0))) ? pixelAtShortOffset(corners, ivec2((j),1)) : pixelAtShortOffset(corners, ivec2((j),0))\nREAD(1); READ(2); READ(3); READ(4); READ(5); READ(6); READ(7);\ncolor.rb = encodedScore;\ncolor.ga = vec2(offset, 0) / 255.0f;\n}';
                }
              ),
              /***/
              8968: (
                /***/
                (module2) => {
                  module2.exports = '@include "keypoints.glsl"\nuniform sampler2D offsetsImage;\nuniform ivec2 imageSize;\nuniform int passId;\nuniform int numPasses;\nuniform int keypointLimit;\nuniform sampler2D encodedKeypoints;\nuniform int descriptorSize;\nuniform int extraSize;\nuniform int encoderLength;\n#define decodeSkipOffset(pixel) (int((pixel).g * 255.0f) | (int((pixel).a * 255.0f) << 8))\nbool findQthKeypoint(int q, int p, inout ivec2 position, out vec4 pixel)\n{\nint notFirstPass = int(passId > 0);\nposition *= notFirstPass;\np |= -(1 - notFirstPass);\np -= notFirstPass;\nint rasterIndex = position.y * imageSize.x + position.x;\nwhile(position.y < imageSize.y && p != q) {\nposition = ivec2(rasterIndex % imageSize.x, rasterIndex / imageSize.x);\npixel = texelFetch(offsetsImage, position, 0);\np += int(!isEncodedFloat16Zero(pixel.rb));\nrasterIndex += max(1, decodeSkipOffset(pixel));\n}\nreturn (p == q);\n}\nvoid main()\n{\nivec2 thread = threadLocation();\nint pixelsPerKeypoint = sizeofEncodedKeypoint(descriptorSize, extraSize) / 4;\nKeypointAddress address = findKeypointAddress(thread, encoderLength, descriptorSize, extraSize);\nint q = findKeypointIndex(address, descriptorSize, extraSize);\ncolor = vec4(0.0f);\nif(address.offset != 0)\nreturn;\ncolor = threadPixel(encodedKeypoints);\nint numPixels = encoderLength * encoderLength;\nint maxKeypoints = numPixels / pixelsPerKeypoint;\nint maxKeypointsPerPass = maxKeypoints / numPasses + int(maxKeypoints % numPasses != 0);\nint targetPassId = q / maxKeypointsPerPass;\nif(passId != targetPassId)\nreturn;\nint lastIndexFromPrevPass = passId * maxKeypointsPerPass - 1;\nKeypointAddress lastAddressFromPrevPass = KeypointAddress(max(0, lastIndexFromPrevPass) * pixelsPerKeypoint, 0);\nKeypoint lastKeypointFromPrevPass = decodeKeypoint(encodedKeypoints, encoderLength, lastAddressFromPrevPass);\nivec2 position = passId > 0 ? ivec2(lastKeypointFromPrevPass.position) : ivec2(0);\nvec4 pixel;\ncolor = encodeNullKeypoint();\nif(q >= min(maxKeypoints, keypointLimit) || !findQthKeypoint(q, lastIndexFromPrevPass, position, pixel))\nreturn;\ncolor = encodeKeypointPosition(vec2(position));\n}';
                }
              ),
              /***/
              1733: (
                /***/
                (module2) => {
                  module2.exports = '@include "keypoints.glsl"\nuniform sampler2D corners;\nuniform sampler2D encodedKeypoints;\nuniform int descriptorSize;\nuniform int extraSize;\nuniform int encoderLength;\nvoid main()\n{\nivec2 thread = threadLocation();\nvec4 pixel = threadPixel(encodedKeypoints);\nint pixelsPerKeypoint = sizeofEncodedKeypoint(descriptorSize, extraSize) / 4;\nKeypointAddress address = findKeypointAddress(thread, encoderLength, descriptorSize, extraSize);\nint q = findKeypointIndex(address, descriptorSize, extraSize);\ncolor = pixel;\nif(address.offset != 1)\nreturn;\nKeypoint keypoint = decodeKeypoint(encodedKeypoints, encoderLength, address);\nvec4 kpix = pixelAt(corners, ivec2(keypoint.position));\nkeypoint.score = decodeFloat16(kpix.rb);\ncolor.r = kpix.a;\ncolor.g = encodeKeypointOrientation(0.0f);\ncolor.ba = encodeKeypointScore(keypoint.score);\n}';
                }
              ),
              /***/
              9674: (
                /***/
                (module2) => {
                  module2.exports = '@include "keypoints.glsl"\nuniform sampler2D corners;\nuniform mediump usampler2D lookupTable;\nuniform int stride;\nuniform int descriptorSize;\nuniform int extraSize;\nuniform int encoderLength;\nuniform int encoderCapacity;\nconst uvec2 NULL_ELEMENT = uvec2(0xFFFFu);\nvoid main()\n{\nivec2 thread = threadLocation();\nKeypointAddress address = findKeypointAddress(thread, encoderLength, descriptorSize, extraSize);\nint index = findKeypointIndex(address, descriptorSize, extraSize);\nivec2 pos = ivec2(index % stride, index / stride);\nuvec4 entry = texelFetch(lookupTable, pos, 0);\nint pixelsPerKeypoint = sizeofEncodedKeypoint(descriptorSize, extraSize) / 4;\nint rasterIndex = address.base + address.offset;\nint numberOfPixels = encoderLength * encoderLength;\nint numberOfValidPixels = numberOfPixels - (numberOfPixels % pixelsPerKeypoint);\nint maxEncoderCapacity = numberOfValidPixels / pixelsPerKeypoint;\ncolor = encodeNullKeypoint();\nif(all(equal(entry.xy, NULL_ELEMENT)) || index >= min(encoderCapacity, maxEncoderCapacity))\nreturn;\ncolor = encodeKeypointPosition(vec2(entry.xy));\nif(address.offset == 0)\nreturn;\ncolor = vec4(0.0f);\nif(address.offset >= sizeofEncodedKeypointHeader() / 4)\nreturn;\nvec4 pixel = texelFetch(corners, ivec2(entry.xy), 0);\nvec2 encodedScore = encodeKeypointScore(decodeFloat16(pixel.rb));\nfloat encodedOrientation = encodeKeypointOrientation(0.0f);\nfloat encodedLod = pixel.a;\ncolor = vec4(encodedLod, encodedOrientation, encodedScore);\n}';
                }
              ),
              /***/
              2090: (
                /***/
                (module2) => {
                  module2.exports = '@include "keypoints.glsl"\nvoid main()\n{\ncolor = encodeNullKeypoint();\n}';
                }
              ),
              /***/
              1855: (
                /***/
                (module2) => {
                  module2.exports = '@include "pyramids.glsl"\n@include "float16.glsl"\nuniform sampler2D corners;\nuniform sampler2D pyramid;\nuniform float lod;\nuniform int threshold;\n#define USE_VARYINGS 1\n#if !defined(FAST_TYPE)\n#error Undefined FAST_TYPE\n#elif FAST_TYPE == 916\nin vec2 v_pix0, v_pix1, v_pix2, v_pix3, v_pix4, v_pix5, v_pix6, v_pix7,\nv_pix8, v_pix9, v_pix10,v_pix11,v_pix12,v_pix13,v_pix14,v_pix15;\n#else\n#error Invalid FAST_TYPE\n#endif\n#define PIX(x,y) pyrPixelAtOffset(pyramid, lod, pot, ivec2((x),(y))).g\n#define XIP(v) textureLod(pyramid, (v), lod).g\nvoid main()\n{\nfloat pixel = threadPixel(pyramid).g;\nvec4 prev = threadPixel(corners);\nivec2 thread = threadLocation();\nivec2 size = outputSize();\nfloat pot = exp2(lod);\nfloat t = float(clamp(threshold, 0, 255)) / 255.0f;\nfloat ct = pixel + t, c_t = pixel - t;\ncolor = vec4(prev.r, pixel, prev.ba);\n#if FAST_TYPE == 916\nconst ivec4 margin = ivec4(3, 3, 4, 4);\nif(any(lessThan(ivec4(thread, size - thread), margin)))\nreturn;\n#if USE_VARYINGS\nfloat p0 = XIP(v_pix0), p4 = XIP(v_pix4), p8 = XIP(v_pix8), p12 = XIP(v_pix12);\n#else\nfloat p0 = PIX(0,3), p4 = PIX(3,0), p8 = PIX(0,-3), p12 = PIX(-3,0);\n#endif\nbvec4 brighter = bvec4(p0 > ct, p4 > ct, p8 > ct, p12 > ct);\nbvec4 darker = bvec4(p0 < c_t, p4 < c_t, p8 < c_t, p12 < c_t);\nbvec4 bpairs = bvec4(all(brighter.xy), all(brighter.yz), all(brighter.zw), all(brighter.wx));\nbvec4 dpairs = bvec4(all(darker.xy), all(darker.yz), all(darker.zw), all(darker.wx));\nif(!(any(bpairs) || any(dpairs)))\nreturn;\n#if USE_VARYINGS\nfloat p1 = XIP(v_pix1), p2 = XIP(v_pix2), p3 = XIP(v_pix3),\np5 = XIP(v_pix5), p6 = XIP(v_pix6), p7 = XIP(v_pix7),\np9 = XIP(v_pix9), p10 = XIP(v_pix10), p11 = XIP(v_pix11),\np13 = XIP(v_pix13), p14 = XIP(v_pix14), p15 = XIP(v_pix15);\n#else\nfloat p1 = PIX(1,3), p2 = PIX(2,2), p3 = PIX(3,1),\np5 = PIX(3,-1), p6 = PIX(2,-2), p7 = PIX(1,-3),\np9 = PIX(-1,-3), p10 = PIX(-2,-2), p11 = PIX(-3,-1),\np13 = PIX(-3,1), p14 = PIX(-2,2), p15 = PIX(-1,3);\n#endif\nbool A=(p0>ct),B=(p1>ct),C=(p2>ct),D=(p3>ct),E=(p4>ct),F=(p5>ct),G=(p6>ct),H=(p7>ct),I=(p8>ct),J=(p9>ct),K=(p10>ct),L=(p11>ct),M=(p12>ct),N=(p13>ct),O=(p14>ct),P=(p15>ct),a=(p0<c_t),b=(p1<c_t),c=(p2<c_t),d=(p3<c_t),e=(p4<c_t),f=(p5<c_t),g=(p6<c_t),h=(p7<c_t),i=(p8<c_t),j=(p9<c_t),k=(p10<c_t),l=(p11<c_t),m=(p12<c_t),n=(p13<c_t),o=(p14<c_t),p=(p15<c_t);\nbool isCorner=A&&(B&&(K&&L&&J&&(M&&N&&O&&P||G&&H&&I&&(M&&N&&O||F&&(M&&N||E&&(M||D))))||C&&(K&&L&&M&&(N&&O&&P||G&&H&&I&&J&&(N&&O||F&&(N||E)))||D&&(N&&(L&&M&&(K&&G&&H&&I&&J&&(O||F)||O&&P)||k&&l&&m&&e&&f&&g&&h&&i&&j)||E&&(O&&(M&&N&&(K&&L&&G&&H&&I&&J||P)||k&&l&&m&&n&&f&&g&&h&&i&&j)||F&&(P&&(N&&O||k&&l&&m&&n&&o&&g&&h&&i&&j)||G&&(O&&P||H&&(P||I)||k&&l&&m&&n&&o&&p&&h&&i&&j)||k&&l&&m&&n&&o&&h&&i&&j&&(p||g))||k&&l&&m&&n&&h&&i&&j&&(o&&(p||g)||f&&(o&&p||g)))||k&&l&&m&&h&&i&&j&&(n&&(o&&p||g&&(o||f))||e&&(n&&o&&p||g&&(n&&o||f))))||k&&l&&h&&i&&j&&(m&&(n&&o&&p||g&&(n&&o||f&&(n||e)))||d&&(m&&n&&o&&p||g&&(m&&n&&o||f&&(m&&n||e)))))||k&&h&&i&&j&&(l&&(m&&n&&o&&p||g&&(m&&n&&o||f&&(m&&n||e&&(m||d))))||c&&(l&&m&&n&&o&&p||g&&(l&&m&&n&&o||f&&(l&&m&&n||e&&(l&&m||d))))))||K&&I&&J&&(L&&M&&N&&O&&P||G&&H&&(L&&M&&N&&O||F&&(L&&M&&N||E&&(L&&M||D&&(L||C)))))||h&&i&&j&&(b&&(k&&l&&m&&n&&o&&p||g&&(k&&l&&m&&n&&o||f&&(k&&l&&m&&n||e&&(k&&l&&m||d&&(k&&l||c)))))||k&&(l&&m&&n&&o&&p||g&&(l&&m&&n&&o||f&&(l&&m&&n||e&&(l&&m||d&&(l||c)))))))||B&&(H&&I&&J&&(K&&L&&M&&N&&O&&P&&a||G&&(K&&L&&M&&N&&O&&a||F&&(K&&L&&M&&N&&a||E&&(K&&L&&M&&a||D&&(K&&L&&a||C)))))||a&&k&&i&&j&&(l&&m&&n&&o&&p||g&&h&&(l&&m&&n&&o||f&&(l&&m&&n||e&&(l&&m||d&&(l||c))))))||C&&(K&&H&&I&&J&&(L&&M&&N&&O&&P&&a&&b||G&&(L&&M&&N&&O&&a&&b||F&&(L&&M&&N&&a&&b||E&&(L&&M&&a&&b||D))))||a&&b&&k&&l&&j&&(m&&n&&o&&p||g&&h&&i&&(m&&n&&o||f&&(m&&n||e&&(m||d)))))||D&&(K&&L&&H&&I&&J&&(M&&N&&O&&P&&a&&b&&c||G&&(M&&N&&O&&a&&b&&c||F&&(M&&N&&a&&b&&c||E)))||a&&b&&k&&l&&m&&c&&(n&&o&&p||g&&h&&i&&j&&(n&&o||f&&(n||e))))||E&&(K&&L&&M&&H&&I&&J&&(N&&O&&P&&a&&b&&c&&d||G&&(N&&O&&a&&b&&c&&d||F))||a&&b&&l&&m&&n&&c&&d&&(k&&g&&h&&i&&j&&(o||f)||o&&p))||F&&(K&&L&&M&&N&&H&&I&&J&&(O&&P&&a&&b&&c&&d&&e||G)||a&&b&&m&&n&&o&&c&&d&&e&&(k&&l&&g&&h&&i&&j||p))||G&&(K&&L&&M&&N&&O&&H&&I&&J||a&&b&&n&&o&&p&&c&&d&&e&&f)||H&&(K&&L&&M&&N&&O&&P&&I&&J||a&&b&&o&&p&&c&&d&&e&&f&&g)||a&&(b&&(k&&l&&j&&(m&&n&&o&&p||g&&h&&i&&(m&&n&&o||f&&(m&&n||e&&(m||d))))||c&&(k&&l&&m&&(n&&o&&p||g&&h&&i&&j&&(n&&o||f&&(n||e)))||d&&(l&&m&&n&&(k&&g&&h&&i&&j&&(o||f)||o&&p)||e&&(m&&n&&o&&(k&&l&&g&&h&&i&&j||p)||f&&(n&&o&&p||g&&(o&&p||h&&(p||i)))))))||k&&i&&j&&(l&&m&&n&&o&&p||g&&h&&(l&&m&&n&&o||f&&(l&&m&&n||e&&(l&&m||d&&(l||c))))))||h&&i&&j&&(k&&l&&m&&n&&o&&p||g&&(k&&l&&m&&n&&o||f&&(k&&l&&m&&n||e&&(k&&l&&m||d&&(k&&l||c&&(b||k))))));\nif(!isCorner)\nreturn;\nmat4 mp = mat4(p0,p1,p2,p3,p4,p5,p6,p7,p8,p9,p10,p11,p12,p13,p14,p15);\nmat4 mct = mp - mat4(ct,ct,ct,ct,ct,ct,ct,ct,ct,ct,ct,ct,ct,ct,ct,ct);\nmat4 mc_t = mat4(c_t,c_t,c_t,c_t,c_t,c_t,c_t,c_t,c_t,c_t,c_t,c_t,c_t,c_t,c_t,c_t) - mp;\nconst vec4 zeros = vec4(0.0f), ones = vec4(1.0f);\nvec4 bs = max(mct[0], zeros), ds = max(mc_t[0], zeros);\nbs += max(mct[1], zeros);     ds += max(mc_t[1], zeros);\nbs += max(mct[2], zeros);     ds += max(mc_t[2], zeros);\nbs += max(mct[3], zeros);     ds += max(mc_t[3], zeros);\nfloat thisScore = max(dot(bs, ones), dot(ds, ones)) / 16.0f;\nfloat prevScore = decodeFloat16(prev.rb);\nvec3 thisResult = vec3(encodeFloat16(thisScore), encodeLod(lod));\ncolor.rba = thisScore > prevScore ? thisResult : color.rba;\n#endif\n}';
                }
              ),
              /***/
              4824: (
                /***/
                (module2) => {
                  module2.exports = "uniform mediump float lod;\n#if !defined(FAST_TYPE)\n#error Undefined FAST_TYPE\n#elif FAST_TYPE == 916\nout vec2 v_pix0, v_pix1, v_pix2, v_pix3, v_pix4, v_pix5, v_pix6, v_pix7,\nv_pix8, v_pix9, v_pix10,v_pix11,v_pix12,v_pix13,v_pix14,v_pix15;\n#else\n#error Invalid FAST_TYPE\n#endif\n#define PIX(x,y) (texCoord + ((pot) * vec2((x),(y))) / texSize)\nvoid vsmain()\n{\nfloat pot = exp2(lod);\n#if FAST_TYPE == 916\nv_pix0 = PIX(0,3); v_pix1 = PIX(1,3), v_pix2 = PIX(2,2), v_pix3 = PIX(3,1);\nv_pix4 = PIX(3,0); v_pix5 = PIX(3,-1), v_pix6 = PIX(2,-2), v_pix7 = PIX(1,-3);\nv_pix8 = PIX(0,-3); v_pix9 = PIX(-1,-3), v_pix10 = PIX(-2,-2), v_pix11 = PIX(-3,-1);\nv_pix12 = PIX(-3,0); v_pix13 = PIX(-3,1), v_pix14 = PIX(-2,2), v_pix15 = PIX(-1,3);\n#endif\n}";
                }
              ),
              /***/
              2381: (
                /***/
                (module2) => {
                  module2.exports = '@include "keypoints.glsl"\n@include "keypoint-descriptors.glsl"\nuniform sampler2D encodedKeypointsA;\nuniform int encoderLengthA;\nuniform sampler2D encodedKeypointsB;\nuniform int encoderLengthB;\nuniform int descriptorSize;\nuniform int extraSize;\nuniform int encoderLength;\nuniform int threshold;\nvoid main()\n{\nivec2 thread = threadLocation();\nKeypointAddress address = findKeypointAddress(thread, encoderLength, descriptorSize, extraSize);\nint index = findKeypointIndex(address, descriptorSize, extraSize);\nint pixelsPerKeypoint = sizeofEncodedKeypoint(descriptorSize, extraSize) / 4;\nvec4 data = readKeypointData(encodedKeypointsA, encoderLengthA, address);\ncolor = data;\nif(address.offset >= sizeofEncodedKeypointHeader() / 4)\nreturn;\nKeypoint keypointA = decodeKeypoint(encodedKeypointsA, encoderLengthA, address);\nKeypoint keypointB = decodeKeypoint(encodedKeypointsB, encoderLengthB, address);\ncolor = encodeNullKeypoint();\nif(isNullKeypoint(keypointA) && isNullKeypoint(keypointB))\nreturn;\ncolor = encodeDiscardedKeypoint();\nif(isDiscardedKeypoint(keypointA) || isDiscardedKeypoint(keypointB))\nreturn;\ncolor = encodeDiscardedKeypoint();\nif(isNullKeypoint(keypointA) || isNullKeypoint(keypointB))\nreturn;\nuint[DESCRIPTOR_SIZE] descriptorA, descriptorB;\ndescriptorA = readKeypointDescriptor(encodedKeypointsA, descriptorSize, extraSize, encoderLengthA, address);\ndescriptorB = readKeypointDescriptor(encodedKeypointsB, descriptorSize, extraSize, encoderLengthB, address);\nint dist = distanceBetweenKeypointDescriptors(descriptorA, descriptorB);\nbool shouldKeep = (dist <= threshold);\ncolor = shouldKeep ? data : encodeDiscardedKeypoint();\n}';
                }
              ),
              /***/
              6060: (
                /***/
                (module2) => {
                  module2.exports = '@include "float16.glsl"\nuniform sampler2D corners;\nuniform sampler2D maxScore;\nuniform float quality;\nvoid main()\n{\nvec4 pixel = threadPixel(corners);\nfloat score = decodeFloat16(pixel.rb);\nfloat maxval = decodeFloat16(threadPixel(maxScore).rb);\nfloat threshold = maxval * clamp(quality, 0.0f, 1.0f);\ncolor = pixel;\ncolor.rb = score >= threshold ? color.rb : encodeFloat16(0.0f);\n}';
                }
              ),
              /***/
              9974: (
                /***/
                (module2) => {
                  module2.exports = '@include "pyramids.glsl"\n@include "float16.glsl"\n@include "filters.glsl"\n#if !defined(WINDOW_SIZE)\n#error Undefined WINDOW_SIZE\n#endif\n#define WINDOW_RADIUS ((WINDOW_SIZE - 1) / 2)\nuniform sampler2D corners;\nuniform sampler2D pyramid;\nuniform sampler2D derivatives;\nuniform float lod;\nuniform float lodStep;\nuniform float gaussian[@WINDOW_SIZE@];\n#define G(x) gaussian[(x) + WINDOW_RADIUS]\n#define W(x,y) (G(x) * G(y))\n#define H(ox,oy) dpix = pixelAtShortOffset(derivatives, ivec2((ox),(oy))); \\\ndf = (1.0f + lod) * decodePairOfFloat16(dpix); \\\nh += vec3(df.x * df.x, df.x * df.y, df.y * df.y) * W((ox),(oy))\nvoid main()\n{\nfloat intensity = 0.0f;\nivec2 thread = threadLocation();\nvec4 pixel = threadPixel(corners);\nvec4 dpix = vec4(0.0f);\nvec2 df = vec2(0.0f);\nvec3 h = vec3(0.0f);\ncolor = pixel;\n#if WINDOW_SIZE == 1\nH(0,0);\n#elif WINDOW_SIZE == 3\nH(-1,-1); H(0,-1); H(1,-1);\nH(-1,0); H(0,0); H(1,0);\nH(-1,1); H(0,1); H(1,1);\n#elif WINDOW_SIZE == 5\nH(-2,-2); H(-1,-2); H(0,-2); H(1,-2); H(2,-2);\nH(-2,-1); H(-1,-1); H(0,-1); H(1,-1); H(2,-1);\nH(-2,0); H(-1,0); H(0,0); H(1,0); H(2,0);\nH(-2,1); H(-1,1); H(0,1); H(1,1); H(2,1);\nH(-2,2); H(-1,2); H(0,2); H(1,2); H(2,2);\n#elif WINDOW_SIZE == 7\nH(-3,-3); H(-2,-3); H(-1,-3); H(0,-3); H(1,-3); H(2,-3); H(3,-3);\nH(-3,-2); H(-2,-2); H(-1,-2); H(0,-2); H(1,-2); H(2,-2); H(3,-2);\nH(-3,-1); H(-2,-1); H(-1,-1); H(0,-1); H(1,-1); H(2,-1); H(3,-1);\nH(-3,0); H(-2,0); H(-1,0); H(0,0); H(1,0); H(2,0); H(3,0);\nH(-3,1); H(-2,1); H(-1,1); H(0,1); H(1,1); H(2,1); H(3,1);\nH(-3,2); H(-2,2); H(-1,2); H(0,2); H(1,2); H(2,2); H(3,2);\nH(-3,3); H(-2,3); H(-1,3); H(0,3); H(1,3); H(2,3); H(3,3);\n#else\n#error Invalid WINDOW_SIZE\n#endif\nfloat response = 0.5f * (h.x + h.z - sqrt((h.x - h.z) * (h.x - h.z) + 4.0f * h.y * h.y));\nresponse /= float(WINDOW_SIZE * WINDOW_SIZE);\nfloat lodPlus = min(float(PYRAMID_MAX_LEVELS - 1), lod + lodStep);\nfloat currentScaleStrength = abs(laplacian(pyramid, vec2(thread), lod));\nfloat previousScaleStrength = abs(laplacian(pyramid, vec2(thread), lodPlus));\nfloat previousResponse = decodeFloat16(pixel.rb);\nvec4 result = vec4(encodeFloat16(response), encodeLod(lod), intensity);\ncolor.rbag = (currentScaleStrength >= previousScaleStrength || previousResponse == 0.0f) ? result : pixel.rbag;\n}';
                }
              ),
              /***/
              3047: (
                /***/
                (module2) => {
                  module2.exports = '@include "keypoint-matches.glsl"\nvoid main()\n{\n#if ENCODE_FILTERS != 0\nKeypointMatch initial = KeypointMatch(MATCH_MAX_INDEX, 0);\n#else\nKeypointMatch initial = KeypointMatch(MATCH_MAX_INDEX, MATCH_MAX_DISTANCE);\n#endif\ncolor = encodeKeypointMatch(initial);\n}';
                }
              ),
              /***/
              3266: (
                /***/
                (module2) => {
                  module2.exports = '@include "keypoint-matches.glsl"\nuniform sampler2D encodedMatches;\nuniform sampler2D encodedKthMatches;\nuniform int numberOfMatchesPerKeypoint;\nuniform int kthMatch;\nvoid main()\n{\nivec2 thread = threadLocation();\nivec2 matcherSize = textureSize(encodedMatches, 0);\nivec2 kthMatcherSize = textureSize(encodedKthMatches, 0);\nint rasterIndex = thread.y * matcherSize.x + thread.x;\nint matchIndex = rasterIndex / numberOfMatchesPerKeypoint;\nint matchCell = rasterIndex % numberOfMatchesPerKeypoint;\ncolor = threadPixel(encodedMatches);\nif(matchCell != kthMatch)\nreturn;\ncolor = encodeKeypointMatch(MATCH_NOT_FOUND);\nif(matchIndex >= kthMatcherSize.x * kthMatcherSize.y)\nreturn;\nivec2 pos = ivec2(matchIndex % kthMatcherSize.x, matchIndex / kthMatcherSize.x);\ncolor = texelFetch(encodedKthMatches, pos, 0);\n}';
                }
              ),
              /***/
              8018: (
                /***/
                (module2) => {
                  module2.exports = '@include "pyramids.glsl"\n@include "float16.glsl"\n@include "filters.glsl"\nuniform sampler2D corners;\nuniform sampler2D pyramid;\nuniform float lodStep;\nuniform float lodOffset;\nvoid main()\n{\nivec2 thread = threadLocation();\nvec4 pixel = threadPixel(corners);\nfloat lod = decodeLod(pixel.a);\nfloat lodMinus = max(0.0f, lod - lodStep + lodOffset);\nfloat lodPlus = min(float(PYRAMID_MAX_LEVELS - 1), lod + lodStep + lodOffset);\nfloat lapMinus = laplacian(pyramid, vec2(thread), lodMinus);\nfloat lapPlus = abs(lodPlus - lodMinus) < 1e-5 ? lapMinus : laplacian(pyramid, vec2(thread), lodPlus);\ncolor = encodePairOfFloat16(vec2(lapMinus, lapPlus));\n}';
                }
              ),
              /***/
              3168: (
                /***/
                (module2) => {
                  module2.exports = '@include "keypoints.glsl"\n@include "float16.glsl"\nuniform sampler2D nextPyramid;\nuniform sampler2D prevPyramid;\nuniform sampler2D encodedFlow;\nuniform sampler2D prevKeypoints;\nuniform int level;\nuniform int depth;\nuniform int numberOfIterations;\nuniform float discardThreshold;\nuniform float epsilon;\nuniform int descriptorSize;\nuniform int extraSize;\nuniform int encoderLength;\n#ifndef WINDOW_SIZE\n#error Undefined WINDOW_SIZE\n#endif\n#define NEXT_IMAGE 1\n#define PREV_IMAGE 0\nconst int WINDOW_RADIUS = (WINDOW_SIZE - 1) / 2;\nconst int WINDOW_SIZE_SQUARED = (WINDOW_SIZE) * (WINDOW_SIZE);\nconst int WINDOW_SIZE_PLUS = (WINDOW_SIZE) + 2;\nconst int WINDOW_SIZE_PLUS_SQUARED = WINDOW_SIZE_PLUS * WINDOW_SIZE_PLUS;\nconst int DBL_WINDOW_SIZE_PLUS_SQUARED = 2 * WINDOW_SIZE_PLUS_SQUARED;\nconst int WINDOW_RADIUS_PLUS = (WINDOW_SIZE_PLUS - 1) / 2;\nconst highp float FLT_SCALE = 9.5367431640625e-7;\nconst highp float FLT_EPSILON = 0.00000011920929f;\nint pixelBuffer[DBL_WINDOW_SIZE_PLUS_SQUARED];\n#define prevPixel(index) pixelBuffer[(index)]\n#define nextPixel(index) pixelBuffer[WINDOW_SIZE_PLUS_SQUARED + (index)]\n#define pixelIndex(i, j) (((j) + WINDOW_RADIUS_PLUS) * WINDOW_SIZE_PLUS + ((i) + WINDOW_RADIUS_PLUS))\nivec2 derivBuffer[WINDOW_SIZE_SQUARED];\n#define derivativesAt(x, y) derivBuffer[((y) + WINDOW_RADIUS) * WINDOW_SIZE + ((x) + WINDOW_RADIUS)]\nvoid readWindow(vec2 center, float lod)\n{\nconst int r = WINDOW_RADIUS;\nivec2 pyrBaseSize = textureSize(prevPyramid, 0);\nfloat pot = exp2(lod);\nivec2 offset; int idx;\n#define readPixelsAt(ox, oy) offset = ivec2((ox), (oy)); \\\nidx = pixelIndex(offset.x, offset.y); \\\nnextPixel(idx) = int(255.0f * pyrSubpixelAtExOffset(nextPyramid, center, lod, pot, offset, pyrBaseSize).g); \\\nprevPixel(idx) = int(255.0f * pyrSubpixelAtExOffset(prevPyramid, center, lod, pot, offset, pyrBaseSize).g)\nfor(int j = 0; j < WINDOW_SIZE; j++) {\nfor(int i = 0; i < WINDOW_SIZE; i++) {\nreadPixelsAt(i-r, j-r);\n}\n}\nint r1 = r+1;\nfor(int k = 0; k < WINDOW_SIZE; k++) {\nreadPixelsAt(-r1, k-r);\nreadPixelsAt( r1, k-r);\nreadPixelsAt(k-r,-r1);\nreadPixelsAt(k-r, r1);\n}\nreadPixelsAt(-r1,-r1);\nreadPixelsAt( r1,-r1);\nreadPixelsAt(-r1, r1);\nreadPixelsAt( r1, r1);\n}\nivec2 computeDerivatives(int imageCode, ivec2 offset)\n{\nconst mat3 dx = mat3(\n3, 0, -3,\n10, 0, -10,\n3, 0, -3\n);\nconst mat3 dy = mat3(\n3, 10, 3,\n0, 0, 0,\n-3, -10, -3\n);\nint indexOffset = imageCode * WINDOW_SIZE_PLUS_SQUARED;\nmat3 window = mat3(\npixelBuffer[indexOffset + pixelIndex(offset.x-1, offset.y-1)],\npixelBuffer[indexOffset + pixelIndex(offset.x+0, offset.y-1)],\npixelBuffer[indexOffset + pixelIndex(offset.x+1, offset.y-1)],\npixelBuffer[indexOffset + pixelIndex(offset.x-1, offset.y+0)],\n0.0f,\npixelBuffer[indexOffset + pixelIndex(offset.x+1, offset.y+0)],\npixelBuffer[indexOffset + pixelIndex(offset.x-1, offset.y+1)],\npixelBuffer[indexOffset + pixelIndex(offset.x+0, offset.y+1)],\npixelBuffer[indexOffset + pixelIndex(offset.x+1, offset.y+1)]\n);\nmat3 fx = matrixCompMult(dx, window);\nmat3 fy = matrixCompMult(dy, window);\nconst vec3 ones = vec3(1.0f);\nreturn ivec2(\ndot(fx[0], ones) + dot(fx[1], ones) + dot(fx[2], ones),\ndot(fy[0], ones) + dot(fy[1], ones) + dot(fy[2], ones)\n);\n}\nint readBufferedPixel(int imageCode, ivec2 offset)\n{\nconst int r = WINDOW_RADIUS;\noffset = clamp(offset, -r, r);\nint indexOffset = imageCode * WINDOW_SIZE_PLUS_SQUARED;\nreturn pixelBuffer[indexOffset + pixelIndex(offset.x, offset.y)];\n}\nint readBufferedSubpixel(int imageCode, vec2 offset)\n{\nivec2 p = ivec2(floor(offset));\nvec2 frc = fract(offset);\nvec2 ifrc = vec2(1.0f) - frc;\nvec4 pix = vec4(\nreadBufferedPixel(imageCode, p),\nreadBufferedPixel(imageCode, p + ivec2(1,0)),\nreadBufferedPixel(imageCode, p + ivec2(0,1)),\nreadBufferedPixel(imageCode, p + ivec2(1,1))\n);\nvec4 sub = vec4(\nifrc.x * ifrc.y,\nfrc.x * ifrc.y,\nifrc.x * frc.y,\nfrc.x * frc.y\n);\nreturn int(0.5f + dot(sub*pix, vec4(1.0f)));\n}\nvec2 computeMismatch(vec2 pyrGuess, vec2 localGuess)\n{\nconst int r = WINDOW_RADIUS;\nint timeDerivative;\nivec2 mismatch = ivec2(0);\nint x, y, _x, _y;\nvec2 d = pyrGuess + localGuess;\n#define innerLoop() \\\nfor(_x = 0; _x < WINDOW_SIZE; _x++) { \\\nx = _x - r; y = _y - r; \\\ntimeDerivative = ( \\\nreadBufferedSubpixel(NEXT_IMAGE, vec2(x, y) + d) - \\\nreadBufferedPixel(PREV_IMAGE, ivec2(x, y)) \\\n); \\\nmismatch += derivativesAt(x, y) * timeDerivative; \\\n}\n@unroll\nfor(_y = 0; _y < WINDOW_SIZE; _y++) {\ninnerLoop();\n}\nreturn vec2(mismatch) * FLT_SCALE;\n}\nbool isInsideImage(vec2 position)\n{\nvec2 imageSize = vec2(textureSize(nextPyramid, 0));\nvec2 border = vec2(WINDOW_SIZE);\nreturn all(bvec4(\ngreaterThanEqual(position, border),\nlessThan(position, imageSize - border)\n));\n}\nvoid main()\n{\nvec4 pixel = threadPixel(encodedFlow);\nivec2 thread = threadLocation();\nfloat windowArea = float(WINDOW_SIZE * WINDOW_SIZE);\nconst int r = WINDOW_RADIUS;\nint keypointIndex = thread.x + thread.y * outputSize().x;\nint pixelsPerKeypoint = sizeofEncodedKeypoint(descriptorSize, extraSize) / 4;\nKeypointAddress address = KeypointAddress(keypointIndex * pixelsPerKeypoint, 0);\nKeypoint keypoint = decodeKeypoint(prevKeypoints, encoderLength, address);\ncolor = encodeNullPairOfFloat16();\nif(isNullKeypoint(keypoint))\nreturn;\ncolor = encodeDiscardedPairOfFloat16();\nif(isBadKeypoint(keypoint))\nreturn;\nvec2 pyrGuess = (level < depth - 1) ? decodePairOfFloat16(pixel) : vec2(0.0f);\npyrGuess *= 2.0f;\nreadWindow(keypoint.position, float(level));\nivec2 derivatives;\nivec3 harris3i = ivec3(0);\nfor(int j = 0; j < WINDOW_SIZE; j++) {\nfor(int i = 0; i < WINDOW_SIZE; i++) {\nderivatives = computeDerivatives(PREV_IMAGE, ivec2(i-r, j-r));\nharris3i += ivec3(\nderivatives.x * derivatives.x,\nderivatives.x * derivatives.y,\nderivatives.y * derivatives.y\n);\nderivativesAt(i-r, j-r) = derivatives;\n}\n}\nhighp vec3 harris = vec3(harris3i) * FLT_SCALE;\nhighp mat2 invHarris = mat2(harris.z, -harris.y, -harris.y, harris.x);\nhighp float det = harris.x * harris.z - harris.y * harris.y;\nhighp float invDet = abs(det) >= FLT_EPSILON ? 1.0f / det : 0.0f;\nhighp float minEigenvalue = 0.5f * ((harris.x + harris.z) - sqrt(\n(harris.x - harris.z) * (harris.x - harris.z) + 4.0f * (harris.y * harris.y)\n));\nint niceNumbers = int(abs(det) >= FLT_EPSILON && minEigenvalue >= discardThreshold * windowArea);\nbool goodKeypoint = (level > 0) || (niceNumbers != 0);\nhighp float eps2 = epsilon * epsilon;\nhighp vec2 mismatch, delta, localGuess = vec2(0.0f);\nfor(int k = 0; k < numberOfIterations; k++) {\nmismatch = niceNumbers != 0 ? computeMismatch(pyrGuess, localGuess) : vec2(0.0f);\ndelta = mismatch * invHarris * invDet;\nniceNumbers *= int(eps2 <= dot(delta, delta));\nlocalGuess += float(niceNumbers) * delta;\n}\nvec2 opticalFlow = pyrGuess + localGuess;\nbool mustDiscard = (level == 0) && any(bvec2(\n!goodKeypoint,\n!isInsideImage(keypoint.position + opticalFlow)\n));\ncolor = !mustDiscard ? encodePairOfFloat16(opticalFlow) : encodeDiscardedPairOfFloat16();\n}';
                }
              ),
              /***/
              3890: (
                /***/
                (module2) => {
                  module2.exports = '#if @FS_USE_CUSTOM_PRECISION@\nprecision mediump int;\nprecision mediump float;\n#endif\n#if !defined(STAGE)\n#error Undefined STAGE\n#elif STAGE == 1\n@include "float16.glsl"\nuniform sampler2D corners;\n#elif STAGE < 1\nuniform mediump usampler2D lookupTable;\n#else\n#define SKIP_TEXTURE_READS 1\n#define DENSITY_FACTOR 0.10\nuniform mediump usampler2D lookupTable;\nuniform int blockSize;\nuniform int width;\nuniform int height;\nin vec2 v_topLeft, v_top, v_topRight,\nv_left, v_center, v_right,\nv_bottomLeft, v_bottom, v_bottomRight;\n#endif\nconst uvec2 NULL_ELEMENT = uvec2(0xFFFFu);\nvoid main()\n{\n#if STAGE == 1\nuvec2 outSize = uvec2(outputSize());\nuvec2 thread = uvec2(threadLocation());\nuvec2 size = uvec2(textureSize(corners, 0));\nuint location = thread.y * outSize.x + thread.x;\nivec2 pos = ivec2(location % size.x, location / size.x);\nvec4 pixel = location < size.x * size.y ? texelFetch(corners, pos, 0) : vec4(0.0f);\nbool isCorner = !isEncodedFloat16Zero(pixel.rb);\ncolor = isCorner ? uvec4(uvec2(pos), 1u, 0u) : uvec4(NULL_ELEMENT, 0u, 0u);\n#elif STAGE > 1\nint dblBlockSize = 2 * blockSize;\nivec2 thread = threadLocation();\nivec2 offset = thread % dblBlockSize;\nivec2 delta = thread - offset;\n#if SKIP_TEXTURE_READS\nif(blockSize >= 8) {\nuint sb = texture(lookupTable, texCoord).z;\nfloat p = max((float(sb) / float(blockSize)) / float(blockSize), DENSITY_FACTOR);\nfloat rowthr = float(dblBlockSize) * p + 3.0f * sqrt(p * (1.0f - p));\ncolor = uvec4(NULL_ELEMENT, 4u * sb, 0u);\nif(offset.y >= max(1, int(ceil(rowthr))))\nreturn;\n}\n#endif\n#define deltaCenter ivec2(0,0)\n#define deltaTop ivec2(0,-blockSize)\n#define deltaTopRight ivec2(blockSize,-blockSize)\n#define deltaRight ivec2(blockSize,0)\n#define deltaBottomRight ivec2(blockSize,blockSize)\n#define deltaBottom ivec2(0,blockSize)\n#define deltaBottomLeft ivec2(-blockSize,blockSize)\n#define deltaLeft ivec2(-blockSize,0)\n#define deltaTopLeft ivec2(-blockSize,-blockSize)\nivec2 boundary = ivec2(width - 1, height - 1) / blockSize;\nivec2 bottomRightPos = thread + deltaBottomRight;\nuvec2 valid = uvec2(\nbottomRightPos.x < width  || bottomRightPos.x / blockSize == boundary.x,\nbottomRightPos.y < height || bottomRightPos.y / blockSize == boundary.y\n);\nuvec4 mask[4];\nmask[0] = uvec4(1u, valid.x, valid.y, valid.x * valid.y);\nmask[1] = uvec4(1u, 1u, valid.y, valid.y);\nmask[2] = uvec4(1u, valid.x, 1u, valid.x);\nmask[3] = uvec4(1u);\n#if SKIP_TEXTURE_READS\n#define calcSb(delta) texelFetch(lookupTable, blockSize * ((thread + (delta)) / blockSize), 0).z\nuint center = calcSb(deltaCenter);\nuint top = calcSb(deltaTop);\nuint topRight = calcSb(deltaTopRight);\nuint right = calcSb(deltaRight);\nuint bottomRight = calcSb(deltaBottomRight);\nuint bottom = calcSb(deltaBottom);\nuint bottomLeft = calcSb(deltaBottomLeft);\nuint left = calcSb(deltaLeft);\nuint topLeft = calcSb(deltaTopLeft);\n#else\n#define calcSb(pos) texture(lookupTable, (pos)).z\nuint center = calcSb(v_center);\nuint top = calcSb(v_top);\nuint topRight = calcSb(v_topRight);\nuint right = calcSb(v_right);\nuint bottomRight = calcSb(v_bottomRight);\nuint bottom = calcSb(v_bottom);\nuint bottomLeft = calcSb(v_bottomLeft);\nuint left = calcSb(v_left);\nuint topLeft = calcSb(v_topLeft);\n#endif\nuvec4 sums[4];\nsums[0] = uvec4(center, right, bottom, bottomRight);\nsums[1] = uvec4(left, center, bottomLeft, bottom);\nsums[2] = uvec4(top, topRight, center, right);\nsums[3] = uvec4(topLeft, top, left, center);\nivec2 cmp = ivec2(greaterThanEqual(offset, ivec2(blockSize)));\nint option = 2 * cmp.y + cmp.x;\nuvec4 cdef = sums[option] * mask[option];\nuint c2b = cdef.x, d2b = cdef.y, e2b = cdef.z, f2b = cdef.w;\nuint sb = center;\nuint s2b = c2b + d2b + e2b + f2b;\ns2b = s2b < sb ? 0xFFFFu : min(0xFFFFu, s2b);\nuint w2b = uint(min(dblBlockSize, width - delta.x));\nuvec2 uoffset = uvec2(offset);\nuint ceiling = s2b >= uoffset.x ? (s2b - uoffset.x) / w2b + uint((s2b - uoffset.x) % w2b > 0u) : 0u;\ncolor = uvec4(NULL_ELEMENT, s2b, 0u);\nif(uoffset.y >= ceiling)\nreturn;\nuint i2b = uoffset.y * w2b + uoffset.x;\nuint j2b = i2b >= c2b ? i2b - c2b : 0u;\nuint k2b = j2b >= d2b ? j2b - d2b : 0u;\nuint l2b = k2b >= e2b ? k2b - e2b : 0u;\nuint wl = uint(min(blockSize, width - delta.x));\nuint wr = uint(min(blockSize, width - delta.x - blockSize));\nivec2 magicOffset = (\n(i2b < c2b) ? ivec2(i2b % wl, i2b / wl) : (\n(j2b < d2b) ? ivec2(j2b % wr, j2b / wr) + ivec2(blockSize, 0) : (\n(k2b < e2b) ? ivec2(k2b % wl, k2b / wl) + ivec2(0, blockSize) : (\n(l2b < f2b) ? ivec2(l2b % wr, l2b / wr) + ivec2(blockSize) : ivec2(0)\n))));\nuvec2 a2b = texelFetch(lookupTable, delta + magicOffset, 0).xy;\ncolor = uvec4(a2b, s2b, 0u);\n#else\nuvec4 pix = texture(lookupTable, texCoord);\ncolor = all(equal(pix.xy, NULL_ELEMENT)) ? vec4(0,1,1,1) : vec4(1,0,0,1);\n#endif\n}';
                }
              ),
              /***/
              8647: (
                /***/
                (module2) => {
                  module2.exports = "#if !defined(STAGE) || STAGE < 1\n#error Invalid STAGE\n#else\nuniform mediump int blockSize;\nout vec2 v_topLeft, v_top, v_topRight,\nv_left, v_center, v_right,\nv_bottomLeft, v_bottom, v_bottomRight;\nvoid vsmain()\n{\nfloat b = float(blockSize);\n#define V(x,y) (texCoord + (vec2((x),(y)) * b) / texSize)\nv_topLeft = V(-1,-1); v_top = V(0,-1); v_topRight = V(1,-1);\nv_left = V(-1,0); v_center = V(0,0); v_right = V(1,0);\nv_bottomLeft = V(-1,1); v_bottom = V(0,1); v_bottomRight = V(1,1);\n}\n#endif";
                }
              ),
              /***/
              4776: (
                /***/
                (module2) => {
                  module2.exports = '@include "keypoints.glsl"\n@include "keypoint-matches.glsl"\n@include "keypoint-descriptors.glsl"\nuniform sampler2D candidates;\nuniform sampler2D filters;\nuniform int matcherLength;\nuniform sampler2D tables;\nuniform sampler2D descriptorDB;\nuniform int tableIndex;\nuniform int bucketCapacity;\nuniform int bucketsPerTable;\nuniform int tablesStride;\nuniform int descriptorDBStride;\nuniform sampler2D encodedKeypoints;\nuniform int descriptorSize;\nuniform int extraSize;\nuniform int encoderLength;\n#if HASH_SIZE > SEQUENCE_MAXLEN\n#error LSH: invalid HASH_SIZE\n#elif SEQUENCE_COUNT * SEQUENCE_MAXLEN * 4 > 16384\n#error LSH: sequences are too large!\n#elif (SEQUENCE_COUNT * SEQUENCE_MAXLEN) % 4 > 0\n#error LSH: sequences of invalid size!\n#endif\nlayout(std140) uniform LSHSequences\n{\nuvec4 sequences[(SEQUENCE_COUNT * SEQUENCE_MAXLEN) / 4];\n};\n#if HASH_SIZE == 10\nconst int SWAP_COUNT[3] = int[3](1, 11, 56);\nconst int[56] SWAP = int[56](0,1,2,4,8,16,32,64,128,256,512,3,5,6,9,10,12,17,18,20,24,33,34,36,40,48,65,66,68,72,80,96,129,130,132,136,144,160,192,257,258,260,264,272,288,320,384,513,514,516,520,528,544,576,640,768);\n#elif HASH_SIZE == 11\nconst int SWAP_COUNT[3] = int[3](1, 12, 67);\nconst int[67] SWAP = int[67](0,1,2,4,8,16,32,64,128,256,512,1024,3,5,6,9,10,12,17,18,20,24,33,34,36,40,48,65,66,68,72,80,96,129,130,132,136,144,160,192,257,258,260,264,272,288,320,384,513,514,516,520,528,544,576,640,768,1025,1026,1028,1032,1040,1056,1088,1152,1280,1536);\n#elif HASH_SIZE == 12\nconst int SWAP_COUNT[3] = int[3](1, 13, 79);\nconst int[79] SWAP = int[79](0,1,2,4,8,16,32,64,128,256,512,1024,2048,3,5,6,9,10,12,17,18,20,24,33,34,36,40,48,65,66,68,72,80,96,129,130,132,136,144,160,192,257,258,260,264,272,288,320,384,513,514,516,520,528,544,576,640,768,1025,1026,1028,1032,1040,1056,1088,1152,1280,1536,2049,2050,2052,2056,2064,2080,2112,2176,2304,2560,3072);\n#elif HASH_SIZE == 13\nconst int SWAP_COUNT[3] = int[3](1, 14, 92);\nconst int[92] SWAP = int[92](0,1,2,4,8,16,32,64,128,256,512,1024,2048,4096,3,5,6,9,10,12,17,18,20,24,33,34,36,40,48,65,66,68,72,80,96,129,130,132,136,144,160,192,257,258,260,264,272,288,320,384,513,514,516,520,528,544,576,640,768,1025,1026,1028,1032,1040,1056,1088,1152,1280,1536,2049,2050,2052,2056,2064,2080,2112,2176,2304,2560,3072,4097,4098,4100,4104,4112,4128,4160,4224,4352,4608,5120,6144);\n#elif HASH_SIZE == 14\nconst int SWAP_COUNT[3] = int[3](1, 15, 106);\nconst int[106] SWAP = int[106](0,1,2,4,8,16,32,64,128,256,512,1024,2048,4096,8192,3,5,6,9,10,12,17,18,20,24,33,34,36,40,48,65,66,68,72,80,96,129,130,132,136,144,160,192,257,258,260,264,272,288,320,384,513,514,516,520,528,544,576,640,768,1025,1026,1028,1032,1040,1056,1088,1152,1280,1536,2049,2050,2052,2056,2064,2080,2112,2176,2304,2560,3072,4097,4098,4100,4104,4112,4128,4160,4224,4352,4608,5120,6144,8193,8194,8196,8200,8208,8224,8256,8320,8448,8704,9216,10240,12288);\n#elif HASH_SIZE == 15\nconst int SWAP_COUNT[3] = int[3](1, 16, 121);\nconst int[121] SWAP = int[121](0,1,2,4,8,16,32,64,128,256,512,1024,2048,4096,8192,16384,3,5,6,9,10,12,17,18,20,24,33,34,36,40,48,65,66,68,72,80,96,129,130,132,136,144,160,192,257,258,260,264,272,288,320,384,513,514,516,520,528,544,576,640,768,1025,1026,1028,1032,1040,1056,1088,1152,1280,1536,2049,2050,2052,2056,2064,2080,2112,2176,2304,2560,3072,4097,4098,4100,4104,4112,4128,4160,4224,4352,4608,5120,6144,8193,8194,8196,8200,8208,8224,8256,8320,8448,8704,9216,10240,12288,16385,16386,16388,16392,16400,16416,16448,16512,16640,16896,17408,18432,20480,24576);\n#elif HASH_SIZE == 16\nconst int SWAP_COUNT[3] = int[3](1, 17, 137);\nconst int[137] SWAP = int[137](0,1,2,4,8,16,32,64,128,256,512,1024,2048,4096,8192,16384,32768,3,5,6,9,10,12,17,18,20,24,33,34,36,40,48,65,66,68,72,80,96,129,130,132,136,144,160,192,257,258,260,264,272,288,320,384,513,514,516,520,528,544,576,640,768,1025,1026,1028,1032,1040,1056,1088,1152,1280,1536,2049,2050,2052,2056,2064,2080,2112,2176,2304,2560,3072,4097,4098,4100,4104,4112,4128,4160,4224,4352,4608,5120,6144,8193,8194,8196,8200,8208,8224,8256,8320,8448,8704,9216,10240,12288,16385,16386,16388,16392,16400,16416,16448,16512,16640,16896,17408,18432,20480,24576,32769,32770,32772,32776,32784,32800,32832,32896,33024,33280,33792,34816,36864,40960,49152);\n#elif HASH_SIZE == 17\nconst int SWAP_COUNT[3] = int[3](1, 18, 154);\nconst int[154] SWAP = int[154](0,1,2,4,8,16,32,64,128,256,512,1024,2048,4096,8192,16384,32768,65536,3,5,6,9,10,12,17,18,20,24,33,34,36,40,48,65,66,68,72,80,96,129,130,132,136,144,160,192,257,258,260,264,272,288,320,384,513,514,516,520,528,544,576,640,768,1025,1026,1028,1032,1040,1056,1088,1152,1280,1536,2049,2050,2052,2056,2064,2080,2112,2176,2304,2560,3072,4097,4098,4100,4104,4112,4128,4160,4224,4352,4608,5120,6144,8193,8194,8196,8200,8208,8224,8256,8320,8448,8704,9216,10240,12288,16385,16386,16388,16392,16400,16416,16448,16512,16640,16896,17408,18432,20480,24576,32769,32770,32772,32776,32784,32800,32832,32896,33024,33280,33792,34816,36864,40960,49152,65537,65538,65540,65544,65552,65568,65600,65664,65792,66048,66560,67584,69632,73728,81920,98304);\n#elif HASH_SIZE == 18\nconst int SWAP_COUNT[3] = int[3](1, 19, 172);\nconst int[172] SWAP = int[172](0,1,2,4,8,16,32,64,128,256,512,1024,2048,4096,8192,16384,32768,65536,131072,3,5,6,9,10,12,17,18,20,24,33,34,36,40,48,65,66,68,72,80,96,129,130,132,136,144,160,192,257,258,260,264,272,288,320,384,513,514,516,520,528,544,576,640,768,1025,1026,1028,1032,1040,1056,1088,1152,1280,1536,2049,2050,2052,2056,2064,2080,2112,2176,2304,2560,3072,4097,4098,4100,4104,4112,4128,4160,4224,4352,4608,5120,6144,8193,8194,8196,8200,8208,8224,8256,8320,8448,8704,9216,10240,12288,16385,16386,16388,16392,16400,16416,16448,16512,16640,16896,17408,18432,20480,24576,32769,32770,32772,32776,32784,32800,32832,32896,33024,33280,33792,34816,36864,40960,49152,65537,65538,65540,65544,65552,65568,65600,65664,65792,66048,66560,67584,69632,73728,81920,98304,131073,131074,131076,131080,131088,131104,131136,131200,131328,131584,132096,133120,135168,139264,147456,163840,196608);\n#elif HASH_SIZE == 19\nconst int SWAP_COUNT[3] = int[3](1, 20, 191);\nconst int[191] SWAP = int[191](0,1,2,4,8,16,32,64,128,256,512,1024,2048,4096,8192,16384,32768,65536,131072,262144,3,5,6,9,10,12,17,18,20,24,33,34,36,40,48,65,66,68,72,80,96,129,130,132,136,144,160,192,257,258,260,264,272,288,320,384,513,514,516,520,528,544,576,640,768,1025,1026,1028,1032,1040,1056,1088,1152,1280,1536,2049,2050,2052,2056,2064,2080,2112,2176,2304,2560,3072,4097,4098,4100,4104,4112,4128,4160,4224,4352,4608,5120,6144,8193,8194,8196,8200,8208,8224,8256,8320,8448,8704,9216,10240,12288,16385,16386,16388,16392,16400,16416,16448,16512,16640,16896,17408,18432,20480,24576,32769,32770,32772,32776,32784,32800,32832,32896,33024,33280,33792,34816,36864,40960,49152,65537,65538,65540,65544,65552,65568,65600,65664,65792,66048,66560,67584,69632,73728,81920,98304,131073,131074,131076,131080,131088,131104,131136,131200,131328,131584,132096,133120,135168,139264,147456,163840,196608,262145,262146,262148,262152,262160,262176,262208,262272,262400,262656,263168,264192,266240,270336,278528,294912,327680,393216);\n#elif HASH_SIZE == 20\nconst int SWAP_COUNT[3] = int[3](1, 21, 211);\nconst int[211] SWAP = int[211](0,1,2,4,8,16,32,64,128,256,512,1024,2048,4096,8192,16384,32768,65536,131072,262144,524288,3,5,6,9,10,12,17,18,20,24,33,34,36,40,48,65,66,68,72,80,96,129,130,132,136,144,160,192,257,258,260,264,272,288,320,384,513,514,516,520,528,544,576,640,768,1025,1026,1028,1032,1040,1056,1088,1152,1280,1536,2049,2050,2052,2056,2064,2080,2112,2176,2304,2560,3072,4097,4098,4100,4104,4112,4128,4160,4224,4352,4608,5120,6144,8193,8194,8196,8200,8208,8224,8256,8320,8448,8704,9216,10240,12288,16385,16386,16388,16392,16400,16416,16448,16512,16640,16896,17408,18432,20480,24576,32769,32770,32772,32776,32784,32800,32832,32896,33024,33280,33792,34816,36864,40960,49152,65537,65538,65540,65544,65552,65568,65600,65664,65792,66048,66560,67584,69632,73728,81920,98304,131073,131074,131076,131080,131088,131104,131136,131200,131328,131584,132096,133120,135168,139264,147456,163840,196608,262145,262146,262148,262152,262160,262176,262208,262272,262400,262656,263168,264192,266240,270336,278528,294912,327680,393216,524289,524290,524292,524296,524304,524320,524352,524416,524544,524800,525312,526336,528384,532480,540672,557056,589824,655360,786432);\n#else\n#error Invalid HASH_SIZE\n#endif\n#if LEVEL < 0 || LEVEL > 2\n#error Invalid LEVEL\n#endif\nconst uint END_OF_LIST = 0xFFFFFFFFu;\nconst int NUMBER_OF_HASHES = SWAP_COUNT[LEVEL];\nuint sequenceElement(int sequenceIndex, int elementIndex)\n{\nint offset = (SEQUENCE_MAXLEN) * sequenceIndex + elementIndex;\nuvec4 tuple = sequences[offset / 4];\nreturn tuple[offset & 3];\n}\nint descriptorHash(uint[DESCRIPTOR_SIZE] descriptor, int sequenceIndex)\n{\nuint bit, b, m;\nint hash = 0;\n@unroll\nfor(int i = 0; i < HASH_SIZE; i++) {\nbit = sequenceElement(sequenceIndex, i);\nb = bit >> 3u;\nm = 1u << (bit & 7u);\nhash = (hash << 1) | int((descriptor[b] & m) != 0u);\n}\nreturn hash;\n}\n#define readTableData(tables, tablesStride, rasterIndex) decodeUint32(texelFetch((tables), ivec2((rasterIndex) % (tablesStride), (rasterIndex) / (tablesStride)), 0))\nvoid main()\n{\nivec2 thread = threadLocation();\nint keypointIndex = thread.x + thread.y * matcherLength;\nint pixelsPerKeypoint = sizeofEncodedKeypoint(descriptorSize, extraSize) / 4;\nKeypointAddress address = KeypointAddress(keypointIndex * pixelsPerKeypoint, 0);\nKeypoint keypoint = decodeKeypoint(encodedKeypoints, encoderLength, address);\ncolor = encodeKeypointMatch(MATCH_NOT_FOUND);\nif(isBadKeypoint(keypoint))\nreturn;\nKeypointMatch candidate = decodeKeypointMatch(threadPixel(candidates));\nKeypointMatch mfilter = decodeKeypointMatch(threadPixel(filters));\nuint[DESCRIPTOR_SIZE] candidateDescriptor;\nuint[DESCRIPTOR_SIZE] descriptor = readKeypointDescriptor(encodedKeypoints, descriptorSize, extraSize, encoderLength, address);\nint hash0 = descriptorHash(descriptor, tableIndex);\nfor(int h = 0; h < NUMBER_OF_HASHES; h++) {\nint hash = hash0 ^ SWAP[h];\nint tableAddress = tableIndex * bucketsPerTable * bucketCapacity;\nint bucketAddress = tableAddress + hash * bucketCapacity;\nbool validEntry = true;\nfor(int b = 0; b < bucketCapacity; b++) {\nint entryAddress = bucketAddress + b;\nuint entry = validEntry ? readTableData(tables, tablesStride, entryAddress) : END_OF_LIST;\nvalidEntry = (validEntry && entry != END_OF_LIST);\nint candidateIndex = int(entry);\ncandidateDescriptor = readKeypointDescriptorFromDB(descriptorDB, descriptorDBStride, validEntry ? candidateIndex : -1);\nint descriptorDistance = distanceBetweenKeypointDescriptors(descriptor, candidateDescriptor);\nKeypointMatch match = KeypointMatch(candidateIndex, descriptorDistance);\nbool betterThanCandidate = (match.dist < candidate.dist) || (match.dist == candidate.dist && match.index > candidate.index);\nbool worseThanFilter = (match.dist > mfilter.dist) || (match.dist == mfilter.dist && match.index < mfilter.index);\nbool nicerMatch = (validEntry && betterThanCandidate && worseThanFilter);\nivec2 v = nicerMatch ? ivec2(match.index, match.dist) : ivec2(candidate.index, candidate.dist);\ncandidate = KeypointMatch(v.x, v.y);\n}\n}\ncolor = encodeKeypointMatch(candidate);\n}';
                }
              ),
              /***/
              2648: (
                /***/
                (module2) => {
                  module2.exports = '@include "keypoints.glsl"\n@include "int32.glsl"\n#if !defined(STAGE)\n#error Undefined STAGE\n#elif STAGE == 1\nuniform sampler2D encodedKeypointsA;\nuniform sampler2D encodedKeypointsB;\nuniform int encoderLengthA;\nuniform int encoderLengthB;\nuniform int encoderCapacityA;\nuniform int encoderCapacityB;\nuniform int descriptorSize;\nuniform int extraSize;\nuniform int encoderLength;\n#elif STAGE == 2\nuniform sampler2D encodedKeypoints;\nuniform int descriptorSize;\nuniform int extraSize;\nuniform int encoderLength;\nuniform int maxKeypoints;\n#elif STAGE == 3\nuniform sampler2D array;\nuniform int blockSize;\n#elif STAGE == 4\nuniform sampler2D array;\nuniform sampler2D encodedKeypoints;\nuniform int descriptorSize;\nuniform int extraSize;\nuniform int encoderLength;\n#elif STAGE == 5\nuniform sampler2D array;\n#else\n#error Invalid STAGE\n#endif\n#define NULL_KEYPOINT_INDEX 0xFFFF\nconst highp uint UNIT = 0x10000u;\nvoid main()\n{\n#if STAGE == 1\nivec2 thread = threadLocation();\nKeypointAddress addr = findKeypointAddress(thread, encoderLength, descriptorSize, extraSize);\nint keypointIndex = findKeypointIndex(addr, descriptorSize, extraSize);\nint newKeypointIndex = keypointIndex < encoderCapacityA ? keypointIndex : keypointIndex - encoderCapacityA;\ncolor = encodeNullKeypoint();\nif(newKeypointIndex >= max(encoderCapacityA, encoderCapacityB))\nreturn;\nint pixelsPerKeypoint = sizeofEncodedKeypoint(descriptorSize, extraSize) / 4;\naddr = KeypointAddress(newKeypointIndex * pixelsPerKeypoint, addr.offset);\nvec4 dataA = readKeypointData(encodedKeypointsA, encoderLengthA, addr);\nvec4 dataB = readKeypointData(encodedKeypointsB, encoderLengthB, addr);\ncolor = keypointIndex < encoderCapacityA ? dataA : dataB;\n#elif STAGE == 2\nivec2 thread = threadLocation();\nint keypointIndex = thread.y * outputSize().x + thread.x;\nint pixelsPerKeypoint = sizeofEncodedKeypoint(descriptorSize, extraSize) / 4;\nKeypointAddress addr = KeypointAddress(keypointIndex * pixelsPerKeypoint, 0);\nKeypoint keypoint = decodeKeypoint(encodedKeypoints, encoderLength, addr);\nbool isValid = !isNullKeypoint(keypoint) && keypointIndex < maxKeypoints;\nkeypointIndex = isValid ? keypointIndex : NULL_KEYPOINT_INDEX;\ncolor = encodeUint32(uint(keypointIndex & 0xFFFF) | (isValid ? UNIT : 0u));\n#elif STAGE == 3\nivec2 thread = threadLocation();\nivec2 size = outputSize();\nint arrayLength = size.x * size.y;\nint arrayIndex = thread.y * size.x + thread.x;\nint arrayIndexLeft = arrayIndex - blockSize;\nint arrayIndexRight = arrayIndex + blockSize;\nint mask = int(arrayIndexRight < arrayLength || arrayIndexRight / blockSize == (arrayLength - 1) / blockSize);\narrayIndexLeft = max(0, arrayIndexLeft);\narrayIndexRight = min(arrayLength - 1, arrayIndexRight);\n#define raster2pos(k) ivec2((k) % size.x, (k) / size.x)\nuvec3 entries32 = uvec3(\ndecodeUint32(threadPixel(array)),\ndecodeUint32(texelFetch(array, raster2pos(arrayIndexLeft), 0)),\ndecodeUint32(texelFetch(array, raster2pos(arrayIndexRight), 0))\n);\nivec3 sb = ivec3((entries32 >> 16u) & 0xFFFFu);\nsb.z *= mask;\nint dblBlockSize = 2 * blockSize;\nint offset = arrayIndex % dblBlockSize;\nint s2b = sb.x + (offset < blockSize ? sb.z : sb.y);\nint l2b = offset < blockSize ? sb.x : sb.y;\nuint keypointIndex = entries32.x & 0xFFFFu;\nuint shiftedS2b = uint(s2b) << 16u;\ncolor = encodeUint32(uint(NULL_KEYPOINT_INDEX) | shiftedS2b);\nif(offset >= s2b)\nreturn;\ncolor = encodeUint32(keypointIndex | shiftedS2b);\nif(offset < l2b)\nreturn;\nvec4 entry = texelFetch(array, raster2pos(arrayIndex + blockSize - l2b), 0);\nkeypointIndex = decodeUint32(entry) & 0xFFFFu;\ncolor = encodeUint32(keypointIndex | shiftedS2b);\n#elif STAGE == 4\nivec2 thread = threadLocation();\nint pixelsPerKeypoint = sizeofEncodedKeypoint(descriptorSize, extraSize) / 4;\nKeypointAddress addr = findKeypointAddress(thread, encoderLength, descriptorSize, extraSize);\nint keypointIndex = findKeypointIndex(addr, descriptorSize, extraSize);\n#define raster2pos(k) ivec2((k) % size.x, (k) / size.x)\nivec2 size = textureSize(array, 0);\nuint sortedPair = decodeUint32(texelFetch(array, raster2pos(keypointIndex), 0));\nint newKeypointIndex = int(sortedPair & 0xFFFFu);\ncolor = encodeNullKeypoint();\nif(newKeypointIndex == NULL_KEYPOINT_INDEX || keypointIndex >= size.x * size.y)\nreturn;\nKeypointAddress newAddr = KeypointAddress(newKeypointIndex * pixelsPerKeypoint, addr.offset);\ncolor = readKeypointData(encodedKeypoints, encoderLength, newAddr);\n#elif STAGE == 5\nuint val = decodeUint32(threadPixel(array));\ncolor = (val & 0xFFFFu) == uint(NULL_KEYPOINT_INDEX) ? vec4(0,1,1,1) : vec4(1,0,0,1);\n#endif\n}';
                }
              ),
              /***/
              8825: (
                /***/
                (module2) => {
                  module2.exports = '@include "pyramids.glsl"\n@include "float16.glsl"\n@include "filters.glsl"\n#if !defined(USE_LAPLACIAN)\n#error Undefined USE_LAPLACIAN\n#endif\nuniform sampler2D corners;\nuniform sampler2D pyramid;\nuniform float lodStep;\n#if USE_LAPLACIAN\nuniform sampler2D pyrLaplacian;\n#endif\nvoid main()\n{\nivec2 thread = threadLocation();\nvec4 pixel = threadPixel(corners);\nfloat score = decodeFloat16(pixel.rb);\nfloat myEncodedLod = pixel.a;\nfloat lod = decodeLod(myEncodedLod);\nfloat lodPlus = lod + lodStep;\nfloat lodMinus = lod - lodStep;\nfloat pot = exp2(lod);\nfloat potPlus = exp2(lodPlus);\nfloat potMinus = exp2(lodMinus);\ncolor = pixel;\nif(score == 0.0f)\nreturn;\n#define P(p,u,v) textureLod(corners, texCoord + (p) * vec2((u),(v)) / texSize, 0.0f)\nvec4 pix[18];\n#define D(u,v) P(potMinus,(u),(v))\npix[0] = D(-1,-1); pix[1] = D(0,-1); pix[2] = D(1,-1);\npix[3] = D(-1,0); pix[4] = D(0,0); pix[5] = D(1,0);\npix[6] = D(-1,1); pix[7] = D(0,1); pix[8] = D(1,1);\n#define U(u,v) P(potPlus,(u),(v))\npix[9] = U(-1,-1); pix[10] = U(0,-1); pix[11] = U(1,-1);\npix[12] = U(-1,0); pix[13] = U(0,0); pix[14] = U(1,0);\npix[15] = U(-1,1); pix[16] = U(0,1); pix[17] = U(1,1);\nfloat scores[18];\n#define C(j) decodeFloat16(pix[j].rb)\nscores[0] = C(0); scores[1] = C(1); scores[2] = C(2);\nscores[3] = C(3); scores[4] = C(4); scores[5] = C(5);\nscores[6] = C(6); scores[7] = C(7); scores[8] = C(8);\nscores[9] = C(9); scores[10] = C(10); scores[11] = C(11);\nscores[12] = C(12); scores[13] = C(13); scores[14] = C(14);\nscores[15] = C(15); scores[16] = C(16); scores[17] = C(17);\nfloat lods[18];\n#define E(j) decodeLod(pix[j].a)\nlods[0] = E(0); lods[1] = E(1); lods[2] = E(2);\nlods[3] = E(3); lods[4] = E(4); lods[5] = E(5);\nlods[6] = E(6); lods[7] = E(7); lods[8] = E(8);\nlods[9] = E(9); lods[10] = E(10); lods[11] = E(11);\nlods[12] = E(12); lods[13] = E(13); lods[14] = E(14);\nlods[15] = E(15); lods[16] = E(16); lods[17] = E(17);\n#if USE_LAPLACIAN\n#define L(p,u,v) textureLod(pyrLaplacian, texCoord + (p) * vec2((u),(v)) / texSize, 0.0f)\nmat3 strengths[2];\nstrengths[0] = mat3(\n#define Lm(u,v) abs(decodeFloat16(L(potMinus,(u),(v)).xy))\nLm(-1,-1), Lm(0,-1), Lm(1,-1),\nLm(-1,0), Lm(0,0), Lm(1,0),\nLm(-1,1), Lm(0,1), Lm(1,1)\n);\nstrengths[1] = mat3(\n#define Lp(u,v) abs(decodeFloat16(L(potPlus,(u),(v)).zw))\nLp(-1,-1), Lp(0,-1), Lp(1,-1),\nLp(-1,0), Lp(0,0), Lp(1,0),\nLp(-1,1), Lp(0,1), Lp(1,1)\n);\nfloat myStrength = abs(laplacian(pyramid, vec2(thread), lod));\n#else\n#define L(u,v) (((v)+1)*3 + ((u)+1))\nmat3 strengths[2];\nstrengths[0] = mat3(\n#define Lm(u,v) scores[L((u),(v))]\nLm(-1,-1), Lm(0,-1), Lm(1,-1),\nLm(-1,0), Lm(0,0), Lm(1,0),\nLm(-1,1), Lm(0,1), Lm(1,1)\n);\nstrengths[1] = mat3(\n#define Lp(u,v) scores[9 + L((u),(v))]\nLp(-1,-1), Lp(0,-1), Lp(1,-1),\nLp(-1,0), Lp(0,0), Lp(1,0),\nLp(-1,1), Lp(0,1), Lp(1,1)\n);\nfloat myStrength = score;\n#endif\n#define B(j,lod) float(isSameLod(lods[j], (lod))) * float(scores[j] > 0.0f)\nmat3 nearLod[2];\nnearLod[0] = mat3(\n#define Bm(j) B((j), lodMinus)\nBm(0), Bm(1), Bm(2),\nBm(3), Bm(4), Bm(5),\nBm(6), Bm(7), Bm(8)\n);\nnearLod[1] = mat3(\n#define Bp(j) B((j), lodPlus)\nBp(9), Bp(10), Bp(11),\nBp(12), Bp(13), Bp(14),\nBp(15), Bp(16), Bp(17)\n);\nmat3 upStrengths = matrixCompMult(strengths[1], nearLod[1]);\nmat3 downStrengths = matrixCompMult(strengths[0], nearLod[0]);\nvec3 maxUpStrength3 = max(upStrengths[0], max(upStrengths[1], upStrengths[2]));\nvec3 maxDownStrength3 = max(downStrengths[0], max(downStrengths[1], downStrengths[2]));\nvec3 maxStrength3 = max(maxUpStrength3, maxDownStrength3);\nfloat maxStrength = max(maxStrength3.x, max(maxStrength3.y, maxStrength3.z));\ncolor.rb = encodeFloat16(score * step(maxStrength, myStrength));\n}';
                }
              ),
              /***/
              5693: (
                /***/
                (module2) => {
                  module2.exports = '@include "pyramids.glsl"\n@include "float16.glsl"\nuniform sampler2D corners;\nvoid main()\n{\nivec2 thread = threadLocation();\nvec4 pixel = threadPixel(corners);\nfloat encodedLod = pixel.a;\nfloat score = decodeFloat16(pixel.rb);\nfloat lod = decodeLod(encodedLod);\nfloat pot = exp2(lod);\ncolor = pixel;\nif(score == 0.0f)\nreturn;\n#if 1\nvec2 gridSize = vec2(pot);\nvec2 gridLocation = floor(mod(texCoord * texSize, gridSize));\nvec2 gridDelta = gridLocation / gridSize - vec2(0.5f);\nfloat gridStep = 1.0f / pot;\nconst float adjustment = 1.25f;\ncolor.rb = encodeFloat16(0.0f);\nif(max(abs(gridDelta.x), abs(gridDelta.y)) > adjustment * gridStep)\nreturn;\n#endif\n#define P(x,y) textureLod(corners, texCoord + pot * vec2((x), (y)) / texSize, 0.0f)\nvec4 pix[9];\npix[0] = P(-1,-1); pix[1] = P(0,-1); pix[2] = P(1,-1);\npix[3] = P(-1, 0); pix[4] = pixel;   pix[5] = P(1, 0);\npix[6] = P(-1, 1); pix[7] = P(0, 1); pix[8] = P(1, 1);\n#define S(j) decodeFloat16(pix[j].rb)\nmat3 scores = mat3(\nS(0), S(1), S(2),\nS(3), S(4), S(5),\nS(6), S(7), S(8)\n);\n#define B(j) float(isSameLod(decodeLod(pix[j].a), lod))\nmat3 sameLod = mat3(\nB(0), B(1), B(2),\nB(3), B(4), B(5),\nB(6), B(7), B(8)\n);\nmat3 sameLodScores = matrixCompMult(scores, sameLod);\nvec3 maxScore3 = max(sameLodScores[0], max(sameLodScores[1], sameLodScores[2]));\nfloat maxScore = max(maxScore3.x, max(maxScore3.y, maxScore3.z));\ncolor.rb = encodeFloat16(score * step(maxScore, score));\n}';
                }
              ),
              /***/
              9280: (
                /***/
                (module2) => {
                  module2.exports = '@include "pyramids.glsl"\n@include "float16.glsl"\nuniform sampler2D image;\nuniform float lodStep;\n#if !defined(MULTISCALE)\n#error Must define MULTISCALE\n#elif MULTISCALE != 0\n#define LOD_STEP (lodStep)\n#define USE_MIDDLE_RING\n#else\n#define LOD_STEP (0.0f)\n#endif\n#define PIX(x,y) pixelAtShortOffset(image, ivec2((x),(y)))\n#define L2(v,i) bvec2(isSameEncodedLod(v[i].a, alphaMinus), isSameEncodedLod(v[i].a, alphaPlus))\n#define L3(v,i) bvec3(isSameEncodedLod(v[i].a, alpha), isSameEncodedLod(v[i].a, alphaMinus), isSameEncodedLod(v[i].a, alphaPlus))\n#define S3(v,i) decodeFloat16(v[i].rb) * float(any(L3(v,i)))\n#define S2(v,i) decodeFloat16(v[i].rb) * float(any(L2(v,i)))\n#define P(i) S3(p,i)\n#define Q(i) S2(q,i)\n#define R(i) S2(r,i)\nconst vec4 O = vec4(0.0f);\nvoid main()\n{\nvec4 pixel = threadPixel(image);\nfloat lod = decodeLod(pixel.a);\nfloat score = decodeFloat16(pixel.rb);\ncolor = pixel;\nif(score == 0.0f)\nreturn;\nvec4 p[8];\np[0] = PIX(0,1); p[1] = PIX(1,1); p[2] = PIX(1,0); p[3] = PIX(1,-1);\np[4] = PIX(0,-1); p[5] = PIX(-1,-1); p[6] = PIX(-1,0); p[7] = PIX(-1,1);\n#ifdef USE_MIDDLE_RING\nvec4 q[16];\nq[0] = PIX(0,2); q[1] = PIX(1,2); q[2] = PIX(2,2); q[3] = PIX(2,1);\nq[4] = PIX(2,0); q[5] = PIX(2,-1); q[6] = PIX(2,-2); q[7] = PIX(1,-2);\nq[8] = PIX(0,-2); q[9] = PIX(-1,-2); q[10] = PIX(-2,-2); q[11] = PIX(-2,-1);\nq[12] = PIX(-2,0); q[13] = PIX(-2,1); q[14] = PIX(-2,2); q[15] = PIX(-1,2);\n#else\nvec4 q[16];\nq[0] = O; q[1] = O; q[2] = O; q[3] = O;\nq[4] = O; q[5] = O; q[6] = O; q[7] = O;\nq[8] = O; q[9] = O; q[10] = O; q[11] = O;\nq[12] = O; q[13] = O; q[14] = O; q[15] = O;\n#endif\n#ifdef USE_OUTER_RING\nvec4 r[16];\nr[0] = PIX(0,3); r[1] = PIX(1,3); r[2] = PIX(3,1); r[3] = PIX(3,0);\nr[4] = PIX(3,-1); r[5] = PIX(1,-3); r[6] = PIX(0,-3); r[7] = PIX(-1,-3);\nr[8] = PIX(-3,-1); r[9] = PIX(-3,0); r[10] = PIX(-3,1); r[11] = PIX(-1,3);\nr[12] = PIX(0,4); r[13] = PIX(4,0); r[14] = PIX(0,-4); r[15] = PIX(-4,0);\n#else\nvec4 r[16];\nr[0] = O; r[1] = O; r[2] = O; r[3] = O;\nr[4] = O; r[5] = O; r[6] = O; r[7] = O;\nr[8] = O; r[9] = O; r[10] = O; r[11] = O;\nr[12] = O; r[13] = O; r[14] = O; r[15] = O;\n#endif\nfloat alphaPlus = encodeLod(lod + LOD_STEP);\nfloat alphaMinus = encodeLod(lod - LOD_STEP);\nfloat alpha = encodeLod(lod);\nmat3 innerScore = mat3(\nP(0), P(1), P(2), P(3),\nP(4), P(5), P(6), P(7),\n0.0f);\nmat4 middleScore = mat4(\nQ(0), Q(1), Q(2), Q(3),\nQ(4), Q(5), Q(6), Q(7),\nQ(8), Q(9), Q(10), Q(11),\nQ(12), Q(13), Q(14), Q(15)\n);\nmat4 outerScore = mat4(\nR(0), R(1), R(2), R(3),\nR(4), R(5), R(6), R(7),\nR(8), R(9), R(10), R(11),\nR(12), R(13), R(14), R(15)\n);\nvec3 maxInnerScore3 = max(innerScore[0], max(innerScore[1], innerScore[2]));\nvec4 maxMiddleScore4 = max(max(middleScore[0], middleScore[1]), max(middleScore[2], middleScore[3]));\nvec4 maxOuterScore4 = max(max(outerScore[0], outerScore[1]), max(outerScore[2], outerScore[3]));\nfloat maxInnerScore = max(maxInnerScore3.x, max(maxInnerScore3.y, maxInnerScore3.z));\nfloat maxMiddleScore = max(max(maxMiddleScore4.x, maxMiddleScore4.y), max(maxMiddleScore4.z, maxMiddleScore4.w));\nfloat maxOuterScore = max(max(maxOuterScore4.x, maxOuterScore4.y), max(maxOuterScore4.z, maxOuterScore4.w));\nfloat maxScore = max(maxInnerScore, max(maxMiddleScore, maxOuterScore));\nfloat finalScore = step(maxScore, score) * score;\ncolor.rb = encodeFloat16(finalScore);\n}';
                }
              ),
              /***/
              9108: (
                /***/
                (module2) => {
                  module2.exports = '@include "keypoints.glsl"\nuniform sampler2D encodedCorners;\nuniform int encoderLength;\nuniform sampler2D image;\nuniform int extraSize;\nconst int descriptorSize = 32;\n#define P(a,b,c,d) ivec4((a),(b),(c),(d))\nconst ivec4 pat31[256] = ivec4[256](\nP(8,-3,9,5),\nP(4,2,7,-12),\nP(-11,9,-8,2),\nP(7,-12,12,-13),\nP(2,-13,2,12),\nP(1,-7,1,6),\nP(-2,-10,-2,-4),\nP(-13,-13,-11,-8),\nP(-13,-3,-12,-9),\nP(10,4,11,9),\nP(-13,-8,-8,-9),\nP(-11,7,-9,12),\nP(7,7,12,6),\nP(-4,-5,-3,0),\nP(-13,2,-12,-3),\nP(-9,0,-7,5),\nP(12,-6,12,-1),\nP(-3,6,-2,12),\nP(-6,-13,-4,-8),\nP(11,-13,12,-8),\nP(4,7,5,1),\nP(5,-3,10,-3),\nP(3,-7,6,12),\nP(-8,-7,-6,-2),\nP(-2,11,-1,-10),\nP(-13,12,-8,10),\nP(-7,3,-5,-3),\nP(-4,2,-3,7),\nP(-10,-12,-6,11),\nP(5,-12,6,-7),\nP(5,-6,7,-1),\nP(1,0,4,-5),\nP(9,11,11,-13),\nP(4,7,4,12),\nP(2,-1,4,4),\nP(-4,-12,-2,7),\nP(-8,-5,-7,-10),\nP(4,11,9,12),\nP(0,-8,1,-13),\nP(-13,-2,-8,2),\nP(-3,-2,-2,3),\nP(-6,9,-4,-9),\nP(8,12,10,7),\nP(0,9,1,3),\nP(7,-5,11,-10),\nP(-13,-6,-11,0),\nP(10,7,12,1),\nP(-6,-3,-6,12),\nP(10,-9,12,-4),\nP(-13,8,-8,-12),\nP(-13,0,-8,-4),\nP(3,3,7,8),\nP(5,7,10,-7),\nP(-1,7,1,-12),\nP(3,-10,5,6),\nP(2,-4,3,-10),\nP(-13,0,-13,5),\nP(-13,-7,-12,12),\nP(-13,3,-11,8),\nP(-7,12,-4,7),\nP(6,-10,12,8),\nP(-9,-1,-7,-6),\nP(-2,-5,0,12),\nP(-12,5,-7,5),\nP(3,-10,8,-13),\nP(-7,-7,-4,5),\nP(-3,-2,-1,-7),\nP(2,9,5,-11),\nP(-11,-13,-5,-13),\nP(-1,6,0,-1),\nP(5,-3,5,2),\nP(-4,-13,-4,12),\nP(-9,-6,-9,6),\nP(-12,-10,-8,-4),\nP(10,2,12,-3),\nP(7,12,12,12),\nP(-7,-13,-6,5),\nP(-4,9,-3,4),\nP(7,-1,12,2),\nP(-7,6,-5,1),\nP(-13,11,-12,5),\nP(-3,7,-2,-6),\nP(7,-8,12,-7),\nP(-13,-7,-11,-12),\nP(1,-3,12,12),\nP(2,-6,3,0),\nP(-4,3,-2,-13),\nP(-1,-13,1,9),\nP(7,1,8,-6),\nP(1,-1,3,12),\nP(9,1,12,6),\nP(-1,-9,-1,3),\nP(-13,-13,-10,5),\nP(7,7,10,12),\nP(12,-5,12,9),\nP(6,3,7,11),\nP(5,-13,6,10),\nP(2,-12,2,3),\nP(3,8,4,-6),\nP(2,6,12,-13),\nP(9,-12,10,3),\nP(-8,4,-7,9),\nP(-11,12,-4,-6),\nP(1,12,2,-8),\nP(6,-9,7,-4),\nP(2,3,3,-2),\nP(6,3,11,0),\nP(3,-3,8,-8),\nP(7,8,9,3),\nP(-11,-5,-6,-4),\nP(-10,11,-5,10),\nP(-5,-8,-3,12),\nP(-10,5,-9,0),\nP(8,-1,12,-6),\nP(4,-6,6,-11),\nP(-10,12,-8,7),\nP(4,-2,6,7),\nP(-2,0,-2,12),\nP(-5,-8,-5,2),\nP(7,-6,10,12),\nP(-9,-13,-8,-8),\nP(-5,-13,-5,-2),\nP(8,-8,9,-13),\nP(-9,-11,-9,0),\nP(1,-8,1,-2),\nP(7,-4,9,1),\nP(-2,1,-1,-4),\nP(11,-6,12,-11),\nP(-12,-9,-6,4),\nP(3,7,7,12),\nP(5,5,10,8),\nP(0,-4,2,8),\nP(-9,12,-5,-13),\nP(0,7,2,12),\nP(-1,2,1,7),\nP(5,11,7,-9),\nP(3,5,6,-8),\nP(-13,-4,-8,9),\nP(-5,9,-3,-3),\nP(-4,-7,-3,-12),\nP(6,5,8,0),\nP(-7,6,-6,12),\nP(-13,6,-5,-2),\nP(1,-10,3,10),\nP(4,1,8,-4),\nP(-2,-2,2,-13),\nP(2,-12,12,12),\nP(-2,-13,0,-6),\nP(4,1,9,3),\nP(-6,-10,-3,-5),\nP(-3,-13,-1,1),\nP(7,5,12,-11),\nP(4,-2,5,-7),\nP(-13,9,-9,-5),\nP(7,1,8,6),\nP(7,-8,7,6),\nP(-7,-4,-7,1),\nP(-8,11,-7,-8),\nP(-13,6,-12,-8),\nP(2,4,3,9),\nP(10,-5,12,3),\nP(-6,-5,-6,7),\nP(8,-3,9,-8),\nP(2,-12,2,8),\nP(-11,-2,-10,3),\nP(-12,-13,-7,-9),\nP(-11,0,-10,-5),\nP(5,-3,11,8),\nP(-2,-13,-1,12),\nP(-1,-8,0,9),\nP(-13,-11,-12,-5),\nP(-10,-2,-10,11),\nP(-3,9,-2,-13),\nP(2,-3,3,2),\nP(-9,-13,-4,0),\nP(-4,6,-3,-10),\nP(-4,12,-2,-7),\nP(-6,-11,-4,9),\nP(6,-3,6,11),\nP(-13,11,-5,5),\nP(11,11,12,6),\nP(7,-5,12,-2),\nP(-1,12,0,7),\nP(-4,-8,-3,-2),\nP(-7,1,-6,7),\nP(-13,-12,-8,-13),\nP(-7,-2,-6,-8),\nP(-8,5,-6,-9),\nP(-5,-1,-4,5),\nP(-13,7,-8,10),\nP(1,5,5,-13),\nP(1,0,10,-13),\nP(9,12,10,-1),\nP(5,-8,10,-9),\nP(-1,11,1,-13),\nP(-9,-3,-6,2),\nP(-1,-10,1,12),\nP(-13,1,-8,-10),\nP(8,-11,10,-6),\nP(2,-13,3,-6),\nP(7,-13,12,-9),\nP(-10,-10,-5,-7),\nP(-10,-8,-8,-13),\nP(4,-6,8,5),\nP(3,12,8,-13),\nP(-4,2,-3,-3),\nP(5,-13,10,-12),\nP(4,-13,5,-1),\nP(-9,9,-4,3),\nP(0,3,3,-9),\nP(-12,1,-6,1),\nP(3,2,4,-8),\nP(-10,-10,-10,9),\nP(8,-13,12,12),\nP(-8,-12,-6,-5),\nP(2,2,3,7),\nP(10,6,11,-8),\nP(6,8,8,-12),\nP(-7,10,-6,5),\nP(-3,-9,-3,9),\nP(-1,-13,-1,5),\nP(-3,-7,-3,4),\nP(-8,-2,-8,3),\nP(4,2,12,12),\nP(2,-5,3,11),\nP(6,-9,11,-13),\nP(3,-1,7,12),\nP(11,-1,12,4),\nP(-3,0,-3,6),\nP(4,-11,4,12),\nP(2,-4,2,1),\nP(-10,-6,-8,1),\nP(-13,7,-11,1),\nP(-13,12,-11,-13),\nP(6,0,11,-13),\nP(0,-1,1,4),\nP(-13,3,-9,-2),\nP(-9,8,-6,-3),\nP(-13,-6,-8,-2),\nP(5,-9,8,10),\nP(2,7,3,-9),\nP(-1,-6,-1,-1),\nP(9,5,11,-2),\nP(11,-3,12,-8),\nP(3,0,3,5),\nP(-1,4,0,10),\nP(3,-6,4,5),\nP(-13,0,-10,5),\nP(5,8,12,11),\nP(8,9,9,-6),\nP(7,-4,8,-12),\nP(-10,4,-10,9),\nP(7,3,12,4),\nP(9,-7,10,-2),\nP(7,0,12,-2),\nP(-1,-6,0,-11)\n);\nvoid getPair(int index, mat2 rot, out vec2 p, out vec2 q)\n{\nivec4 data = pat31[index];\nvec2 op = vec2(data.xy);\nvec2 oq = vec2(data.zw);\np = rot * op;\nq = rot * oq;\n}\nvoid main()\n{\nvec4 pixel = threadPixel(encodedCorners);\nivec2 thread = threadLocation();\nKeypointAddress address = findKeypointAddress(thread, encoderLength, descriptorSize, extraSize);\nint descriptorCell = address.offset - sizeofEncodedKeypoint(0, extraSize) / 4;\ncolor = pixel;\nif(descriptorCell < 0)\nreturn;\nKeypoint keypoint = decodeKeypoint(encodedCorners, encoderLength, address);\nif(isBadKeypoint(keypoint))\nreturn;\nfloat degreesOrientation = round(360.0f + degrees(keypoint.orientation));\nfloat orientation = radians(degreesOrientation - mod(degreesOrientation, 12.0f));\nfloat kcos = cos(orientation);\nfloat ksin = sin(orientation);\nmat2 rot = mat2(kcos, ksin, -ksin, kcos);\nfloat pot = exp2(keypoint.lod);\nint patternStart = 32 * descriptorCell;\nuint test[4] = uint[4](0u, 0u, 0u, 0u);\nfor(int t = 0; t < 4; t++) {\nuint bits = 0u;\nvec2 p, q;\nvec4 a, b;\nint i = t * 8;\n@unroll\nfor(int j = 0; j < 8; j++) {\ngetPair(patternStart + i + j, rot, p, q);\na = texelFetch(image, ivec2(round(keypoint.position + pot * p)), 0);\nb = texelFetch(image, ivec2(round(keypoint.position + pot * q)), 0);\nbits |= uint(a.g < b.g) << j;\n}\ntest[t] = bits;\n}\ncolor = vec4(test[0], test[1], test[2], test[3]) / 255.0f;\n}';
                }
              ),
              /***/
              7137: (
                /***/
                (module2) => {
                  module2.exports = '@include "keypoints.glsl"\nuniform sampler2D image;\nuniform sampler2D encodedKeypoints;\nuniform int descriptorSize;\nuniform int extraSize;\nuniform int encoderLength;\n#define P(x,y) ivec2((x),(y))\nconst int diskPointCount[16] = int[16](0, 4, 12, 28, 48, 80, 112, 148, 196, 252, 316, 376, 440, 528, 612, 708);\nconst ivec2 diskPoint[708] = ivec2[708](\nP(0,-1),P(-1,0),P(1,0),P(0,1),\nP(-1,-1),P(1,-1),P(-1,1),P(1,1),P(0,-2),P(-2,0),P(2,0),P(0,2),\nP(-1,-2),P(1,-2),P(-2,-1),P(2,-1),P(-2,1),P(2,1),P(-1,2),P(1,2),P(-2,-2),P(2,-2),P(-2,2),P(2,2),P(0,-3),P(-3,0),P(3,0),P(0,3),\nP(-1,-3),P(1,-3),P(-3,-1),P(3,-1),P(-3,1),P(3,1),P(-1,3),P(1,3),P(-2,-3),P(2,-3),P(-3,-2),P(3,-2),P(-3,2),P(3,2),P(-2,3),P(2,3),P(0,-4),P(-4,0),P(4,0),P(0,4),\nP(-1,-4),P(1,-4),P(-4,-1),P(4,-1),P(-4,1),P(4,1),P(-1,4),P(1,4),P(-3,-3),P(3,-3),P(-3,3),P(3,3),P(-2,-4),P(2,-4),P(-4,-2),P(4,-2),P(-4,2),P(4,2),P(-2,4),P(2,4),P(0,-5),P(-3,-4),P(3,-4),P(-4,-3),P(4,-3),P(-5,0),P(5,0),P(-4,3),P(4,3),P(-3,4),P(3,4),P(0,5),\nP(-1,-5),P(1,-5),P(-5,-1),P(5,-1),P(-5,1),P(5,1),P(-1,5),P(1,5),P(-2,-5),P(2,-5),P(-5,-2),P(5,-2),P(-5,2),P(5,2),P(-2,5),P(2,5),P(-4,-4),P(4,-4),P(-4,4),P(4,4),P(-3,-5),P(3,-5),P(-5,-3),P(5,-3),P(-5,3),P(5,3),P(-3,5),P(3,5),P(0,-6),P(-6,0),P(6,0),P(0,6),\nP(-1,-6),P(1,-6),P(-6,-1),P(6,-1),P(-6,1),P(6,1),P(-1,6),P(1,6),P(-2,-6),P(2,-6),P(-6,-2),P(6,-2),P(-6,2),P(6,2),P(-2,6),P(2,6),P(-4,-5),P(4,-5),P(-5,-4),P(5,-4),P(-5,4),P(5,4),P(-4,5),P(4,5),P(-3,-6),P(3,-6),P(-6,-3),P(6,-3),P(-6,3),P(6,3),P(-3,6),P(3,6),P(0,-7),P(-7,0),P(7,0),P(0,7),\nP(-1,-7),P(1,-7),P(-5,-5),P(5,-5),P(-7,-1),P(7,-1),P(-7,1),P(7,1),P(-5,5),P(5,5),P(-1,7),P(1,7),P(-4,-6),P(4,-6),P(-6,-4),P(6,-4),P(-6,4),P(6,4),P(-4,6),P(4,6),P(-2,-7),P(2,-7),P(-7,-2),P(7,-2),P(-7,2),P(7,2),P(-2,7),P(2,7),P(-3,-7),P(3,-7),P(-7,-3),P(7,-3),P(-7,3),P(7,3),P(-3,7),P(3,7),P(-5,-6),P(5,-6),P(-6,-5),P(6,-5),P(-6,5),P(6,5),P(-5,6),P(5,6),P(0,-8),P(-8,0),P(8,0),P(0,8),\nP(-1,-8),P(1,-8),P(-4,-7),P(4,-7),P(-7,-4),P(7,-4),P(-8,-1),P(8,-1),P(-8,1),P(8,1),P(-7,4),P(7,4),P(-4,7),P(4,7),P(-1,8),P(1,8),P(-2,-8),P(2,-8),P(-8,-2),P(8,-2),P(-8,2),P(8,2),P(-2,8),P(2,8),P(-6,-6),P(6,-6),P(-6,6),P(6,6),P(-3,-8),P(3,-8),P(-8,-3),P(8,-3),P(-8,3),P(8,3),P(-3,8),P(3,8),P(-5,-7),P(5,-7),P(-7,-5),P(7,-5),P(-7,5),P(7,5),P(-5,7),P(5,7),P(-4,-8),P(4,-8),P(-8,-4),P(8,-4),P(-8,4),P(8,4),P(-4,8),P(4,8),P(0,-9),P(-9,0),P(9,0),P(0,9),\nP(-1,-9),P(1,-9),P(-9,-1),P(9,-1),P(-9,1),P(9,1),P(-1,9),P(1,9),P(-2,-9),P(2,-9),P(-6,-7),P(6,-7),P(-7,-6),P(7,-6),P(-9,-2),P(9,-2),P(-9,2),P(9,2),P(-7,6),P(7,6),P(-6,7),P(6,7),P(-2,9),P(2,9),P(-5,-8),P(5,-8),P(-8,-5),P(8,-5),P(-8,5),P(8,5),P(-5,8),P(5,8),P(-3,-9),P(3,-9),P(-9,-3),P(9,-3),P(-9,3),P(9,3),P(-3,9),P(3,9),P(-4,-9),P(4,-9),P(-9,-4),P(9,-4),P(-9,4),P(9,4),P(-4,9),P(4,9),P(-7,-7),P(7,-7),P(-7,7),P(7,7),P(0,-10),P(-6,-8),P(6,-8),P(-8,-6),P(8,-6),P(-10,0),P(10,0),P(-8,6),P(8,6),P(-6,8),P(6,8),P(0,10),\nP(-1,-10),P(1,-10),P(-10,-1),P(10,-1),P(-10,1),P(10,1),P(-1,10),P(1,10),P(-2,-10),P(2,-10),P(-10,-2),P(10,-2),P(-10,2),P(10,2),P(-2,10),P(2,10),P(-5,-9),P(5,-9),P(-9,-5),P(9,-5),P(-9,5),P(9,5),P(-5,9),P(5,9),P(-3,-10),P(3,-10),P(-10,-3),P(10,-3),P(-10,3),P(10,3),P(-3,10),P(3,10),P(-7,-8),P(7,-8),P(-8,-7),P(8,-7),P(-8,7),P(8,7),P(-7,8),P(7,8),P(-4,-10),P(4,-10),P(-10,-4),P(10,-4),P(-10,4),P(10,4),P(-4,10),P(4,10),P(-6,-9),P(6,-9),P(-9,-6),P(9,-6),P(-9,6),P(9,6),P(-6,9),P(6,9),P(0,-11),P(-11,0),P(11,0),P(0,11),\nP(-1,-11),P(1,-11),P(-11,-1),P(11,-1),P(-11,1),P(11,1),P(-1,11),P(1,11),P(-2,-11),P(2,-11),P(-5,-10),P(5,-10),P(-10,-5),P(10,-5),P(-11,-2),P(11,-2),P(-11,2),P(11,2),P(-10,5),P(10,5),P(-5,10),P(5,10),P(-2,11),P(2,11),P(-8,-8),P(8,-8),P(-8,8),P(8,8),P(-3,-11),P(3,-11),P(-7,-9),P(7,-9),P(-9,-7),P(9,-7),P(-11,-3),P(11,-3),P(-11,3),P(11,3),P(-9,7),P(9,7),P(-7,9),P(7,9),P(-3,11),P(3,11),P(-6,-10),P(6,-10),P(-10,-6),P(10,-6),P(-10,6),P(10,6),P(-6,10),P(6,10),P(-4,-11),P(4,-11),P(-11,-4),P(11,-4),P(-11,4),P(11,4),P(-4,11),P(4,11),P(0,-12),P(-12,0),P(12,0),P(0,12),\nP(-1,-12),P(1,-12),P(-8,-9),P(8,-9),P(-9,-8),P(9,-8),P(-12,-1),P(12,-1),P(-12,1),P(12,1),P(-9,8),P(9,8),P(-8,9),P(8,9),P(-1,12),P(1,12),P(-5,-11),P(5,-11),P(-11,-5),P(11,-5),P(-11,5),P(11,5),P(-5,11),P(5,11),P(-2,-12),P(2,-12),P(-12,-2),P(12,-2),P(-12,2),P(12,2),P(-2,12),P(2,12),P(-7,-10),P(7,-10),P(-10,-7),P(10,-7),P(-10,7),P(10,7),P(-7,10),P(7,10),P(-3,-12),P(3,-12),P(-12,-3),P(12,-3),P(-12,3),P(12,3),P(-3,12),P(3,12),P(-6,-11),P(6,-11),P(-11,-6),P(11,-6),P(-11,6),P(11,6),P(-6,11),P(6,11),P(-4,-12),P(4,-12),P(-12,-4),P(12,-4),P(-12,4),P(12,4),P(-4,12),P(4,12),P(-9,-9),P(9,-9),P(-9,9),P(9,9),P(-8,-10),P(8,-10),P(-10,-8),P(10,-8),P(-10,8),P(10,8),P(-8,10),P(8,10),P(0,-13),P(-5,-12),P(5,-12),P(-12,-5),P(12,-5),P(-13,0),P(13,0),P(-12,5),P(12,5),P(-5,12),P(5,12),P(0,13),\nP(-1,-13),P(1,-13),P(-7,-11),P(7,-11),P(-11,-7),P(11,-7),P(-13,-1),P(13,-1),P(-13,1),P(13,1),P(-11,7),P(11,7),P(-7,11),P(7,11),P(-1,13),P(1,13),P(-2,-13),P(2,-13),P(-13,-2),P(13,-2),P(-13,2),P(13,2),P(-2,13),P(2,13),P(-3,-13),P(3,-13),P(-13,-3),P(13,-3),P(-13,3),P(13,3),P(-3,13),P(3,13),P(-6,-12),P(6,-12),P(-12,-6),P(12,-6),P(-12,6),P(12,6),P(-6,12),P(6,12),P(-9,-10),P(9,-10),P(-10,-9),P(10,-9),P(-10,9),P(10,9),P(-9,10),P(9,10),P(-4,-13),P(4,-13),P(-8,-11),P(8,-11),P(-11,-8),P(11,-8),P(-13,-4),P(13,-4),P(-13,4),P(13,4),P(-11,8),P(11,8),P(-8,11),P(8,11),P(-4,13),P(4,13),P(-7,-12),P(7,-12),P(-12,-7),P(12,-7),P(-12,7),P(12,7),P(-7,12),P(7,12),P(-5,-13),P(5,-13),P(-13,-5),P(13,-5),P(-13,5),P(13,5),P(-5,13),P(5,13),P(0,-14),P(-14,0),P(14,0),P(0,14),\nP(-1,-14),P(1,-14),P(-14,-1),P(14,-1),P(-14,1),P(14,1),P(-1,14),P(1,14),P(-2,-14),P(2,-14),P(-10,-10),P(10,-10),P(-14,-2),P(14,-2),P(-14,2),P(14,2),P(-10,10),P(10,10),P(-2,14),P(2,14),P(-9,-11),P(9,-11),P(-11,-9),P(11,-9),P(-11,9),P(11,9),P(-9,11),P(9,11),P(-3,-14),P(3,-14),P(-6,-13),P(6,-13),P(-13,-6),P(13,-6),P(-14,-3),P(14,-3),P(-14,3),P(14,3),P(-13,6),P(13,6),P(-6,13),P(6,13),P(-3,14),P(3,14),P(-8,-12),P(8,-12),P(-12,-8),P(12,-8),P(-12,8),P(12,8),P(-8,12),P(8,12),P(-4,-14),P(4,-14),P(-14,-4),P(14,-4),P(-14,4),P(14,4),P(-4,14),P(4,14),P(-7,-13),P(7,-13),P(-13,-7),P(13,-7),P(-13,7),P(13,7),P(-7,13),P(7,13),P(-5,-14),P(5,-14),P(-10,-11),P(10,-11),P(-11,-10),P(11,-10),P(-14,-5),P(14,-5),P(-14,5),P(14,5),P(-11,10),P(11,10),P(-10,11),P(10,11),P(-5,14),P(5,14),P(0,-15),P(-9,-12),P(9,-12),P(-12,-9),P(12,-9),P(-15,0),P(15,0),P(-12,9),P(12,9),P(-9,12),P(9,12),P(0,15)\n);\nconst int DEFAULT_PATCH_RADIUS = 15;\nconst int MIN_PATCH_RADIUS = 2;\nvoid main()\n{\nvec4 pixel = threadPixel(encodedKeypoints);\nivec2 thread = threadLocation();\nint keypointIndex = thread.x + thread.y * outputSize().x;\nint pixelsPerKeypoint = sizeofEncodedKeypoint(descriptorSize, extraSize) / 4;\nKeypointAddress address = KeypointAddress(keypointIndex * pixelsPerKeypoint, 0);\nKeypoint keypoint = decodeKeypoint(encodedKeypoints, encoderLength, address);\nvec2 m = vec2(0.0f);\nfloat pot = exp2(keypoint.lod);\nvec2 imageSize = vec2(textureSize(image, 0));\nint scaledRadius = int(ceil(float(DEFAULT_PATCH_RADIUS) / pot));\nint radius = max(scaledRadius, MIN_PATCH_RADIUS);\nint count = diskPointCount[radius];\nfor(int j = 0; j < count; j++) {\nvec2 offset = vec2(diskPoint[j]);\nvec2 position = keypoint.position + round(pot * offset);\nvec4 patchPixel = texture(image, (position + vec2(0.5f)) / imageSize);\nm += offset * patchPixel.g;\n}\nfloat angle = fastAtan2(m.y, m.x);\nfloat encodedOrientation = encodeKeypointOrientation(angle);\ncolor = vec4(0.0f, encodedOrientation, 0.0f, 0.0f);\n}';
                }
              ),
              /***/
              9739: (
                /***/
                (module2) => {
                  module2.exports = '@include "keypoints.glsl"\n@include "filters.glsl"\n#if !defined(METHOD)\n#error Undefined METHOD\n#endif\nuniform sampler2D pyramid;\nuniform float lodStep;\nuniform sampler2D encodedKeypoints;\nuniform int descriptorSize;\nuniform int extraSize;\nuniform int encoderLength;\n#if METHOD == 1\nuniform int threshold;\n#endif\nconst float eps = 1e-6;\nfloat cornerStrength(vec2 position, float lod)\n{\n#if METHOD == 0\nreturn laplacian(pyramid, position, lod);\n#elif METHOD == 1\nfloat pot = exp2(lod);\nfloat t = float(clamp(threshold, 0, 255)) / 255.0f;\n#define P(x,y) pyrPixelAtOffset(pyramid, lod, pot, ivec2((x),(y))).g\nmat4 mp = mat4(\nP(0,3),P(3,0),P(0,-3),P(-3,0),\nP(1,3),P(2,2),P(3,1),P(3,-1),\nP(2,-2),P(1,-3),P(-1,-3),P(-2,-2),\nP(-3,-1),P(-3,1),P(-2,2),P(-1,3)\n);\nfloat c = P(0,0);\nfloat ct = c + t, c_t = c - t;\nmat4 mct = mp - mat4(ct,ct,ct,ct,ct,ct,ct,ct,ct,ct,ct,ct,ct,ct,ct,ct);\nmat4 mc_t = mat4(c_t,c_t,c_t,c_t,c_t,c_t,c_t,c_t,c_t,c_t,c_t,c_t,c_t,c_t,c_t,c_t) - mp;\nconst vec4 zeros = vec4(0.0f), ones = vec4(1.0f);\nvec4 bs = max(mct[0], zeros), ds = max(mc_t[0], zeros);\nbs += max(mct[1], zeros);     ds += max(mc_t[1], zeros);\nbs += max(mct[2], zeros);     ds += max(mc_t[2], zeros);\nbs += max(mct[3], zeros);     ds += max(mc_t[3], zeros);\nreturn max(dot(bs, ones), dot(ds, ones)) / 16.0f;\n#else\n#error Invalid method\n#endif\n}\nvoid main()\n{\nvec4 pixel = threadPixel(encodedKeypoints);\nivec2 thread = threadLocation();\nKeypointAddress address = findKeypointAddress(thread, encoderLength, descriptorSize, extraSize);\ncolor = pixel;\nif(address.offset != 1)\nreturn;\nKeypoint keypoint = decodeKeypoint(encodedKeypoints, encoderLength, address);\nif(isBadKeypoint(keypoint))\nreturn;\nvec3 strength = vec3(\ncornerStrength(keypoint.position, max(0.0f, keypoint.lod - lodStep)),\ncornerStrength(keypoint.position, keypoint.lod),\ncornerStrength(keypoint.position, keypoint.lod + lodStep)\n);\nvec3 p = mat3(\n2, -3, 1,\n-4, 4, 0,\n2, -1, 0\n) * strength;\nfloat maxStrength = max(strength.x, max(strength.y, strength.z));\nvec3 diffStrength = abs(strength - vec3(maxStrength));\nvec3 strengthIndicators = vec3(lessThan(diffStrength, vec3(eps)));\nfloat maxPoint = min(1.0f, dot(vec3(0.0f, 0.5f, 1.0f), strengthIndicators));\nbool hasMax = p.x < -eps;\nfloat pmax = hasMax ? -0.5f * p.y / p.x : maxPoint;\nfloat alpha = abs(pmax - 0.5f) <= 0.5f ? pmax : maxPoint;\nfloat lodOffset = mix(-lodStep, lodStep, alpha);\nfloat lod = keypoint.lod + lodOffset;\ncolor.r = encodeLod(lod);\n}';
                }
              ),
              /***/
              8231: (
                /***/
                (module2) => {
                  module2.exports = '@include "float16.glsl"\nuniform sampler2D corners;\nuniform int iterationNumber;\nvoid main()\n{\nivec2 thread = threadLocation();\nivec2 bounds = outputSize();\nint jump = (1 << iterationNumber);\nint clusterLength = jump << 1;\nint clusterMask = clusterLength - 1;\nivec2 clusterPos = ivec2(thread >> (1 + iterationNumber)) << (1 + iterationNumber);\nivec2 next1 = clusterPos + ((thread - clusterPos + ivec2(jump, 0)) & clusterMask);\nivec2 next2 = clusterPos + ((thread - clusterPos + ivec2(0, jump)) & clusterMask);\nivec2 next3 = clusterPos + ((thread - clusterPos + ivec2(jump, jump)) & clusterMask);\nvec4 p0 = threadPixel(corners);\nvec4 p1 = texelFetch(corners, next1 % bounds, 0);\nvec4 p2 = texelFetch(corners, next2 % bounds, 0);\nvec4 p3 = texelFetch(corners, next3 % bounds, 0);\nfloat s0 = decodeFloat16(p0.rb);\nfloat s1 = decodeFloat16(p1.rb);\nfloat s2 = decodeFloat16(p2.rb);\nfloat s3 = decodeFloat16(p3.rb);\nbool b0 = s0 >= s1 && s0 >= s2 && s0 >= s3;\nbool b1 = s1 >= s0 && s1 >= s2 && s1 >= s3;\nbool b2 = s2 >= s0 && s2 >= s1 && s2 >= s3;\ncolor = vec4(0.0f);\ncolor.rb = b0 ? p0.rb : (\nb1 ? p1.rb : (\nb2 ? p2.rb : p3.rb\n)\n);\n}';
                }
              ),
              /***/
              2518: (
                /***/
                (module2) => {
                  module2.exports = '@include "keypoints.glsl"\nuniform sampler2D encodedKeypoints;\nuniform int descriptorSize;\nuniform int extraSize;\nuniform int encoderLength;\n#if PERMUTATION_MAXLEN % 4 > 0 || PERMUTATION_MAXLEN * 4 > 16384\n#error Invalid PERMUTATION_MAXLEN\n#endif\nlayout(std140) uniform Permutation\n{\nivec4 permutation[PERMUTATION_MAXLEN / 4];\n};\nint permutationElement(int index)\n{\nint base = index - (index % PERMUTATION_MAXLEN);\nint offset = index - base;\nivec4 tuple = permutation[offset / 4];\nint newOffset = tuple[offset & 3];\nreturn base + newOffset;\n}\nvoid main()\n{\nivec2 thread = threadLocation();\nint pixelsPerKeypoint = sizeofEncodedKeypoint(descriptorSize, extraSize) / 4;\nKeypointAddress myAddress = findKeypointAddress(thread, encoderLength, descriptorSize, extraSize);\nint myIndex = findKeypointIndex(myAddress, descriptorSize, extraSize);\nint otherIndex = permutationElement(myIndex);\nKeypointAddress otherAddress = KeypointAddress(otherIndex * pixelsPerKeypoint, myAddress.offset);\nKeypoint myKeypoint = decodeKeypoint(encodedKeypoints, encoderLength, myAddress);\nKeypoint otherKeypoint = decodeKeypoint(encodedKeypoints, encoderLength, otherAddress);\ncolor = readKeypointData(encodedKeypoints, encoderLength, otherAddress);\n}';
                }
              ),
              /***/
              8096: (
                /***/
                (module2) => {
                  module2.exports = '@include "keypoints.glsl"\n#if !defined(STAGE)\n#error Undefined STAGE\n#elif STAGE == 1\nuniform sampler2D encodedKeypoints;\nuniform int descriptorSize;\nuniform int extraSize;\nuniform int encoderLength;\n#elif STAGE == 2\nuniform sampler2D permutation;\nuniform int blockSize;\nuniform int dblLog2BlockSize;\n#elif STAGE == 3\nuniform sampler2D permutation;\nuniform int maxKeypoints;\nuniform sampler2D encodedKeypoints;\nuniform int descriptorSize;\nuniform int extraSize;\n#else\n#error Invalid STAGE\n#endif\nstruct PermutationElement\n{\nint keypointIndex;\nfloat score;\nbool valid;\n};\nvec4 encodePermutationElement(PermutationElement element)\n{\nconst vec2 ONES = vec2(1.0f);\nvec2 encodedScore = element.valid ? encodeFloat16(element.score) : ONES;\nvec2 encodedIndex = vec2(element.keypointIndex & 255, (element.keypointIndex >> 8) & 255) / 255.0f;\nreturn vec4(encodedIndex, encodedScore);\n}\nPermutationElement decodePermutationElement(vec4 pixel)\n{\nconst vec2 ONES = vec2(1.0f);\nPermutationElement element;\nelement.keypointIndex = int(pixel.r * 255.0f) | (int(pixel.g * 255.0f) << 8);\nelement.valid = !all(equal(pixel.ba, ONES));\nelement.score = element.valid ? decodeFloat16(pixel.ba) : -1.0f;\nreturn element;\n}\nPermutationElement readPermutationElement(sampler2D permutation, int elementIndex, int stride, int height)\n{\nconst vec4 INVALID_PIXEL = vec4(1.0f);\nivec2 pos = ivec2(elementIndex % stride, elementIndex / stride);\nvec4 pixel = pos.y < height ? pixelAt(permutation, pos) : INVALID_PIXEL;\nreturn decodePermutationElement(pixel);\n}\n#if STAGE == 2\nPermutationElement selectKth(sampler2D permutation, int k, int la, int ra, int lb, int rb)\n{\nfloat scoreA, scoreB;\nint ha, hb, ma, mb;\nbool discard1stHalf, altb;\nbool locked = false;\nint tmp, result = 0;\nint stride = outputSize().x;\nint height = outputSize().y;\nfor(int i = 0; i < dblLog2BlockSize; i++) {\ntmp = (lb > rb && !locked) ? (la+k) : result;\nresult = (la > ra && !locked) ? (lb+k) : tmp;\nlocked = locked || (la > ra) || (lb > rb);\nha = (ra - la + 1) / 2;\nhb = (rb - lb + 1) / 2;\nma = la + ha;\nmb = lb + hb;\nscoreA = readPermutationElement(permutation, ma, stride, height).score;\nscoreB = readPermutationElement(permutation, mb, stride, height).score;\ndiscard1stHalf = (k > ha + hb);\naltb = (-scoreA < -scoreB);\nk -= int(discard1stHalf && altb) * (ha + 1);\nk -= int(discard1stHalf && !altb) * (hb + 1);\nla += int(discard1stHalf && altb) * (ma + 1 - la);\nlb += int(discard1stHalf && !altb) * (mb + 1 - lb);\nra += int(!discard1stHalf && !altb) * (ma - 1 - ra);\nrb += int(!discard1stHalf && altb) * (mb - 1 - rb);\n}\nreturn readPermutationElement(permutation, result, stride, height);\n}\n#endif\nvoid main()\n{\n#if STAGE == 1\nivec2 thread = threadLocation();\nint stride = outputSize().x;\nint keypointIndex = thread.y * stride + thread.x;\nint pixelsPerKeypoint = sizeofEncodedKeypoint(descriptorSize, extraSize) / 4;\nKeypointAddress address = KeypointAddress(keypointIndex * pixelsPerKeypoint, 0);\nKeypoint keypoint = decodeKeypoint(encodedKeypoints, encoderLength, address);\nPermutationElement element;\nelement.keypointIndex = keypointIndex;\nelement.score = keypoint.score;\nelement.valid = !isBadKeypoint(keypoint);\ncolor = encodePermutationElement(element);\n#elif STAGE == 2\nivec2 thread = threadLocation();\nint stride = outputSize().x;\nint elementIndex = thread.y * stride + thread.x;\nint blockIndex = elementIndex / blockSize;\nint blockOffset = elementIndex % blockSize;\nint la = blockIndex * blockSize;\nint lb = la + blockSize / 2;\nint ra = lb - 1;\nint rb = (blockIndex + 1) * blockSize - 1;\nint k = blockOffset;\nPermutationElement element = selectKth(permutation, k, la, ra, lb, rb);\ncolor = encodePermutationElement(element);\n#elif STAGE == 3\nivec2 thread = threadLocation();\nint newEncoderLength = outputSize().x;\nKeypointAddress myAddress = findKeypointAddress(thread, newEncoderLength, descriptorSize, extraSize);\nint myKeypointIndex = findKeypointIndex(myAddress, descriptorSize, extraSize);\nivec2 psize = textureSize(permutation, 0);\nPermutationElement element = readPermutationElement(permutation, myKeypointIndex, psize.x, psize.y);\nint oldEncoderLength = textureSize(encodedKeypoints, 0).x;\nint pixelsPerKeypoint = sizeofEncodedKeypoint(descriptorSize, extraSize) / 4;\nKeypointAddress address = KeypointAddress(element.keypointIndex * pixelsPerKeypoint, myAddress.offset);\nvec4 keypointData = readKeypointData(encodedKeypoints, oldEncoderLength, address);\ncolor = myKeypointIndex < maxKeypoints && element.valid ? keypointData : encodeNullKeypoint();\n#endif\n}';
                }
              ),
              /***/
              5795: (
                /***/
                (module2) => {
                  module2.exports = '@include "keypoints.glsl"\n@include "float16.glsl"\n#if !defined(METHOD)\n#error Must define METHOD\n#endif\nuniform sampler2D pyramid;\nuniform sampler2D encodedKeypoints;\nuniform int descriptorSize;\nuniform int extraSize;\nuniform int encoderLength;\nuniform int maxIterations;\nuniform float epsilon;\nconst int PATCH_RADIUS = 1;\nconst int PATCH_SIZE = 2 * PATCH_RADIUS + 1;\nconst int PATCH_SIZE_SQUARED = PATCH_SIZE * PATCH_SIZE;\nconst int LARGE_PATCH_RADIUS = PATCH_RADIUS + 1;\nconst int LARGE_PATCH_SIZE = 2 * LARGE_PATCH_RADIUS + 1;\nconst int LARGE_PATCH_SIZE_SQUARED = LARGE_PATCH_SIZE * LARGE_PATCH_SIZE;\nconst int LARGER_PATCH_RADIUS = LARGE_PATCH_RADIUS + 1;\nconst int LARGER_PATCH_SIZE = 2 * LARGER_PATCH_RADIUS + 1;\nconst int LARGER_PATCH_SIZE_SQUARED = LARGER_PATCH_SIZE * LARGER_PATCH_SIZE;\nconst float EPS = 1e-5;\nfloat smoothPixelBuffer[LARGER_PATCH_SIZE_SQUARED];\nvec2 derivativesBuffer[LARGE_PATCH_SIZE_SQUARED];\nfloat responseBuffer[PATCH_SIZE_SQUARED];\n#define patchPixelAt(u,v) smoothPixelBuffer[((v) + LARGER_PATCH_RADIUS) * LARGER_PATCH_SIZE + ((u) + LARGER_PATCH_RADIUS)]\n#define derivativesAt(u,v) derivativesBuffer[((v) + LARGE_PATCH_RADIUS) * LARGE_PATCH_SIZE + ((u) + LARGE_PATCH_RADIUS)]\n#define responseAt(u,v) responseBuffer[((v) + PATCH_RADIUS) * PATCH_SIZE + ((u) + PATCH_RADIUS)]\nvoid readPixels(vec2 center, float lod)\n{\nivec2 pyrBaseSize = textureSize(pyramid, 0);\nfloat pot = exp2(lod);\nint u, v;\nfor(int j = 0; j < LARGER_PATCH_SIZE; j++) {\nfor(int i = 0; i < LARGER_PATCH_SIZE; i++) {\nu = i - LARGER_PATCH_RADIUS;\nv = j - LARGER_PATCH_RADIUS;\npatchPixelAt(u,v) = pyrSubpixelAtExOffset(pyramid, center, lod, pot, ivec2(u,v), pyrBaseSize).g;\n}\n}\n}\nvoid computeDerivatives()\n{\nconst mat3 dx = mat3(\n-1, 0, 1,\n-2, 0, 2,\n-1, 0, 1\n);\nconst mat3 dy = mat3(\n1, 2, 1,\n0, 0, 0,\n-1,-2,-1\n);\nint u, v;\nmat3 pix, convX, convY;\nconst vec3 ones = vec3(1.0f);\nfor(int j = 0; j < LARGE_PATCH_SIZE; j++) {\nfor(int i = 0; i < LARGE_PATCH_SIZE; i++) {\nu = i - LARGE_PATCH_RADIUS;\nv = j - LARGE_PATCH_RADIUS;\npix = mat3(\npatchPixelAt(u+1,v+1), patchPixelAt(u+0,v+1), patchPixelAt(u-1,v+1),\npatchPixelAt(u+1,v+0), patchPixelAt(u+0,v+0), patchPixelAt(u-1,v+0),\npatchPixelAt(u+1,v-1), patchPixelAt(u+0,v-1), patchPixelAt(u-1,v-1)\n);\nconvX = matrixCompMult(dx, pix);\nconvY = matrixCompMult(dy, pix);\nderivativesAt(u,v) = vec2(\ndot(ones, vec3(\ndot(convX[0], ones),\ndot(convX[1], ones),\ndot(convX[2], ones)\n)),\ndot(ones, vec3(\ndot(convY[0], ones),\ndot(convY[1], ones),\ndot(convY[2], ones)\n))\n);\n}\n}\n}\nvec2 computeResponseMap()\n{\nfloat patchArea = float(PATCH_SIZE * PATCH_SIZE);\nvec3 h; vec2 d, c = vec2(0.0f);\nconst vec3 ones = vec3(1.0f);\nfloat response, sum = 0.0f;\nint u, v;\n#define H(r,s) d = derivativesAt((r),(s)); h += vec3(d.x * d.x, d.x * d.y, d.y * d.y)\nfor(int j = 0; j < PATCH_SIZE; j++) {\nfor(int i = 0; i < PATCH_SIZE; i++) {\nu = i - PATCH_RADIUS;\nv = j - PATCH_RADIUS;\nh = vec3(0.0f);\nH(u-1,v-1); H(u+0,v-1); H(u+1,v-1);\nH(u-1,v+0); H(u+0,v+0); H(u+1,v+0);\nH(u-1,v+1); H(u+0,v+1); H(u+1,v+1);\nresponse = 0.5f * (h.x + h.z - sqrt((h.x - h.z) * (h.x - h.z) + 4.0f * h.y * h.y));\nresponse /= patchArea;\nresponseAt(u,v) = response;\nc += vec2(u,v) * response;\nsum += response;\n}\n}\nreturn abs(sum) > EPS ? c / sum : vec2(0.0f);\n}\n#if METHOD == 0\nvec2 quadratic1d()\n{\nfloat a = 0.5f * (responseAt(-1,0) - 2.0f * responseAt(0,0) + responseAt(1,0));\nfloat b = 0.5f * (responseAt(1,0) - responseAt(-1,0));\nfloat c = responseAt(0,0);\nfloat d = 0.5f * (responseAt(0,-1) - 2.0f * responseAt(0,0) + responseAt(0,1));\nfloat e = 0.5f * (responseAt(0,1) - responseAt(0,-1));\nfloat f = responseAt(0,0);\nbool hasMax = a < -EPS && d < -EPS;\nreturn hasMax ? -0.5f * vec2(b / a, e / d) : vec2(0.0f);\n}\n#endif\n#if METHOD == 1\nvec2 taylor2d()\n{\nfloat dx = (-responseAt(-1,0) + responseAt(1,0)) * 0.5f;\nfloat dy = (-responseAt(0,-1) + responseAt(0,1)) * 0.5f;\nfloat dxx = responseAt(-1,0) - 2.0f * responseAt(0,0) + responseAt(1,0);\nfloat dyy = responseAt(0,-1) - 2.0f * responseAt(0,0) + responseAt(0,1);\nfloat dxy = (responseAt(-1,-1) + responseAt(1,1) - responseAt(1,-1) - responseAt(-1,1)) * 0.25f;\nfloat det = dxx * dyy - dxy * dxy;\nmat2 inv = mat2(dyy, -dxy, -dxy, dxx);\nbool hasMax = det > EPS && dxx < 0.0f;\nreturn hasMax ? inv * vec2(dx, dy) / (-det) : vec2(0.0f);\n}\n#endif\n#if METHOD == 2\nvoid bilinearUpsample(ivec2 patchOffset, vec4 pixelsOfPatch)\n{\nint u, v, i, j;\nvec2 frc, ifrc; vec4 sub;\nconst vec4 ones = vec4(1.0f);\nfloat s = 1.0f / float(PATCH_SIZE - 1);\nint xoff = 2 * patchOffset.x;\nint yoff = 2 * patchOffset.y;\nfor(j = 0; j < PATCH_SIZE; j++) {\nfor(i = 0; i < PATCH_SIZE; i++) {\nu = i - PATCH_RADIUS;\nv = j - PATCH_RADIUS;\nfrc = vec2(i, j) * s;\nifrc = vec2(1.0f) - frc;\nsub = vec4(\nifrc.x * ifrc.y,\nfrc.x * ifrc.y,\nifrc.x * frc.y,\nfrc.x * frc.y\n);\npatchPixelAt(u+xoff,v+yoff) = dot(sub*pixelsOfPatch, ones);\n}\n}\n}\n#endif\n#if METHOD == 3\nvoid bicubicUpsample(ivec2 patchOffset, vec4 pixelsOfPatch, vec4 dx, vec4 dy, vec4 dxy)\n{\nfloat x, y, s = 1.0f / float(PATCH_SIZE - 1);\nint u, v, i, j;\nfloat f00 = pixelsOfPatch.x;\nfloat f10 = pixelsOfPatch.y;\nfloat f01 = pixelsOfPatch.z;\nfloat f11 = pixelsOfPatch.w;\nfloat fx00 = dx.x;\nfloat fx10 = dx.y;\nfloat fx01 = dx.z;\nfloat fx11 = dx.w;\nfloat fy00 = dy.x;\nfloat fy10 = dy.y;\nfloat fy01 = dy.z;\nfloat fy11 = dy.w;\nfloat fxy00 = dxy.x;\nfloat fxy10 = dxy.y;\nfloat fxy01 = dxy.z;\nfloat fxy11 = dxy.w;\nmat4 bicubic = mat4(\n1, 0, -3, 2,\n0, 0, 3, -2,\n0, 1, -2, 1,\n0, 0, -1, 1\n) * mat4(\nf00, f10, fx00, fx10,\nf01, f11, fx01, fx11,\nfy00, fy10, fxy00, fxy10,\nfy01, fy11, fxy01, fxy11\n) * mat4(\n1, 0, 0, 0,\n0, 0, 1, 0,\n-3, 3, -2, -1,\n2, -2, 1, 1\n);\nint xoff = 2 * patchOffset.x;\nint yoff = 2 * patchOffset.y;\nfor(j = 0; j < PATCH_SIZE; j++) {\nfor(i = 0; i < PATCH_SIZE; i++) {\nu = i - PATCH_RADIUS;\nv = j - PATCH_RADIUS;\nx = float(i) * s;\ny = float(j) * s;\npatchPixelAt(u+xoff,v+yoff) = dot(\nvec4(1, x, x*x, x*x*x),\nbicubic * vec4(1, y, y*y, y*y*y)\n);\n}\n}\n}\n#endif\n#if METHOD == 2 || METHOD == 3\nvoid upsamplePatch(int left, int top, int right, int bottom)\n{\nint x, y, k;\nvec4 ptch[9];\nvec2 d00, d10, d01, d11;\nfor(k = 0; k < 9; k++) {\nx = -1 + (k % 3);\ny = -1 + (k / 3);\nptch[k] = vec4(\npatchPixelAt(left+x, top+y),\npatchPixelAt(right+x, top+y),\npatchPixelAt(left+x, bottom+y),\npatchPixelAt(right+x, bottom+y)\n);\n}\nfor(k = 0; k < 9; k++) {\nx = -1 + (k % 3);\ny = -1 + (k / 3);\n#if METHOD == 2\nbilinearUpsample(ivec2(x, y), ptch[k]);\n#elif METHOD == 3\nd00 = derivativesAt(left+x, top+y);\nd10 = derivativesAt(right+x, top+y);\nd01 = derivativesAt(left+x, bottom+y);\nd11 = derivativesAt(right+x, bottom+y);\nbicubicUpsample(ivec2(x, y), ptch[k],\nvec4(d00.x, d10.x, d01.x, d11.x),\nvec4(d00.y, d10.y, d01.y, d11.y),\n0.25f * vec4(\n(patchPixelAt(left+x + 1,top+y + 1) + patchPixelAt(left+x - 1, top+y - 1)) - (patchPixelAt(left+x + 1, top+y - 1) + patchPixelAt(left+x - 1, top+y + 1)),\n(patchPixelAt(right+x + 1,top+y + 1) + patchPixelAt(right+x - 1, top+y - 1)) - (patchPixelAt(right+x + 1, top+y - 1) + patchPixelAt(right+x - 1, top+y + 1)),\n(patchPixelAt(left+x + 1,bottom+y + 1) + patchPixelAt(left+x - 1, bottom+y - 1)) - (patchPixelAt(left+x + 1, bottom+y - 1) + patchPixelAt(left+x - 1, bottom+y + 1)),\n(patchPixelAt(right+x + 1,bottom+y + 1) + patchPixelAt(right+x - 1, bottom+y - 1)) - (patchPixelAt(right+x + 1, bottom+y - 1) + patchPixelAt(right+x - 1, bottom+y + 1))\n)\n);\n#endif\n}\n}\nvec2 upsampleResponseMap(int left, int top, int right, int bottom)\n{\nupsamplePatch(left, top, right, bottom);\ncomputeDerivatives();\nreturn computeResponseMap();\n}\nvec2 iterativeUpsample(vec2 initialGuess)\n{\nint refine = 1;\nfloat scale = 0.5f;\nfloat eps2 = epsilon * epsilon;\nvec2 guess = initialGuess, localGuess = initialGuess;\nfor(int k = 0; k < maxIterations; k++) {\nivec4 quad = ivec4(floor(localGuess.x), floor(localGuess.y), ceil(localGuess.x), ceil(localGuess.y));\nvec2 response = (refine != 0) ? upsampleResponseMap(quad.x, quad.y, quad.z, quad.w) : vec2(0.0f);\nlocalGuess = response * scale;\nguess += localGuess;\nscale *= 0.5f;\nrefine *= int(dot(localGuess, localGuess) >= eps2);\n}\nreturn guess;\n}\n#endif\nvoid main()\n{\nivec2 thread = threadLocation();\nint keypointIndex = thread.x + thread.y * outputSize().x;\nint pixelsPerKeypoint = sizeofEncodedKeypoint(descriptorSize, extraSize) / 4;\nKeypointAddress address = KeypointAddress(keypointIndex * pixelsPerKeypoint, 0);\nKeypoint keypoint = decodeKeypoint(encodedKeypoints, encoderLength, address);\ncolor = encodeNullPairOfFloat16();\nif(isNullKeypoint(keypoint))\nreturn;\ncolor = encodeDiscardedPairOfFloat16();\nif(isBadKeypoint(keypoint))\nreturn;\nreadPixels(keypoint.position, keypoint.lod);\ncomputeDerivatives();\nvec2 offset = computeResponseMap();\n#if METHOD == 0\noffset = quadratic1d();\n#elif METHOD == 1\noffset = taylor2d();\n#elif METHOD == 2 || METHOD == 3\noffset = iterativeUpsample(offset);\n#else\n#error Unknown METHOD\n#endif\nfloat pot = exp2(keypoint.lod);\ncolor = encodePairOfFloat16(offset * pot);\n}';
                }
              ),
              /***/
              3169: (
                /***/
                (module2) => {
                  module2.exports = '@include "keypoints.glsl"\n@include "float16.glsl"\nuniform sampler2D encodedFlow;\nuniform sampler2D encodedKeypoints;\nuniform int descriptorSize;\nuniform int extraSize;\nuniform int encoderLength;\nvoid main()\n{\nvec4 pixel = threadPixel(encodedKeypoints);\nivec2 thread = threadLocation();\nint len = textureSize(encodedFlow, 0).x;\nKeypointAddress myAddress = findKeypointAddress(thread, encoderLength, descriptorSize, extraSize);\nKeypoint keypoint = decodeKeypoint(encodedKeypoints, encoderLength, myAddress);\nint myIndex = findKeypointIndex(myAddress, descriptorSize, extraSize);\ncolor = pixel;\nif(isBadKeypoint(keypoint))\nreturn;\nivec2 location = ivec2(myIndex % len, myIndex / len);\nvec4 encodedFlow = myIndex < len * len ? pixelAt(encodedFlow, location) : encodeDiscardedKeypoint();\nbool discardFlow = isDiscardedPairOfFloat16(encodedFlow);\nvec2 flow = !discardFlow ? decodePairOfFloat16(encodedFlow) : vec2(0.0f);\nvec4 newPosition = encodeKeypointPosition(keypoint.position + flow);\nvec4 newPixel = myAddress.offset == 0 ? newPosition : pixel;\ncolor = !discardFlow ? newPixel : encodeDiscardedKeypoint();\n}';
                }
              ),
              /***/
              1337: (
                /***/
                (module2) => {
                  module2.exports = '@include "keypoints.glsl"\nuniform sampler2D encodedOrientations;\nuniform sampler2D encodedKeypoints;\nuniform int descriptorSize;\nuniform int extraSize;\nuniform int encoderLength;\nvoid main()\n{\nvec4 pixel = threadPixel(encodedKeypoints);\nivec2 thread = threadLocation();\nKeypointAddress myAddress = findKeypointAddress(thread, encoderLength, descriptorSize, extraSize);\nint myIndex = findKeypointIndex(myAddress, descriptorSize, extraSize);\nint orientationEncoderLength = textureSize(encodedOrientations, 0).x;\nivec2 location = ivec2(myIndex % orientationEncoderLength, myIndex / orientationEncoderLength);\nvec4 targetPixel = pixelAt(encodedOrientations, location);\nKeypoint keypoint = decodeKeypoint(encodedKeypoints, encoderLength, myAddress);\nbool isValid = !isBadKeypoint(keypoint);\nfloat encodedOrientation = targetPixel.g;\ncolor = isValid && myAddress.offset == 1 ? vec4(pixel.r, encodedOrientation, pixel.ba) : pixel;\n}';
                }
              ),
              /***/
              6187: (
                /***/
                (module2) => {
                  module2.exports = '@include "keypoints.glsl"\nuniform sampler2D encodedData;\nuniform int strideOfEncodedData;\nuniform sampler2D encodedKeypoints;\nuniform int descriptorSize;\nuniform int extraSize;\nuniform int encoderLength;\nvec4 readEncodedData(sampler2D encodedData, int strideOfEncodedData, int elementId, int pixelsPerElement, int pixelOffset)\n{\nint rasterIndex = elementId * pixelsPerElement + pixelOffset;\nivec2 pos = ivec2(rasterIndex % strideOfEncodedData, rasterIndex / strideOfEncodedData);\nreturn texelFetch(encodedData, pos, 0);\n}\nvoid main()\n{\nivec2 thread = threadLocation();\nKeypointAddress myAddress = findKeypointAddress(thread, encoderLength, descriptorSize, extraSize);\nint myIndex = findKeypointIndex(myAddress, descriptorSize, extraSize);\nint headerSize = sizeofEncodedKeypointHeader();\nint extraCell = myAddress.offset - headerSize / 4;\nint numberOfExtraCells = extraSize / 4;\ncolor = threadPixel(encodedKeypoints);\nif(extraCell < 0 || extraCell >= numberOfExtraCells)\nreturn;\nKeypoint keypoint = decodeKeypoint(encodedKeypoints, encoderLength, myAddress);\nif(isBadKeypoint(keypoint))\nreturn;\ncolor = readEncodedData(encodedData, strideOfEncodedData, myIndex, numberOfExtraCells, extraCell);\n}';
                }
              ),
              /***/
              477: (
                /***/
                (module2) => {
                  module2.exports = '@include "keypoints.glsl"\nuniform sampler2D encodedKeypoints;\nuniform int startIndex;\nuniform int endIndex;\nuniform int descriptorSize;\nuniform int extraSize;\nuniform int encoderLength;\n#ifndef BUFFER_SIZE\n#error Undefined BUFFER_SIZE\n#endif\nlayout(std140) uniform KeypointBuffer\n{\nvec4 keypointBuffer[BUFFER_SIZE];\n};\nvoid main()\n{\nvec4 pixel = threadPixel(encodedKeypoints);\nivec2 thread = threadLocation();\nKeypointAddress address = findKeypointAddress(thread, encoderLength, descriptorSize, extraSize);\nint index = findKeypointIndex(address, descriptorSize, extraSize);\ncolor = pixel;\nif(index < startIndex)\nreturn;\ncolor = encodeNullKeypoint();\nif(index >= endIndex)\nreturn;\nvec4 data = keypointBuffer[index - startIndex];\nswitch(address.offset) {\ncase 0: {\ncolor = encodeKeypointPosition(data.xy);\nbreak;\n}\ncase 1: {\nvec2 score = encodeKeypointScore(max(data.w, 0.0f));\nfloat scale = encodeLod(data.z);\nfloat rotation = encodeKeypointOrientation(0.0f);\ncolor = vec4(scale, rotation, score);\nbreak;\n}\ndefault: {\ncolor = vec4(0.0f);\nbreak;\n}\n}\n}';
                }
              ),
              /***/
              4050: (
                /***/
                (module2) => {
                  module2.exports = "uniform sampler2D image;\nvoid main()\n{\n#if 1\ncolor = texture(image, texCoord);\n#else\nivec2 thread = threadLocation();\nivec2 pos = min(thread * 2, textureSize(image, 0) - ivec2(1));\ncolor = pixelAt(image, pos);\n#endif\n}";
                }
              ),
              /***/
              5545: (
                /***/
                (module2) => {
                  module2.exports = "uniform sampler2D image;\nvoid main()\n{\nivec2 thread = threadLocation();\nvec4 pixel = pixelAt(image, thread / 2);\ncolor = (((thread.x + thread.y) & 1) == 0) ? pixel : vec4(0.0f, 0.0f, 0.0f, pixel.a);\n}";
                }
              ),
              /***/
              7113: (
                /***/
                (module2) => {
                  module2.exports = '@include "subpixel.glsl"\nuniform sampler2D image0;\nuniform sampler2D image1;\nuniform float alpha;\nuniform float beta;\nuniform float gamma;\nconst vec4 BACKGROUND = vec4(0.0f);\nvoid main()\n{\nivec2 location = threadLocation();\nivec2 size0 = textureSize(image0, 0);\nivec2 size1 = textureSize(image1, 0);\nvec4 pix0 = all(lessThan(location, size0)) ? pixelAt(image0, location) : BACKGROUND;\nvec4 pix1 = all(lessThan(location, size1)) ? pixelAt(image1, location) : BACKGROUND;\nvec4 pix = clamp(alpha * pix0 + beta * pix1 + vec4(gamma), 0.0f, 1.0f);\ncolor = vec4(pix.rgb, 1.0f);\n}';
                }
              ),
              /***/
              1202: (
                /***/
                (module2) => {
                  module2.exports = '@include "subpixel.glsl"\nuniform sampler2D image;\nvoid main()\n{\nvec2 imageSize = vec2(textureSize(image, 0));\n#if !defined(INTERPOLATION_METHOD)\n#error Must define INTERPOLATION_METHOD\n#elif INTERPOLATION_METHOD == 0\nvec2 pos = texCoord * imageSize;\ncolor = textureLod(image, (round(pos) + vec2(0.5f)) / imageSize, 0.0f);\n#elif INTERPOLATION_METHOD == 1\ncolor = subpixelAtBI(image, texCoord * imageSize);\n#else\n#error Invalid INTERPOLATION_METHOD\n#endif\n}';
                }
              ),
              /***/
              7971: (
                /***/
                (module2) => {
                  module2.exports = '@include "subpixel.glsl"\nuniform sampler2D image;\nuniform mat3 inverseHomography;\nconst vec4 emptyColor = vec4(0.0f, 0.0f, 0.0f, 1.0f);\nvec2 perspectiveWarp(mat3 homography, vec2 p)\n{\nvec3 q = homography * vec3(p, 1.0f);\nreturn q.xy / q.z;\n}\nvoid main()\n{\nivec2 location = threadLocation();\nivec2 size = outputSize();\nconst vec2 zero = vec2(0.0f);\nvec2 target = perspectiveWarp(inverseHomography, vec2(location));\nbool withinBounds = all(bvec4(greaterThanEqual(target, zero), lessThan(target, vec2(size))));\ncolor = withinBounds ? subpixelAtBI(image, target) : emptyColor;\n}';
                }
              ),
              /***/
              6122: (
                /***/
                (module2) => {
                  module2.exports = '@include "colors.glsl"\nuniform sampler2D dest, src;\nuniform int destComponents;\nuniform int srcComponentId;\nvoid main()\n{\nvec4 destPixel = threadPixel(dest);\nvec4 srcPixel = threadPixel(src);\nbvec4 flags = bvec4(\n(destComponents & PIXELCOMPONENT_RED) != 0,\n(destComponents & PIXELCOMPONENT_GREEN) != 0,\n(destComponents & PIXELCOMPONENT_BLUE) != 0,\n(destComponents & PIXELCOMPONENT_ALPHA) != 0\n);\ncolor = mix(destPixel, vec4(srcPixel[srcComponentId]), flags);\n}';
                }
              ),
              /***/
              371: (
                /***/
                (module2) => {
                  module2.exports = '#if !defined(TYPE)\n#error Undefined TYPE\n#elif TYPE == 1\n@include "keypoints.glsl"\n#define nullPixel() encodeNullKeypoint()\n#elif TYPE == 2\n@include "float16.glsl"\n#define nullPixel() encodeNullPairOfFloat16()\n#else\n#error Invalid TYPE\n#endif\nuniform sampler2D image;\nvoid main()\n{\nivec2 thread = threadLocation();\nivec2 imageSize = textureSize(image, 0);\nint rasterIndex = thread.y * outputSize().x + thread.x;\nbool isValidPixel = rasterIndex < imageSize.x * imageSize.y;\nivec2 pos = ivec2(rasterIndex % imageSize.x, rasterIndex / imageSize.x);\nvec4 nullpix = nullPixel();\ncolor = isValidPixel ? texelFetch(image, pos, 0) : nullpix;\n}';
                }
              ),
              /***/
              7307: (
                /***/
                (module2) => {
                  module2.exports = "uniform sampler2D image;\nvoid main()\n{\ncolor = threadPixel(image);\n}";
                }
              ),
              /***/
              8614: (
                /***/
                (module2) => {
                  module2.exports = '@include "colors.glsl"\nuniform sampler2D image;\nuniform int pixelComponents;\nuniform float value;\nvoid main()\n{\nvec4 pixel = threadPixel(image);\nbvec4 flags = bvec4(\n(pixelComponents & PIXELCOMPONENT_RED) != 0,\n(pixelComponents & PIXELCOMPONENT_GREEN) != 0,\n(pixelComponents & PIXELCOMPONENT_BLUE) != 0,\n(pixelComponents & PIXELCOMPONENT_ALPHA) != 0\n);\ncolor = mix(pixel, vec4(value), flags);\n}';
                }
              ),
              /***/
              6271: (
                /***/
                (module2) => {
                  module2.exports = "uniform float value;\nvoid main()\n{\ncolor = vec4(value);\n}";
                }
              ),
              /***/
              3016: (
                /***/
                (module2) => {
                  module2.exports = "void vsmain()\n{\ngl_Position *= vec4(1,-1,1,1);\n}";
                }
              ),
              /***/
              3630: (
                /***/
                (module2) => {
                  module2.exports = "uniform sampler2D image;\nuniform int iterationNumber;\nvoid main()\n{\nivec2 thread = threadLocation();\nivec2 last = outputSize() - ivec2(1);\nint jump = (1 << iterationNumber);\nint clusterLength = jump << 1;\nint clusterMask = clusterLength - 1;\nivec2 clusterPos = ivec2(thread >> (1 + iterationNumber)) << (1 + iterationNumber);\nivec2 next1 = clusterPos + ((thread - clusterPos + ivec2(jump, 0)) & clusterMask);\nivec2 next2 = clusterPos + ((thread - clusterPos + ivec2(0, jump)) & clusterMask);\nivec2 next3 = clusterPos + ((thread - clusterPos + ivec2(jump, jump)) & clusterMask);\nvec4 p0 = texelFetch(image, thread, 0);\nvec4 p1 = texelFetch(image, min(next1, last), 0);\nvec4 p2 = texelFetch(image, min(next2, last), 0);\nvec4 p3 = texelFetch(image, min(next3, last), 0);\nvec4 pmax = max(max(p0, p1), max(p2, p3));\nvec4 pmin = min(min(p0, p1), min(p2, p3));\ncolor = vec4(pmax.r, pmin.g, pmax.r - pmin.g, p0.a);\n}";
                }
              ),
              /***/
              8508: (
                /***/
                (module2) => {
                  module2.exports = '@include "pyramids.glsl"\n@include "float16.glsl"\nuniform sampler2D pyramid;\nuniform float lod;\n#define USE_VARYINGS 1\nin vec2 v_pix0, v_pix1, v_pix2,\nv_pix3, v_pix4, v_pix5,\nv_pix6, v_pix7, v_pix8;\nconst mat3 hkern = mat3(\n1.0f, 0.0f,-1.0f,\n2.0f, 0.0f,-2.0f,\n1.0f, 0.0f,-1.0f\n), vkern = mat3(\n1.0f, 2.0f, 1.0f,\n0.0f, 0.0f, 0.0f,\n-1.0f,-2.0f,-1.0f\n);\n#define PIX(x,y) pyrPixelAtOffset(pyramid, lod, pot, ivec2((x),(y))).g\n#define XIP(v) textureLod(pyramid, (v), lod).g\nvoid main()\n{\nconst vec3 ones = vec3(1.0f);\nfloat pot = exp2(lod);\nmat3 win = mat3(\n#if USE_VARYINGS\nXIP(v_pix0), XIP(v_pix1), XIP(v_pix2),\nXIP(v_pix3), XIP(v_pix4), XIP(v_pix5),\nXIP(v_pix6), XIP(v_pix7), XIP(v_pix8)\n#else\nPIX(-1,-1), PIX(0,-1), PIX(1,-1),\nPIX(-1,0), PIX(0,0), PIX(1,0),\nPIX(-1,1), PIX(0,1), PIX(1,1)\n#endif\n);\nmat3 dx = matrixCompMult(hkern, win);\nmat3 dy = matrixCompMult(vkern, win);\nvec2 df = vec2(\ndot(dx[0] + dx[1] + dx[2], ones),\ndot(dy[0] + dy[1] + dy[2], ones)\n);\ncolor = encodePairOfFloat16(df);\n}';
                }
              ),
              /***/
              8073: (
                /***/
                (module2) => {
                  module2.exports = "uniform mediump float lod;\nout vec2 v_pix0, v_pix1, v_pix2,\nv_pix3, v_pix4, v_pix5,\nv_pix6, v_pix7, v_pix8;\n#define PIX(x,y) (texCoord + ((pot) * vec2((x),(y))) / texSize)\nvoid vsmain()\n{\nfloat pot = exp2(lod);\nv_pix0 = PIX(-1,-1); v_pix1 = PIX(0,-1); v_pix2 = PIX(1,-1);\nv_pix3 = PIX(-1,0); v_pix4 = PIX(0,0); v_pix5 = PIX(1,0);\nv_pix6 = PIX(-1,1); v_pix7 = PIX(0,1); v_pix8 = PIX(1,1);\n}";
                }
              ),
              /***/
              3575: (
                /***/
                (module2) => {
                  module2.exports = `AGFzbQEAAAABiwETYAABfmADf39/AX9gAX8AYAN/f38AYAF9AX9gAX8Bf2ACf38Bf2AFf39/f38B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`;
                }
              )
              /******/
            };
            var __webpack_module_cache__ = {};
            function __webpack_require__(moduleId) {
              var cachedModule = __webpack_module_cache__[moduleId];
              if (cachedModule !== void 0) {
                return cachedModule.exports;
              }
              var module2 = __webpack_module_cache__[moduleId] = {
                /******/
                // no module.id needed
                /******/
                // no module.loaded needed
                /******/
                exports: {}
                /******/
              };
              __webpack_modules__[moduleId](module2, module2.exports, __webpack_require__);
              return module2.exports;
            }
            (() => {
              __webpack_require__.d = (exports2, definition) => {
                for (var key in definition) {
                  if (__webpack_require__.o(definition, key) && !__webpack_require__.o(exports2, key)) {
                    Object.defineProperty(exports2, key, { enumerable: true, get: definition[key] });
                  }
                }
              };
            })();
            (() => {
              __webpack_require__.o = (obj, prop) => Object.prototype.hasOwnProperty.call(obj, prop);
            })();
            (() => {
              __webpack_require__.r = (exports2) => {
                if (typeof Symbol !== "undefined" && Symbol.toStringTag) {
                  Object.defineProperty(exports2, Symbol.toStringTag, { value: "Module" });
                }
                Object.defineProperty(exports2, "__esModule", { value: true });
              };
            })();
            var __webpack_exports__ = {};
            (() => {
              "use strict";
              __webpack_require__.d(__webpack_exports__, {
                "default": () => (
                  /* binding */
                  Speedy29
                )
              });
              var speedy_gl = __webpack_require__(1001);
              var utils = __webpack_require__(9037);
              var settings = __webpack_require__(2199);
              var speedy_promise = __webpack_require__(9192);
              ;
              const callbacks2 = (
                /** @type {Function[]} */
                []
              );
              const args2 = (
                /** @type {any[][]} */
                []
              );
              const ASAP_KEY2 = "asap" + Math.random().toString(36).substr(1);
              window.addEventListener("message", (event) => {
                if (event.source !== window || event.data !== ASAP_KEY2) return;
                event.stopPropagation();
                if (callbacks2.length == 0) return;
                const fn = callbacks2.pop();
                const argArray = args2.pop();
                fn.apply(void 0, argArray);
              }, true);
              function asap2(fn, ...params) {
                callbacks2.unshift(fn);
                args2.unshift(params);
                window.postMessage(ASAP_KEY2, "*");
              }
              var utils_errors = __webpack_require__(8581);
              ;
              const DEFAULT_NUMBER_OF_BUFFERS = 2;
              const runOnNextFrame = navigator.userAgent.includes("Firefox") ? (fn, ...args3) => setTimeout(fn, 10, ...args3) : (
                // RAF produces a warning on Firefox
                (fn, ...args3) => requestAnimationFrame(() => fn.apply(void 0, args3))
              );
              class SpeedyTextureReader {
                /**
                 * Constructor
                 * @param {number} [numberOfBuffers]
                 */
                constructor(numberOfBuffers = DEFAULT_NUMBER_OF_BUFFERS) {
                  utils.A.assert(numberOfBuffers > 0);
                  this._initialized = false;
                  this._pixelBuffer = new Array(numberOfBuffers).fill(null).map(() => new Uint8Array(0));
                  this._pbo = new Array(numberOfBuffers).fill(null);
                  this._consumerIndex = 0;
                  this._producerIndex = numberOfBuffers - 1;
                  this._promise = Array.from({
                    length: numberOfBuffers
                  }, () => speedy_promise.i.resolve());
                  this._busy = new Array(numberOfBuffers).fill(false);
                  this._ready = new Array(numberOfBuffers).fill(true);
                }
                /**
                 * Initialize this object
                 * @param {SpeedyGPU} gpu
                 */
                init(gpu2) {
                  this._allocatePBOs(gpu2);
                  gpu2.subscribe(this._allocatePBOs, this, gpu2);
                  this._initialized = true;
                }
                /**
                 * Release resources
                 * @param {SpeedyGPU} gpu
                 * @returns {null}
                 */
                release(gpu2) {
                  gpu2.unsubscribe(this._allocatePBOs, this);
                  this._deallocatePBOs(gpu2);
                  this._initialized = false;
                  return null;
                }
                /**
                 * Read pixels from a texture, synchronously.
                 * You may optionally specify a (x,y,width,height) sub-rectangle.
                 * @param {SpeedyDrawableTexture} texture a texture with a FBO
                 * @param {number} [x]
                 * @param {number} [y] 
                 * @param {number} [width]
                 * @param {number} [height]
                 * @returns {Uint8Array} pixels in the RGBA format
                 */
                readPixelsSync(texture, x = 0, y = 0, width = texture.width, height = texture.height) {
                  utils.A.assert(this._initialized);
                  const gl = texture.gl;
                  const fbo = texture.glFbo;
                  width = Math.max(0, Math.min(width, texture.width));
                  height = Math.max(0, Math.min(height, texture.height));
                  x = Math.max(0, Math.min(x, texture.width - width));
                  y = Math.max(0, Math.min(y, texture.height - height));
                  const sizeofBuffer = width * height * 4;
                  this._reallocate(sizeofBuffer);
                  if (gl.isContextLost()) return this._pixelBuffer[0].subarray(0, sizeofBuffer);
                  gl.bindFramebuffer(gl.FRAMEBUFFER, fbo);
                  gl.readPixels(x, y, width, height, gl.RGBA, gl.UNSIGNED_BYTE, this._pixelBuffer[0]);
                  gl.bindFramebuffer(gl.FRAMEBUFFER, null);
                  return this._pixelBuffer[0].subarray(0, sizeofBuffer);
                }
                /**
                 * Read pixels from a texture, asynchronously, with PBOs.
                 * You may optionally specify a (x,y,width,height) sub-rectangle.
                 * @param {SpeedyDrawableTexture} texture a texture with a FBO
                 * @param {number} [x]
                 * @param {number} [y] 
                 * @param {number} [width]
                 * @param {number} [height]
                 * @param {boolean} [useBufferedDownloads] accelerate downloads by returning pixels from the texture of the previous call (useful for streaming)
                 * @returns {SpeedyPromise<Uint8Array>} resolves to an array of pixels in the RGBA format
                 */
                readPixelsAsync(texture, x = 0, y = 0, width = texture.width, height = texture.height, useBufferedDownloads = false) {
                  utils.A.assert(this._initialized);
                  const gl = texture.gl;
                  const fbo = texture.glFbo;
                  width = Math.max(0, Math.min(width, texture.width));
                  height = Math.max(0, Math.min(height, texture.height));
                  x = Math.max(0, Math.min(x, texture.width - width));
                  y = Math.max(0, Math.min(y, texture.height - height));
                  const sizeofBuffer = width * height * 4;
                  this._reallocate(sizeofBuffer);
                  if (gl.isContextLost()) return speedy_promise.i.resolve(this._pixelBuffer[0].subarray(0, sizeofBuffer));
                  if (!useBufferedDownloads) {
                    const pixelBuffer = this._pixelBuffer[0].subarray(0, sizeofBuffer);
                    return SpeedyTextureReader._readPixelsViaPBO(gl, this._pbo[0], pixelBuffer, fbo, x, y, width, height).then(() => pixelBuffer);
                  }
                  const numberOfBuffers = this._pixelBuffer.length;
                  const producerIndex = this._producerIndex;
                  if (!this._busy[producerIndex]) {
                    const pbo = this._pbo[producerIndex];
                    const pixelBuffer = this._pixelBuffer[producerIndex].subarray(0, sizeofBuffer);
                    this._producerIndex = (producerIndex + 1) % numberOfBuffers;
                    this._ready[producerIndex] = false;
                    this._busy[producerIndex] = true;
                    this._promise[producerIndex] = SpeedyTextureReader._readPixelsViaPBO(gl, pbo, pixelBuffer, fbo, x, y, width, height).then(() => {
                      this._busy[producerIndex] = false;
                      this._ready[producerIndex] = true;
                    });
                  } else ;
                  const consumerIndex = this._consumerIndex;
                  this._consumerIndex = (consumerIndex + 1) % numberOfBuffers;
                  if (!this._ready[consumerIndex]) {
                    return this._promise[consumerIndex].then(() => {
                      this._ready[consumerIndex] = false;
                      return this._pixelBuffer[consumerIndex];
                    });
                  }
                  this._ready[consumerIndex] = false;
                  return speedy_promise.i.resolve(this._pixelBuffer[consumerIndex]);
                }
                /**
                 * Reallocate the pixel buffers, so that they can hold the required number of bytes
                 * If the pixel buffers already have the required capacity, then nothing is done
                 * @param {number} size in bytes
                 */
                _reallocate(size) {
                  if (size <= this._pixelBuffer[0].byteLength) return;
                  for (let i = 0; i < this._pixelBuffer.length; i++) {
                    const newBuffer = new Uint8Array(size);
                    this._pixelBuffer[i] = newBuffer;
                  }
                }
                /**
                 * Allocate PBOs
                 * @param {SpeedyGPU} gpu
                 */
                _allocatePBOs(gpu2) {
                  const gl = gpu2.gl;
                  for (let i = 0; i < this._pbo.length; i++) this._pbo[i] = gl.createBuffer();
                }
                /**
                 * Deallocate PBOs
                 * @param {SpeedyGPU} gpu
                 */
                _deallocatePBOs(gpu2) {
                  const gl = gpu2.gl;
                  for (let i = this._pbo.length - 1; i >= 0; i--) {
                    gl.deleteBuffer(this._pbo[i]);
                    this._pbo[i] = null;
                  }
                }
                /**
                 * Read pixels to a Uint8Array, asynchronously, using a Pixel Buffer Object (PBO)
                 * It's assumed that the target texture is in the RGBA8 format
                 * @param {WebGL2RenderingContext} gl
                 * @param {WebGLBuffer} pbo
                 * @param {Uint8Array} outputBuffer with size >= width * height * 4
                 * @param {WebGLFramebuffer} fbo
                 * @param {GLint} x
                 * @param {GLint} y
                 * @param {GLsizei} width
                 * @param {GLsizei} height
                 * @returns {SpeedyPromise<void>}
                 */
                static _readPixelsViaPBO(gl, pbo, outputBuffer, fbo, x, y, width, height) {
                  const size = width * height * 4;
                  utils.A.assert(outputBuffer.byteLength >= size, `Invalid buffer size`);
                  gl.bindBuffer(gl.PIXEL_PACK_BUFFER, pbo);
                  gl.bufferData(gl.PIXEL_PACK_BUFFER, size, gl.DYNAMIC_READ);
                  gl.bindFramebuffer(gl.FRAMEBUFFER, fbo);
                  gl.readPixels(x, y, width, height, gl.RGBA, gl.UNSIGNED_BYTE, 0);
                  gl.bindFramebuffer(gl.FRAMEBUFFER, null);
                  gl.bindBuffer(gl.PIXEL_PACK_BUFFER, null);
                  const sync = gl.fenceSync(gl.SYNC_GPU_COMMANDS_COMPLETE, 0);
                  gl.flush();
                  return new speedy_promise.i((resolve, reject) => {
                    if (settings.w.gpuPollingMode != "asap") runOnNextFrame(SpeedyTextureReader._clientWaitAsync, gl, sync, 0, resolve, reject);
                    else asap2(SpeedyTextureReader._clientWaitAsync, gl, sync, 0, resolve, reject);
                  }).then(() => {
                    gl.bindBuffer(gl.PIXEL_PACK_BUFFER, pbo);
                    gl.getBufferSubData(gl.PIXEL_PACK_BUFFER, 0, outputBuffer);
                    gl.bindBuffer(gl.PIXEL_PACK_BUFFER, null);
                  }).catch((err) => {
                    throw new utils_errors.Er(`Can't getBufferSubDataAsync(): error in clientWaitAsync()`, err);
                  }).finally(() => {
                    gl.deleteSync(sync);
                  });
                }
                /**
                 * Waits for a sync object to become signaled
                 * @param {WebGL2RenderingContext} gl
                 * @param {WebGLSync} sync
                 * @param {GLbitfield} flags may be gl.SYNC_FLUSH_COMMANDS_BIT or 0
                 * @param {Function} resolve
                 * @param {Function} reject
                 * @param {number} [pollInterval] in milliseconds
                 * @param {number} [remainingAttempts] for timeout
                 */
                static _clientWaitAsync(gl, sync, flags, resolve, reject, pollInterval = 10, remainingAttempts = 1e3) {
                  (function poll() {
                    const status = gl.clientWaitSync(sync, flags, 0);
                    if (remainingAttempts-- <= 0) {
                      reject(new utils_errors.MU(`GPU polling timeout`, utils_errors.wB.from(gl)));
                    } else if (status === gl.CONDITION_SATISFIED || status === gl.ALREADY_SIGNALED) {
                      resolve();
                    } else {
                      if (settings.w.gpuPollingMode != "asap") requestAnimationFrame(poll);
                      else asap2(poll);
                    }
                  })();
                }
              }
              var globals = __webpack_require__(3816);
              ;
              class SpeedyTexture {
                /**
                 * Constructor
                 * @param {WebGL2RenderingContext} gl
                 * @param {number} width texture width in pixels
                 * @param {number} height texture height in pixels
                 * @param {number} [format]
                 * @param {number} [internalFormat]
                 * @param {number} [dataType]
                 * @param {number} [filter]
                 * @param {number} [wrap]
                 */
                constructor(gl, width, height, format = gl.RGBA, internalFormat = gl.RGBA8, dataType = gl.UNSIGNED_BYTE, filter = gl.NEAREST, wrap = gl.MIRRORED_REPEAT) {
                  this._gl = gl;
                  this._width = Math.max(1, width | 0);
                  this._height = Math.max(1, height | 0);
                  this._hasMipmaps = false;
                  this._format = format;
                  this._internalFormat = internalFormat;
                  this._dataType = dataType;
                  this._filter = filter;
                  this._wrap = wrap;
                  this._glTexture = SpeedyTexture._createTexture(this._gl, this._width, this._height, this._format, this._internalFormat, this._dataType, this._filter, this._wrap);
                }
                /**
                 * Releases the texture
                 * @returns {null}
                 */
                release() {
                  const gl = this._gl;
                  if (this._glTexture == null) throw new utils_errors.Er(`The SpeedyTexture has already been released`);
                  this.discardMipmaps();
                  gl.deleteTexture(this._glTexture);
                  this._glTexture = null;
                  this._width = this._height = 0;
                  return null;
                }
                /**
                 * Upload pixel data to the texture. The texture will be resized if needed.
                 * @param {TexImageSource} data
                 * @param {number} [width] in pixels
                 * @param {number} [height] in pixels
                 * @return {SpeedyTexture} this
                 */
                upload(data, width = this._width, height = this._height) {
                  const gl = this._gl;
                  if (data instanceof HTMLVideoElement) {
                    if (data.readyState < 2) {
                      return this;
                    }
                  }
                  utils.A.assert(width > 0 && height > 0);
                  this.discardMipmaps();
                  this._width = width;
                  this._height = height;
                  this._internalFormat = gl.RGBA8;
                  this._format = gl.RGBA;
                  this._dataType = gl.UNSIGNED_BYTE;
                  SpeedyTexture._upload(gl, this._glTexture, this._width, this._height, data, 0, this._format, this._internalFormat, this._dataType);
                  return this;
                }
                /**
                 * Clear the texture
                 * @returns {this}
                 */
                clear() {
                  const gl = this._gl;
                  if (gl.isContextLost()) return this;
                  gl.bindTexture(gl.TEXTURE_2D, this._glTexture);
                  gl.texImage2D(gl.TEXTURE_2D, 0, this._internalFormat, this._width, this._height, 0, this._format, this._dataType, null);
                  gl.bindTexture(gl.TEXTURE_2D, null);
                  this.discardMipmaps();
                  return this;
                }
                /**
                 * Resize this texture. Its content will be lost!
                 * @param {number} width new width, in pixels
                 * @param {number} height new height, in pixels
                 * @returns {this}
                 */
                resize(width, height) {
                  const gl = this._gl;
                  if (this._width === width && this._height === height) return this;
                  width |= 0;
                  height |= 0;
                  if (width > globals.MAX_TEXTURE_LENGTH || height > globals.MAX_TEXTURE_LENGTH) throw new utils_errors.EM(`Maximum texture size exceeded. Using ${width} x ${height}, expected up to ${globals.MAX_TEXTURE_LENGTH} x ${globals.MAX_TEXTURE_LENGTH}.`);
                  else if (width < 1 || height < 1) throw new utils_errors.qw(`Invalid texture size: ${width} x ${height}`);
                  if (gl.isContextLost()) return this;
                  this._width = width;
                  this._height = height;
                  gl.bindTexture(gl.TEXTURE_2D, this._glTexture);
                  gl.texImage2D(gl.TEXTURE_2D, 0, this._internalFormat, this._width, this._height, 0, this._format, this._dataType, null);
                  gl.bindTexture(gl.TEXTURE_2D, null);
                  this.discardMipmaps();
                  return this;
                }
                /**
                 * Generate mipmap
                 * @param {SpeedyDrawableTexture[]} [mipmap] custom texture for each mip level
                 * @returns {SpeedyTexture} this
                 */
                generateMipmaps(mipmap = []) {
                  const gl = this._gl;
                  if (this._hasMipmaps) return this;
                  gl.bindTexture(gl.TEXTURE_2D, this._glTexture);
                  gl.texParameteri(gl.TEXTURE_2D, gl.TEXTURE_MIN_FILTER, gl.NEAREST_MIPMAP_LINEAR);
                  gl.generateMipmap(gl.TEXTURE_2D);
                  gl.bindTexture(gl.TEXTURE_2D, null);
                  if (mipmap.length > 0) {
                    const width = this.width, height = this.height;
                    const numMipmaps = 1 + Math.floor(Math.log2(Math.max(width, height)));
                    utils.A.assert(mipmap.length <= numMipmaps);
                    for (let level = 1; level < mipmap.length; level++) {
                      const w = Math.max(1, width >>> level);
                      const h = Math.max(1, height >>> level);
                      utils.A.assert(mipmap[level].width === w && mipmap[level].height === h);
                      mipmap[level].copyTo(this, level);
                    }
                  }
                  this._hasMipmaps = true;
                  return this;
                }
                /**
                 * Invalidates previously generated mipmap, if any
                 */
                discardMipmaps() {
                  const gl = this._gl;
                  if (!this._hasMipmaps) return;
                  gl.bindTexture(gl.TEXTURE_2D, this._glTexture);
                  gl.texParameteri(gl.TEXTURE_2D, gl.TEXTURE_MIN_FILTER, this._filter);
                  gl.bindTexture(gl.TEXTURE_2D, null);
                  this._hasMipmaps = false;
                }
                /**
                 * Does this texture have a mipmap?
                 * @returns {boolean}
                 */
                hasMipmaps() {
                  return this._hasMipmaps;
                }
                /**
                 * Has this texture been released?
                 * @returns {boolean}
                 */
                isReleased() {
                  return this._glTexture == null;
                }
                /**
                 * The internal WebGLTexture
                 * @returns {WebGLTexture}
                 */
                get glTexture() {
                  return this._glTexture;
                }
                /**
                 * The width of the texture, in pixels
                 * @returns {number}
                 */
                get width() {
                  return this._width;
                }
                /**
                 * The height of the texture, in pixels
                 * @returns {number}
                 */
                get height() {
                  return this._height;
                }
                /**
                 * The WebGL Context
                 * @returns {WebGL2RenderingContext}
                 */
                get gl() {
                  return this._gl;
                }
                /**
                 * Create a WebGL texture
                 * @param {WebGL2RenderingContext} gl
                 * @param {number} width in pixels
                 * @param {number} height in pixels
                 * @param {number} format usually gl.RGBA
                 * @param {number} internalFormat usually gl.RGBA8
                 * @param {number} dataType usually gl.UNSIGNED_BYTE
                 * @param {number} filter usually gl.NEAREST or gl.LINEAR
                 * @param {number} wrap gl.REPEAT, gl.MIRRORED_REPEAT or gl.CLAMP_TO_EDGE
                 * @returns {WebGLTexture}
                 */
                static _createTexture(gl, width, height, format, internalFormat, dataType, filter, wrap) {
                  utils.A.assert(width > 0 && height > 0);
                  const texture = gl.createTexture();
                  gl.bindTexture(gl.TEXTURE_2D, texture);
                  gl.texParameteri(gl.TEXTURE_2D, gl.TEXTURE_MIN_FILTER, filter);
                  gl.texParameteri(gl.TEXTURE_2D, gl.TEXTURE_MAG_FILTER, filter);
                  gl.texParameteri(gl.TEXTURE_2D, gl.TEXTURE_WRAP_S, wrap);
                  gl.texParameteri(gl.TEXTURE_2D, gl.TEXTURE_WRAP_T, wrap);
                  gl.texImage2D(gl.TEXTURE_2D, 0, internalFormat, width, height, 0, format, dataType, null);
                  gl.bindTexture(gl.TEXTURE_2D, null);
                  return texture;
                }
                /**
                 * Upload pixel data to a WebGL texture
                 * @param {WebGL2RenderingContext} gl
                 * @param {WebGLTexture} texture
                 * @param {GLsizei} width texture width
                 * @param {GLsizei} height texture height
                 * @param {TexImageSource} pixels
                 * @param {GLint} lod mipmap level-of-detail
                 * @param {number} format
                 * @param {number} internalFormat
                 * @param {number} dataType
                 * @returns {WebGLTexture} texture
                 */
                static _upload(gl, texture, width, height, pixels, lod, format, internalFormat, dataType) {
                  gl.bindTexture(gl.TEXTURE_2D, texture);
                  gl.texImage2D(
                    gl.TEXTURE_2D,
                    // target
                    lod,
                    // mip level
                    internalFormat,
                    // internal format
                    width,
                    // texture width
                    height,
                    // texture height
                    0,
                    // border
                    format,
                    // source format
                    dataType,
                    // source type
                    pixels
                  );
                  gl.bindTexture(gl.TEXTURE_2D, null);
                  return texture;
                }
              }
              class SpeedyDrawableTexture extends SpeedyTexture {
                /**
                 * Constructor
                 * @param {WebGL2RenderingContext} gl
                 * @param {number} width texture width in pixels
                 * @param {number} height texture height in pixels
                 * @param {number} [format]
                 * @param {number} [internalFormat]
                 * @param {number} [dataType]
                 * @param {number} [filter]
                 * @param {number} [wrap]
                 */
                constructor(gl, width, height, format = void 0, internalFormat = void 0, dataType = void 0, filter = void 0, wrap = void 0) {
                  super(gl, width, height, format, internalFormat, dataType, filter, wrap);
                  this._glFbo = SpeedyDrawableTexture._createFramebuffer(gl, this._glTexture);
                }
                /**
                 * Releases the texture
                 * @returns {null}
                 */
                release() {
                  const gl = this._gl;
                  if (this._glFbo == null) throw new utils_errors.Er(`The SpeedyDrawableTexture has already been released`);
                  gl.deleteFramebuffer(this._glFbo);
                  this._glFbo = null;
                  return super.release();
                }
                /**
                 * The internal WebGLFramebuffer
                 * @returns {WebGLFramebuffer}
                 */
                get glFbo() {
                  return this._glFbo;
                }
                /**
                 * Copy this texture into another
                 * (you may have to discard the mipmaps after calling this function)
                 * @param {SpeedyTexture} texture target texture
                 * @param {number} [lod] level-of-detail of the target texture
                 */
                copyTo(texture, lod = 0) {
                  const gl = this._gl;
                  if (gl.isContextLost()) return;
                  const pot = 1 << (lod |= 0);
                  const expectedWidth = Math.max(1, Math.floor(texture.width / pot));
                  const expectedHeight = Math.max(1, Math.floor(texture.height / pot));
                  utils.A.assert(this._width === expectedWidth && this._height === expectedHeight);
                  SpeedyDrawableTexture._copyToTexture(gl, this._glFbo, texture.glTexture, 0, 0, this._width, this._height, lod);
                }
                /*
                 * Resize this texture
                 * @param {number} width new width, in pixels
                 * @param {number} height new height, in pixels
                 * @param {boolean} [preserveContent] should we preserve the content of the texture? EXPENSIVE!
                 * @returns {this}
                 */
                /*resize(width, height, preserveContent = false)
                {
                    const gl = this._gl;
                     // no need to preserve the content?
                    if(!preserveContent)
                        return super.resize(width, height);
                     // no need to resize?
                    if(this._width === width && this._height === height)
                        return this;
                     // validate size
                    width |= 0; height |= 0;
                    Utils.assert(width > 0 && height > 0);
                     // context loss?
                    if(gl.isContextLost())
                        return this;
                     // allocate new texture
                    const newTexture = SpeedyTexture._createTexture(gl, width, height);
                     // initialize the new texture with zeros to avoid a
                    // warning when calling copyTexSubImage2D() on Firefox
                    // this may not be very efficient?
                    SpeedyTexture._upload(gl, newTexture, width, height, zeros(width * height * 4)); // RGBA: 4 bytes per pixel
                     // copy the old texture to the new one
                    const oldWidth = this._width, oldHeight = this._height;
                    SpeedyDrawableTexture._copyToTexture(gl, this._glFbo, newTexture, 0, 0, Math.min(width, oldWidth), Math.min(height, oldHeight), 0);
                     // bind FBO
                    gl.bindFramebuffer(gl.FRAMEBUFFER, this._glFbo);
                     // invalidate old data (is this needed?)
                    gl.invalidateFramebuffer(gl.FRAMEBUFFER, [gl.COLOR_ATTACHMENT0]);
                     // attach the new texture to the existing framebuffer
                    gl.framebufferTexture2D(gl.FRAMEBUFFER,         // target
                                            gl.COLOR_ATTACHMENT0,   // color buffer
                                            gl.TEXTURE_2D,          // tex target
                                            newTexture,             // texture
                                            0);                     // mipmap level
                     // unbind FBO
                    gl.bindFramebuffer(gl.FRAMEBUFFER, null);
                     // release the old texture and replace it
                    gl.deleteTexture(this._glTexture);
                    this._glTexture = newTexture;
                     // update dimensions & discard mipmaps
                    this.discardMipmaps();
                    this._width = width;
                    this._height = height;
                     // done!
                    return this;
                }
                */
                /**
                 * Clear the texture
                 * @returns {this}
                 */
                clear() {
                  return this.clearToColor(0, 0, 0, 0);
                }
                /**
                 * Clear the texture to a color
                 * @param {number} r red component, a value in [0,1]
                 * @param {number} g green component, a value in [0,1]
                 * @param {number} b blue component, a value in [0,1]
                 * @param {number} a alpha component, a value in [0,1]
                 * @returns {this}
                 */
                clearToColor(r, g, b, a) {
                  const gl = this._gl;
                  if (gl.isContextLost()) return this;
                  r = Math.max(0, Math.min(+r, 1));
                  g = Math.max(0, Math.min(+g, 1));
                  b = Math.max(0, Math.min(+b, 1));
                  a = Math.max(0, Math.min(+a, 1));
                  this.discardMipmaps();
                  gl.bindFramebuffer(gl.FRAMEBUFFER, this._glFbo);
                  gl.viewport(0, 0, this._width, this._height);
                  gl.clearColor(r, g, b, a);
                  gl.clear(gl.COLOR_BUFFER_BIT);
                  gl.bindFramebuffer(gl.FRAMEBUFFER, null);
                  return this;
                }
                /**
                 * Inspect the pixels of the texture for debugging purposes
                 * @param {SpeedyGPU} gpu
                 * @param {SpeedyTextureReader} [textureReader] optional texture reader
                 * @returns {Uint8Array}
                 */
                inspect(gpu2, textureReader) {
                  if (textureReader === void 0) {
                    textureReader = new SpeedyTextureReader();
                    textureReader.init(gpu2);
                    const pixels = textureReader.readPixelsSync(this);
                    textureReader.release(gpu2);
                    return new Uint8Array(pixels);
                  } else {
                    const pixels = textureReader.readPixelsSync(this);
                    return new Uint8Array(pixels);
                  }
                }
                /**
                 * Inspect the pixels of the texture as unsigned 32-bit integers
                 * @param {SpeedyGPU} gpu
                 * @param {SpeedyTextureReader} [textureReader] optional texture reader
                 * @returns {Uint32Array}
                 */
                inspect32(gpu2, textureReader) {
                  utils.A.assert(globals.LITTLE_ENDIAN);
                  return new Uint32Array(this.inspect(gpu2, textureReader).buffer);
                }
                /**
                 * Create a FBO associated with an existing texture
                 * @param {WebGL2RenderingContext} gl
                 * @param {WebGLTexture} texture
                 * @returns {WebGLFramebuffer}
                 */
                static _createFramebuffer(gl, texture) {
                  const fbo = gl.createFramebuffer();
                  gl.bindFramebuffer(gl.FRAMEBUFFER, fbo);
                  gl.framebufferTexture2D(
                    gl.FRAMEBUFFER,
                    // target
                    gl.COLOR_ATTACHMENT0,
                    // color buffer
                    gl.TEXTURE_2D,
                    // tex target
                    texture,
                    // texture
                    0
                  );
                  const status = gl.checkFramebufferStatus(gl.FRAMEBUFFER);
                  if (status != gl.FRAMEBUFFER_COMPLETE) {
                    const error = (() => ["FRAMEBUFFER_UNSUPPORTED", "FRAMEBUFFER_INCOMPLETE_ATTACHMENT", "FRAMEBUFFER_INCOMPLETE_DIMENSIONS", "FRAMEBUFFER_INCOMPLETE_MISSING_ATTACHMENT", "FRAMEBUFFER_INCOMPLETE_MULTISAMPLE"].filter((err) => gl[err] === status)[0] || "unknown error")();
                    throw new utils_errors.wB(`Can't create framebuffer: ${error} (${status})`);
                  }
                  gl.bindFramebuffer(gl.FRAMEBUFFER, null);
                  return fbo;
                }
                /**
                 * Copy data from a framebuffer to a texture
                 * @param {WebGL2RenderingContext} gl
                 * @param {WebGLFramebuffer} fbo we'll read the data from this
                 * @param {WebGLTexture} texture destination texture
                 * @param {GLint} x xpos (where to start copying)
                 * @param {GLint} y ypos (where to start copying)
                 * @param {GLsizei} width width of the texture
                 * @param {GLsizei} height height of the texture
                 * @param {GLint} [lod] mipmap level-of-detail
                 * @returns {WebGLTexture} texture
                 */
                static _copyToTexture(gl, fbo, texture, x, y, width, height, lod = 0) {
                  gl.bindTexture(gl.TEXTURE_2D, texture);
                  gl.bindFramebuffer(gl.FRAMEBUFFER, fbo);
                  gl.copyTexSubImage2D(
                    gl.TEXTURE_2D,
                    // target
                    lod,
                    // mipmap level
                    0,
                    // xoffset
                    0,
                    // yoffset
                    x,
                    // xpos (where to start copying)
                    y,
                    // ypos (where to start copying)
                    width,
                    // width of the texture
                    height
                    // height of the texture
                  );
                  gl.bindFramebuffer(gl.FRAMEBUFFER, null);
                  gl.bindTexture(gl.TEXTURE_2D, null);
                  return texture;
                }
              }
              var shader_declaration = __webpack_require__(9420);
              ;
              const UNIFORM_SETTERS = Object.freeze({
                "sampler2D": "uniform1i",
                "isampler2D": "uniform1i",
                "usampler2D": "uniform1i",
                "float": "uniform1f",
                "int": "uniform1i",
                "uint": "uniform1ui",
                "bool": "uniform1i",
                "vec2": "uniform2f",
                "vec3": "uniform3f",
                "vec4": "uniform4f",
                "ivec2": "uniform2i",
                "ivec3": "uniform3i",
                "ivec4": "uniform4i",
                "uvec2": "uniform2ui",
                "uvec3": "uniform3ui",
                "uvec4": "uniform4ui",
                "bvec2": "uniform2i",
                "bvec3": "uniform3i",
                "bvec4": "uniform4i",
                "mat2": "uniformMatrix2fv",
                "mat3": "uniformMatrix3fv",
                "mat4": "uniformMatrix4fv"
              });
              class SpeedyProgram extends Function {
                /**
                 * Creates a new SpeedyProgram
                 * @param {WebGL2RenderingContext} gl WebGL context
                 * @param {ShaderDeclaration} shaderdecl Shader declaration
                 * @param {SpeedyProgramOptions} [options] user options
                 */
                constructor(gl, shaderdecl, options = {}) {
                  super("...args", "return this._self._call(...args)");
                  this._self = this.bind(this);
                  this._self._init(gl, shaderdecl, options);
                  return this._self;
                }
                /**
                 * Initialize the SpeedyProgram
                 * @param {WebGL2RenderingContext} gl WebGL context
                 * @param {ShaderDeclaration} shaderdecl Shader declaration
                 * @param {SpeedyProgramOptions} options user options
                 */
                _init(gl, shaderdecl, options) {
                  if (gl.isContextLost()) throw new utils_errors.Er(`Can't initialize SpeedyProgram: lost context`);
                  options = Object.assign({
                    // default options
                    renderToTexture: true,
                    pingpong: false
                  }, options);
                  this._gl = gl;
                  this._program = SpeedyProgram._compile(gl, shaderdecl.vertexSource, shaderdecl.fragmentSource);
                  this._geometry = new ProgramGeometry(gl, {
                    position: shaderdecl.locationOfAttributes.position,
                    texCoord: shaderdecl.locationOfAttributes.texCoord
                  });
                  this._argnames = shaderdecl.arguments;
                  this._argIsArray = new Array(this._argnames.length).fill(false);
                  this._ubo = null;
                  this._renderToTexture = Boolean(options.renderToTexture);
                  this._width = 1;
                  this._height = 1;
                  this._size = [1, 1];
                  this._texture = new Array(options.pingpong ? 2 : 1).fill(null);
                  this._textureIndex = 0;
                  this._uniform = /* @__PURE__ */ new Map();
                  this._shaderdecl = shaderdecl;
                  gl.useProgram(this._program);
                  for (const name of shaderdecl.uniforms) {
                    const type = shaderdecl.uniformType(name);
                    const location = gl.getUniformLocation(this._program, name);
                    this._uniform.set(name, new UniformVariable(type, location));
                  }
                  for (let j = 0; j < this._argnames.length; j++) {
                    const argname = this._argnames[j];
                    if (!this._uniform.has(argname)) {
                      this._argIsArray[j] = this._uniform.has(indexedVariable(argname, 0));
                      if (!this._argIsArray[j]) throw new utils_errors.Er(`Expected uniform "${argname}", as declared in the argument list`);
                    }
                  }
                }
                /**
                 * Run the SpeedyProgram
                 * @param  {...SpeedyProgramUniformValue} args
                 * @returns {SpeedyDrawableTexture}
                 */
                _call(...args3) {
                  const gl = this._gl;
                  const argnames = this._argnames;
                  const texture = this._texture[this._textureIndex];
                  if (args3.length != argnames.length) throw new utils_errors.qw(`Can't run shader: incorrect number of arguments (expected ${argnames.length}, got ${args3.length})`);
                  for (let j = args3.length - 1; j >= 0; j--) {
                    if (args3[j] === texture) throw new utils_errors.EM(`Can't run shader: don't use its output texture as an input to itself. Consider using pingpong rendering!`);
                  }
                  if (gl.isContextLost()) return texture;
                  gl.useProgram(this._program);
                  gl.bindVertexArray(this._geometry.vao);
                  const fbo = this._renderToTexture ? texture.glFbo : null;
                  const texSize = this._uniform.get("texSize");
                  this._size[0] = this._width;
                  this._size[1] = this._height;
                  texSize.setValue(gl, this._size);
                  for (let i = 0, texNo = 0; i < args3.length; i++) {
                    const argname = argnames[i];
                    if (!this._argIsArray[i]) {
                      const uniform = this._uniform.get(argname);
                      texNo = uniform.setValue(gl, args3[i], texNo);
                    } else {
                      const array = args3[i];
                      if (Array.isArray(array)) {
                        if (this._uniform.has(indexedVariable(argname, array.length))) throw new utils_errors.qw(`Can't run shader: too few elements in the "${argname}" array`);
                        for (let j = 0, uniform = void 0; (uniform = this._uniform.get(indexedVariable(argname, j))) !== void 0; j++) texNo = uniform.setValue(gl, array[j], texNo);
                      } else throw new utils_errors.qw(`Can't run shader: expected an array for "${argname}"`);
                    }
                  }
                  if (this._ubo !== null) this._ubo.update();
                  gl.bindFramebuffer(gl.FRAMEBUFFER, fbo);
                  gl.viewport(0, 0, this._width, this._height);
                  gl.drawArrays(gl.TRIANGLES, 0, 6);
                  gl.bindFramebuffer(gl.FRAMEBUFFER, null);
                  gl.bindVertexArray(null);
                  if (texture != null) texture.discardMipmaps();
                  this._pingpong();
                  return texture;
                }
                /**
                 * Set the output texture(s) and its (their) shape(s)
                 * @param {number} width new width, in pixels
                 * @param {number} height new height, in pixels
                 * @param  {...SpeedyDrawableTexture|null} texture output texture(s)
                 * @returns {SpeedyProgram} this
                 */
                outputs(width, height, ...texture) {
                  this._setOutputTexture(...texture);
                  this._setOutputSize(width, height);
                  return this;
                }
                /**
                 * Set the size of the output
                 * @param {number} width new width, in pixels
                 * @param {number} height new height, in pixels
                 * @returns {SpeedyProgram} this
                 */
                _setOutputSize(width, height) {
                  utils.A.assert(width > 0 && height > 0);
                  this._width = width | 0;
                  this._height = height | 0;
                  for (let i = 0; i < this._texture.length; i++) {
                    if (this._texture[i] != null) this._texture[i].resize(this._width, this._height);
                  }
                  return this;
                }
                /**
                 * Use the provided texture(s) as output
                 * @param {...SpeedyDrawableTexture} texture set to null to use the internal texture(s)
                 * @returns {SpeedyProgram} this
                 */
                _setOutputTexture(...texture) {
                  utils.A.assert(texture.length === this._texture.length, `Incorrect number of textures (expected ${this._texture.length})`);
                  for (let i = 0; i < this._texture.length; i++) this._texture[i] = texture[i];
                  this._textureIndex = 0;
                  return this;
                }
                /**
                 * Clear the internal textures
                 * @returns {SpeedyDrawableTexture}
                 */
                clear() {
                  const texture = this._texture[this._textureIndex];
                  for (let i = 0; i < this._texture.length; i++) this._texture[i].clear();
                  this._pingpong();
                  return texture;
                }
                /**
                 * Set data using a Uniform Buffer Object
                 * @param {string} blockName uniform block name
                 * @param {ArrayBufferView} data
                 * @returns {SpeedyProgram} this
                 */
                setUBO(blockName, data) {
                  if (this._ubo === null) this._ubo = new UBOHelper(this._gl, this._program);
                  this._ubo.set(blockName, data);
                  return this;
                }
                /**
                 * Release the resources associated with this SpeedyProgram
                 * @returns {null}
                 */
                release() {
                  const gl = this._gl;
                  if (this._ubo != null) this._ubo = this._ubo.release();
                  this._texture.fill(null);
                  this._geometry = this._geometry.release();
                  gl.deleteProgram(this._program);
                  this._program = null;
                  return null;
                }
                /**
                 * A constant #defined in the shader declaration
                 * @param {string} name
                 * @returns {number}
                 */
                definedConstant(name) {
                  return this._shaderdecl.definedConstant(name);
                }
                /**
                 * Helper method for pingpong rendering: alternates
                 * the texture index from 0 to 1 and vice-versa
                 */
                _pingpong() {
                  if (this._texture.length > 1) this._textureIndex = 1 - this._textureIndex;
                }
                /**
                 * Compile and link GLSL shaders
                 * @param {WebGL2RenderingContext} gl
                 * @param {string} vertexShaderSource GLSL code of the vertex shader
                 * @param {string} fragmentShaderSource GLSL code of the fragment shader
                 * @returns {WebGLProgram}
                 */
                static _compile(gl, vertexShaderSource, fragmentShaderSource) {
                  const program = gl.createProgram();
                  const vertexShader = gl.createShader(gl.VERTEX_SHADER);
                  const fragmentShader = gl.createShader(gl.FRAGMENT_SHADER);
                  gl.shaderSource(vertexShader, vertexShaderSource);
                  gl.compileShader(vertexShader);
                  gl.attachShader(program, vertexShader);
                  gl.shaderSource(fragmentShader, fragmentShaderSource);
                  gl.compileShader(fragmentShader);
                  gl.attachShader(program, fragmentShader);
                  gl.linkProgram(program);
                  gl.validateProgram(program);
                  if (gl.getProgramParameter(program, gl.LINK_STATUS)) return program;
                  const errors = [gl.getShaderInfoLog(fragmentShader), gl.getShaderInfoLog(vertexShader), gl.getProgramInfoLog(program)];
                  gl.deleteProgram(program);
                  gl.deleteShader(fragmentShader);
                  gl.deleteShader(vertexShader);
                  const spaces = (i) => Math.max(0, 2 - Math.floor(Math.log10(i)));
                  const col = (k) => new Array(spaces(k)).fill(" ").join("") + k + ". ";
                  const source = errors[0] ? fragmentShaderSource : vertexShaderSource;
                  const formattedSource = source.split("\n").map((line, no) => col(1 + no) + line).join("\n");
                  throw new utils_errors.wB(`

---------- ERROR ----------

` + errors.filter((err) => err).join("\n") + `

---------- SOURCE CODE ----------

` + formattedSource + "\n");
                }
              }
              function ProgramGeometry(gl, location) {
                this.vao = gl.createVertexArray();
                this.vbo = Object.freeze({
                  position: gl.createBuffer(),
                  texCoord: gl.createBuffer()
                });
                this._gl = gl;
                gl.bindVertexArray(this.vao);
                gl.bindBuffer(gl.ARRAY_BUFFER, this.vbo.position);
                gl.bufferData(gl.ARRAY_BUFFER, new Float32Array([
                  // clip coordinates (CCW)
                  -1,
                  -1,
                  1,
                  -1,
                  -1,
                  1,
                  -1,
                  1,
                  1,
                  -1,
                  1,
                  1
                ]), gl.STATIC_DRAW);
                gl.enableVertexAttribArray(location.position);
                gl.vertexAttribPointer(
                  location.position,
                  // attribute location
                  2,
                  // 2 components per vertex (x,y)
                  gl.FLOAT,
                  // type
                  false,
                  // don't normalize
                  0,
                  // default stride (tightly packed)
                  0
                );
                gl.bindBuffer(gl.ARRAY_BUFFER, this.vbo.texCoord);
                gl.bufferData(gl.ARRAY_BUFFER, new Float32Array([
                  // texture coordinates (CCW)
                  0,
                  0,
                  1,
                  0,
                  0,
                  1,
                  0,
                  1,
                  1,
                  0,
                  1,
                  1
                ]), gl.STATIC_DRAW);
                gl.enableVertexAttribArray(location.texCoord);
                gl.vertexAttribPointer(
                  location.texCoord,
                  // attribute location
                  2,
                  // 2 components per vertex (x,y)
                  gl.FLOAT,
                  // type
                  false,
                  // don't normalize
                  0,
                  // default stride (tightly packed)
                  0
                );
                gl.bindBuffer(gl.ARRAY_BUFFER, null);
                gl.bindVertexArray(null);
                return Object.freeze(this);
              }
              ProgramGeometry.prototype.release = function() {
                const gl = this._gl;
                gl.deleteVertexArray(this.vao);
                gl.deleteBuffer(this.vbo.position);
                gl.deleteBuffer(this.vbo.texCoord);
                return null;
              };
              function UniformVariable(type, location) {
                this.type = String(type);
                if (!Object.prototype.hasOwnProperty.call(UNIFORM_SETTERS, this.type)) throw new utils_errors.EM(`Unsupported uniform type: ${this.type}`);
                this.location = location;
                this.setter = UNIFORM_SETTERS[this.type];
                const n = Number(this.setter.match(/^uniform(Matrix)?(\d)/)[2]) | 0;
                this.dim = this.type.startsWith("mat") ? 2 : this.type.indexOf("vec") >= 0 ? 1 : 0;
                this.length = this.dim == 2 ? n * n : n;
                this._value = null;
              }
              UniformVariable.prototype.setValue = function(gl, value, texNo = -1) {
                const setValue = (
                  /** @type {Function} */
                  gl[this.setter]
                );
                if (typeof value === "object" && this.type.endsWith("sampler2D")) {
                  if (texNo >= gl.MAX_COMBINED_TEXTURE_IMAGE_UNITS) throw new utils_errors.EM(`Can't activate texture unit ${texNo}: max is ${gl.MAX_COMBINED_TEXTURE_IMAGE_UNITS}`);
                  else if (Array.isArray(value)) throw new utils_errors.EM(`Can't pass arrays of textures to shaders`);
                  else if (value == null) throw new utils_errors.qw(`Can't run shader: cannot use ${value} as an input texture`);
                  else if (texNo < 0) throw new utils_errors.qw(`Missing texNo`);
                  const tex = value;
                  gl.activeTexture(gl.TEXTURE0 + texNo);
                  gl.bindTexture(gl.TEXTURE_2D, tex.glTexture);
                  gl.uniform1i(this.location, texNo);
                  texNo++;
                } else if (value === this._value && typeof value !== "object") {
                } else if (typeof value === "number" || typeof value === "boolean") {
                  setValue.call(gl, this.location, value);
                } else if (Array.isArray(value)) {
                  if (value.length === this.length) {
                    if (this.dim == 2) setValue.call(gl, this.location, false, value);
                    else setValue.call(gl, this.location, ...value);
                  } else throw new utils_errors.qw(`Can't run shader: incorrect number of values for ${this.type}: "${value}"`);
                } else throw new utils_errors.qw(`Can't run shader: unrecognized argument "${value}"`);
                this._value = value;
                return texNo;
              };
              function UBOHelper(gl, program) {
                this._gl = gl;
                this._program = program;
                this._nextIndex = 0;
                this._ubo = /* @__PURE__ */ Object.create(null);
              }
              UBOHelper.prototype.set = function(name, data) {
                const gl = this._gl;
                if (this._ubo[name] === void 0) {
                  this._ubo[name] = {
                    buffer: gl.createBuffer(),
                    blockBindingIndex: this._nextIndex++,
                    blockIndex: -1,
                    data: null
                  };
                }
                const ubo = this._ubo[name];
                if (ubo.blockIndex < 0) {
                  const blockIndex = gl.getUniformBlockIndex(this._program, name);
                  gl.uniformBlockBinding(this._program, blockIndex, ubo.blockBindingIndex);
                  ubo.blockIndex = blockIndex;
                }
                ubo.data = data;
              };
              UBOHelper.prototype.update = function() {
                const gl = this._gl;
                for (const name in this._ubo) {
                  const ubo = this._ubo[name];
                  gl.bindBuffer(gl.UNIFORM_BUFFER, ubo.buffer);
                  gl.bufferData(gl.UNIFORM_BUFFER, ubo.data, gl.DYNAMIC_DRAW);
                  gl.bindBufferBase(gl.UNIFORM_BUFFER, ubo.blockBindingIndex, ubo.buffer);
                  gl.bindBuffer(gl.UNIFORM_BUFFER, null);
                }
              };
              UBOHelper.prototype.release = function() {
                const gl = this._gl;
                for (const name in this._ubo) {
                  const ubo = this._ubo[name];
                  gl.deleteBuffer(ubo.buffer);
                  ubo.data = null;
                }
                return null;
              };
              function indexedVariable(variable, index) {
                const cache = indexedVariable.cache;
                let nameList = cache.get(variable);
                if (nameList === void 0) cache.set(variable, nameList = []);
                if (nameList[index] === void 0) nameList[index] = `${variable}[${index}]`;
                return nameList[index];
              }
              indexedVariable.cache = /* @__PURE__ */ new Map();
              ;
              const PROGRAM_HELPERS = Object.freeze({
                /**
                 * Pingpong Rendering: the output texture of a
                 * program cannot be used as an input to itself.
                 * This is a convenient helper in these situations
                 * @returns {SpeedyProgramOptions}
                 */
                usesPingpongRendering() {
                  return {
                    pingpong: true
                  };
                },
                /**
                 * Render to canvas
                 * Use it when we're supposed to see the texture
                 * @returns {SpeedyProgramOptions}
                 */
                rendersToCanvas() {
                  return {
                    renderToTexture: false
                  };
                }
              });
              class SpeedyProgramGroup {
                /**
                 * Class constructor
                 * @protected
                 * @param {SpeedyGPU} gpu
                 */
                constructor(gpu2) {
                  this._gpu = gpu2;
                  this._programs = [];
                }
                /**
                 * Declare a program
                 * @protected
                 * @param {string} name Program name
                 * @param {ShaderDeclarationBuilder} builder Builder of a ShaderDeclaration
                 * @param {SpeedyProgramOptions} [options] Program settings
                 * @returns {this}
                 */
                declare(name, builder, options = {}) {
                  Object.defineProperty(this, name, {
                    get: (() => {
                      const key = (
                        /** @type {symbol} */
                        Symbol(name)
                      );
                      return () => this[key] || (this[key] = this._createProgram(builder.build(), options));
                    })()
                  });
                  return this;
                }
                /**
                 * Neat helpers to be used when declaring programs
                 * @returns {SpeedyProgramHelpers}
                 */
                get program() {
                  return PROGRAM_HELPERS;
                }
                /**
                 * Releases all programs from this group
                 * @returns {null}
                 */
                release() {
                  for (let i = 0; i < this._programs.length; i++) this._programs[i].release();
                  return null;
                }
                /**
                 * Spawn a SpeedyProgram
                 * @param {ShaderDeclaration} shaderdecl Shader declaration
                 * @param {SpeedyProgramOptions} [options] Program settings
                 * @returns {SpeedyProgram}
                 */
                _createProgram(shaderdecl, options = {}) {
                  const program = new SpeedyProgram(this._gpu.gl, shaderdecl, options);
                  this._programs.push(program);
                  return program;
                }
              }
              ;
              const copy = (0, shader_declaration.bf)("utils/copy.glsl").withArguments("image");
              const copyKeypoints = (0, shader_declaration.bf)("utils/copy-raster.glsl").withDefines({
                "TYPE": 1
              }).withArguments("image");
              const copy2DVectors = (0, shader_declaration.bf)("utils/copy-raster.glsl").withDefines({
                "TYPE": 2
              }).withArguments("image");
              const flipY = (0, shader_declaration.bf)("utils/copy.glsl", "utils/flip-y.vs.glsl").withArguments("image");
              const fill = (0, shader_declaration.bf)("utils/fill.glsl").withArguments("value");
              const fillComponents = (0, shader_declaration.bf)("utils/fill-components.glsl").withArguments("image", "pixelComponents", "value");
              const copyComponents = (0, shader_declaration.bf)("utils/copy-components.glsl").withArguments("dest", "src", "destComponents", "srcComponentId");
              const scanMinMax2D = (0, shader_declaration.bf)("utils/scan-minmax2d.glsl").withArguments("image", "iterationNumber");
              const sobelDerivatives = (0, shader_declaration.bf)("utils/sobel-derivatives.glsl", "utils/sobel-derivatives.vs.glsl").withArguments("pyramid", "lod");
              class SpeedyProgramGroupUtils extends SpeedyProgramGroup {
                /**
                 * Class constructor
                 * @param {SpeedyGPU} gpu
                 */
                constructor(gpu2) {
                  super(gpu2);
                  this.declare("renderToCanvas", flipY, Object.assign({}, this.program.rendersToCanvas())).declare("copy", copy).declare("copyKeypoints", copyKeypoints).declare("copy2DVectors", copy2DVectors).declare("fill", fill).declare("fillComponents", fillComponents).declare("copyComponents", copyComponents).declare("scanMinMax2D", scanMinMax2D, Object.assign({}, this.program.usesPingpongRendering())).declare("sobelDerivatives", sobelDerivatives);
                }
              }
              var convolution = __webpack_require__(1672);
              ;
              const rgb2grey = (0, shader_declaration.bf)("filters/rgb2grey.glsl").withArguments("image");
              const filters_convolution = [3, 5, 7].reduce((obj, ksize) => (obj[ksize] = (0, shader_declaration.bf)("filters/convolution2d.glsl").withDefines({
                "KERNEL_SIZE_SQUARED": ksize * ksize
              }).withArguments("image", "kernel"), obj), {});
              const convolutionX = [3, 5, 7, 9, 11, 13, 15].reduce((obj, ksize) => (obj[ksize] = (0, shader_declaration.bf)("filters/convolution1d.glsl").withDefines({
                "KERNEL_SIZE": ksize,
                "AXIS": 0
              }).withArguments("image", "kernel"), obj), {});
              const convolutionY = [3, 5, 7, 9, 11, 13, 15].reduce((obj, ksize) => (obj[ksize] = (0, shader_declaration.bf)("filters/convolution1d.glsl").withDefines({
                "KERNEL_SIZE": ksize,
                "AXIS": 1
              }).withArguments("image", "kernel"), obj), {});
              const median = [3, 5, 7].reduce((obj, ksize) => (obj[ksize] = (0, shader_declaration.bf)("filters/fast-median.glsl").withDefines({
                "KERNEL_SIZE": ksize
              }).withArguments("image"), obj), {});
              const normalizeGreyscale = (0, shader_declaration.bf)("filters/normalize-image.glsl").withDefines({
                "GREYSCALE": 1
              }).withArguments("minmax2d", "minValue", "maxValue");
              const normalizeColored = (0, shader_declaration.bf)("filters/normalize-image.glsl").withDefines({
                "GREYSCALE": 0
              }).withArguments("minmax2dRGB", "minValue", "maxValue");
              const nightvision = (0, shader_declaration.bf)("filters/nightvision.glsl").withDefines({
                "GREYSCALE": 0
              }).withArguments("image", "illuminationMap", "gain", "offset", "decay");
              const nightvisionGreyscale = (0, shader_declaration.bf)("filters/nightvision.glsl").withDefines({
                "GREYSCALE": 1
              }).withArguments("image", "illuminationMap", "gain", "offset", "decay");
              const ksize2sigma = (ksize) => Math.max(1, ksize / 6);
              const gaussian = (ksize) => utils.A.gaussianKernel(ksize2sigma(ksize), ksize);
              const box = (ksize) => new Array(ksize).fill(1 / ksize);
              class SpeedyProgramGroupFilters extends SpeedyProgramGroup {
                /**
                 * Class constructor
                 * @param {SpeedyGPU} gpu
                 */
                constructor(gpu2) {
                  super(gpu2);
                  this.declare("rgb2grey", rgb2grey).declare("median3", median[3]).declare("median5", median[5]).declare("median7", median[7]).declare("convolution3", filters_convolution[3]).declare("convolution5", filters_convolution[5]).declare("convolution7", filters_convolution[7]).declare("convolution3x", convolutionX[3]).declare("convolution3y", convolutionY[3]).declare("convolution5x", convolutionX[5]).declare("convolution5y", convolutionY[5]).declare("convolution7x", convolutionX[7]).declare("convolution7y", convolutionY[7]).declare("convolution9x", convolutionX[9]).declare("convolution9y", convolutionY[9]).declare("convolution11x", convolutionX[11]).declare("convolution11y", convolutionY[11]).declare("convolution13x", convolutionX[13]).declare("convolution13y", convolutionY[13]).declare("convolution15x", convolutionX[15]).declare("convolution15y", convolutionY[15]).declare("normalizeGreyscale", normalizeGreyscale).declare("normalizeColored", normalizeColored).declare("nightvision", nightvision).declare("nightvisionGreyscale", nightvisionGreyscale).declare("illuminationMapLoX", (0, convolution.convX)(utils.A.gaussianKernel(80, 31))).declare("illuminationMapLoY", (0, convolution.convY)(utils.A.gaussianKernel(80, 31))).declare("illuminationMapX", (0, convolution.convX)(utils.A.gaussianKernel(80, 63))).declare("illuminationMapY", (0, convolution.convY)(utils.A.gaussianKernel(80, 63))).declare("illuminationMapHiX", (0, convolution.convX)(utils.A.gaussianKernel(80, 255))).declare("illuminationMapHiY", (0, convolution.convY)(utils.A.gaussianKernel(80, 255))).declare("gaussian3x", (0, convolution.convX)([0.25, 0.5, 0.25])).declare("gaussian3y", (0, convolution.convY)([0.25, 0.5, 0.25])).declare("gaussian5x", (0, convolution.convX)([0.05, 0.25, 0.4, 0.25, 0.05])).declare("gaussian5y", (0, convolution.convY)([0.05, 0.25, 0.4, 0.25, 0.05])).declare("gaussian7x", (0, convolution.convX)(gaussian(7))).declare("gaussian7y", (0, convolution.convY)(gaussian(7))).declare("gaussian9x", (0, convolution.convX)(gaussian(9))).declare("gaussian9y", (0, convolution.convY)(gaussian(9))).declare("gaussian11x", (0, convolution.convX)(gaussian(11))).declare("gaussian11y", (0, convolution.convY)(gaussian(11))).declare("box3x", (0, convolution.convX)(box(3))).declare("box3y", (0, convolution.convY)(box(3))).declare("box5x", (0, convolution.convX)(box(5))).declare("box5y", (0, convolution.convY)(box(5))).declare("box7x", (0, convolution.convX)(box(7))).declare("box7y", (0, convolution.convY)(box(7))).declare("box9x", (0, convolution.convX)(box(9))).declare("box9y", (0, convolution.convY)(box(9))).declare("box11x", (0, convolution.convX)(box(11))).declare("box11y", (0, convolution.convY)(box(11)));
                }
              }
              var speedy_namespace = __webpack_require__(6634);
              ;
              const DESCRIPTORDB_BYTESPERPIXEL = 4;
              const DESCRIPTORDB_MAXLOG2STRIDE = 11;
              class SpeedyDescriptorDB extends speedy_namespace.Q {
                /**
                 * Create a database of binary descriptors
                 * @param {SpeedyTexture} texture output texture
                 * @param {Uint8Array[]} descriptors binary descriptors
                 * @param {number} descriptorSize in bytes, a multiple of 4
                 * @returns {SpeedyTexture} texture
                 */
                static create(texture, descriptors, descriptorSize) {
                  utils.A.assert(descriptorSize % DESCRIPTORDB_BYTESPERPIXEL == 0, `Invalid descriptorSize: ${descriptorSize}`);
                  const numberOfDescriptors = descriptors.length;
                  const pixelsPerDescriptor = descriptorSize / DESCRIPTORDB_BYTESPERPIXEL;
                  const n = Math.log2(pixelsPerDescriptor * Math.max(numberOfDescriptors, 1)) / 2;
                  const log2stride = Math.min(DESCRIPTORDB_MAXLOG2STRIDE, Math.ceil(n));
                  const stride = 1 << log2stride;
                  const width = stride, height = stride;
                  const capacity = width * height / pixelsPerDescriptor;
                  if (numberOfDescriptors > capacity) throw new utils_errors.EM(`The capacity of the descriptorDB (${capacity} for ${descriptorSize * 8}-bit descriptors) has been exceeded`);
                  const data = new Uint8Array(width * height * DESCRIPTORDB_BYTESPERPIXEL);
                  for (let i = 0; i < numberOfDescriptors; i++) {
                    const byteOffset = i * descriptorSize;
                    const descriptor = descriptors[i];
                    utils.A.assert(descriptor.byteLength === descriptorSize);
                    utils.A.assert(byteOffset + descriptorSize <= data.byteLength);
                    data.set(descriptor, byteOffset);
                  }
                  const MEGABYTE = 1048576;
                  const totalSize = numberOfDescriptors * descriptorSize;
                  utils.A.log(`Creating a ${width}x${height} database of ${numberOfDescriptors} ${descriptorSize * 8}-bit descriptors (total size: ${(totalSize / MEGABYTE).toFixed(2)} MB)`);
                  texture.resize(width, height);
                  texture.upload(data);
                  return texture;
                }
              }
              ;
              const LSH_DEFAULT_NUMBER_OF_TABLES = 8;
              const LSH_DEFAULT_HASH_SIZE = 15;
              const LSH_ACCEPTABLE_NUMBER_OF_TABLES = [4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32];
              const LSH_ACCEPTABLE_HASH_SIZES = [10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20];
              const LSH_ACCEPTABLE_DESCRIPTOR_SIZES = [32, 64];
              const generateLSHProfiles = (t, h, p) => !LSH_ACCEPTABLE_HASH_SIZES.includes(h) || !LSH_ACCEPTABLE_NUMBER_OF_TABLES.includes(t) ? null : [{
                name: "x-small",
                bucketCapacity: 1,
                tableCount: t,
                hashSize: h,
                capacity: findTableCapacity(h, 1, p)
              }, {
                name: "small",
                bucketCapacity: 2,
                tableCount: t,
                hashSize: h,
                capacity: findTableCapacity(h, 2, p)
              }, {
                name: "small-plus",
                bucketCapacity: 3,
                tableCount: t,
                hashSize: h,
                capacity: findTableCapacity(h, 3, p)
              }, {
                name: "medium",
                bucketCapacity: 4,
                tableCount: t,
                hashSize: h,
                capacity: findTableCapacity(h, 4, p)
              }, {
                name: "medium-plus",
                bucketCapacity: 5,
                tableCount: t,
                hashSize: h,
                capacity: findTableCapacity(h, 5, p)
              }, {
                name: "large",
                bucketCapacity: 6,
                tableCount: t,
                hashSize: h,
                capacity: findTableCapacity(h, 6, p)
              }, {
                name: "x-large",
                bucketCapacity: 8,
                tableCount: t,
                hashSize: h,
                capacity: findTableCapacity(h, 8, p)
              }];
              const LSH_SEQUENCE_MAXLEN = Math.max(...LSH_ACCEPTABLE_HASH_SIZES);
              const LSH_SEQUENCE_COUNT = Math.max(...LSH_ACCEPTABLE_NUMBER_OF_TABLES);
              const partitionedSort = (seq) => (utils.A.range(LSH_SEQUENCE_COUNT).forEach((i) => seq.subarray(i * LSH_SEQUENCE_MAXLEN, (i + 1) * LSH_SEQUENCE_MAXLEN).sort()), seq);
              const padSequences = (p, seq) => (utils.A.range(LSH_SEQUENCE_COUNT).forEach((i) => seq.subarray((i + 1) * LSH_SEQUENCE_MAXLEN - p, (i + 1) * LSH_SEQUENCE_MAXLEN).fill(195939070)), seq);
              const LSH_SEQUENCES = ((f) => LSH_ACCEPTABLE_HASH_SIZES.reduce((p, o) => (p[o] = f(o), p), {}))((h) => ({
                // for 256-bit descriptors
                32: partitionedSort(padSequences(LSH_SEQUENCE_MAXLEN - h, new Uint32Array([...utils.A.shuffle(utils.A.range(256)), ...utils.A.shuffle(utils.A.range(256)), ...utils.A.shuffle(utils.A.range(256))].slice(0, LSH_SEQUENCE_COUNT * LSH_SEQUENCE_MAXLEN)))),
                // for 512-bit descriptors
                64: partitionedSort(padSequences(LSH_SEQUENCE_MAXLEN - h, new Uint32Array([...utils.A.shuffle(utils.A.range(512)), ...utils.A.shuffle(utils.A.range(512))].slice(0, LSH_SEQUENCE_COUNT * LSH_SEQUENCE_MAXLEN))))
              }));
              const LSH_BYTESPERPIXEL = 4;
              const nextPot = (x) => x > 1 ? 1 << Math.ceil(Math.log2(x)) : 1;
              class SpeedyLSH {
                /**
                 * Constructor
                 * @param {SpeedyTexture} lshTables texture to be used as the set of LSH tables
                 * @param {SpeedyTexture} descriptorDB texture to be used as the descriptor database
                 * @param {Uint8Array[]} descriptors the binary descriptors you'll store (make sure you don't repeat them, otherwise they will just waste space)
                 * @param {number} [tableCount] number of LSH tables, preferably a power of two
                 * @param {number} [hashSize] number of bits of a hash of a descriptor
                 * @param {number} [probability] probability of no discard events happening in the theoretical model
                 */
                constructor(lshTables, descriptorDB, descriptors, tableCount = LSH_DEFAULT_NUMBER_OF_TABLES, hashSize = LSH_DEFAULT_HASH_SIZE, probability = 0.95) {
                  const descriptorCount = descriptors.length;
                  const descriptorSize = descriptorCount > 0 ? descriptors[0].byteLength : 0;
                  const lshProfiles = generateLSHProfiles(tableCount, hashSize, probability);
                  utils.A.assert(descriptorCount > 0, `Can't build LSH tables without descriptors!`);
                  utils.A.assert(LSH_ACCEPTABLE_DESCRIPTOR_SIZES.includes(descriptorSize), `Can't build LSH tables: unacceptable descriptor size of ${descriptorSize} bytes`);
                  utils.A.assert(descriptors.findIndex((d) => d.byteLength !== descriptorSize) < 0, `Can't build LSH tables: incorrectly sized descriptors. Expected ${descriptorSize} bytes for each`);
                  utils.A.assert(descriptorCount < globals.MATCH_MAX_INDEX, `Can't build LSH tables: too many descriptors (${descriptors.length})`);
                  utils.A.assert(lshProfiles != null, `Can't build LSH tables: unacceptable number of tables (${tableCount}) x hash size (${hashSize})`);
                  this._profile = lshProfiles.find((profile) => descriptorCount <= profile.capacity) || lshProfiles[lshProfiles.length - 1];
                  this._descriptorSize = descriptorSize;
                  this._descriptorCount = descriptorCount;
                  this._sequences = this._pickSequences(this._descriptorSize);
                  this._tables = this._createStaticTables(lshTables, this._sequences, descriptors, descriptorSize);
                  this._descriptorDB = SpeedyDescriptorDB.create(descriptorDB, descriptors, descriptorSize);
                }
                /**
                 * Descriptor size, in bytes
                 * @returns {number}
                 */
                get descriptorSize() {
                  return this._descriptorSize;
                }
                /**
                 * Number of descriptors stored in this LSH data structure
                 * @returns {number}
                 */
                get descriptorCount() {
                  return this._descriptorCount;
                }
                /**
                 * LSH bit sequences
                 * @returns {BitSequences}
                 */
                get sequences() {
                  return this._sequences;
                }
                /**
                 * Number of bits that make a hash
                 * @returns {number}
                 */
                get hashSize() {
                  return this._profile.hashSize;
                }
                /**
                 * Maximum number of descriptors that can be stored in a bucket of a table
                 * @returns {number}
                 */
                get bucketCapacity() {
                  return this._profile.bucketCapacity;
                }
                /**
                 * How many buckets per table do we have?
                 * @returns {number}
                 */
                get bucketsPerTable() {
                  return 1 << this._profile.hashSize;
                }
                /**
                 * Number of LSH tables
                 * @returns {number}
                 */
                get tableCount() {
                  return this._profile.tableCount;
                }
                /**
                 * Size of one LSH table, in bytes
                 * @returns {number}
                 */
                get tableSize() {
                  return this.bucketsPerTable * this.bucketCapacity * LSH_BYTESPERPIXEL;
                }
                /**
                 * Size of all LSH tables combined, in bytes
                 * @returns {number}
                 */
                get totalSize() {
                  return this.tableCount * this.tableSize;
                }
                /**
                 * LSH tables texture
                 * @returns {SpeedyDrawableTexture}
                 */
                get tables() {
                  return this._tables;
                }
                /**
                 * A collection of descriptors
                 * @returns {SpeedyDrawableTexture}
                 */
                get descriptorDB() {
                  return this._descriptorDB;
                }
                /**
                 * Pick the appropriate LSH sequences for a particular descriptor size
                 * @param {number} descriptorSize in bytes
                 * @returns {BitSequences}
                 */
                _pickSequences(descriptorSize) {
                  utils.A.assert(Object.prototype.hasOwnProperty.call(LSH_SEQUENCES, this.hashSize));
                  utils.A.assert(Object.prototype.hasOwnProperty.call(LSH_SEQUENCES[this.hashSize], descriptorSize));
                  return LSH_SEQUENCES[this.hashSize][descriptorSize];
                }
                /**
                 * Create LSH tables
                 * @param {SpeedyTexture} texture output texture
                 * @param {BitSequences} sequences bit sequences
                 * @param {Uint8Array[]} descriptors non-empty array of binary descriptors, ALL HAVING THE SAME SIZE
                 * @param {number} descriptorSize in bytes
                 * @returns {SpeedyTexture} texture
                 */
                _createStaticTables(texture, sequences, descriptors, descriptorSize) {
                  const END_OF_LIST = 4294967295;
                  const profileName = this._profile.name;
                  const tableCapacity = this._profile.capacity;
                  const tableCount = this.tableCount;
                  const bucketsPerTable = this.bucketsPerTable;
                  const bucketSize = this.bucketCapacity * LSH_BYTESPERPIXEL;
                  const hashSize = this.hashSize;
                  const numberOfPixels = this.tableCount * this.bucketsPerTable * this.bucketCapacity;
                  const textureWidth = Math.min(nextPot(Math.sqrt(numberOfPixels)), 4096);
                  const textureHeight = Math.ceil(numberOfPixels / textureWidth);
                  const numberOfDescriptors = descriptors.length;
                  utils.A.assert(hashSize <= LSH_SEQUENCE_MAXLEN);
                  utils.A.assert(tableCount <= LSH_SEQUENCE_COUNT);
                  utils.A.assert(numberOfPixels <= textureWidth * textureHeight);
                  const MEGABYTE = 1048576;
                  utils.A.log(`Building ${tableCount} ${profileName} LSH tables with ${numberOfDescriptors} ${descriptorSize * 8}-bit descriptors each and hashSize = ${hashSize} bits (${textureWidth}x${textureHeight}, with ${(this.tableSize / MEGABYTE).toFixed(2)} MB per table and total size = ${(this.totalSize / MEGABYTE).toFixed(2)} MB), `);
                  if (numberOfDescriptors > tableCapacity) {
                    const exceedingPercentage = 100 * numberOfDescriptors / tableCapacity;
                    utils.A.warning(`There are too many descriptors (${numberOfDescriptors}) for a ${profileName} LSH table. That's ${exceedingPercentage.toFixed(2)}% of its theoretical capacity. Consider increasing the hashSize (currently set to ${hashSize}) or reducing the number of descriptors to avoid degradation.`);
                  }
                  const buffer = new ArrayBuffer(textureWidth * textureHeight * LSH_BYTESPERPIXEL);
                  const bytes = new Uint8Array(buffer).fill(255);
                  const data = new DataView(buffer);
                  const permutation = utils.A.shuffle(utils.A.range(numberOfDescriptors));
                  const numberOfDiscardedDescriptorsPerTable = new Array(tableCount).fill(0);
                  for (let i = 0; i < numberOfDescriptors; i++) {
                    const descriptorIndex = permutation[i];
                    const hashes = this._hashCodes(descriptors[descriptorIndex], sequences);
                    for (let table = 0; table < tableCount; table++) {
                      const hash = hashes[table];
                      const tableByteOffset = table * bucketsPerTable * bucketSize;
                      const bucketByteOffset = tableByteOffset + hash * bucketSize;
                      let index = END_OF_LIST;
                      for (let entryByteOffset = 0; entryByteOffset < bucketSize; entryByteOffset += LSH_BYTESPERPIXEL) {
                        const byteOffset = bucketByteOffset + entryByteOffset;
                        index = data.getUint32(byteOffset, true);
                        if (index == END_OF_LIST) {
                          data.setUint32(byteOffset, descriptorIndex, true);
                          break;
                        }
                      }
                      if (index != END_OF_LIST) numberOfDiscardedDescriptorsPerTable[table]++;
                    }
                  }
                  const numberOfDiscardedDescriptors = numberOfDiscardedDescriptorsPerTable.reduce((sum, val) => sum + val, 0);
                  const profile = numberOfDiscardedDescriptorsPerTable.map((d) => 100 * d / numberOfDescriptors);
                  utils.A.log(`When building ${tableCount} ${profileName} LSH tables with ${numberOfDescriptors} ${descriptorSize * 8}-bit descriptors each and hashSize = ${hashSize} bits, I got the following discard profile: ` + profile.map((x) => x.toFixed(2) + "%").join(", ") + `. Average: ${(100 * numberOfDiscardedDescriptors / (tableCount * numberOfDescriptors)).toFixed(2)}%. Minimum: ${Math.min(...profile).toFixed(2)}%. Table capacity: ${tableCapacity}.`);
                  texture.resize(textureWidth, textureHeight);
                  texture.upload(bytes);
                  return texture;
                }
                /**
                 * Pick bits from a binary descriptor
                 * @param {Uint8Array} descriptor a single descriptor
                 * @param {BitSequences} sequences flattened array of tableCount sequences of LSH_SEQUENCE_MAXLEN elements each
                 * @returns {number[]} hash code for each table
                 */
                _hashCodes(descriptor, sequences) {
                  const tableCount = this.tableCount;
                  const hashSize = this.hashSize;
                  const bucketsPerTable = this.bucketsPerTable;
                  const hashes = new Array(tableCount);
                  utils.A.assert(hashSize <= LSH_SEQUENCE_MAXLEN && sequences.length >= LSH_SEQUENCE_MAXLEN * tableCount);
                  for (let table = 0; table < tableCount; table++) {
                    const offset = LSH_SEQUENCE_MAXLEN * table;
                    let hash = 0;
                    for (let i = 0; i < hashSize; i++) {
                      let bit = sequences[offset + i];
                      let b = bit >>> 3;
                      let m = 1 << (bit & 7);
                      hash = hash << 1 | (descriptor[b] & m) != 0;
                    }
                    utils.A.assert(hash >= 0 && hash < bucketsPerTable);
                    hashes[table] = hash;
                  }
                  return hashes;
                }
              }
              function cumulativePoisson(lambda, k) {
                const exp = Math.exp(-lambda);
                let sum = 1, fat = 1, pow = 1;
                for (let i = 1; i <= k; i++) sum += (pow *= lambda) / (fat *= i);
                return sum * exp;
              }
              function findTableCapacity(hashSize, bucketCapacity, probability = 0.99) {
                const n = 1 << hashSize;
                const c = bucketCapacity;
                const p = probability;
                let l = 1, r = n * c;
                let m = 0, pm = 0;
                while (l < r) {
                  m = Math.floor((l + r) / 2);
                  pm = cumulativePoisson(m / n, c);
                  if (pm > p)
                    l = m + 1;
                  else r = m;
                }
                return m;
              }
              ;
              const fast9_16 = (0, shader_declaration.bf)("keypoints/fast.glsl", "keypoints/fast.vs.glsl").withDefines({
                "FAST_TYPE": 916
              }).withArguments("corners", "pyramid", "lod", "threshold");
              const harris = [1, 3, 5, 7].reduce((obj, win) => (obj[win] = (0, shader_declaration.bf)("keypoints/harris.glsl").withDefines({
                "WINDOW_SIZE": win
              }).withArguments("corners", "pyramid", "derivatives", "lod", "lodStep", "gaussian"), obj), {});
              const harrisScoreFindMax = (0, shader_declaration.bf)("keypoints/score-findmax.glsl").withArguments("corners", "iterationNumber");
              const harrisScoreCutoff = (0, shader_declaration.bf)("keypoints/harris-cutoff.glsl").withArguments("corners", "maxScore", "quality");
              const subpixelQuadratic1d = (0, shader_declaration.bf)("keypoints/subpixel-refinement.glsl").withDefines({
                "METHOD": 0
              }).withArguments("pyramid", "encodedKeypoints", "descriptorSize", "extraSize", "encoderLength", "maxIterations", "epsilon");
              const subpixelTaylor2d = (0, shader_declaration.bf)("keypoints/subpixel-refinement.glsl").withDefines({
                "METHOD": 1
              }).withArguments("pyramid", "encodedKeypoints", "descriptorSize", "extraSize", "encoderLength", "maxIterations", "epsilon");
              const subpixelBilinear = (0, shader_declaration.bf)("keypoints/subpixel-refinement.glsl").withDefines({
                "METHOD": 2
              }).withArguments("pyramid", "encodedKeypoints", "descriptorSize", "extraSize", "encoderLength", "maxIterations", "epsilon");
              const subpixelBicubic = (0, shader_declaration.bf)("keypoints/subpixel-refinement.glsl").withDefines({
                "METHOD": 3
              }).withArguments("pyramid", "encodedKeypoints", "descriptorSize", "extraSize", "encoderLength", "maxIterations", "epsilon");
              const refineScaleLoG = (0, shader_declaration.bf)("keypoints/refine-scale.glsl").withDefines({
                "METHOD": 0
              }).withArguments("pyramid", "lodStep", "encodedKeypoints", "descriptorSize", "extraSize", "encoderLength");
              const refineScaleFAST916 = (0, shader_declaration.bf)("keypoints/refine-scale.glsl").withDefines({
                "METHOD": 1
              }).withArguments("pyramid", "lodStep", "encodedKeypoints", "descriptorSize", "extraSize", "encoderLength", "threshold");
              const allocateDescriptors = (0, shader_declaration.bf)("keypoints/allocate-descriptors.glsl").withArguments("inputEncodedKeypoints", "inputDescriptorSize", "inputExtraSize", "inputEncoderLength", "outputDescriptorSize", "outputExtraSize", "outputEncoderLength");
              const allocateExtra = (0, shader_declaration.bf)("keypoints/allocate-extra.glsl").withArguments("inputEncodedKeypoints", "inputDescriptorSize", "inputExtraSize", "inputEncoderLength", "outputDescriptorSize", "outputExtraSize", "outputEncoderLength");
              const transferToExtra = (0, shader_declaration.bf)("keypoints/transfer-to-extra.glsl").withArguments("encodedData", "strideOfEncodedData", "encodedKeypoints", "descriptorSize", "extraSize", "encoderLength");
              const orbDescriptor = (0, shader_declaration.bf)("keypoints/orb-descriptor.glsl").withArguments("image", "encodedCorners", "extraSize", "encoderLength");
              const orbOrientation = (0, shader_declaration.bf)("keypoints/orb-orientation.glsl").withArguments("image", "encodedKeypoints", "descriptorSize", "extraSize", "encoderLength");
              const nonMaxSuppression = (0, shader_declaration.bf)("keypoints/nonmax-suppression.glsl").withDefines({
                "MULTISCALE": 0
              }).withArguments("image", "lodStep");
              const multiscaleNonMaxSuppression = (0, shader_declaration.bf)("keypoints/nonmax-suppression.glsl").withDefines({
                "MULTISCALE": 1
              }).withArguments("image", "lodStep");
              const nonmaxSpace = (0, shader_declaration.bf)("keypoints/nonmax-space.glsl").withArguments("corners");
              const nonmaxScale = (0, shader_declaration.bf)("keypoints/nonmax-scale.glsl").withDefines({
                "USE_LAPLACIAN": 1
              }).withArguments("corners", "pyramid", "pyrLaplacian", "lodStep");
              const nonmaxScaleSimple = (0, shader_declaration.bf)("keypoints/nonmax-scale.glsl").withDefines({
                "USE_LAPLACIAN": 0
              }).withArguments("corners", "pyramid", "lodStep");
              const laplacian = (0, shader_declaration.bf)("keypoints/laplacian.glsl").withArguments("corners", "pyramid", "lodStep", "lodOffset");
              const lk = [3, 5, 7, 9, 11, 13, 15, 17, 19, 21].reduce((obj, win) => (obj[win] = (0, shader_declaration.bf)("keypoints/lk.glsl").withDefines({
                "WINDOW_SIZE": win
              }).withArguments("encodedFlow", "prevKeypoints", "nextPyramid", "prevPyramid", "level", "depth", "numberOfIterations", "discardThreshold", "epsilon", "descriptorSize", "extraSize", "encoderLength"), obj), {});
              const transferFlow = (0, shader_declaration.bf)("keypoints/transfer-flow.glsl").withArguments("encodedFlow", "encodedKeypoints", "descriptorSize", "extraSize", "encoderLength");
              const bfMatcherInitCandidates = (0, shader_declaration.bf)("keypoints/knn-init.glsl").withDefines({
                "ENCODE_FILTERS": 0
              });
              const bfMatcherInitFilters = (0, shader_declaration.bf)("keypoints/knn-init.glsl").withDefines({
                "ENCODE_FILTERS": 1
              });
              const bfMatcherTransfer = (0, shader_declaration.bf)("keypoints/knn-transfer.glsl").withArguments("encodedMatches", "encodedKthMatches", "numberOfMatchesPerKeypoint", "kthMatch");
              const bfMatcher32 = (0, shader_declaration.bf)("keypoints/bf-knn.glsl").withDefines({
                "DESCRIPTOR_SIZE": 32,
                "NUMBER_OF_KEYPOINTS_PER_PASS": 16
              }).withArguments("encodedMatches", "encodedFilters", "matcherLength", "dbEncodedKeypoints", "dbDescriptorSize", "dbExtraSize", "dbEncoderLength", "encodedKeypoints", "descriptorSize", "extraSize", "encoderLength", "passId");
              const bfMatcher64 = (0, shader_declaration.bf)("keypoints/bf-knn.glsl").withDefines({
                "DESCRIPTOR_SIZE": 64,
                "NUMBER_OF_KEYPOINTS_PER_PASS": 8
              }).withArguments("encodedMatches", "encodedFilters", "matcherLength", "dbEncodedKeypoints", "dbDescriptorSize", "dbExtraSize", "dbEncoderLength", "encodedKeypoints", "descriptorSize", "extraSize", "encoderLength", "passId");
              const lshKnnInitCandidates = (0, shader_declaration.bf)("keypoints/knn-init.glsl").withDefines({
                "ENCODE_FILTERS": 0
              });
              const lshKnnInitFilters = (0, shader_declaration.bf)("keypoints/knn-init.glsl").withDefines({
                "ENCODE_FILTERS": 1
              });
              const lshKnn = LSH_ACCEPTABLE_DESCRIPTOR_SIZES.reduce((obj, descriptorSize) => (obj[descriptorSize] = LSH_ACCEPTABLE_HASH_SIZES.reduce((obj2, hashSize) => (obj2[hashSize] = [0, 1, 2].reduce((obj3, level) => (obj3[level] = (0, shader_declaration.bf)("keypoints/lsh-knn.glsl").withDefines({
                "DESCRIPTOR_SIZE": descriptorSize,
                "HASH_SIZE": hashSize,
                "LEVEL": level,
                "SEQUENCE_MAXLEN": LSH_SEQUENCE_MAXLEN,
                "SEQUENCE_COUNT": LSH_SEQUENCE_COUNT
              }).withArguments("candidates", "filters", "matcherLength", "tables", "descriptorDB", "tableIndex", "bucketCapacity", "bucketsPerTable", "tablesStride", "descriptorDBStride", "encodedKeypoints", "descriptorSize", "extraSize", "encoderLength"), obj3), {}), obj2), {}), obj), {});
              const lshKnnTransfer = (0, shader_declaration.bf)("keypoints/knn-transfer.glsl").withArguments("encodedMatches", "encodedKthMatches", "numberOfMatchesPerKeypoint", "kthMatch");
              const sortCreatePermutation = (0, shader_declaration.bf)("keypoints/sort-keypoints.glsl").withDefines({
                "STAGE": 1
              }).withArguments("encodedKeypoints", "descriptorSize", "extraSize", "encoderLength");
              const sortMergePermutation = (0, shader_declaration.bf)("keypoints/sort-keypoints.glsl").withDefines({
                "STAGE": 2
              }).withArguments("permutation", "blockSize", "dblLog2BlockSize");
              const sortApplyPermutation = (0, shader_declaration.bf)("keypoints/sort-keypoints.glsl").withDefines({
                "STAGE": 3
              }).withArguments("permutation", "maxKeypoints", "encodedKeypoints", "descriptorSize", "extraSize");
              const mixKeypointsPreInit = (0, shader_declaration.bf)("keypoints/mix-keypoints.glsl").withDefines({
                "STAGE": 1
              }).withArguments("encodedKeypointsA", "encodedKeypointsB", "encoderLengthA", "encoderLengthB", "encoderCapacityA", "encoderCapacityB", "descriptorSize", "extraSize", "encoderLength");
              const mixKeypointsInit = (0, shader_declaration.bf)("keypoints/mix-keypoints.glsl").withDefines({
                "STAGE": 2
              }).withArguments("encodedKeypoints", "descriptorSize", "extraSize", "encoderLength", "maxKeypoints");
              const mixKeypointsSort = (0, shader_declaration.bf)("keypoints/mix-keypoints.glsl").withDefines({
                "STAGE": 3
              }).withArguments("array", "blockSize");
              const mixKeypointsView = (0, shader_declaration.bf)("keypoints/mix-keypoints.glsl").withDefines({
                "STAGE": 5
              }).withArguments("array");
              const mixKeypointsApply = (0, shader_declaration.bf)("keypoints/mix-keypoints.glsl").withDefines({
                "STAGE": 4
              }).withArguments("array", "encodedKeypoints", "descriptorSize", "extraSize", "encoderLength");
              const initLookupTable = (0, shader_declaration.bf)("keypoints/lookup-of-locations.glsl").withDefines({
                "FS_OUTPUT_TYPE": 2,
                "STAGE": 1
              }).withArguments("corners");
              const sortLookupTable = (0, shader_declaration.bf)("keypoints/lookup-of-locations.glsl", "keypoints/lookup-of-locations.vs.glsl").withDefines({
                "FS_OUTPUT_TYPE": 2,
                "FS_USE_CUSTOM_PRECISION": 1,
                "STAGE": 2
              }).withArguments("lookupTable", "blockSize", "width", "height");
              const viewLookupTable = (0, shader_declaration.bf)("keypoints/lookup-of-locations.glsl").withDefines({
                "STAGE": -1
              }).withArguments("lookupTable");
              const encodeKeypoints = (0, shader_declaration.bf)("keypoints/encode-keypoints.glsl").withArguments("corners", "lookupTable", "stride", "descriptorSize", "extraSize", "encoderLength", "encoderCapacity");
              const encodeKeypointSkipOffsets = (0, shader_declaration.bf)("keypoints/encode-keypoint-offsets.glsl").withArguments("corners", "imageSize");
              const encodeKeypointLongSkipOffsets = (0, shader_declaration.bf)("keypoints/encode-keypoint-long-offsets.glsl").withDefines({
                "MAX_ITERATIONS": 6
              }).withArguments("offsetsImage", "imageSize");
              const encodeKeypointPositions = (0, shader_declaration.bf)("keypoints/encode-keypoint-positions.glsl").withArguments("offsetsImage", "imageSize", "passId", "numPasses", "keypointLimit", "encodedKeypoints", "descriptorSize", "extraSize", "encoderLength");
              const encodeKeypointProperties = (0, shader_declaration.bf)("keypoints/encode-keypoint-properties.glsl").withArguments("corners", "encodedKeypoints", "descriptorSize", "extraSize", "encoderLength");
              const encodeNullKeypoints = (0, shader_declaration.bf)("keypoints/encode-null-keypoints.glsl").withArguments();
              const transferOrientation = (0, shader_declaration.bf)("keypoints/transfer-orientation.glsl").withArguments("encodedOrientations", "encodedKeypoints", "descriptorSize", "extraSize", "encoderLength");
              const uploadKeypoints = (0, shader_declaration.bf)("keypoints/upload-keypoints.glsl").withDefines({
                // UBOs can hold at least 16KB of data;
                // gl.MAX_UNIFORM_BLOCK_SIZE >= 16384
                // according to the GL ES 3 reference.
                // Each keypoint uses 16 bytes (vec4)
                "BUFFER_SIZE": 1024
                //16384 / 16
              }).withArguments("encodedKeypoints", "startIndex", "endIndex", "descriptorSize", "extraSize", "encoderLength");
              const applyHomography = (0, shader_declaration.bf)("keypoints/apply-homography.glsl").withArguments("homography", "encodedKeypoints", "descriptorSize", "extraSize", "encoderLength");
              const clipBorder = (0, shader_declaration.bf)("keypoints/clip-border.glsl").withArguments("imageWidth", "imageHeight", "borderTop", "borderRight", "borderBottom", "borderLeft", "encodedKeypoints", "descriptorSize", "extraSize", "encoderLength");
              const distanceFilter = (0, shader_declaration.bf)("keypoints/distance-filter.glsl").withArguments("encodedKeypointsA", "encoderLengthA", "encodedKeypointsB", "encoderLengthB", "descriptorSize", "extraSize", "encoderLength", "threshold");
              const hammingDistanceFilter32 = (0, shader_declaration.bf)("keypoints/hamming-distance-filter.glsl").withDefines({
                "DESCRIPTOR_SIZE": 32
              }).withArguments("encodedKeypointsA", "encoderLengthA", "encodedKeypointsB", "encoderLengthB", "descriptorSize", "extraSize", "encoderLength", "threshold");
              const hammingDistanceFilter64 = (0, shader_declaration.bf)("keypoints/hamming-distance-filter.glsl").withDefines({
                "DESCRIPTOR_SIZE": 64
              }).withArguments("encodedKeypointsA", "encoderLengthA", "encodedKeypointsB", "encoderLengthB", "descriptorSize", "extraSize", "encoderLength", "threshold");
              const shuffle = (0, shader_declaration.bf)("keypoints/shuffle.glsl").withDefines({
                "PERMUTATION_MAXLEN": 2048
              }).withArguments("encodedKeypoints", "descriptorSize", "extraSize", "encoderLength");
              const clip = (0, shader_declaration.bf)("keypoints/clip.glsl").withArguments("encodedKeypoints", "descriptorSize", "extraSize", "encoderLength", "maxKeypoints");
              class SpeedyProgramGroupKeypoints extends SpeedyProgramGroup {
                /**
                 * Class constructor
                 * @param {SpeedyGPU} gpu
                 */
                constructor(gpu2) {
                  super(gpu2);
                  this.declare("fast9_16", fast9_16, Object.assign({}, this.program.usesPingpongRendering())).declare("harris1", harris[1], Object.assign({}, this.program.usesPingpongRendering())).declare("harris3", harris[3], Object.assign({}, this.program.usesPingpongRendering())).declare("harris5", harris[5], Object.assign({}, this.program.usesPingpongRendering())).declare("harris7", harris[7], Object.assign({}, this.program.usesPingpongRendering())).declare("harrisScoreFindMax", harrisScoreFindMax, Object.assign({}, this.program.usesPingpongRendering())).declare("harrisScoreCutoff", harrisScoreCutoff).declare("subpixelQuadratic1d", subpixelQuadratic1d).declare("subpixelTaylor2d", subpixelTaylor2d).declare("subpixelBicubic", subpixelBicubic).declare("subpixelBilinear", subpixelBilinear).declare("refineScaleLoG", refineScaleLoG).declare("refineScaleFAST916", refineScaleFAST916).declare("allocateDescriptors", allocateDescriptors).declare("allocateExtra", allocateExtra).declare("transferToExtra", transferToExtra).declare("orbDescriptor", orbDescriptor).declare("orbOrientation", orbOrientation).declare("nonmax", nonMaxSuppression).declare("pyrnonmax", multiscaleNonMaxSuppression).declare("nonmaxSpace", nonmaxSpace).declare("nonmaxScale", nonmaxScale).declare("nonmaxScaleSimple", nonmaxScaleSimple).declare("laplacian", laplacian).declare("lk21", lk[21], Object.assign({}, this.program.usesPingpongRendering())).declare("lk19", lk[19], Object.assign({}, this.program.usesPingpongRendering())).declare("lk17", lk[17], Object.assign({}, this.program.usesPingpongRendering())).declare("lk15", lk[15], Object.assign({}, this.program.usesPingpongRendering())).declare("lk13", lk[13], Object.assign({}, this.program.usesPingpongRendering())).declare("lk11", lk[11], Object.assign({}, this.program.usesPingpongRendering())).declare("lk9", lk[9], Object.assign({}, this.program.usesPingpongRendering())).declare("lk7", lk[7], Object.assign({}, this.program.usesPingpongRendering())).declare("lk5", lk[5], Object.assign({}, this.program.usesPingpongRendering())).declare("lk3", lk[3], Object.assign({}, this.program.usesPingpongRendering())).declare("transferFlow", transferFlow).declare("bfMatcherInitCandidates", bfMatcherInitCandidates).declare("bfMatcherInitFilters", bfMatcherInitFilters).declare("bfMatcherTransfer", bfMatcherTransfer, Object.assign({}, this.program.usesPingpongRendering())).declare("bfMatcher32", bfMatcher32, Object.assign({}, this.program.usesPingpongRendering())).declare("bfMatcher64", bfMatcher64, Object.assign({}, this.program.usesPingpongRendering())).declare("lshKnnInitCandidates", lshKnnInitCandidates).declare("lshKnnInitFilters", lshKnnInitFilters).declare("lshKnnTransfer", lshKnnTransfer, Object.assign({}, this.program.usesPingpongRendering())).declare("sortCreatePermutation", sortCreatePermutation).declare("sortMergePermutation", sortMergePermutation, Object.assign({}, this.program.usesPingpongRendering())).declare("sortApplyPermutation", sortApplyPermutation).declare("mixKeypointsPreInit", mixKeypointsPreInit).declare("mixKeypointsInit", mixKeypointsInit).declare("mixKeypointsSort", mixKeypointsSort, Object.assign({}, this.program.usesPingpongRendering())).declare("mixKeypointsView", mixKeypointsView).declare("mixKeypointsApply", mixKeypointsApply).declare("encodeNullKeypoints", encodeNullKeypoints).declare("encodeKeypoints", encodeKeypoints).declare("initLookupTable", initLookupTable).declare("sortLookupTable", sortLookupTable, Object.assign({}, this.program.usesPingpongRendering())).declare("viewLookupTable", viewLookupTable).declare("encodeKeypointSkipOffsets", encodeKeypointSkipOffsets).declare("encodeKeypointLongSkipOffsets", encodeKeypointLongSkipOffsets, Object.assign({}, this.program.usesPingpongRendering())).declare("encodeKeypointPositions", encodeKeypointPositions, Object.assign({}, this.program.usesPingpongRendering())).declare("encodeKeypointProperties", encodeKeypointProperties).declare("transferOrientation", transferOrientation).declare("uploadKeypoints", uploadKeypoints, Object.assign({}, this.program.usesPingpongRendering())).declare("applyHomography", applyHomography).declare("clipBorder", clipBorder).declare("distanceFilter", distanceFilter).declare("hammingDistanceFilter32", hammingDistanceFilter32).declare("hammingDistanceFilter64", hammingDistanceFilter64).declare("shuffle", shuffle).declare("clip", clip);
                  for (const descriptorSize of Object.keys(lshKnn)) {
                    for (const hashSize of Object.keys(lshKnn[descriptorSize])) {
                      for (const level of Object.keys(lshKnn[descriptorSize][hashSize])) {
                        const name = `lshKnn${descriptorSize}h${hashSize}lv${level}`;
                        this.declare(name, lshKnn[descriptorSize][hashSize][level], Object.assign({}, this.program.usesPingpongRendering()));
                      }
                    }
                  }
                }
              }
              ;
              const upsample2 = (0, shader_declaration.bf)("pyramids/upsample2.glsl").withArguments("image");
              const downsample2 = (0, shader_declaration.bf)("pyramids/downsample2.glsl").withArguments("image");
              class SpeedyProgramGroupPyramids extends SpeedyProgramGroup {
                /**
                 * Class constructor
                 * @param {SpeedyGPU} gpu
                 */
                constructor(gpu2) {
                  super(gpu2);
                  this.declare("upsample2", upsample2).declare("downsample2", downsample2).declare("smoothX", (0, convolution.convX)([0.05, 0.25, 0.4, 0.25, 0.05])).declare("smoothY", (0, convolution.convY)([0.05, 0.25, 0.4, 0.25, 0.05])).declare("smoothX2", (0, convolution.convX)([
                    0.1,
                    0.5,
                    0.8,
                    0.5,
                    0.1
                    // NOTE: this would saturate the image, but we apply it
                    // on a 2x upsampled version with lots of zero pixels
                  ])).declare("smoothY2", (0, convolution.convY)([0.1, 0.5, 0.8, 0.5, 0.1], 1 / 2));
                }
              }
              ;
              const warpPerspective = (0, shader_declaration.bf)("transforms/warp-perspective.glsl").withArguments("image", "inverseHomography");
              const resizeNearest = (0, shader_declaration.bf)("transforms/resize.glsl").withDefines({
                "INTERPOLATION_METHOD": 0
                // Nearest neighbors
              }).withArguments("image");
              const resizeBilinear = (0, shader_declaration.bf)("transforms/resize.glsl").withDefines({
                "INTERPOLATION_METHOD": 1
                // Bilinear interpolation
              }).withArguments("image");
              const additiveMix = (0, shader_declaration.bf)("transforms/additive-mix.glsl").withArguments("image0", "image1", "alpha", "beta", "gamma");
              class SpeedyProgramGroupTransforms extends SpeedyProgramGroup {
                /**
                 * Class constructor
                 * @param {SpeedyGPU} gpu
                 */
                constructor(gpu2) {
                  super(gpu2);
                  this.declare("warpPerspective", warpPerspective).declare("resizeNearest", resizeNearest).declare("resizeBilinear", resizeBilinear).declare("additiveMix", additiveMix);
                }
              }
              ;
              class SpeedyProgramCenter {
                /**
                 * Class constructor
                 * @param {SpeedyGPU} gpu reference to SpeedyGPU
                 */
                constructor(gpu2) {
                  this._gpu = gpu2;
                  this._filters = null;
                  this._transforms = null;
                  this._pyramids = null;
                  this._keypoints = null;
                  this._utils = null;
                }
                /**
                 * Image filters & convolutions
                 * @returns {SpeedyProgramGroupFilters}
                 */
                get filters() {
                  return this._filters || (this._filters = new SpeedyProgramGroupFilters(this._gpu));
                }
                /**
                 * Geometric transformations
                 * @returns {SpeedyProgramGroupTransforms}
                 */
                get transforms() {
                  return this._transforms || (this._transforms = new SpeedyProgramGroupTransforms(this._gpu));
                }
                /**
                 * Image pyramids & scale-space
                 * @returns {SpeedyProgramGroupPyramids}
                 */
                get pyramids() {
                  return this._pyramids || (this._pyramids = new SpeedyProgramGroupPyramids(this._gpu));
                }
                /**
                 * Keypoint detection & description
                 * @returns {SpeedyProgramGroupKeypoints}
                 */
                get keypoints() {
                  return this._keypoints || (this._keypoints = new SpeedyProgramGroupKeypoints(this._gpu));
                }
                /**
                 * Utility programs
                 * @returns {SpeedyProgramGroupUtils}
                 */
                get utils() {
                  return this._utils || (this._utils = new SpeedyProgramGroupUtils(this._gpu));
                }
                /**
                 * Release all programs from all groups. You'll
                 * no longer be able to use any of them.
                 * @returns {null}
                 */
                release() {
                  for (const key in this) {
                    if (Object.prototype.hasOwnProperty.call(this, key) && this[key] != null) {
                      const group = this[key];
                      if (group instanceof SpeedyProgramGroup) group.release();
                    }
                  }
                  return null;
                }
              }
              ;
              const DEFAULT_CAPACITY2 = 1024;
              const BUCKET = Symbol("Bucket");
              class TextureBucket {
                /**
                 * Constructor
                 * @param {SpeedyDrawableTexture} texture managed texture
                 * @param {TextureBucketIndex} index index of this bucket
                 * @param {TextureBucketIndex} next index of the next bucket
                 */
                constructor(texture, index, next) {
                  this.texture = texture;
                  this.index = index;
                  this.next = next;
                  this.free = true;
                }
              }
              class SpeedyTexturePool {
                /**
                 * Constructor
                 * @param {SpeedyGPU} gpu
                 * @param {number} [capacity] number of textures in the pool
                 */
                constructor(gpu2, capacity = DEFAULT_CAPACITY2) {
                  utils.A.assert(capacity > 0);
                  this._bucket = Array.from({
                    length: capacity
                  }, (_, i) => new TextureBucket(null, i, i - 1));
                  this._head = capacity - 1;
                  this._gpu = gpu2;
                }
                /**
                 * Get a texture from the pool
                 * @returns {SpeedyDrawableTexture}
                 */
                allocate() {
                  if (this._head < 0) throw new utils_errors.l(`Exhausted pool (capacity: ${this._bucket.length})`);
                  const bucket = this._bucket[this._head];
                  bucket.free = false;
                  this._head = bucket.next;
                  if (bucket.texture == null)
                    bucket.texture = SpeedyTexturePool._createManagedTexture(this._gpu.gl, bucket);
                  return bucket.texture;
                }
                /**
                 * Put a texture back in the pool
                 * @param {SpeedyDrawableTexture} texture
                 * @returns {null}
                 */
                free(texture) {
                  const bucket = texture[BUCKET];
                  utils.A.assert(bucket !== void 0 && !bucket.free, `Unmanaged texture or double free`);
                  bucket.next = this._head;
                  bucket.free = true;
                  this._head = bucket.index;
                  return null;
                }
                /**
                 * Release the texture pool
                 * @returns {null}
                 */
                release() {
                  for (let i = 0; i < this._bucket.length; i++) {
                    if (this._bucket[i].texture != null) this._bucket[i].texture = this._bucket[i].texture.release();
                  }
                  return null;
                }
                /**
                 * Create a texture with a reference to a bucket
                 * @param {WebGL2RenderingContext} gl
                 * @param {TextureBucket} bucket
                 * @returns {SpeedyDrawableTexture}
                 */
                static _createManagedTexture(gl, bucket) {
                  const texture = new SpeedyDrawableTexture(gl, 1, 1);
                  return Object.defineProperty(texture, BUCKET, {
                    configurable: false,
                    enumerable: false,
                    writable: false,
                    value: bucket
                  });
                }
              }
              var types = __webpack_require__(6049);
              ;
              const PRIVATE_TOKEN = Symbol();
              class SpeedyMediaSource {
                /**
                 * @protected Constructor
                 * @param {symbol} token
                 */
                constructor(token) {
                  if (token !== PRIVATE_TOKEN) throw new utils_errors.Er();
                  this._data = null;
                }
                /**
                 * Load a media source
                 * @param {SpeedyMediaSourceNativeElement} wrappedObject
                 * @returns {SpeedyPromise<SpeedyMediaSource>}
                 */
                static load(wrappedObject) {
                  if (wrappedObject instanceof HTMLImageElement) return SpeedyImageMediaSource.load(wrappedObject);
                  else if (wrappedObject instanceof HTMLVideoElement) return SpeedyVideoMediaSource.load(wrappedObject);
                  else if (wrappedObject instanceof HTMLCanvasElement) return SpeedyCanvasMediaSource.load(wrappedObject);
                  else if (typeof OffscreenCanvas !== "undefined" && wrappedObject instanceof OffscreenCanvas) return SpeedyOffscreenCanvasMediaSource.load(wrappedObject);
                  else if (wrappedObject instanceof ImageBitmap) return SpeedyBitmapMediaSource.load(wrappedObject);
                  else if (wrappedObject instanceof ImageData) return SpeedyDataMediaSource.load(wrappedObject);
                  else throw new utils_errors.qw(`Unsupported media type: ${wrappedObject}`);
                }
                /**
                 * The underlying wrapped object
                 * @returns {SpeedyMediaSourceNativeElement}
                 */
                get data() {
                  return this._data;
                }
                /**
                 * Is the underlying media loaded?
                 * @returns {boolean}
                 */
                isLoaded() {
                  return this._data !== null;
                }
                /**
                 * The type of the underlying media source
                 * @abstract
                 * @returns {MediaType}
                 */
                get type() {
                  throw new utils_errors.aQ();
                }
                /**
                 * Media width, in pixels
                 * @abstract
                 * @returns {number}
                 */
                get width() {
                  throw new utils_errors.aQ();
                }
                /**
                 * Media height, in pixels
                 * @abstract
                 * @returns {number}
                 */
                get height() {
                  throw new utils_errors.aQ();
                }
                /**
                 * Clone this media source
                 * @abstract
                 * @returns {SpeedyPromise<SpeedyMediaSource>}
                 */
                clone() {
                  throw new utils_errors.aQ();
                }
                /**
                 * Release resources associated with this object
                 * @returns {null}
                 */
                release() {
                  return this._data = null;
                }
                /**
                 * Load the underlying media
                 * @abstract
                 * @param {SpeedyMediaSourceNativeElement} element
                 * @returns {SpeedyPromise<SpeedyMediaSource>}
                 */
                _load(element) {
                  throw new utils_errors.aQ();
                }
                /**
                 * Wait for an event to be triggered in an element
                 * @param {Element} element
                 * @param {string} eventName
                 * @param {number} [timeout] in ms
                 * @returns {SpeedyPromise<Element>}
                 */
                static _waitUntil(element, eventName, timeout = 3e4) {
                  return new speedy_promise.i((resolve, reject) => {
                    utils.A.log(`Waiting for ${eventName} to be triggered in ${element}...`);
                    const timer = setTimeout(() => {
                      clear();
                      reject(new utils_errors.MU(`${eventName} has not been triggered in ${element}: timeout (${timeout}ms)`));
                    }, timeout);
                    function clear() {
                      clearTimeout(timer);
                      element.removeEventListener("error", handleError, false);
                      element.removeEventListener(eventName, handleSuccess, false);
                    }
                    function handleError() {
                      const hasError = element.error !== null && typeof element.error === "object";
                      const error = hasError ? element.error : {
                        code: -1,
                        message: ""
                      };
                      const info = `${error.message} (error code ${error.code})`;
                      clear();
                      reject(new utils_errors.FJ(`Can't load ${element}. ${info}`));
                    }
                    function handleSuccess() {
                      clear();
                      resolve(element);
                    }
                    element.addEventListener("error", handleError, false);
                    element.addEventListener(eventName, handleSuccess, false);
                  });
                }
              }
              class SpeedyImageMediaSource extends SpeedyMediaSource {
                /**
                 * @private Constructor
                 * @param {symbol} token
                 */
                constructor(token) {
                  super(token);
                  this._data = null;
                }
                /**
                 * The underlying wrapped object
                 * @returns {HTMLImageElement}
                 */
                get data() {
                  return this._data;
                }
                /**
                 * The type of the underlying media source
                 * @returns {MediaType}
                 */
                get type() {
                  return types.zu.Image;
                }
                /**
                 * Media width, in pixels
                 * @returns {number}
                 */
                get width() {
                  return this._data ? this._data.naturalWidth : 0;
                }
                /**
                 * Media height, in pixels
                 * @returns {number}
                 */
                get height() {
                  return this._data ? this._data.naturalHeight : 0;
                }
                /**
                 * Clone this media source
                 * @returns {SpeedyPromise<SpeedyMediaSource>}
                 */
                clone() {
                  if (this._data == null) throw new utils_errors.Er(`Media not loaded`);
                  const newNode = (
                    /** @type {HTMLImageElement} */
                    this._data.cloneNode(true)
                  );
                  return SpeedyImageMediaSource.load(newNode);
                }
                /**
                 * Load the underlying media
                 * @param {HTMLImageElement} image
                 * @returns {SpeedyPromise<SpeedyMediaSource>}
                 */
                _load(image) {
                  if (this.isLoaded()) this.release();
                  if (image.complete && image.naturalWidth !== 0) {
                    return new speedy_promise.i((resolve) => {
                      this._data = image;
                      resolve(this);
                    });
                  } else {
                    return SpeedyMediaSource._waitUntil(image, "load").then(() => {
                      this._data = image;
                      return this;
                    });
                  }
                }
                /**
                 * Load the underlying media
                 * @param {HTMLImageElement} image
                 * @returns {SpeedyPromise<SpeedyMediaSource>}
                 */
                static load(image) {
                  return new SpeedyImageMediaSource(PRIVATE_TOKEN)._load(image);
                }
              }
              class SpeedyVideoMediaSource extends SpeedyMediaSource {
                /**
                 * @private Constructor
                 * @param {symbol} token
                 */
                constructor(token) {
                  super(token);
                  this._data = null;
                }
                /**
                 * The underlying wrapped object
                 * @returns {HTMLVideoElement}
                 */
                get data() {
                  return this._data;
                }
                /**
                 * The type of the underlying media source
                 * @returns {MediaType}
                 */
                get type() {
                  return types.zu.Video;
                }
                /**
                 * Media width, in pixels
                 * @returns {number}
                 */
                get width() {
                  return this._data ? this._data.videoWidth : 0;
                }
                /**
                 * Media height, in pixels
                 * @returns {number}
                 */
                get height() {
                  return this._data ? this._data.videoHeight : 0;
                }
                /**
                 * Clone this media source
                 * @returns {SpeedyPromise<SpeedyMediaSource>}
                 */
                clone() {
                  if (this._data == null) throw new utils_errors.Er(`Media not loaded`);
                  const newNode = (
                    /** @type {HTMLVideoElement} */
                    this._data.cloneNode(true)
                  );
                  return SpeedyVideoMediaSource.load(newNode);
                }
                /**
                 * Load the underlying media
                 * @param {HTMLVideoElement} video
                 * @returns {SpeedyPromise<SpeedyMediaSource>}
                 */
                _load(video) {
                  if (this.isLoaded()) this.release();
                  utils.A.log("Loading a video...");
                  video.load();
                  return SpeedyVideoMediaSource._waitUntilPlayable(video).then(() => {
                    return SpeedyVideoMediaSource._handleAutoplay(video).then(() => {
                      this._data = video;
                      return this;
                    });
                  });
                }
                /**
                 * Load the underlying media
                 * @param {HTMLVideoElement} video
                 * @returns {SpeedyPromise<SpeedyMediaSource>}
                 */
                static load(video) {
                  return new SpeedyVideoMediaSource(PRIVATE_TOKEN)._load(video);
                }
                /**
                 * Handle browser quirks concerning autoplay
                 * @param {HTMLVideoElement} video
                 * @returns {SpeedyPromise<void>} gets rejected if we can't autoplay
                 */
                static _handleAutoplay(video) {
                  if (video.autoplay) {
                    return new speedy_promise.i((resolve, reject) => {
                      const promise = video.play();
                      if (promise === void 0) {
                        resolve();
                        return;
                      }
                      promise.then(resolve, reject);
                    });
                  }
                  return speedy_promise.i.resolve();
                }
                /**
                 * Wait for the input video to be playable
                 * @param {HTMLVideoElement} video
                 * @returns {SpeedyPromise<HTMLVideoElement>} resolves to the input video when it can be played
                 */
                static _waitUntilPlayable(video) {
                  const TIMEOUT = 3e4, INTERVAL = 500;
                  if (video.readyState >= 3) return speedy_promise.i.resolve(video);
                  return new speedy_promise.i((resolve, reject) => {
                    let ms = 0, t = setInterval(() => {
                      if (video.readyState >= 3) {
                        clearInterval(t);
                        resolve(video);
                      } else if ((ms += INTERVAL) >= TIMEOUT) {
                        clearInterval(t);
                        reject(new utils_errors.MU("The video took too long to load"));
                      }
                    }, INTERVAL);
                  });
                }
              }
              class SpeedyCanvasMediaSource extends SpeedyMediaSource {
                /**
                 * @private Constructor
                 * @param {symbol} token
                 */
                constructor(token) {
                  super(token);
                  this._data = null;
                }
                /**
                 * The underlying wrapped object
                 * @returns {HTMLCanvasElement}
                 */
                get data() {
                  return this._data;
                }
                /**
                 * The type of the underlying media source
                 * @returns {MediaType}
                 */
                get type() {
                  return types.zu.Canvas;
                }
                /**
                 * Media width, in pixels
                 * @returns {number}
                 */
                get width() {
                  return this._data ? this._data.width : 0;
                }
                /**
                 * Media height, in pixels
                 * @returns {number}
                 */
                get height() {
                  return this._data ? this._data.height : 0;
                }
                /**
                 * Clone this media source
                 * @returns {SpeedyPromise<SpeedyMediaSource>}
                 */
                clone() {
                  if (this._data == null) throw new utils_errors.Er(`Media not loaded`);
                  const newCanvas = utils.A.createCanvas(this.width, this.height);
                  const newContext = newCanvas.getContext("2d");
                  newContext.drawImage(this._data, 0, 0);
                  return SpeedyCanvasMediaSource.load(newCanvas);
                }
                /**
                 * Load the underlying media
                 * @param {HTMLCanvasElement} canvas
                 * @returns {SpeedyPromise<SpeedyMediaSource>}
                 */
                _load(canvas) {
                  if (this.isLoaded()) this.release();
                  return new speedy_promise.i((resolve) => {
                    this._data = canvas;
                    resolve(this);
                  });
                }
                /**
                 * Load the underlying media
                 * @param {HTMLCanvasElement} canvas
                 * @returns {SpeedyPromise<SpeedyMediaSource>}
                 */
                static load(canvas) {
                  return new SpeedyCanvasMediaSource(PRIVATE_TOKEN)._load(canvas);
                }
              }
              class SpeedyOffscreenCanvasMediaSource extends SpeedyMediaSource {
                /**
                 * @private Constructor
                 * @param {symbol} token
                 */
                constructor(token) {
                  super(token);
                  this._data = null;
                }
                /**
                 * The underlying wrapped object
                 * @returns {OffscreenCanvas}
                 */
                get data() {
                  return this._data;
                }
                /**
                 * The type of the underlying media source
                 * @returns {MediaType}
                 */
                get type() {
                  return types.zu.OffscreenCanvas;
                }
                /**
                 * Media width, in pixels
                 * @returns {number}
                 */
                get width() {
                  return this._data ? this._data.width : 0;
                }
                /**
                 * Media height, in pixels
                 * @returns {number}
                 */
                get height() {
                  return this._data ? this._data.height : 0;
                }
                /**
                 * Clone this media source
                 * @returns {SpeedyPromise<SpeedyMediaSource>}
                 */
                clone() {
                  if (this._data == null) throw new utils_errors.Er(`Media not loaded`);
                  const newCanvas = new OffscreenCanvas(this.width, this.height);
                  const newContext = newCanvas.getContext("2d");
                  newContext.drawImage(this._data, 0, 0);
                  return SpeedyOffscreenCanvasMediaSource.load(newCanvas);
                }
                /**
                 * Load the underlying media
                 * @param {OffscreenCanvas} offscreenCanvas
                 * @returns {SpeedyPromise<SpeedyMediaSource>}
                 */
                _load(offscreenCanvas) {
                  if (this.isLoaded()) this.release();
                  return new speedy_promise.i((resolve) => {
                    this._data = offscreenCanvas;
                    resolve(this);
                  });
                }
                /**
                 * Load the underlying media
                 * @param {OffscreenCanvas} offscreenCanvas
                 * @returns {SpeedyPromise<SpeedyMediaSource>}
                 */
                static load(offscreenCanvas) {
                  return new SpeedyOffscreenCanvasMediaSource(PRIVATE_TOKEN)._load(offscreenCanvas);
                }
              }
              class SpeedyBitmapMediaSource extends SpeedyMediaSource {
                /**
                 * @private Constructor
                 * @param {symbol} token
                 */
                constructor(token) {
                  super(token);
                  this._data = null;
                }
                /**
                 * The underlying wrapped object
                 * @returns {ImageBitmap}
                 */
                get data() {
                  return this._data;
                }
                /**
                 * The type of the underlying media source
                 * @returns {MediaType}
                 */
                get type() {
                  return types.zu.Bitmap;
                }
                /**
                 * Media width, in pixels
                 * @returns {number}
                 */
                get width() {
                  return this._data ? this._data.width : 0;
                }
                /**
                 * Media height, in pixels
                 * @returns {number}
                 */
                get height() {
                  return this._data ? this._data.height : 0;
                }
                /**
                 * Clone this media source
                 * @returns {SpeedyPromise<SpeedyMediaSource>}
                 */
                clone() {
                  if (this._data == null) throw new utils_errors.Er(`Media not loaded`);
                  return new speedy_promise.i((resolve, reject) => {
                    createImageBitmap(this._data).then((newBitmap) => {
                      const newSource = new SpeedyBitmapMediaSource(PRIVATE_TOKEN);
                      newSource._load(newBitmap).then(resolve, reject);
                    }, reject);
                  });
                }
                /**
                 * Release resources associated with this object
                 * @returns {null}
                 */
                release() {
                  if (this._data != null) this._data.close();
                  return super.release();
                }
                /**
                 * Load the underlying media
                 * @param {ImageBitmap} bitmap
                 * @returns {SpeedyPromise<SpeedyMediaSource>}
                 */
                _load(bitmap) {
                  if (this.isLoaded()) this.release();
                  return new speedy_promise.i((resolve) => {
                    this._data = bitmap;
                    resolve(this);
                  });
                }
                /**
                 * Load the underlying media
                 * @param {ImageBitmap} bitmap
                 * @returns {SpeedyPromise<SpeedyMediaSource>}
                 */
                static load(bitmap) {
                  return new SpeedyBitmapMediaSource(PRIVATE_TOKEN)._load(bitmap);
                }
              }
              class SpeedyDataMediaSource extends SpeedyMediaSource {
                /**
                 * @private Constructor
                 * @param {symbol} token
                 */
                constructor(token) {
                  super(token);
                  this._data = null;
                }
                /**
                 * The underlying wrapped object
                 * @returns {ImageData}
                 */
                get data() {
                  return this._data;
                }
                /**
                 * The type of the underlying media source
                 * @returns {MediaType}
                 */
                get type() {
                  return types.zu.Data;
                }
                /**
                 * Media width, in pixels
                 * @returns {number}
                 */
                get width() {
                  return this._data ? this._data.width : 0;
                }
                /**
                 * Media height, in pixels
                 * @returns {number}
                 */
                get height() {
                  return this._data ? this._data.height : 0;
                }
                /**
                 * Clone this media source
                 * @returns {SpeedyPromise<SpeedyMediaSource>}
                 */
                clone() {
                  if (this._data == null) throw new utils_errors.Er(`Media not loaded`);
                  const imageDataCopy = new ImageData(new Uint8ClampedArray(this._data.data), this._data.width, this._data.height);
                  return SpeedyDataMediaSource.load(imageDataCopy);
                }
                /**
                 * Load the underlying media
                 * @param {ImageData} imageData
                 * @returns {SpeedyPromise<SpeedyMediaSource>}
                 */
                _load(imageData) {
                  if (this.isLoaded()) this.release();
                  return new speedy_promise.i((resolve) => {
                    this._data = imageData;
                    resolve(this);
                  });
                }
                /**
                 * Load the underlying media
                 * @param {ImageData} imageData
                 * @returns {SpeedyPromise<SpeedyMediaSource>}
                 */
                static load(imageData) {
                  return new SpeedyDataMediaSource(PRIVATE_TOKEN)._load(imageData);
                }
              }
              var observable = __webpack_require__(3211);
              ;
              class SpeedyGPU extends observable.c {
                /**
                 * Constructor
                 */
                constructor() {
                  super();
                  this._speedyGL = speedy_gl.c.instance;
                  this._programs = new SpeedyProgramCenter(this);
                  this._texturePool = new SpeedyTexturePool(this);
                  this._speedyGL.subscribe(this._reset, this);
                }
                /**
                 * Access point to all GPU programs
                 * @returns {SpeedyProgramCenter}
                 */
                get programs() {
                  return this._programs;
                }
                /**
                 * The WebGL Rendering Context
                 * Be careful not to cache this, as the WebGL Rendering Context may be lost!
                 * @returns {WebGL2RenderingContext}
                 */
                get gl() {
                  return this._speedyGL.gl;
                }
                /**
                 * Internal canvas
                 * @returns {HTMLCanvasElement}
                 */
                get canvas() {
                  return this._speedyGL.canvas;
                }
                /**
                 * Texture pool
                 * @returns {SpeedyTexturePool}
                 */
                get texturePool() {
                  return this._texturePool;
                }
                /**
                 * Renders a texture to the canvas
                 * @param {SpeedyTexture} texture
                 * @returns {HTMLCanvasElement} returned for convenience
                 */
                renderToCanvas(texture) {
                  const width = texture.width;
                  const height = texture.height;
                  const canvas = this.canvas;
                  if (width > canvas.width || height > canvas.height) {
                    utils.A.warning(`Resizing the canvas to ${width} x ${height}`);
                    canvas.width = width;
                    canvas.height = height;
                  }
                  this.programs.utils.renderToCanvas.outputs(width, height, null);
                  this.programs.utils.renderToCanvas(texture);
                  return canvas;
                }
                /**
                 * Upload an image to the GPU
                 * @param {SpeedyMediaSource} source
                 * @param {SpeedyTexture} outputTexture
                 * @returns {SpeedyTexture} outputTexture
                 */
                upload(source, outputTexture) {
                  return outputTexture.upload(source.data, source.width, source.height);
                }
                /**
                 * Releases resources
                 * @returns {null}
                 */
                release() {
                  utils.A.assert(!this.isReleased());
                  this._programs = this._programs.release();
                  this._texturePool = this._texturePool.release();
                  this._speedyGL.unsubscribe(this._reset);
                  return null;
                }
                /**
                 * Has this SpeedyGPU been released?
                 * @returns {boolean}
                 */
                isReleased() {
                  return this._programs == null;
                }
                /**
                 * Lose & restore the WebGL context (useful for testing purposes)
                 * @return {SpeedyPromise<void>} resolves as soon as the context is restored
                 */
                loseAndRestoreWebGLContext() {
                  return this._speedyGL.loseAndRestoreContext().then(() => void 0);
                }
                /**
                 * Reset the internal state
                 * (called on context reset)
                 */
                _reset() {
                  if (this.isReleased()) return;
                  this._programs = new SpeedyProgramCenter(this);
                  this._texturePool = new SpeedyTexturePool(this);
                  this._notify();
                }
              }
              ;
              class SpeedySize {
                /**
                 * Constructor
                 * @param {number} width non-negative number
                 * @param {number} height non-negative number
                 */
                constructor(width, height) {
                  this._width = Math.max(0, +width);
                  this._height = Math.max(0, +height);
                }
                //
                // ===== METHODS =====
                //
                /**
                 * Width
                 * @returns {number}
                 */
                get width() {
                  return this._width;
                }
                /**
                 * Width
                 * @param {number} value
                 */
                set width(value) {
                  this._width = Math.max(0, +value);
                }
                /**
                 * Height
                 * @returns {number}
                 */
                get height() {
                  return this._height;
                }
                /**
                 * Height
                 * @param {number} value
                 */
                set height(value) {
                  this._height = Math.max(0, +value);
                }
                /**
                 * Convert to string
                 * @returns {string}
                 */
                toString() {
                  return `SpeedySize(${this.width}, ${this.height})`;
                }
                /**
                 * Is this size equal to anotherSize?
                 * @param {SpeedySize} anotherSize
                 * @returns {boolean}
                 */
                equals(anotherSize) {
                  return this.width === anotherSize.width && this.height === anotherSize.height;
                }
                /**
                 * The area of the rectangle
                 * @returns {number}
                 */
                area() {
                  return this.width * this.height;
                }
              }
              ;
              const speedy_media_PRIVATE_TOKEN = Symbol();
              class SpeedyMedia {
                /**
                 * @private Constructor. It receives a VALID media source that is ALREADY LOADED.
                 * @param {symbol} token
                 * @param {SpeedyMediaSource} source
                 * @param {SpeedyMediaOptions} [options] options object
                 */
                constructor(token, source, options = {}) {
                  if (token !== speedy_media_PRIVATE_TOKEN) throw new utils_errors.Er();
                  this._source = source;
                  this._format = options.format !== void 0 ? options.format : types.f5.RGBA;
                  this._options = Object.freeze(Object.assign(Object.assign({}, options), {}, {
                    format: this._format
                  }));
                  if (!source.isLoaded()) throw new utils_errors.Er(`Source not loaded: ${source}`);
                  else if (this._format !== types.f5.RGBA && this._format !== types.f5.GREY) throw new utils_errors.qw(`Invalid format: ${this._format}`);
                }
                /**
                 * Load a media source
                 * Will wait until the HTML media source is loaded
                 * @param {SpeedyMediaSourceNativeElement} mediaSource An image, video or canvas
                 * @param {SpeedyMediaOptions} [options] options object
                 * @param {boolean} [log] show log message?
                 * @returns {SpeedyPromise<SpeedyMedia>}
                 */
                static load(mediaSource, options = {}, log = true) {
                  return SpeedyMediaSource.load(mediaSource).then((source) => {
                    utils.A.assert(source.width !== 0 && source.height !== 0);
                    const media = new SpeedyMedia(speedy_media_PRIVATE_TOKEN, source, options);
                    if (log) utils.A.log(`Loaded SpeedyMedia with a ${mediaSource}.`);
                    return media;
                  });
                }
                /**
                 * The media element (image, video, canvas) encapsulated by this SpeedyMedia object
                 * @returns {SpeedyMediaSourceNativeElement} the media element
                 */
                get source() {
                  return this._source ? this._source.data : null;
                }
                /**
                 * The type of the media attached to this SpeedyMedia object
                 * @returns {"image" | "video" | "canvas" | "offscreen-canvas" | "bitmap" | "data" | "unknown"}
                 */
                get type() {
                  if (this.isReleased()) return "unknown";
                  switch (this._source.type) {
                    case types.zu.Image:
                      return "image";
                    case types.zu.Video:
                      return "video";
                    case types.zu.Canvas:
                      return "canvas";
                    case types.zu.OffscreenCanvas:
                      return "offscreen-canvas";
                    case types.zu.Bitmap:
                      return "bitmap";
                    case types.zu.Data:
                      return "data";
                    default:
                      return "unknown";
                  }
                }
                /**
                 * Gets the width of the media
                 * @returns {number} media width
                 */
                get width() {
                  return this._source ? this._source.width : 0;
                }
                /**
                 * Gets the height of the media
                 * @returns {number} media height
                 */
                get height() {
                  return this._source ? this._source.height : 0;
                }
                /**
                 * The size of this media, in pixels
                 * @returns {SpeedySize}
                 */
                get size() {
                  return this._source ? new SpeedySize(this._source.width, this._source.height) : new SpeedySize(0, 0);
                }
                /**
                 * Returns a read-only object featuring advanced options
                 * related to this SpeedyMedia object
                 * @returns {SpeedyMediaOptions}
                 */
                get options() {
                  return this._options;
                }
                /**
                 * Releases resources associated with this media
                 * @returns {null}
                 */
                release() {
                  if (!this.isReleased()) {
                    utils.A.log("Releasing SpeedyMedia object...");
                    this._source = this._source.release();
                  }
                  return null;
                }
                /**
                 * Has this media been released?
                 * @returns {boolean}
                 */
                isReleased() {
                  return this._source == null;
                }
                /**
                 * Clones the SpeedyMedia object
                 * @returns {SpeedyPromise<SpeedyMedia>} a clone object
                 */
                clone() {
                  if (this.isReleased()) throw new utils_errors.Er(`Can't clone a SpeedyMedia that has been released`);
                  const clone = new SpeedyMedia(speedy_media_PRIVATE_TOKEN, this._source, this._options);
                  return speedy_promise.i.resolve(clone);
                }
                /**
                 * Converts the media to an ImageBitmap
                 * @returns {SpeedyPromise<ImageBitmap>}
                 */
                toBitmap() {
                  if (this.isReleased()) throw new utils_errors.Er("Can't convert SpeedyMedia to ImageBitmap: the media has been released");
                  else if (!this._source.isLoaded()) throw new utils_errors.Er("Can't convert SpeedyMedia to bitmap: the media hasn't been loaded");
                  else if (this._source.type == types.zu.Bitmap) return speedy_promise.i.resolve(this._source.data);
                  else return new speedy_promise.i((resolve, reject) => createImageBitmap(this._source.data).then(resolve, reject));
                }
              }
              ;
              class SpeedyPlatform extends speedy_namespace.Q {
                /**
                 * Renderer string of the graphics driver
                 * @returns {string}
                 */
                static get renderer() {
                  return speedy_gl.c.instance.renderer;
                }
                /**
                 * Vendor string of the graphics driver
                 * @returns {string}
                 */
                static get vendor() {
                  return speedy_gl.c.instance.vendor;
                }
              }
              ;
              class SpeedyVector2 {
                /**
                 * Create a 2D vector
                 * @param {number} x
                 * @param {number} y
                 */
                constructor(x, y) {
                  this._x = +x;
                  this._y = +y;
                }
                //
                // ===== METHODS =====
                //
                /**
                 * x-coordinate
                 * @returns {number}
                 */
                get x() {
                  return this._x;
                }
                /**
                 * x-coordinate
                 * @param {number} value
                 */
                set x(value) {
                  this._x = +value;
                }
                /**
                 * y-coordinate
                 * @returns {number}
                 */
                get y() {
                  return this._y;
                }
                /**
                 * y-coordinate
                 * @param {number} value
                 */
                set y(value) {
                  this._y = +value;
                }
                /**
                 * Convert to string
                 * @returns {string}
                 */
                toString() {
                  return `SpeedyVector2(${this.x.toFixed(5)}, ${this.y.toFixed(5)})`;
                }
                /**
                 * Is this vector equal to v?
                 * @param {SpeedyVector2} v
                 * @returns {boolean}
                 */
                equals(v) {
                  return this.x === v.x && this.y === v.y;
                }
                /**
                 * Dot product between this vector and another vector
                 * @param {SpeedyVector2} v another vector
                 * @returns {number}
                 */
                dot(v) {
                  return this.x * v.x + this.y * v.y;
                }
                /**
                 * The distance between this vector and another vector
                 * @param {SpeedyVector2} v another vector
                 * @returns {number}
                 */
                distanceTo(v) {
                  const dx = this.x - v.x;
                  const dy = this.y - v.y;
                  return Math.sqrt(dx * dx + dy * dy);
                }
                /**
                 * Euclidean norm
                 * @returns {number}
                 */
                length() {
                  return Math.sqrt(this.x * this.x + this.y * this.y);
                }
                /**
                 * Returns a normalized version of this vector
                 * @returns {SpeedyVector2}
                 */
                normalized() {
                  const len = this.length();
                  if (len > 0) return new SpeedyVector2(this.x / len, this.y / len);
                  else return new SpeedyVector2(0, 0);
                }
                /**
                 * Returns a copy of this vector translated by offset
                 * @param {SpeedyVector2} offset
                 * @returns {SpeedyVector2}
                 */
                plus(offset) {
                  return new SpeedyVector2(this.x + offset.x, this.y + offset.y);
                }
                /**
                 * Returns a copy of this vector translated by -offset
                 * @param {SpeedyVector2} offset
                 * @returns {SpeedyVector2}
                 */
                minus(offset) {
                  return new SpeedyVector2(this.x - offset.x, this.y - offset.y);
                }
                /**
                 * Returns a copy of this vector scaled by a scalar
                 * @param {number} scalar
                 * @returns {SpeedyVector2}
                 */
                times(scalar) {
                  return new SpeedyVector2(this.x * scalar, this.y * scalar);
                }
              }
              ;
              class SpeedyPoint2 {
                /**
                 * Create a 2D point
                 * @param {number} x
                 * @param {number} y
                 */
                constructor(x, y) {
                  this._x = +x;
                  this._y = +y;
                }
                //
                // ===== METHODS =====
                //
                /**
                 * x-coordinate
                 * @returns {number}
                 */
                get x() {
                  return this._x;
                }
                /**
                 * x-coordinate
                 * @param {number} value
                 */
                set x(value) {
                  this._x = +value;
                }
                /**
                 * y-coordinate
                 * @returns {number}
                 */
                get y() {
                  return this._y;
                }
                /**
                 * y-coordinate
                 * @param {number} value
                 */
                set y(value) {
                  this._y = +value;
                }
                /**
                 * Convert to string
                 * @returns {string}
                 */
                toString() {
                  return `SpeedyPoint2(${this.x.toFixed(5)}, ${this.y.toFixed(5)})`;
                }
                /**
                 * Add a vector to this point
                 * @param {SpeedyVector2} v 
                 * @returns {SpeedyPoint2}
                 */
                plus(v) {
                  return new SpeedyPoint2(this.x + v.x, this.y + v.y);
                }
                /**
                 * Subtracts a point p from this point
                 * @param {SpeedyPoint2} p 
                 * @returns {SpeedyVector2}
                 */
                minus(p) {
                  return new SpeedyVector2(this.x - p.x, this.y - p.y);
                }
                /**
                 * Is this point equal to p?
                 * @param {SpeedyPoint2} p
                 * @returns {boolean}
                 */
                equals(p) {
                  return this.x === p.x && this.y === p.y;
                }
              }
              var speedy_matrix_expr = __webpack_require__(6306);
              var speedy_matrix_wasm = __webpack_require__(6465);
              var speedy_matrix = __webpack_require__(4188);
              ;
              class SpeedyMatrixFactory extends Function {
                /**
                 * Constructor
                 */
                constructor() {
                  super("...args", "return args.length > 1 ? this._create(...args) : this._from(args[0])");
                  return this.bind(this);
                }
                /**
                 * @private
                 *
                 * Create a new matrix filled with the specified size and entries
                 * @param {number} rows
                 * @param {number} [columns]
                 * @param {number[]} [entries] in column-major format
                 * @returns {SpeedyMatrix}
                 */
                _create(rows, columns = rows, entries = []) {
                  return speedy_matrix.SpeedyMatrix.Create(rows, columns, entries);
                }
                /**
                 * @private
                 *
                 * Evaluate an expression synchronously and store the result in a new matrix
                 * @param {SpeedyMatrixExpr} expr matrix expression
                 * @returns {SpeedyMatrix}
                 */
                _from(expr) {
                  return speedy_matrix.SpeedyMatrix.From(expr);
                }
                /**
                 * Create a new matrix filled with zeros with the specified size
                 * @param {number} rows
                 * @param {number} [columns]
                 * @returns {SpeedyMatrix}
                 */
                Zeros(rows, columns = rows) {
                  return speedy_matrix.SpeedyMatrix.Zeros(rows, columns);
                }
                /**
                 * Create a new matrix filled with ones with the specified size
                 * @param {number} rows
                 * @param {number} [columns]
                 * @returns {SpeedyMatrix}
                 */
                Ones(rows, columns = rows) {
                  return speedy_matrix.SpeedyMatrix.Ones(rows, columns);
                }
                /**
                 * Create an identity matrix with the specified size
                 * @param {number} rows
                 * @param {number} [columns]
                 * @returns {SpeedyMatrix}
                 */
                Eye(rows, columns = rows) {
                  return speedy_matrix.SpeedyMatrix.Eye(rows, columns);
                }
                /**
                 * Returns a promise that resolves immediately if the WebAssembly routines
                 * are ready to be used, or as soon as they do become ready
                 * @returns {SpeedyPromise<void>}
                 */
                ready() {
                  return speedy_matrix.SpeedyMatrix.ready();
                }
                /**
                 * QR decomposition
                 * @param {SpeedyMatrix} Q is m x n (reduced) or m x m (full), output
                 * @param {SpeedyMatrix} R is n x n (reduced) or m x n (full), output
                 * @param {SpeedyMatrix} mat is m x n, input
                 * @param {object} [options]
                 * @param {'reduced'|'full'} [options.mode]
                 * @returns {SpeedyPromise<[SpeedyMatrix,SpeedyMatrix]>} resolves to [Q,R]
                 */
                qr(Q, R, mat, {
                  mode = "reduced"
                } = {}) {
                  const A = mat, m = mat.rows, n = mat.columns;
                  if (mode == "reduced") {
                    if (Q.rows != m || Q.columns != n || R.rows != n || R.columns != n) throw new utils_errors.qw(`Invalid shape for reduced QR`);
                  } else if (mode == "full") {
                    if (Q.rows != m || Q.columns != m || R.rows != m || R.columns != n) throw new utils_errors.qw(`Invalid shape for full QR`);
                  } else throw new utils_errors.qw(`Invalid mode for QR: "${mode}"`);
                  return speedy_matrix_wasm.U.ready().then(({
                    wasm,
                    memory
                  }) => {
                    const Qptr = speedy_matrix_wasm.U.allocateMat32(wasm, memory, Q);
                    const Rptr = speedy_matrix_wasm.U.allocateMat32(wasm, memory, R);
                    const Aptr = speedy_matrix_wasm.U.allocateMat32(wasm, memory, A);
                    speedy_matrix_wasm.U.copyToMat32(wasm, memory, Aptr, A);
                    if (mode == "reduced") wasm.exports.Mat32_qr_reduced(Qptr, Rptr, Aptr);
                    else wasm.exports.Mat32_qr_full(Qptr, Rptr, Aptr);
                    speedy_matrix_wasm.U.copyFromMat32(wasm, memory, Qptr, Q);
                    speedy_matrix_wasm.U.copyFromMat32(wasm, memory, Rptr, R);
                    speedy_matrix_wasm.U.deallocateMat32(wasm, memory, Aptr);
                    speedy_matrix_wasm.U.deallocateMat32(wasm, memory, Rptr);
                    speedy_matrix_wasm.U.deallocateMat32(wasm, memory, Qptr);
                    return [Q, R];
                  });
                }
                /**
                 * Solve a possibly overdetermined system of linear
                 * equations Ax = b for x using ordinary least squares
                 * @param {SpeedyMatrix} solution n x 1, output
                 * @param {SpeedyMatrix} A m x n, m >= n, input
                 * @param {SpeedyMatrix} b m x 1, output
                 * @param {object} [options]
                 * @param {'qr'} [options.method] method of resolution
                 * @returns {SpeedyPromise<SpeedyMatrix>} resolves to solution
                 */
                ols(solution, A, b, {
                  method = "qr"
                } = {}) {
                  const m = A.rows, n = A.columns;
                  const x = solution;
                  if (m < n || n == 0) throw new utils_errors.qw(`Can't solve an underdetermined system of equations`);
                  else if (b.rows != m || b.columns != 1 || x.rows != n || x.columns != 1) throw new utils_errors.qw(`Invalid shapes`);
                  return speedy_matrix_wasm.U.ready().then(({
                    wasm,
                    memory
                  }) => {
                    const Aptr = speedy_matrix_wasm.U.allocateMat32(wasm, memory, A);
                    const bptr = speedy_matrix_wasm.U.allocateMat32(wasm, memory, b);
                    const xptr = speedy_matrix_wasm.U.allocateMat32(wasm, memory, x);
                    speedy_matrix_wasm.U.copyToMat32(wasm, memory, Aptr, A);
                    speedy_matrix_wasm.U.copyToMat32(wasm, memory, bptr, b);
                    switch (method) {
                      case "qr":
                        wasm.exports.Mat32_qr_ols(xptr, Aptr, bptr, 2);
                        break;
                      default:
                        throw new utils_errors.qw(`Invalid method: "${method}"`);
                    }
                    speedy_matrix_wasm.U.copyFromMat32(wasm, memory, xptr, x);
                    speedy_matrix_wasm.U.deallocateMat32(wasm, memory, xptr);
                    speedy_matrix_wasm.U.deallocateMat32(wasm, memory, bptr);
                    speedy_matrix_wasm.U.deallocateMat32(wasm, memory, Aptr);
                    return solution;
                  });
                }
                /**
                 * Solve a system of linear equations Ax = b for x
                 * @param {SpeedyMatrix} solution m x 1, output
                 * @param {SpeedyMatrix} A m x m, input
                 * @param {SpeedyMatrix} b m x 1, output
                 * @param {object} [options]
                 * @param {'qr'} [options.method] method of resolution
                 * @returns {SpeedyPromise<SpeedyMatrix>} resolves to solution
                 */
                solve(solution, A, b, {
                  method = "qr"
                } = {}) {
                  const m = A.rows, n = A.columns;
                  const x = solution;
                  if (m != n) throw new utils_errors.qw(`Can't solve an over or underdetermined system of equations`);
                  else if (b.rows != m || b.columns != 1 || x.rows != m || x.columns != 1) throw new utils_errors.qw(`Invalid shapes`);
                  return speedy_matrix_wasm.U.ready().then(({
                    wasm,
                    memory
                  }) => {
                    switch (method) {
                      case "qr":
                        return this.ols(x, A, b, {
                          method
                        });
                      /*case 'lu':
                          break;*/
                      default:
                        throw new utils_errors.qw(`Invalid method: "${method}"`);
                    }
                  });
                }
                /**
                 * Compute a perspective transformation using 4 correspondences of points
                 * @param {SpeedyMatrix} homography 3x3 output - homography matrix
                 * @param {SpeedyMatrix} src 2x4 input points - source coordinates
                 * @param {SpeedyMatrix} dest 2x4 input points - destination coordinates
                 * @returns {SpeedyPromise<SpeedyMatrix>} resolves to homography
                 */
                perspective(homography, src, dest) {
                  if (src.rows != 2 || src.columns != 4 || dest.rows != 2 || dest.columns != 4) throw new utils_errors.qw(`You need two 2x4 input matrices to compute a perspective transformation`);
                  else if (homography.rows != 3 || homography.columns != 3) throw new utils_errors.qw(`The output of perspective() is a 3x3 homography`);
                  return speedy_matrix_wasm.U.ready().then(({
                    wasm,
                    memory
                  }) => {
                    const homptr = speedy_matrix_wasm.U.allocateMat32(wasm, memory, homography);
                    const srcptr = speedy_matrix_wasm.U.allocateMat32(wasm, memory, src);
                    const destptr = speedy_matrix_wasm.U.allocateMat32(wasm, memory, dest);
                    speedy_matrix_wasm.U.copyToMat32(wasm, memory, srcptr, src);
                    speedy_matrix_wasm.U.copyToMat32(wasm, memory, destptr, dest);
                    wasm.exports.Mat32_homography_ndlt4(homptr, srcptr, destptr);
                    speedy_matrix_wasm.U.copyFromMat32(wasm, memory, homptr, homography);
                    speedy_matrix_wasm.U.deallocateMat32(wasm, memory, destptr);
                    speedy_matrix_wasm.U.deallocateMat32(wasm, memory, srcptr);
                    speedy_matrix_wasm.U.deallocateMat32(wasm, memory, homptr);
                    return homography;
                  });
                }
                /**
                 * Compute a perspective transformation using n >= 4 correspondences of points
                 * @param {SpeedyMatrix} homography 3x3 output - homography matrix
                 * @param {SpeedyMatrix} src 2 x n input points - source coordinates
                 * @param {SpeedyMatrix} dest 2 x n input points - destination coordinates
                 * @param {object} [options]
                 * @param {'default'|'pransac'} [options.method] method of computation
                 * @param {SpeedyMatrix|null} [options.mask] (pransac) 1 x n output: i-th entry will be 1 if the i-th input point is an inlier, or 0 otherwise
                 * @param {number} [options.reprojectionError] (pransac) given in pixels, used to separate inliers from outliers of a particular model (e.g., 1 pixel)
                 * @param {number} [options.numberOfHypotheses] (pransac) number of hypotheses to be generated up-front (e.g., 512)
                 * @param {number} [options.bundleSize] (pransac) how many points should we check before reducing the number of viable hypotheses (e.g., 128)
                 * @returns {SpeedyPromise<SpeedyMatrix>} resolves to homography
                 */
                findHomography(homography, src, dest, {
                  method = "default",
                  mask = null,
                  reprojectionError = 3,
                  numberOfHypotheses = 512,
                  bundleSize = 128
                } = {}) {
                  if (src.rows != 2 || src.columns < 4 || dest.rows != 2 || dest.columns != src.columns) throw new utils_errors.qw(`You need two 2 x n (n >= 4) input matrices to compute a homography`);
                  else if (homography.rows != 3 || homography.columns != 3) throw new utils_errors.qw(`The output of findHomography() is a 3x3 homography`);
                  else if (mask != null && (mask.rows != 1 || mask.columns != src.columns)) throw new utils_errors.qw(`Invalid shape of the inliers mask`);
                  return speedy_matrix_wasm.U.ready().then(({
                    wasm,
                    memory
                  }) => {
                    const homptr = speedy_matrix_wasm.U.allocateMat32(wasm, memory, homography);
                    const srcptr = speedy_matrix_wasm.U.allocateMat32(wasm, memory, src);
                    const destptr = speedy_matrix_wasm.U.allocateMat32(wasm, memory, dest);
                    const maskptr = mask != null ? speedy_matrix_wasm.U.allocateMat32(wasm, memory, mask) : 0;
                    speedy_matrix_wasm.U.copyToMat32(wasm, memory, srcptr, src);
                    speedy_matrix_wasm.U.copyToMat32(wasm, memory, destptr, dest);
                    switch (method) {
                      case "pransac":
                        utils.A.assert(reprojectionError >= 0 && numberOfHypotheses > 0 && bundleSize > 0);
                        wasm.exports.Mat32_pransac_homography(homptr, maskptr, srcptr, destptr, numberOfHypotheses, bundleSize, reprojectionError);
                        break;
                      case "default":
                      case "dlt":
                        wasm.exports.Mat32_homography_ndlt(homptr, srcptr, destptr);
                        break;
                      default:
                        throw new utils_errors.qw(`Illegal method for findHomography(): "${method}"`);
                    }
                    speedy_matrix_wasm.U.copyFromMat32(wasm, memory, homptr, homography);
                    if (mask != null) speedy_matrix_wasm.U.copyFromMat32(wasm, memory, maskptr, mask);
                    if (mask != null) speedy_matrix_wasm.U.deallocateMat32(wasm, memory, maskptr);
                    speedy_matrix_wasm.U.deallocateMat32(wasm, memory, destptr);
                    speedy_matrix_wasm.U.deallocateMat32(wasm, memory, srcptr);
                    speedy_matrix_wasm.U.deallocateMat32(wasm, memory, homptr);
                    return homography;
                  });
                }
                /**
                 * Apply a perspective transformation to a set of 2D points
                 * @param {SpeedyMatrix} dest 2 x n output matrix
                 * @param {SpeedyMatrix} src 2 x n input matrix (a set of points)
                 * @param {SpeedyMatrix} transform 3x3 homography matrix
                 * @returns {SpeedyPromise<SpeedyMatrix>} resolves to dest
                 */
                applyPerspectiveTransform(dest, src, transform) {
                  if (src.rows != 2 || dest.rows != 2 || src.columns != dest.columns) throw new utils_errors.qw(`Invalid shapes`);
                  else if (transform.rows != 3 || transform.columns != 3) throw new utils_errors.qw(`The perspective transformation must be a 3x3 matrix`);
                  return speedy_matrix_wasm.U.ready().then(({
                    wasm,
                    memory
                  }) => {
                    const matptr = speedy_matrix_wasm.U.allocateMat32(wasm, memory, transform);
                    const srcptr = speedy_matrix_wasm.U.allocateMat32(wasm, memory, src);
                    const destptr = speedy_matrix_wasm.U.allocateMat32(wasm, memory, dest);
                    speedy_matrix_wasm.U.copyToMat32(wasm, memory, srcptr, src);
                    speedy_matrix_wasm.U.copyToMat32(wasm, memory, matptr, transform);
                    wasm.exports.Mat32_transform_perspective(destptr, srcptr, matptr);
                    speedy_matrix_wasm.U.copyFromMat32(wasm, memory, destptr, dest);
                    speedy_matrix_wasm.U.deallocateMat32(wasm, memory, destptr);
                    speedy_matrix_wasm.U.deallocateMat32(wasm, memory, srcptr);
                    speedy_matrix_wasm.U.deallocateMat32(wasm, memory, matptr);
                    return dest;
                  });
                }
                /**
                 * Compute an affine transform using 3 correspondences of points
                 * @param {SpeedyMatrix} transform 2x3 output - affine transform
                 * @param {SpeedyMatrix} src 2x3 input points - source coordinates
                 * @param {SpeedyMatrix} dest 2x3 input points - destination coordinates
                 * @returns {SpeedyPromise<SpeedyMatrix>} resolves to homography
                 */
                affine(transform, src, dest) {
                  if (src.rows != 2 || src.columns != 3 || dest.rows != 2 || dest.columns != 3) throw new utils_errors.qw(`You need two 2x3 input matrices to compute an affine transform`);
                  else if (transform.rows != 2 || transform.columns != 3) throw new utils_errors.qw(`The output of affine() is a 2x3 matrix`);
                  return speedy_matrix_wasm.U.ready().then(({
                    wasm,
                    memory
                  }) => {
                    const matptr = speedy_matrix_wasm.U.allocateMat32(wasm, memory, transform);
                    const srcptr = speedy_matrix_wasm.U.allocateMat32(wasm, memory, src);
                    const destptr = speedy_matrix_wasm.U.allocateMat32(wasm, memory, dest);
                    speedy_matrix_wasm.U.copyToMat32(wasm, memory, srcptr, src);
                    speedy_matrix_wasm.U.copyToMat32(wasm, memory, destptr, dest);
                    wasm.exports.Mat32_affine_direct3(matptr, srcptr, destptr);
                    speedy_matrix_wasm.U.copyFromMat32(wasm, memory, matptr, transform);
                    speedy_matrix_wasm.U.deallocateMat32(wasm, memory, destptr);
                    speedy_matrix_wasm.U.deallocateMat32(wasm, memory, srcptr);
                    speedy_matrix_wasm.U.deallocateMat32(wasm, memory, matptr);
                    return transform;
                  });
                }
                /**
                 * Compute an affine transformation using n >= 3 correspondences of points
                 * @param {SpeedyMatrix} transform 2x3 output - affine transform
                 * @param {SpeedyMatrix} src 2 x n input points - source coordinates
                 * @param {SpeedyMatrix} dest 2 x n input points - destination coordinates
                 * @param {object} [options]
                 * @param {'default'|'pransac'} [options.method] method of computation
                 * @param {SpeedyMatrix|null} [options.mask] (pransac) 1 x n output: i-th entry will be 1 if the i-th input point is an inlier, or 0 otherwise
                 * @param {number} [options.reprojectionError] (pransac) given in pixels, used to separate inliers from outliers of a particular model (e.g., 1 pixel)
                 * @param {number} [options.numberOfHypotheses] (pransac) number of hypotheses to be generated up-front (e.g., 512)
                 * @param {number} [options.bundleSize] (pransac) how many points should we check before reducing the number of viable hypotheses (e.g., 128)
                 * @returns {SpeedyPromise<SpeedyMatrix>} resolves to an affine transform
                 */
                findAffineTransform(transform, src, dest, {
                  method = "default",
                  mask = null,
                  reprojectionError = 3,
                  numberOfHypotheses = 512,
                  bundleSize = 128
                } = {}) {
                  if (src.rows != 2 || src.columns < 3 || dest.rows != 2 || dest.columns != src.columns) throw new utils_errors.qw(`You need two 2 x n (n >= 3) input matrices to compute an affine transform`);
                  else if (transform.rows != 2 || transform.columns != 3) throw new utils_errors.qw(`The output of findAffineTransform() is a 2x3 matrix`);
                  else if (mask != null && (mask.rows != 1 || mask.columns != src.columns)) throw new utils_errors.qw(`Invalid shape of the inliers mask`);
                  return speedy_matrix_wasm.U.ready().then(({
                    wasm,
                    memory
                  }) => {
                    const matptr = speedy_matrix_wasm.U.allocateMat32(wasm, memory, transform);
                    const srcptr = speedy_matrix_wasm.U.allocateMat32(wasm, memory, src);
                    const destptr = speedy_matrix_wasm.U.allocateMat32(wasm, memory, dest);
                    const maskptr = mask != null ? speedy_matrix_wasm.U.allocateMat32(wasm, memory, mask) : 0;
                    speedy_matrix_wasm.U.copyToMat32(wasm, memory, srcptr, src);
                    speedy_matrix_wasm.U.copyToMat32(wasm, memory, destptr, dest);
                    switch (method) {
                      case "pransac":
                        utils.A.assert(reprojectionError >= 0 && numberOfHypotheses > 0 && bundleSize > 0);
                        wasm.exports.Mat32_pransac_affine(matptr, maskptr, srcptr, destptr, numberOfHypotheses, bundleSize, reprojectionError);
                        break;
                      case "default":
                        wasm.exports.Mat32_affine_direct(matptr, srcptr, destptr);
                        break;
                      default:
                        throw new utils_errors.qw(`Illegal method for findAffineTransform(): "${method}"`);
                    }
                    speedy_matrix_wasm.U.copyFromMat32(wasm, memory, matptr, transform);
                    if (mask != null) speedy_matrix_wasm.U.copyFromMat32(wasm, memory, maskptr, mask);
                    if (mask != null) speedy_matrix_wasm.U.deallocateMat32(wasm, memory, maskptr);
                    speedy_matrix_wasm.U.deallocateMat32(wasm, memory, destptr);
                    speedy_matrix_wasm.U.deallocateMat32(wasm, memory, srcptr);
                    speedy_matrix_wasm.U.deallocateMat32(wasm, memory, matptr);
                    return transform;
                  });
                }
                /**
                 * Apply an affine transformation to a set of 2D points
                 * @param {SpeedyMatrix} dest 2 x n output matrix
                 * @param {SpeedyMatrix} src 2 x n input matrix (a set of points)
                 * @param {SpeedyMatrix} transform 2x3 affine transform
                 * @returns {SpeedyPromise<SpeedyMatrix>} resolves to dest
                 */
                applyAffineTransform(dest, src, transform) {
                  if (src.rows != 2 || dest.rows != 2 || src.columns != dest.columns) throw new utils_errors.qw(`Invalid shapes`);
                  else if (transform.rows != 2 || transform.columns != 3) throw new utils_errors.qw(`The affine transformation must be a 2x3 matrix`);
                  return speedy_matrix_wasm.U.ready().then(({
                    wasm,
                    memory
                  }) => {
                    const matptr = speedy_matrix_wasm.U.allocateMat32(wasm, memory, transform);
                    const srcptr = speedy_matrix_wasm.U.allocateMat32(wasm, memory, src);
                    const destptr = speedy_matrix_wasm.U.allocateMat32(wasm, memory, dest);
                    speedy_matrix_wasm.U.copyToMat32(wasm, memory, srcptr, src);
                    speedy_matrix_wasm.U.copyToMat32(wasm, memory, matptr, transform);
                    wasm.exports.Mat32_transform_affine(destptr, srcptr, matptr);
                    speedy_matrix_wasm.U.copyFromMat32(wasm, memory, destptr, dest);
                    speedy_matrix_wasm.U.deallocateMat32(wasm, memory, destptr);
                    speedy_matrix_wasm.U.deallocateMat32(wasm, memory, srcptr);
                    speedy_matrix_wasm.U.deallocateMat32(wasm, memory, matptr);
                    return dest;
                  });
                }
              }
              ;
              const SpeedyPipelineMessageType = Object.freeze({
                Nothing: Symbol("Nothing"),
                Image: Symbol("Image"),
                Keypoints: Symbol("Keypoints"),
                Vector2: Symbol("Vector2"),
                LSHTables: Symbol("LSHTables"),
                KeypointMatches: Symbol("KeypointMatches")
              });
              class SpeedyPipelineMessage {
                /**
                 * Constructor
                 * @param {SpeedyPipelineMessageType} type message type
                 */
                constructor(type) {
                  this._type = type;
                }
                /**
                 * Message type
                 * @returns {SpeedyPipelineMessageType}
                 */
                get type() {
                  return this._type;
                }
                /**
                 * Checks if the type of this message is equal to parameter type
                 * @param {SpeedyPipelineMessageType} type
                 * @returns {boolean}
                 */
                hasType(type) {
                  return this._type === type;
                }
                /**
                 * Is this an empty message?
                 * @returns {boolean}
                 */
                isEmpty() {
                  return this.hasType(SpeedyPipelineMessageType.Nothing);
                }
                /**
                 * Convert to string
                 * @returns {string}
                 */
                toString() {
                  const type = Object.keys(SpeedyPipelineMessageType).find((type2) => SpeedyPipelineMessageType[type2] === this.type);
                  return `message of type ${type}`;
                }
                /**
                 * Inspect this message for debugging purposes
                 * @param {SpeedyGPU} gpu
                 * @returns {SpeedyPipelineMessageDiagnosticData}
                 */
                inspect(gpu2) {
                  throw new utils_errors.aQ();
                }
                /**
                 * Set parameters
                 * @abstract
                 * @param  {...any} args
                 * @returns {SpeedyPipelineMessage} this message
                 */
                set(...args3) {
                  throw new utils_errors.aQ();
                }
                /**
                 * Create a message of the specified type
                 * @param {SpeedyPipelineMessageType} type
                 * @returns {SpeedyPipelineMessage}
                 */
                static create(type) {
                  return createMessage(type);
                }
              }
              class SpeedyPipelineMessageWithNothing extends SpeedyPipelineMessage {
                /**
                 * Constructor
                 */
                constructor() {
                  super(SpeedyPipelineMessageType.Nothing);
                }
                /**
                 * Set parameters
                 * @returns {SpeedyPipelineMessage} this message
                 */
                set() {
                  return this;
                }
                /**
                 * Inspect this message for debugging purposes
                 * @param {SpeedyGPU} gpu
                 * @returns {SpeedyPipelineMessageDiagnosticData}
                 */
                inspect(gpu2) {
                  return {
                    type: this.constructor.name
                  };
                }
              }
              class SpeedyPipelineMessageWithImage extends SpeedyPipelineMessage {
                /**
                 * Constructor
                 */
                constructor() {
                  super(SpeedyPipelineMessageType.Image);
                  this._image = null;
                  this._format = types.f5.RGBA;
                }
                /**
                 * Set parameters
                 * @param {SpeedyDrawableTexture} image the image we carry
                 * @param {ImageFormat} [format] image format
                 * @returns {SpeedyPipelineMessage} this message
                 */
                set(image, format = types.f5.RGBA) {
                  this._image = image;
                  this._format = format;
                  return this;
                }
                /**
                 * Inspect this message for debugging purposes
                 * @param {SpeedyGPU} gpu
                 * @returns {SpeedyPipelineMessageDiagnosticData}
                 */
                inspect(gpu2) {
                  const formatName = Object.keys(types.f5).find((format) => types.f5[format] === this.format);
                  return {
                    type: this.constructor.name,
                    format: String(formatName),
                    imageSize: this.image ? `${this.image.width}x${this.image.height}` : "0x0",
                    image: this.image ? "<image data>" : "",
                    hasMipmaps: this.image && this.image.hasMipmaps() ? "yes" : "no"
                  };
                }
                /**
                 * The image we carry
                 * @returns {SpeedyDrawableTexture}
                 */
                get image() {
                  return this._image;
                }
                /**
                 * Image format
                 * @returns {ImageFormat}
                 */
                get format() {
                  return this._format;
                }
              }
              class SpeedyPipelineMessageWithKeypoints extends SpeedyPipelineMessage {
                /**
                 * Constructor
                 */
                constructor() {
                  super(SpeedyPipelineMessageType.Keypoints);
                  this._encodedKeypoints = null;
                  this._descriptorSize = 0;
                  this._extraSize = 0;
                  this._encoderLength = 1;
                }
                /**
                 * Set parameters
                 * @param {SpeedyDrawableTexture} encodedKeypoints encoded keypoints
                 * @param {number} descriptorSize in bytes
                 * @param {number} extraSize in bytes
                 * @param {number} encoderLength positive integer
                 * @returns {SpeedyPipelineMessage} this message
                 */
                set(encodedKeypoints, descriptorSize, extraSize, encoderLength) {
                  this._encodedKeypoints = encodedKeypoints;
                  this._descriptorSize = descriptorSize | 0;
                  this._extraSize = extraSize | 0;
                  this._encoderLength = encoderLength | 0;
                  utils.A.assert(this._descriptorSize >= 0 && this._extraSize >= 0);
                  utils.A.assert(this._encoderLength === this._encodedKeypoints.width, "Invalid encoderLength");
                  utils.A.assert(this._encodedKeypoints.width === this._encodedKeypoints.height, "Invalid encodedKeypoints texture");
                  return this;
                }
                /**
                 * Inspect this message for debugging purposes
                 * @param {SpeedyGPU} gpu
                 * @returns {SpeedyPipelineMessageDiagnosticData}
                 */
                inspect(gpu2) {
                  return {
                    type: this.constructor.name,
                    descriptorSize: this.descriptorSize,
                    extraSize: this.extraSize,
                    encoderLength: this.encoderLength,
                    encodedKeypointsSize: this.encodedKeypoints ? `${this.encodedKeypoints.width}x${this.encodedKeypoints.height}` : "0x0",
                    encodedKeypoints: this.encodedKeypoints ? utils.A.formatBinaryData(this.encodedKeypoints.inspect(gpu2).buffer) : ""
                  };
                }
                /**
                 * Encoded keypoints
                 * @returns {SpeedyDrawableTexture}
                 */
                get encodedKeypoints() {
                  return this._encodedKeypoints;
                }
                /**
                 * Descriptor size, in bytes
                 * @returns {number}
                 */
                get descriptorSize() {
                  return this._descriptorSize;
                }
                /**
                 * Extra size, in bytes
                 * @returns {number}
                 */
                get extraSize() {
                  return this._extraSize;
                }
                /**
                 * Encoder length
                 * @returns {number}
                 */
                get encoderLength() {
                  return this._encoderLength;
                }
              }
              class SpeedyPipelineMessageWith2DVectors extends SpeedyPipelineMessage {
                /**
                 * Constructor
                 */
                constructor() {
                  super(SpeedyPipelineMessageType.Vector2);
                  this._vectors = null;
                }
                /**
                 * Set parameters
                 * @param {SpeedyDrawableTexture} vectors the set of vectors
                 * @returns {SpeedyPipelineMessage} this message
                 */
                set(vectors) {
                  this._vectors = vectors;
                  return this;
                }
                /**
                 * Inspect this message for debugging purposes
                 * @param {SpeedyGPU} gpu
                 * @returns {SpeedyPipelineMessageDiagnosticData}
                 */
                inspect(gpu2) {
                  return {
                    type: this.constructor.name,
                    vectorsSize: this.vectors ? `${this.vectors.width}x${this.vectors.height}` : "0x0",
                    vectors: this.vectors ? utils.A.formatBinaryData(this.vectors.inspect(gpu2).buffer) : ""
                  };
                }
                /**
                 * The set of vectors
                 * @returns {SpeedyDrawableTexture}
                 */
                get vectors() {
                  return this._vectors;
                }
              }
              class SpeedyPipelineMessageWithLSHTables extends SpeedyPipelineMessage {
                /**
                 * Constructor
                 */
                constructor() {
                  super(SpeedyPipelineMessageType.LSHTables);
                  this._lsh = null;
                }
                /**
                 * Set parameters
                 * @param {SpeedyLSH} lsh
                 * @returns {SpeedyPipelineMessage} this message
                 */
                set(lsh) {
                  this._lsh = lsh;
                  return this;
                }
                /**
                 * Inspect this message for debugging purposes
                 * @param {SpeedyGPU} gpu
                 * @returns {SpeedyPipelineMessageDiagnosticData}
                 */
                inspect(gpu2) {
                  return {
                    type: this.constructor.name,
                    lsh: "<LSH tables>"
                  };
                }
                /**
                 * LSH data structure
                 * @returns {SpeedyLSH}
                 */
                get lsh() {
                  return this._lsh;
                }
              }
              class SpeedyPipelineMessageWithKeypointMatches extends SpeedyPipelineMessage {
                /**
                 * Constructor
                 */
                constructor() {
                  super(SpeedyPipelineMessageType.KeypointMatches);
                  this._encodedMatches = null;
                  this._matchesPerKeypoint = 1;
                }
                /**
                 * Set parameters
                 * @param {SpeedyDrawableTexture} encodedMatches
                 * @param {number} matchesPerKeypoint
                 * @returns {SpeedyPipelineMessage} this message
                 */
                set(encodedMatches, matchesPerKeypoint) {
                  this._encodedMatches = encodedMatches;
                  this._matchesPerKeypoint = matchesPerKeypoint | 0;
                  utils.A.assert(this._matchesPerKeypoint > 0);
                  return this;
                }
                /**
                 * Inspect this message for debugging purposes
                 * @param {SpeedyGPU} gpu
                 * @returns {SpeedyPipelineMessageDiagnosticData}
                 */
                inspect(gpu2) {
                  return {
                    type: this.constructor.name,
                    matchesPerKeypoint: this.matchesPerKeypoint,
                    encodedMatchesSize: this.encodedMatches ? `${this.encodedMatches.width}x${this.encodedMatches.height}` : "0x0",
                    encodedMatches: this.encodedMatches ? utils.A.formatBinaryData(this.encodedMatches.inspect(gpu2).buffer) : ""
                  };
                }
                /**
                 * The matches
                 * @returns {SpeedyDrawableTexture}
                 */
                get encodedMatches() {
                  return this._encodedMatches;
                }
                /**
                 * Number of matches per keypoint
                 * @returns {number}
                 */
                get matchesPerKeypoint() {
                  return this._matchesPerKeypoint;
                }
              }
              const MESSAGE_CLASS = Object.freeze({
                [SpeedyPipelineMessageType.Nothing]: SpeedyPipelineMessageWithNothing,
                [SpeedyPipelineMessageType.Image]: SpeedyPipelineMessageWithImage,
                [SpeedyPipelineMessageType.Keypoints]: SpeedyPipelineMessageWithKeypoints,
                [SpeedyPipelineMessageType.Vector2]: SpeedyPipelineMessageWith2DVectors,
                [SpeedyPipelineMessageType.LSHTables]: SpeedyPipelineMessageWithLSHTables,
                [SpeedyPipelineMessageType.KeypointMatches]: SpeedyPipelineMessageWithKeypointMatches
              });
              function createMessage(type) {
                return new MESSAGE_CLASS[
                  // error TS2538: Type 'Symbol' cannot be used as an index type.
                  // heck, what the hack...
                  /** @type {any} */
                  type
                ]();
              }
              ;
              const always = (message) => true;
              class SpeedyPipelinePortSpec {
                /**
                 * Constructor
                 * @param {SpeedyPipelineMessageType} expectedMessageType expected message type
                 * @param {SpeedyPipelineMessageConstraint} [messageConstraint] message validation function
                 */
                constructor(expectedMessageType, messageConstraint = always) {
                  this._expectedMessageType = expectedMessageType;
                  this._isValidMessage = typeof messageConstraint === "function" ? messageConstraint : always;
                  utils.A.assert(this._expectedMessageType != SpeedyPipelineMessageType.Nothing);
                }
                /**
                 * Checks if two specs have the same expected type
                 * @param {SpeedyPipelinePortSpec} spec
                 * @returns {boolean}
                 */
                isCompatibleWith(spec) {
                  return this._expectedMessageType == spec._expectedMessageType;
                }
                /**
                 * Is the given message accepted by a port that abides by this specification?
                 * @param {SpeedyPipelineMessage} message
                 * @returns {boolean}
                 */
                accepts(message) {
                  return message.hasType(this._expectedMessageType) && this._isValidMessage(message);
                }
                /**
                 * Convert to string
                 * @returns {string}
                 */
                toString() {
                  const type = Object.keys(SpeedyPipelineMessageType).find((type2) => SpeedyPipelineMessageType[type2] === this._expectedMessageType);
                  return `Port expects ${type} satisfying ${this._isValidMessage}`;
                }
                /**
                 * Expected message type
                 * @returns {SpeedyPipelineMessageType}
                 */
                get expectedMessageType() {
                  return this._expectedMessageType;
                }
              }
              ;
              const DEFAULT_INPUT_PORT_NAME = "in";
              const DEFAULT_OUTPUT_PORT_NAME = "out";
              const ACCEPTABLE_PORT_NAME = /^[a-z][a-zA-Z0-9]*$/;
              const EMPTY_MESSAGE = new SpeedyPipelineMessageWithNothing();
              class SpeedyPipelinePort {
                /**
                 * Constructor
                 * @param {string} name the name of this port 
                 * @param {SpeedyPipelinePortSpec} spec port specification
                 * @param {SpeedyPipelineNode} node the node to which this port belongs
                 */
                constructor(name, spec, node) {
                  this._name = String(name);
                  this._spec = spec;
                  this._node = node;
                  this._message = EMPTY_MESSAGE;
                  utils.A.assert(ACCEPTABLE_PORT_NAME.test(this._name), `Port name "${this._name}" is not acceptable`);
                }
                /**
                 * The name of this port
                 * @returns {string}
                 */
                get name() {
                  return this._name;
                }
                /**
                 * The node to which this port belongs
                 * @returns {SpeedyPipelineNode}
                 */
                get node() {
                  return this._node;
                }
                /**
                 * Connect this port to another
                 * @abstract
                 * @param {SpeedyPipelinePort} port
                 */
                connectTo(port) {
                  throw new utils_errors.aQ();
                }
                /**
                 * Is this an input port?
                 * @abstract
                 * @returns {boolean}
                 */
                isInputPort() {
                  throw new utils_errors.aQ();
                }
                /**
                 * Is this an output port?
                 * @returns {boolean}
                 */
                isOutputPort() {
                  return !this.isInputPort();
                }
                /**
                 * Clear the message stored in this port
                 */
                clearMessage() {
                  this._message = EMPTY_MESSAGE;
                }
                /**
                 * Is there a valid message located in this port?
                 * @returns {boolean}
                 */
                hasMessage() {
                  return !this._message.isEmpty();
                }
                /**
                 * Read the message that is in this port
                 * @returns {SpeedyPipelineMessage}
                 */
                read() {
                  if (this._message.isEmpty()) throw new utils_errors.Er(`Can't read from port ${this.name}: nothing to read`);
                  return this._message;
                }
                /**
                 * Write a message to this port
                 * @param {SpeedyPipelineMessage} message
                 */
                write(message) {
                  throw new utils_errors.EM(`Can't write ${message} to port ${this.name}: unsupported operation`);
                }
                /**
                 * Inspect this port for debugging purposes
                 * @param {SpeedyGPU} gpu
                 * @returns {SpeedyPipelinePortDiagnosticData} diagnostic data
                 */
                inspect(gpu2) {
                  return this._message.inspect(gpu2);
                }
                /**
                 * Default port name
                 * @abstract
                 * @returns {string}
                 */
                static get DEFAULT_NAME() {
                  throw new utils_errors.aQ();
                }
              }
              class SpeedyPipelineOutputPort extends SpeedyPipelinePort {
                /**
                 * Constructor
                 * @param {string} name the name of this port 
                 * @param {SpeedyPipelinePortSpec} spec port specification
                 * @param {SpeedyPipelineNode} node the node to which this port belongs
                 */
                constructor(name, spec, node) {
                  super(name, spec, node);
                  this._cachedMessage = null;
                }
                /**
                 * Connect this port to another
                 * @param {SpeedyPipelineInputPort} port
                 */
                connectTo(port) {
                  if (!port.isInputPort()) throw new utils_errors.qw(`Can't connect output port ${this.name} to port ${port.name}: expected an input port`);
                  port.connectTo(this);
                }
                /**
                 * Is this an input port?
                 * @returns {boolean}
                 */
                isInputPort() {
                  return false;
                }
                /**
                 * Write a message to this port
                 * @param {SpeedyPipelineMessage} message
                 */
                write(message) {
                  if (!this._spec.accepts(message)) throw new utils_errors.qw(`Can't write ${message} to port ${this.name}. ${this._spec}`);
                  this._message = message;
                }
                /**
                 * Write a message to this port using a cached message object
                 * @param  {...any} args to be passed to SpeedyPipelineMessage.set()
                 */
                swrite(...args3) {
                  if (this._cachedMessage == null) this._cachedMessage = SpeedyPipelineMessage.create(this._spec.expectedMessageType);
                  this.write(this._cachedMessage.set(...args3));
                }
                /**
                 * Default port name
                 * @returns {string}
                 */
                static get DEFAULT_NAME() {
                  return DEFAULT_OUTPUT_PORT_NAME;
                }
              }
              class SpeedyPipelineInputPort extends SpeedyPipelinePort {
                /**
                 * Constructor
                 * @param {string} name the name of this port 
                 * @param {SpeedyPipelinePortSpec} spec port specification
                 * @param {SpeedyPipelineNode} node the node to which this port belongs
                 */
                constructor(name, spec, node) {
                  super(name, spec, node);
                  this._incomingLink = null;
                }
                /**
                 * Incoming link
                 * @returns {SpeedyPipelineOutputPort|null}
                 */
                get incomingLink() {
                  return this._incomingLink;
                }
                /**
                 * Connect this port to another
                 * @param {SpeedyPipelineOutputPort} port
                 */
                connectTo(port) {
                  if (!port.isOutputPort()) throw new utils_errors.qw(`Can't connect input port ${this.name} of "${this.node.fullName}" to input port ${port.name} of "${port.node.fullName}": expected an output port`);
                  else if (!this._spec.isCompatibleWith(port._spec)) throw new utils_errors.qw(`Can't connect port ${this.name} of "${this.node.fullName}" to port ${port.name} of "${port.node.fullName}": incompatible types`);
                  this._incomingLink = port;
                }
                /**
                 * Unlink this port
                 */
                disconnect() {
                  this._incomingLink = null;
                }
                /**
                 * Is this an input port?
                 * @returns {boolean}
                 */
                isInputPort() {
                  return true;
                }
                /**
                 * Receive a message using the incoming link
                 * @param {string} [nodeName]
                 * @returns {SpeedyPipelineMessage}
                 */
                pullMessage(nodeName = "") {
                  const name = nodeName.length > 0 ? `${this.name} of ${nodeName}` : this.name;
                  if (this._incomingLink == null) throw new utils_errors.Er(`No incoming link for input port ${name}`);
                  const message = this._incomingLink.read();
                  if (!this._spec.accepts(message)) throw new utils_errors.qw(`Can't receive ${message} at port ${name}: ${this._spec}`);
                  return this._message = message;
                }
                /**
                 * Default port name
                 * @returns {string}
                 */
                static get DEFAULT_NAME() {
                  return DEFAULT_INPUT_PORT_NAME;
                }
              }
              ;
              class SpeedyPipelinePortBuilder {
                /**
                 * Constructor
                 * @param {typeof SpeedyPipelinePort} portClass input or output?
                 * @param {string} portName
                 */
                constructor(portClass, portName) {
                  this._class = portClass;
                  this._name = String(portName);
                  this._type = SpeedyPipelineMessageType.Nothing;
                  this._messageConstraint = void 0;
                }
                /**
                 * Declare that the new port expects a certain type of message
                 * @param {SpeedyPipelineMessageType} type expected type
                 * @returns {SpeedyPipelinePortBuilder} this builder
                 */
                expects(type) {
                  utils.A.assert(this._type == SpeedyPipelineMessageType.Nothing);
                  utils.A.assert(type != SpeedyPipelineMessageType.Nothing);
                  this._type = type;
                  return this;
                }
                /**
                 * Declare that the new port expects messages satisfying a constraint
                 * @param {SpeedyPipelineMessageConstraint} constraint
                 * @returns {SpeedyPipelinePortBuilder} this builder
                 */
                satisfying(constraint) {
                  utils.A.assert(this._type != SpeedyPipelineMessageType.Nothing, "You must first declare what type of message this port expects");
                  utils.A.assert(this._messageConstraint === void 0);
                  utils.A.assert(typeof constraint === "function");
                  this._messageConstraint = constraint;
                  return this;
                }
                /**
                 * Build a port
                 * @param {SpeedyPipelineNode} node the node to which the new port will belong
                 * @returns {SpeedyPipelinePort}
                 */
                build(node) {
                  const spec = new SpeedyPipelinePortSpec(this._type, this._messageConstraint);
                  return Reflect.construct(this._class, [this._name, spec, node]);
                }
              }
              function InputPort(portName = SpeedyPipelineInputPort.DEFAULT_NAME) {
                return new SpeedyPipelinePortBuilder(SpeedyPipelineInputPort, portName);
              }
              function OutputPort(portName = SpeedyPipelineOutputPort.DEFAULT_NAME) {
                return new SpeedyPipelinePortBuilder(SpeedyPipelineOutputPort, portName);
              }
              ;
              const generateRandomName = () => Math.random().toString(16).substr(2);
              const createInputPortDictionary = () => (
                /** @type {InputPortDictionary} */
                /* @__PURE__ */ Object.create(null)
              );
              const createOutputPortDictionary = () => (
                /** @type {OutputPortDictionary} */
                /* @__PURE__ */ Object.create(null)
              );
              function InputPortDictionary(ports) {
                return ports.reduce((dict, port) => (dict[port.name] = port, dict), createInputPortDictionary());
              }
              function OutputPortDictionary(ports) {
                return ports.reduce((dict, port) => (dict[port.name] = port, dict), createOutputPortDictionary());
              }
              let _texView = false;
              class SpeedyPipelineNode {
                /**
                 * Constructor
                 * @param {string} [name] the name of this node
                 * @param {number} [texCount] number of work textures
                 * @param {SpeedyPipelinePortBuilder[]} [portBuilders] port builders
                 */
                constructor(name = generateRandomName(), texCount = 0, portBuilders = []) {
                  this._name = String(name);
                  this._tex = new Array(texCount).fill(null);
                  const ports = portBuilders.map((builder) => builder.build(this));
                  const inputPorts = (
                    /** @type {SpeedyPipelineInputPort[]} */
                    ports.filter((port) => port.isInputPort())
                  );
                  const outputPorts = (
                    /** @type {SpeedyPipelineOutputPort[]} */
                    ports.filter((port) => port.isOutputPort())
                  );
                  this._inputPorts = InputPortDictionary(inputPorts);
                  this._outputPorts = OutputPortDictionary(outputPorts);
                  if (this._name.length == 0) throw new utils_errors.qw(`Invalid name "${this._name}" for node ${this.fullName}`);
                  else if (portBuilders.length == 0) throw new utils_errors.qw(`No ports have been found in node ${this.fullName}`);
                }
                /**
                 * The name of this node
                 * @returns {string}
                 */
                get name() {
                  return this._name;
                }
                /**
                 * Name and type of this node
                 * @returns {string}
                 */
                get fullName() {
                  return `${this.constructor.name}[${this.name}]`;
                }
                /**
                 * Find input port by name
                 * @param {string} [portName]
                 * @returns {SpeedyPipelineInputPort}
                 */
                input(portName = SpeedyPipelineInputPort.DEFAULT_NAME) {
                  if (portName in this._inputPorts) return this._inputPorts[portName];
                  throw new utils_errors.qw(`Can't find input port ${portName} in node ${this.fullName}`);
                }
                /**
                 * Find output port by name
                 * @param {string} [portName]
                 * @returns {SpeedyPipelineOutputPort}
                 */
                output(portName = SpeedyPipelineOutputPort.DEFAULT_NAME) {
                  if (portName in this._outputPorts) return this._outputPorts[portName];
                  throw new utils_errors.qw(`Can't find output port ${portName} in node ${this.fullName}`);
                }
                /**
                 * Get data from the input ports and execute
                 * the task that this node is supposed to!
                 * @param {SpeedyGPU} gpu
                 * @returns {void|SpeedyPromise<void>}
                 */
                execute(gpu2) {
                  let portName;
                  for (portName in this._outputPorts) this._outputPorts[portName].clearMessage();
                  for (portName in this._inputPorts) this._inputPorts[portName].pullMessage(this.fullName);
                  const runTask = this._run(gpu2);
                  if (typeof runTask === "undefined") return void this._finishExecution(gpu2);
                  else return runTask.then(() => this._finishExecution(gpu2));
                }
                /**
                 * Finish the execution of this node;
                 * to be called after execute()
                 * @param {SpeedyGPU} gpu
                 */
                _finishExecution(gpu2) {
                  for (const portName in this._outputPorts) {
                    utils.A.assert(this._outputPorts[portName].hasMessage(), `Did you forget to write data to the output port ${portName} of ${this.fullName}?`);
                  }
                  if (settings.w.logging === "diagnostic") {
                    utils.A.log(`%c ${this.fullName} `, "font-size:12pt;font-weight:bold;color:white;background:blue");
                    for (const portName in this._inputPorts) utils.A.log(`%c-> ${portName}:`, "font-size:10pt;font-weight:bold", this._inputPorts[portName].inspect(gpu2));
                    for (const portName in this._outputPorts) utils.A.log(`%c<- ${portName}:`, "font-size:10pt;font-weight:bold", this._outputPorts[portName].inspect(gpu2));
                  }
                }
                /**
                 * Run the specific task of this node
                 * @abstract
                 * @param {SpeedyGPU} gpu
                 * @returns {void|SpeedyPromise<void>}
                 */
                _run(gpu2) {
                  throw new utils_errors.aQ();
                }
                /**
                 * Initializes this node
                 * @param {SpeedyGPU} gpu
                 */
                init(gpu2) {
                  gpu2.subscribe(this._allocateWorkTextures, this, gpu2);
                  this._allocateWorkTextures(gpu2);
                }
                /**
                 * Releases this node
                 * @param {SpeedyGPU} gpu
                 */
                release(gpu2) {
                  this._deallocateWorkTextures(gpu2);
                  gpu2.unsubscribe(this._allocateWorkTextures, this);
                }
                /**
                 * Clear all ports
                 */
                clearPorts() {
                  let portName;
                  for (portName in this._inputPorts) this._inputPorts[portName].clearMessage();
                  for (portName in this._outputPorts) this._outputPorts[portName].clearMessage();
                }
                /**
                 * Find all nodes that feed input to this node
                 * @returns {SpeedyPipelineNode[]}
                 */
                inputNodes() {
                  const nodes = [];
                  for (const portName in this._inputPorts) {
                    const port = this._inputPorts[portName];
                    if (port.incomingLink != null) nodes.push(port.incomingLink.node);
                  }
                  return nodes;
                }
                /**
                 * Is this a source of the pipeline?
                 * @returns {boolean}
                 */
                isSource() {
                  return false;
                }
                /**
                 * Is this a sink of the pipeline?
                 * @returns {boolean}
                 */
                isSink() {
                  return false;
                }
                /**
                 * Allocate work texture(s)
                 * @param {SpeedyGPU} gpu
                 */
                _allocateWorkTextures(gpu2) {
                  for (let j = 0; j < this._tex.length; j++) this._tex[j] = gpu2.texturePool.allocate();
                }
                /**
                 * Deallocate work texture(s)
                 * @param {SpeedyGPU} gpu
                 */
                _deallocateWorkTextures(gpu2) {
                  for (let j = this._tex.length - 1; j >= 0; j--) this._tex[j] = gpu2.texturePool.free(this._tex[j]);
                }
                /**
                 * Visually inspect a texture for debugging purposes
                 * @param {SpeedyGPU} gpu
                 * @param {SpeedyDrawableTexture} texture
                 */
                _visualize(gpu2, texture) {
                  const canvas = gpu2.renderToCanvas(texture);
                  if (!_texView) {
                    document.body.appendChild(canvas);
                    _texView = true;
                  }
                }
              }
              class SpeedyPipelineSourceNode extends SpeedyPipelineNode {
                /**
                 * Constructor
                 * @param {string} [name] the name of this node
                 * @param {number} [texCount] number of work textures
                 * @param {SpeedyPipelinePortBuilder[]} [portBuilders] port builders
                 */
                constructor(name = void 0, texCount = void 0, portBuilders = void 0) {
                  super(name, texCount, portBuilders);
                  utils.A.assert(Object.keys(this._inputPorts).length == 0);
                }
                /**
                 * Is this a source of the pipeline?
                 * @returns {boolean}
                 */
                isSource() {
                  return true;
                }
              }
              class SpeedyPipelineSinkNode extends SpeedyPipelineNode {
                /**
                 * Constructor
                 * @param {string} [name] the name of this node
                 * @param {number} [texCount] number of work textures
                 * @param {SpeedyPipelinePortBuilder[]} [portBuilders] port builders
                 */
                constructor(name = void 0, texCount = void 0, portBuilders = void 0) {
                  super(name, texCount, portBuilders);
                  utils.A.assert(Object.keys(this._outputPorts).length == 0);
                }
                /**
                 * Export data from this node to the user
                 * @abstract
                 * @returns {SpeedyPromise<any>}
                 */
                export() {
                  throw new utils_errors.aQ();
                }
                /**
                 * Is this a sink of the pipeline?
                 * @returns {boolean}
                 */
                isSink() {
                  return true;
                }
              }
              ;
              const MATCH_NOT_FOUND = -1;
              class SpeedyKeypointMatch {
                /**
                 * Constructor
                 * @param {number} index index of the stored keypoint, a non-negative integer
                 * @param {number} distance a measure of the quality of the match, a non-negative number
                 */
                constructor(index, distance) {
                  const isValid = distance < globals.MATCH_MAX_DISTANCE;
                  this._index = isValid ? index | 0 : MATCH_NOT_FOUND;
                  this._distance = isValid ? +distance : Number.POSITIVE_INFINITY;
                  return Object.freeze(this);
                }
                /**
                 * The index of the stored keypoint
                 * @returns {number}
                 */
                get index() {
                  return this._index;
                }
                /**
                 * A measure of the quality of the match (lower values indicate better matches)
                 * @returns {number}
                 */
                get distance() {
                  return this._distance;
                }
                /**
                 * A string representation of the keypoint match
                 * @returns {string}
                 */
                toString() {
                  return `SpeedyKeypointMatch(${this.index},${this.distance})`;
                }
              }
              ;
              class SpeedyKeypoint {
                /**
                 * Constructor
                 * @param {number} x X position
                 * @param {number} y Y position
                 * @param {number} [lod] Level-of-detail
                 * @param {number} [rotation] Rotation in radians
                 * @param {number} [score] Cornerness measure
                 * @param {SpeedyKeypointDescriptor|null} [descriptor] Keypoint descriptor, if any
                 */
                constructor(x, y, lod = 0, rotation = 0, score = 0, descriptor = null) {
                  this._position = new SpeedyPoint2(+x, +y);
                  this._lod = +lod;
                  this._rotation = +rotation;
                  this._score = +score;
                  this._descriptor = descriptor;
                }
                /**
                 * Converts this keypoint to a descriptive string
                 * @returns {string}
                 */
                toString() {
                  return `SpeedyKeypoint(${this.x},${this.y})`;
                }
                /**
                 * The position of this keypoint
                 * @returns {SpeedyPoint2}
                 */
                get position() {
                  return this._position;
                }
                /**
                 * The x-position of this keypoint
                 * @returns {number}
                 */
                get x() {
                  return this._position.x;
                }
                /**
                 * The x-position of this keypoint
                 * @param {number} value
                 */
                set x(value) {
                  this._position.x = +value;
                }
                /**
                 * The y-position of this keypoint
                 * @returns {number}
                 */
                get y() {
                  return this._position.y;
                }
                /**
                 * The y-position of this keypoint
                 * @param {number} value
                 */
                set y(value) {
                  this._position.y = +value;
                }
                /**
                 * The pyramid level-of-detail from which this keypoint was extracted
                 * @returns {number}
                 */
                get lod() {
                  return this._lod;
                }
                /**
                 * Scale: 2^lod
                 * @returns {number}
                 */
                get scale() {
                  return Math.pow(2, this._lod);
                }
                /**
                 * The orientation of the keypoint, in radians
                 * @returns {number} Angle in radians
                 */
                get rotation() {
                  return this._rotation;
                }
                /**
                 * Score: a cornerness measure
                 * @returns {number} Score
                 */
                get score() {
                  return this._score;
                }
                /**
                 * Keypoint descriptor
                 * @return {SpeedyKeypointDescriptor|null}
                 */
                get descriptor() {
                  return this._descriptor;
                }
              }
              class SpeedyTrackedKeypoint extends SpeedyKeypoint {
                /**
                 * Constructor
                 * @param {number} x X position
                 * @param {number} y Y position
                 * @param {number} [lod] Level-of-detail
                 * @param {number} [rotation] Rotation in radians
                 * @param {number} [score] Cornerness measure
                 * @param {SpeedyKeypointDescriptor|null} [descriptor] Keypoint descriptor, if any
                 * @param {SpeedyVector2} [flow] flow vector
                 */
                constructor(x, y, lod = 0, rotation = 0, score = 0, descriptor = null, flow = new SpeedyVector2(0, 0)) {
                  super(x, y, lod, rotation, score, descriptor);
                  this._flow = flow;
                }
                /**
                 * Flow vector
                 * @returns {SpeedyVector2}
                 */
                get flow() {
                  return this._flow;
                }
              }
              class SpeedyMatchedKeypoint extends SpeedyKeypoint {
                /**
                 * Constructor
                 * @param {number} x X position
                 * @param {number} y Y position
                 * @param {number} [lod] Level-of-detail
                 * @param {number} [rotation] Rotation in radians
                 * @param {number} [score] Cornerness measure
                 * @param {SpeedyKeypointDescriptor|null} [descriptor] Keypoint descriptor, if any
                 * @param {SpeedyKeypointMatch[]} [matches] Keypoint matches, if any
                 */
                constructor(x, y, lod = 0, rotation = 0, score = 0, descriptor = null, matches = []) {
                  super(x, y, lod, rotation, score, descriptor);
                  this._matches = matches;
                }
                /**
                 * Keypoint matches
                 * @returns {SpeedyKeypointMatch[]}
                 */
                get matches() {
                  return this._matches;
                }
              }
              ;
              let gpu = null;
              let referenceCount = 0;
              class SpeedyPipeline {
                /**
                 * Constructor
                 */
                constructor() {
                  this._nodes = [];
                  this._sequence = [];
                  this._busy = false;
                }
                /**
                 * Find a node by its name
                 * @template T extends SpeedyPipelineNode
                 * @param {string} name
                 * @returns {T|null}
                 */
                node(name) {
                  for (let i = 0, n = this._nodes.length; i < n; i++) {
                    if (this._nodes[i].name === name) return this._nodes[i];
                  }
                  return null;
                }
                /**
                 * Initialize the pipeline
                 * @param  {...SpeedyPipelineNode} nodes
                 * @returns {SpeedyPipeline} this pipeline
                 */
                init(...nodes) {
                  if (this._nodes.length > 0) throw new utils_errors.Er(`The pipeline has already been initialized`);
                  else if (nodes.length == 0) throw new utils_errors.qw(`Can't initialize the pipeline. Please specify its nodes`);
                  if (0 == referenceCount++) {
                    utils.A.assert(!gpu, "Duplicate SpeedyGPU instance");
                    gpu = new SpeedyGPU();
                  }
                  for (let i = 0; i < nodes.length; i++) {
                    const node = nodes[i];
                    if (!this._nodes.includes(node)) this._nodes.push(node);
                  }
                  this._sequence = SpeedyPipeline._tsort(this._nodes);
                  SpeedyPipeline._validateSequence(this._sequence);
                  for (let i = 0; i < this._sequence.length; i++) this._sequence[i].init(gpu);
                  return this;
                }
                /**
                 * Release the resources associated with this pipeline
                 * @returns {null}
                 */
                release() {
                  if (this._nodes.length == 0) throw new utils_errors.Er(`The pipeline has already been released or has never been initialized`);
                  for (let i = this._sequence.length - 1; i >= 0; i--) this._sequence[i].release(gpu);
                  this._sequence.length = 0;
                  this._nodes.length = 0;
                  if (0 == --referenceCount) gpu = gpu.release();
                  return null;
                }
                /**
                 * Run the pipeline
                 * @returns {SpeedyPromise<SpeedyPipelineOutput>} results are indexed by the names of the sink nodes
                 */
                run() {
                  utils.A.assert(this._sequence.length > 0, `The pipeline has not been initialized or has been released`);
                  if (this._busy) {
                    return new speedy_promise.i((resolve, reject) => {
                      setTimeout(() => this.run().then(resolve, reject), 0);
                    });
                  } else {
                    this._busy = true;
                  }
                  const sinks = (
                    /** @type {SpeedyPipelineSinkNode[]} */
                    this._sequence.filter((node) => node.isSink())
                  );
                  const template = SpeedyPipeline._createOutputTemplate(sinks);
                  if (settings.w.logging === "diagnostic") utils.A.log("%c RUNNING PIPELINE ", "background:red;color:white;font-size:28pt;font-weight:bold");
                  return SpeedyPipeline._runSequence(this._sequence).then(() => (
                    // export results
                    speedy_promise.i.all(sinks.map((sink) => sink.export().turbocharge())).then((results) => (
                      // aggregate results by the names of the sinks
                      results.reduce((obj, val, idx) => (obj[sinks[idx].name] = val, obj), template)
                    ))
                  )).finally(() => {
                    for (let i = this._sequence.length - 1; i >= 0; i--) this._sequence[i].clearPorts();
                    this._busy = false;
                    if (settings.w.logging === "diagnostic") {
                      utils.A.log("%c PIPELINE OUTPUT \n", "background:green;color:white;font-size:16pt;font-weight:bold");
                      Object.keys(template).forEach((entry) => {
                        utils.A.log("%c" + entry + ":", "font-size:10pt;font-weight:bold", template[entry]);
                      });
                    }
                  }).turbocharge();
                }
                /**
                 * @internal
                 *
                 * GPU instance
                 * @returns {SpeedyGPU}
                 */
                get _gpu() {
                  return gpu;
                }
                /**
                 * Execute the tasks of a sequence of nodes
                 * @param {SpeedyPipelineNode[]} sequence sequence of nodes
                 * @param {number} [i] in [0,n)
                 * @param {number} [n] number of nodes
                 * @returns {SpeedyPromise<void>}
                 */
                static _runSequence(sequence, i = 0, n = sequence.length) {
                  for (; i < n; i++) {
                    const runTask = sequence[i].execute(gpu);
                    gpu.gl.flush();
                    if (typeof runTask !== "undefined") return runTask.then(() => SpeedyPipeline._runSequence(sequence, i + 1, n));
                  }
                  return speedy_promise.i.resolve();
                }
                /**
                 * Topological sorting
                 * @param {SpeedyPipelineNode[]} nodes 
                 * @returns {SpeedyPipelineNode[]}
                 */
                static _tsort(nodes) {
                  const outlinks = SpeedyPipeline._outlinks(nodes);
                  const stack = nodes.map((node) => (
                    /** @type {StackNode} */
                    [node, false]
                  ));
                  const trash = /* @__PURE__ */ new Set();
                  const sorted = new Array(nodes.length);
                  let j = sorted.length;
                  while (stack.length > 0) {
                    const [node, done] = stack.pop();
                    if (!done) {
                      if (!trash.has(node)) {
                        const outnodes = outlinks.get(node);
                        trash.add(node);
                        stack.push([node, true]);
                        stack.push(...outnodes.map((node2) => (
                          /** @type {StackNode} */
                          [node2, false]
                        )));
                        if (outnodes.some((node2) => trash.has(node2) && !sorted.includes(node2))) throw new utils_errors.Er(`Pipeline networks cannot have cycles!`);
                      }
                    } else sorted[--j] = node;
                  }
                  return sorted;
                }
                /**
                 * Figure out the outgoing links of all nodes
                 * @param {SpeedyPipelineNode[]} nodes
                 * @returns {Map<SpeedyPipelineNode,SpeedyPipelineNode[]>}
                 */
                static _outlinks(nodes) {
                  const outlinks = /* @__PURE__ */ new Map();
                  for (let k = 0; k < nodes.length; k++) outlinks.set(nodes[k], []);
                  for (let i = 0; i < nodes.length; i++) {
                    const to = nodes[i];
                    const inputs = to.inputNodes();
                    for (let j = 0; j < inputs.length; j++) {
                      const from = inputs[j];
                      const links = outlinks.get(from);
                      if (!links) throw new utils_errors.Er(`Can't initialize the pipeline. Missing node: ${from.fullName}. Did you forget to add it to the initialization list?`);
                      if (!links.includes(to)) links.push(to);
                    }
                  }
                  return outlinks;
                }
                /**
                 * Generate the output template by aggregating the names of the sinks
                 * @param {SpeedyPipelineNode[]} [sinks]
                 * @returns {SpeedyPipelineOutput}
                 */
                static _createOutputTemplate(sinks = []) {
                  const template = /* @__PURE__ */ Object.create(null);
                  for (let i = sinks.length - 1; i >= 0; i--) template[sinks[i].name] = null;
                  return template;
                }
                /**
                 * Validate a sequence of nodes
                 * @param {SpeedyPipelineNode[]} sequence
                 */
                static _validateSequence(sequence) {
                  if (sequence.length == 0) throw new utils_errors.Er(`Pipeline doesn't have nodes`);
                  else if (!sequence[0].isSource()) throw new utils_errors.Er(`Pipeline doesn't have a source`);
                  else if (!sequence.find((node) => node.isSink())) throw new utils_errors.Er(`Pipeline doesn't have a sink`);
                }
              }
              ;
              const UPLOAD_BUFFER_SIZE = 2;
              class SpeedyPipelineNodeImageSource extends SpeedyPipelineSourceNode {
                /**
                 * Constructor
                 * @param {string} [name] name of the node
                 */
                constructor(name = void 0) {
                  super(name, UPLOAD_BUFFER_SIZE, [OutputPort().expects(SpeedyPipelineMessageType.Image)]);
                  this._media = null;
                  this._textureIndex = 0;
                }
                /**
                 * Source media
                 * @returns {SpeedyMedia|null}
                 */
                get media() {
                  return this._media;
                }
                /**
                 * Source media
                 * @param {SpeedyMedia|null} media
                 */
                set media(media) {
                  if (media !== null && !(media instanceof SpeedyMedia)) throw new utils_errors.qw(`Not a SpeedyMedia: ${media}`);
                  this._media = media;
                }
                /**
                 * Run the specific task of this node
                 * @param {SpeedyGPU} gpu
                 * @returns {void|SpeedyPromise<void>}
                 */
                _run(gpu2) {
                  if (this._media == null) throw new utils_errors.Er(`Did you forget to set the media of ${this.fullName}?`);
                  this._textureIndex = (this._textureIndex + 1) % this._tex.length;
                  const outputTexture = this._tex[this._textureIndex];
                  gpu2.upload(this._media._source, outputTexture);
                  this.output().swrite(outputTexture, this._media._format);
                }
              }
              ;
              const DEFAULT_MEDIA_TYPE = "bitmap";
              class SpeedyPipelineNodeImageSink extends SpeedyPipelineSinkNode {
                /**
                 * Constructor
                 * @param {string} [name] name of the node
                 */
                constructor(name = "image") {
                  super(name, 0, [InputPort().expects(SpeedyPipelineMessageType.Image)]);
                  this._mediaType = DEFAULT_MEDIA_TYPE;
                  this._bitmap = null;
                  this._data = null;
                  this._format = types.f5.RGBA;
                  this._textureReader = new SpeedyTextureReader(1);
                }
                /**
                 * The media type that is exported from this node
                 * @returns {SpeedyPipelineNodeImageSinkExportedMediaType}
                 */
                get mediaType() {
                  return this._mediaType;
                }
                /**
                 * The media type that is exported from this node
                 * @param {SpeedyPipelineNodeImageSinkExportedMediaType} value
                 */
                set mediaType(value) {
                  if (value != "bitmap" && value != "data") throw new utils_errors.qw(`Invalid mediaType for ${this.fullName}: "${value}"`);
                  this._mediaType = value;
                }
                /**
                 * Initializes this node
                 * @param {SpeedyGPU} gpu
                 */
                init(gpu2) {
                  super.init(gpu2);
                  this._textureReader.init(gpu2);
                }
                /**
                 * Releases this node
                 * @param {SpeedyGPU} gpu
                 */
                release(gpu2) {
                  this._textureReader.release(gpu2);
                  super.release(gpu2);
                }
                /**
                 * Export data from this node to the user
                 * @returns {SpeedyPromise<SpeedyMedia>}
                 */
                export() {
                  const bitmapOrData = this._mediaType != "data" ? this._bitmap : this._data;
                  utils.A.assert(bitmapOrData != null);
                  return SpeedyMedia.load(bitmapOrData, {
                    format: this._format
                  }, false);
                }
                /**
                 * Run the specific task of this node
                 * @param {SpeedyGPU} gpu
                 * @returns {void|SpeedyPromise<void>}
                 */
                _run(gpu2) {
                  const {
                    image,
                    format
                  } = (
                    /** @type {SpeedyPipelineMessageWithImage} */
                    this.input().read()
                  );
                  if (this._mediaType != "data") {
                    return new speedy_promise.i((resolve) => {
                      const canvas = gpu2.renderToCanvas(image);
                      createImageBitmap(canvas, 0, canvas.height - image.height, image.width, image.height).then((bitmap) => {
                        this._bitmap = bitmap;
                        this._format = format;
                        this._data = null;
                        resolve();
                      });
                    });
                  } else {
                    return this._textureReader.readPixelsAsync(image, 0, 0, image.width, image.height, false).then((pixels) => {
                      const dataArray = new Uint8ClampedArray(pixels.buffer);
                      this._data = new ImageData(dataArray, image.width, image.height);
                      this._format = format;
                      this._bitmap = null;
                    });
                  }
                }
              }
              ;
              const INPUT_PORT = ["in0", "in1"];
              class SpeedyPipelineNodeImageMultiplexer extends SpeedyPipelineNode {
                /**
                 * Constructor
                 * @param {string} [name] name of the node
                 */
                constructor(name = void 0) {
                  super(name, 0, [...INPUT_PORT.map((portName) => InputPort(portName).expects(SpeedyPipelineMessageType.Image)), OutputPort().expects(SpeedyPipelineMessageType.Image)]);
                  this._port = 0;
                }
                /**
                 * The number of the port that should be linked to the output
                 * @returns {number}
                 */
                get port() {
                  return this._port;
                }
                /**
                 * The number of the port that should be linked to the output
                 * @param {number} port
                 */
                set port(port) {
                  if (port < 0 || port >= INPUT_PORT.length) throw new utils_errors.qw(`Invalid port: ${port}`);
                  this._port = port | 0;
                }
                /**
                 * Run the specific task of this node
                 * @param {SpeedyGPU} gpu
                 * @returns {void|SpeedyPromise<void>}
                 */
                _run(gpu2) {
                  const message = this.input(INPUT_PORT[this._port]).read();
                  this.output().write(message);
                }
              }
              ;
              class SpeedyPipelineNodeImageBuffer extends SpeedyPipelineNode {
                /**
                 * Constructor
                 * @param {string} [name] name of the node
                 */
                constructor(name = void 0) {
                  super(name, 2, [InputPort().expects(SpeedyPipelineMessageType.Image), OutputPort().expects(SpeedyPipelineMessageType.Image)]);
                  this._pageIndex = 0;
                  this._initialized = false;
                  this._previousFormat = types.f5.RGBA;
                  this._frozen = false;
                }
                /**
                 * A frozen buffer discards the input, effectively increasing the buffering time
                 * @returns {boolean}
                 */
                get frozen() {
                  return this._frozen;
                }
                /**
                 * A frozen buffer discards the input, effectively increasing the buffering time
                 * @param {boolean} value
                 */
                set frozen(value) {
                  this._frozen = Boolean(value);
                }
                /**
                 * Releases this node
                 * @param {SpeedyGPU} gpu
                 */
                release(gpu2) {
                  this._initialized = false;
                  super.release(gpu2);
                }
                /**
                 * Run the specific task of this node
                 * @param {SpeedyGPU} gpu
                 * @returns {void|SpeedyPromise<void>}
                 */
                _run(gpu2) {
                  const {
                    image,
                    format
                  } = (
                    /** @type {SpeedyPipelineMessageWithImage} */
                    this.input().read()
                  );
                  const previousFormat = this._previousFormat;
                  const page = this._tex;
                  const previousInputTexture = page[1 - this._pageIndex];
                  const outputTexture = page[this._pageIndex];
                  if (image.hasMipmaps()) throw new utils_errors.EM(`${this.fullName} can't bufferize a pyramid`);
                  if (!this._frozen || !this._initialized) {
                    this._previousFormat = format;
                    previousInputTexture.resize(image.width, image.height);
                    image.copyTo(previousInputTexture);
                    this._pageIndex = 1 - this._pageIndex;
                  }
                  if (!this._initialized) {
                    this._initialized = true;
                    this.output().swrite(previousInputTexture, format);
                    return;
                  }
                  this.output().swrite(outputTexture, previousFormat);
                }
              }
              ;
              const MAX_LEVELS = globals.PYRAMID_MAX_LEVELS;
              const MAX_TEXTURES = 2 * MAX_LEVELS;
              class SpeedyPipelineNodeImagePyramid extends SpeedyPipelineNode {
                /**
                 * Constructor
                 * @param {string} [name] name of the node
                 */
                constructor(name = void 0) {
                  super(name, MAX_TEXTURES + 1, [InputPort().expects(SpeedyPipelineMessageType.Image), OutputPort().expects(SpeedyPipelineMessageType.Image)]);
                }
                /**
                 * Run the specific task of this node
                 * @param {SpeedyGPU} gpu
                 * @returns {void|SpeedyPromise<void>}
                 */
                _run(gpu2) {
                  const {
                    image,
                    format
                  } = (
                    /** @type {SpeedyPipelineMessageWithImage} */
                    this.input().read()
                  );
                  const outputTexture = this._tex[0];
                  const pyramids = gpu2.programs.pyramids;
                  let width = image.width, height = image.height;
                  const mipLevels = 1 + Math.floor(Math.log2(Math.max(width, height)));
                  const mip = new Array(MAX_TEXTURES + 1);
                  for (let i = MAX_TEXTURES; i >= 1; i--) mip[i - 1] = this._tex[i];
                  mip[0].resize(width, height);
                  image.copyTo(mip[0]);
                  const numLevels = Math.min(mipLevels, MAX_LEVELS);
                  for (let level = 1; level < numLevels; level++) {
                    const halfWidth = Math.max(1, width >>> 1);
                    const halfHeight = Math.max(1, height >>> 1);
                    const tmp = level - 1 + MAX_LEVELS;
                    pyramids.smoothX.outputs(width, height, mip[tmp])(mip[level - 1]);
                    pyramids.smoothY.outputs(width, height, mip[level - 1])(mip[tmp]);
                    pyramids.downsample2.outputs(halfWidth, halfHeight, mip[level])(mip[level - 1]);
                    gpu2.gl.flush();
                    width = halfWidth;
                    height = halfHeight;
                  }
                  outputTexture.resize(image.width, image.height);
                  outputTexture.clear();
                  image.copyTo(outputTexture);
                  outputTexture.generateMipmaps(mip.slice(0, numLevels));
                  this.output().swrite(outputTexture, format);
                }
              }
              ;
              class SpeedyPipelineNodeImageMixer extends SpeedyPipelineNode {
                /**
                 * Constructor
                 * @param {string} [name] name of the node
                 */
                constructor(name = void 0) {
                  super(name, 1, [InputPort("in0").expects(SpeedyPipelineMessageType.Image), InputPort("in1").expects(SpeedyPipelineMessageType.Image), OutputPort().expects(SpeedyPipelineMessageType.Image)]);
                  this._alpha = 0.5;
                  this._beta = 0.5;
                  this._gamma = 0;
                }
                /**
                 * Alpha coefficient (applied to image0)
                 * @returns {number}
                 */
                get alpha() {
                  return this._alpha;
                }
                /**
                 * Alpha coefficient (applied to image0)
                 * @param {number} value
                 */
                set alpha(value) {
                  this._alpha = +value;
                }
                /**
                 * Beta coefficient (applied to image1)
                 * @returns {number}
                 */
                get beta() {
                  return this._beta;
                }
                /**
                 * Beta coefficient (applied to image1)
                 * @param {number} value
                 */
                set beta(value) {
                  this._beta = +value;
                }
                /**
                 * Gamma coefficient (brightness control)
                 * @returns {number}
                 */
                get gamma() {
                  return this._gamma;
                }
                /**
                 * Gamma coefficient (brightness control)
                 * @param {number} value
                 */
                set gamma(value) {
                  this._gamma = +value;
                }
                /**
                 * Run the specific task of this node
                 * @param {SpeedyGPU} gpu
                 * @returns {void|SpeedyPromise<void>}
                 */
                _run(gpu2) {
                  const in0 = (
                    /** @type {SpeedyPipelineMessageWithImage} */
                    this.input("in0").read()
                  );
                  const in1 = (
                    /** @type {SpeedyPipelineMessageWithImage} */
                    this.input("in1").read()
                  );
                  const image0 = in0.image, image1 = in1.image;
                  const format0 = in0.format, format1 = in1.format;
                  const width = Math.max(image0.width, image1.width);
                  const height = Math.max(image0.height, image1.height);
                  const alpha = this._alpha, beta = this._beta, gamma = this._gamma;
                  const outputTexture = this._tex[0];
                  if (format0 != format1) throw new utils_errors.EM(`Can't mix images of different formats`);
                  gpu2.programs.transforms.additiveMix.outputs(width, height, outputTexture);
                  gpu2.programs.transforms.additiveMix(image0, image1, alpha, beta, gamma);
                  this.output().swrite(outputTexture, format0);
                }
              }
              ;
              class SpeedyPipelineNodeImagePortalSink extends SpeedyPipelineNode {
                /**
                 * Constructor
                 * @param {string} [name] name of the node
                 */
                constructor(name = void 0) {
                  super(name, 1, [InputPort().expects(SpeedyPipelineMessageType.Image)]);
                  this._format = types.f5.RGBA;
                  this._initialized = false;
                }
                /**
                 * Stored image
                 * @returns {SpeedyTexture}
                 */
                get image() {
                  if (!this._initialized) throw new utils_errors.Er(`Portal error: ${this.fullName} holds no data`);
                  return this._tex[0];
                }
                /**
                 * Stored image format
                 * @returns {ImageFormat}
                 */
                get format() {
                  if (!this._initialized) throw new utils_errors.Er(`Portal error: ${this.fullName} holds no data`);
                  return this._format;
                }
                /**
                 * Initializes this node
                 * @param {SpeedyGPU} gpu
                 */
                init(gpu2) {
                  super.init(gpu2);
                  this._tex[0].resize(1, 1).clear();
                  this._format = types.f5.RGBA;
                  this._initialized = true;
                }
                /**
                 * Releases this node
                 * @param {SpeedyGPU} gpu
                 */
                release(gpu2) {
                  this._initialized = false;
                  super.release(gpu2);
                }
                /**
                 * Run the specific task of this node
                 * @param {SpeedyGPU} gpu
                 * @returns {void|SpeedyPromise<void>}
                 */
                _run(gpu2) {
                  const {
                    image,
                    format
                  } = (
                    /** @type {SpeedyPipelineMessageWithImage} */
                    this.input().read()
                  );
                  const tex = this._tex[0];
                  if (image.hasMipmaps()) throw new utils_errors.EM(`${this.fullName} can't store a pyramid`);
                  this._format = format;
                  tex.resize(image.width, image.height);
                  image.copyTo(tex);
                }
              }
              class SpeedyPipelineNodeImagePortalSource extends SpeedyPipelineSourceNode {
                /**
                 * Constructor
                 * @param {string} [name] name of the node
                 */
                constructor(name = void 0) {
                  super(name, 0, [OutputPort().expects(SpeedyPipelineMessageType.Image)]);
                  this._source = null;
                }
                /**
                 * Data source
                 * @returns {SpeedyPipelineNodeImagePortalSink|null}
                 */
                get source() {
                  return this._source;
                }
                /**
                 * Data source
                 * @param {SpeedyPipelineNodeImagePortalSink|null} node
                 */
                set source(node) {
                  if (node !== null && !(node instanceof SpeedyPipelineNodeImagePortalSink)) throw new utils_errors.qw(`Incompatible source for ${this.fullName}`);
                  this._source = node;
                }
                /**
                 * Run the specific task of this node
                 * @param {SpeedyGPU} gpu
                 * @returns {void|SpeedyPromise<void>}
                 */
                _run(gpu2) {
                  if (this._source == null) throw new utils_errors.Er(`${this.fullName} has no source`);
                  this.output().swrite(this._source.image, this._source.format);
                }
              }
              ;
              class SpeedyPipelineImagePortalFactory extends speedy_namespace.Q {
                /**
                 * Create an image portal source
                 * @param {string} [name] name of the node
                 * @returns {SpeedyPipelineNodeImagePortalSource}
                 */
                static Source(name = void 0) {
                  return new SpeedyPipelineNodeImagePortalSource(name);
                }
                /**
                 * Create an image portal sink
                 * @param {string} [name] name of the node
                 * @returns {SpeedyPipelineNodeImagePortalSink}
                 */
                static Sink(name = void 0) {
                  return new SpeedyPipelineNodeImagePortalSink(name);
                }
              }
              class SpeedyPipelineImageFactory extends speedy_namespace.Q {
                /**
                 * Create an image source
                 * @param {string} [name] name of the node
                 * @returns {SpeedyPipelineNodeImageSource}
                 */
                static Source(name = void 0) {
                  return new SpeedyPipelineNodeImageSource(name);
                }
                /**
                 * Create an image sink
                 * @param {string} [name] name of the node
                 * @returns {SpeedyPipelineNodeImageSink}
                 */
                static Sink(name = void 0) {
                  return new SpeedyPipelineNodeImageSink(name);
                }
                /**
                 * Create an image multiplexer
                 * @param {string} [name] name of the node
                 * @returns {SpeedyPipelineNodeImageMultiplexer}
                 */
                static Multiplexer(name = void 0) {
                  return new SpeedyPipelineNodeImageMultiplexer(name);
                }
                /**
                 * Create an image buffer
                 * @param {string} [name] name of the node
                 * @returns {SpeedyPipelineNodeImageBuffer}
                 */
                static Buffer(name = void 0) {
                  return new SpeedyPipelineNodeImageBuffer(name);
                }
                /**
                 * Image Pyramid
                 * @param {string} [name] name of the node
                 * @returns {SpeedyPipelineNodeImagePyramid}
                 */
                static Pyramid(name = void 0) {
                  return new SpeedyPipelineNodeImagePyramid(name);
                }
                /**
                 * Image Mixer (blending)
                 * @param {string} [name] name of the node
                 * @returns {SpeedyPipelineNodeImageMixer}
                 */
                static Mixer(name = void 0) {
                  return new SpeedyPipelineNodeImageMixer(name);
                }
                /**
                 * Image Portals
                 * @returns {typeof SpeedyPipelineImagePortalFactory}
                 */
                static get Portal() {
                  return SpeedyPipelineImagePortalFactory;
                }
              }
              ;
              class SpeedyPipelineNodeGreyscale extends SpeedyPipelineNode {
                /**
                 * Constructor
                 * @param {string} [name] name of the node
                 */
                constructor(name = void 0) {
                  super(name, 1, [InputPort().expects(SpeedyPipelineMessageType.Image), OutputPort().expects(SpeedyPipelineMessageType.Image)]);
                }
                /**
                 * Run the specific task of this node
                 * @param {SpeedyGPU} gpu
                 * @returns {void|SpeedyPromise<void>}
                 */
                _run(gpu2) {
                  const {
                    image,
                    format
                  } = (
                    /** @type {SpeedyPipelineMessageWithImage} */
                    this.input().read()
                  );
                  const width = image.width, height = image.height;
                  const outputTexture = this._tex[0];
                  const filters = gpu2.programs.filters;
                  filters.rgb2grey.outputs(width, height, outputTexture);
                  filters.rgb2grey(image);
                  this.output().swrite(outputTexture, types.f5.GREY);
                }
              }
              ;
              const DEFAULT_KERNEL = Object.freeze({
                3: [0.27901008925473514, 0.44197982149052983, 0.27901008925473514],
                // 1D convolution (sigma = 1)
                5: [0.06135959781344021, 0.2447701955296099, 0.3877404133138998, 0.2447701955296099, 0.06135959781344021],
                // 1D convolution (separable kernel)
                7: [0.03873542500847274, 0.11308485700794121, 0.2150068609928349, 0.26634571398150225, 0.2150068609928349, 0.11308485700794121, 0.03873542500847274],
                9: [0.028532262603370988, 0.067234535494912, 0.12400932997922749, 0.17904386461741617, 0.20236001461014655, 0.17904386461741617, 0.12400932997922749, 0.067234535494912, 0.028532262603370988],
                11: [0.022656882730580346, 0.04610857898527292, 0.08012661469398517, 0.11890414969751599, 0.15067709325491124, 0.16305336127546846, 0.15067709325491124, 0.11890414969751599, 0.08012661469398517, 0.04610857898527292, 0.022656882730580346],
                13: [0.018815730430644363, 0.03447396964662016, 0.05657737457255748, 0.08317258170844948, 0.10952340502389682, 0.12918787500405662, 0.13649812722755, 0.12918787500405662, 0.10952340502389682, 0.08317258170844948, 0.05657737457255748, 0.03447396964662016, 0.018815730430644363],
                15: [0.016100340991695383, 0.027272329212157102, 0.042598338587449644, 0.06135478775568558, 0.08148767614129326, 0.09979838342934616, 0.11270444144735056, 0.11736740487004466, 0.11270444144735056, 0.09979838342934616, 0.08148767614129326, 0.06135478775568558, 0.042598338587449644, 0.027272329212157102, 0.016100340991695383]
                //3: [ 0.25, 0.5, 0.25 ],
                //5: [ 0.05, 0.25, 0.4, 0.25, 0.05 ],
              });
              const DEFAULT_SIGMA = new SpeedyVector2(0, 0);
              const CONVOLUTION_X = Object.freeze({
                3: "convolution3x",
                5: "convolution5x",
                7: "convolution7x",
                9: "convolution9x",
                11: "convolution11x",
                13: "convolution13x",
                15: "convolution15x"
              });
              const CONVOLUTION_Y = Object.freeze({
                3: "convolution3y",
                5: "convolution5y",
                7: "convolution7y",
                9: "convolution9y",
                11: "convolution11y",
                13: "convolution13y",
                15: "convolution15y"
              });
              class SpeedyPipelineNodeGaussianBlur extends SpeedyPipelineNode {
                /**
                 * Constructor
                 * @param {string} [name] name of the node
                 */
                constructor(name = void 0) {
                  super(name, 2, [InputPort().expects(SpeedyPipelineMessageType.Image), OutputPort().expects(SpeedyPipelineMessageType.Image)]);
                  this._kernelSize = new SpeedySize(5, 5);
                  this._sigma = DEFAULT_SIGMA;
                  this._kernel = {
                    x: DEFAULT_KERNEL[this._kernelSize.width],
                    y: DEFAULT_KERNEL[this._kernelSize.height]
                  };
                }
                /**
                 * Size of the kernel
                 * @returns {SpeedySize}
                 */
                get kernelSize() {
                  return this._kernelSize;
                }
                /**
                 * Size of the kernel
                 * @param {SpeedySize} kernelSize
                 */
                set kernelSize(kernelSize) {
                  utils.A.assert(kernelSize instanceof SpeedySize);
                  const kw = kernelSize.width, kh = kernelSize.height;
                  if (kw < 3 || kh < 3 || kw > 15 || kh > 15 || kw % 2 == 0 || kh % 2 == 0) throw new utils_errors.EM(`Unsupported kernel size: ${kw}x${kh}`);
                  this._kernelSize = kernelSize;
                  this._updateKernel();
                }
                /**
                 * Sigma of the Gaussian kernel
                 * @returns {SpeedyVector2}
                 */
                get sigma() {
                  return this._sigma;
                }
                /**
                 * Sigma of the Gaussian kernel
                 * @param {SpeedyVector2} sigma
                 */
                set sigma(sigma) {
                  utils.A.assert(sigma instanceof SpeedyVector2, `Sigma must be a SpeedyVector2`);
                  utils.A.assert(sigma.x >= 0 && sigma.y >= 0);
                  this._sigma = sigma;
                  this._updateKernel();
                }
                /**
                 * Run the specific task of this node
                 * @param {SpeedyGPU} gpu
                 * @returns {void|SpeedyPromise<void>}
                 */
                _run(gpu2) {
                  const {
                    image,
                    format
                  } = (
                    /** @type {SpeedyPipelineMessageWithImage} */
                    this.input().read()
                  );
                  const width = image.width, height = image.height;
                  const kernX = this._kernel.x;
                  const kernY = this._kernel.y;
                  const convX = CONVOLUTION_X[this._kernelSize.width];
                  const convY = CONVOLUTION_Y[this._kernelSize.height];
                  const tex = this._tex[0];
                  const outputTexture = this._tex[1];
                  gpu2.programs.filters[convX].outputs(width, height, tex)(image, kernX);
                  gpu2.programs.filters[convY].outputs(width, height, outputTexture)(tex, kernY);
                  this.output().swrite(outputTexture, format);
                }
                /**
                 * Update the internal kernel to match
                 * sigma and kernelSize
                 */
                _updateKernel() {
                  if (this._sigma.x == DEFAULT_SIGMA.x) this._kernel.x = DEFAULT_KERNEL[this._kernelSize.width];
                  else this._kernel.x = utils.A.gaussianKernel(this._sigma.x, this._kernelSize.width, true);
                  if (this._sigma.y == DEFAULT_SIGMA.y) this._kernel.y = DEFAULT_KERNEL[this._kernelSize.height];
                  else this._kernel.y = utils.A.gaussianKernel(this._sigma.y, this._kernelSize.height, true);
                }
              }
              ;
              const BOX_FILTER = Object.freeze({
                3: new Array(3).fill(1 / 3),
                5: new Array(5).fill(1 / 5),
                7: new Array(7).fill(1 / 7),
                9: new Array(9).fill(1 / 9),
                11: new Array(11).fill(1 / 11),
                13: new Array(13).fill(1 / 13),
                15: new Array(15).fill(1 / 15)
              });
              const simple_blur_CONVOLUTION_X = Object.freeze({
                3: "convolution3x",
                5: "convolution5x",
                7: "convolution7x",
                9: "convolution9x",
                11: "convolution11x",
                13: "convolution13x",
                15: "convolution15x"
              });
              const simple_blur_CONVOLUTION_Y = Object.freeze({
                3: "convolution3y",
                5: "convolution5y",
                7: "convolution7y",
                9: "convolution9y",
                11: "convolution11y",
                13: "convolution13y",
                15: "convolution15y"
              });
              class SpeedyPipelineNodeSimpleBlur extends SpeedyPipelineNode {
                /**
                 * Constructor
                 * @param {string} [name] name of the node
                 */
                constructor(name = void 0) {
                  super(name, 2, [InputPort().expects(SpeedyPipelineMessageType.Image), OutputPort().expects(SpeedyPipelineMessageType.Image)]);
                  this._kernelSize = new SpeedySize(5, 5);
                  this._kernel = {
                    x: BOX_FILTER[this._kernelSize.width],
                    y: BOX_FILTER[this._kernelSize.height]
                  };
                }
                /**
                 * Size of the kernel
                 * @returns {SpeedySize}
                 */
                get kernelSize() {
                  return this._kernelSize;
                }
                /**
                 * Size of the kernel
                 * @param {SpeedySize} kernelSize
                 */
                set kernelSize(kernelSize) {
                  utils.A.assert(kernelSize instanceof SpeedySize);
                  const kw = kernelSize.width, kh = kernelSize.height;
                  if (kw < 3 || kh < 3 || kw > 15 || kh > 15 || kw % 2 == 0 || kh % 2 == 0) throw new utils_errors.EM(`Unsupported kernel size: ${kw}x${kh}`);
                  this._kernelSize = kernelSize;
                  this._kernel.x = BOX_FILTER[this._kernelSize.width];
                  this._kernel.y = BOX_FILTER[this._kernelSize.height];
                }
                /**
                 * Run the specific task of this node
                 * @param {SpeedyGPU} gpu
                 * @returns {void|SpeedyPromise<void>}
                 */
                _run(gpu2) {
                  const {
                    image,
                    format
                  } = (
                    /** @type {SpeedyPipelineMessageWithImage} */
                    this.input().read()
                  );
                  const width = image.width, height = image.height;
                  const kernX = this._kernel.x;
                  const kernY = this._kernel.y;
                  const convX = simple_blur_CONVOLUTION_X[this._kernelSize.width];
                  const convY = simple_blur_CONVOLUTION_Y[this._kernelSize.height];
                  const tex = this._tex[0];
                  const outputTexture = this._tex[1];
                  gpu2.programs.filters[convX].outputs(width, height, tex)(image, kernX);
                  gpu2.programs.filters[convY].outputs(width, height, outputTexture)(tex, kernY);
                  this.output().swrite(outputTexture, format);
                }
              }
              ;
              const MEDIAN = {
                3: "median3",
                5: "median5",
                7: "median7"
              };
              class SpeedyPipelineNodeMedianBlur extends SpeedyPipelineNode {
                /**
                 * Constructor
                 * @param {string} [name] name of the node
                 */
                constructor(name = void 0) {
                  super(name, 1, [InputPort().expects(SpeedyPipelineMessageType.Image).satisfying((msg) => msg.format === types.f5.GREY), OutputPort().expects(SpeedyPipelineMessageType.Image)]);
                  this._kernelSize = new SpeedySize(5, 5);
                }
                /**
                 * Size of the kernel
                 * @returns {SpeedySize}
                 */
                get kernelSize() {
                  return this._kernelSize;
                }
                /**
                 * Size of the kernel
                 * @param {SpeedySize} kernelSize
                 */
                set kernelSize(kernelSize) {
                  utils.A.assert(kernelSize instanceof SpeedySize);
                  const ksize = kernelSize.width;
                  if (!(ksize == 3 || ksize == 5 || ksize == 7)) throw new utils_errors.EM(`Supported kernel sizes: 3x3, 5x5, 7x7`);
                  else if (kernelSize.width != kernelSize.height) throw new utils_errors.EM(`Use a square kernel`);
                  this._kernelSize = kernelSize;
                }
                /**
                 * Run the specific task of this node
                 * @param {SpeedyGPU} gpu
                 * @returns {void|SpeedyPromise<void>}
                 */
                _run(gpu2) {
                  const {
                    image,
                    format
                  } = (
                    /** @type {SpeedyPipelineMessageWithImage} */
                    this.input().read()
                  );
                  const width = image.width, height = image.height;
                  const ksize = this._kernelSize.width;
                  const med = MEDIAN[ksize];
                  const outputTexture = this._tex[0];
                  gpu2.programs.filters[med].outputs(width, height, outputTexture)(image);
                  this.output().swrite(outputTexture, format);
                }
              }
              ;
              const CONVOLUTION = {
                3: "convolution3",
                5: "convolution5",
                7: "convolution7"
              };
              class SpeedyPipelineNodeConvolution extends SpeedyPipelineNode {
                /**
                 * Constructor
                 * @param {string} [name] name of the node
                 */
                constructor(name = void 0) {
                  super(name, 1, [InputPort().expects(SpeedyPipelineMessageType.Image), OutputPort().expects(SpeedyPipelineMessageType.Image)]);
                  this._kernel = speedy_matrix.SpeedyMatrix.Create(3, 3, [0, 0, 0, 0, 1, 0, 0, 0, 0]);
                }
                /**
                 * Convolution kernel
                 * @returns {SpeedyMatrix}
                 */
                get kernel() {
                  return this._kernel;
                }
                /**
                 * Convolution kernel
                 * @param {SpeedyMatrix} kernel
                 */
                set kernel(kernel) {
                  if (kernel.rows != kernel.columns) throw new utils_errors.EM(`Use a square kernel`);
                  else if (!(kernel.rows == 3 || kernel.rows == 5 || kernel.rows == 7)) throw new utils_errors.EM(`Invalid kernel size. Supported sizes: 3x3, 5x5, 7x7`);
                  this._kernel = kernel;
                }
                /**
                 * Run the specific task of this node
                 * @param {SpeedyGPU} gpu
                 * @returns {void|SpeedyPromise<void>}
                 */
                _run(gpu2) {
                  const {
                    image,
                    format
                  } = (
                    /** @type {SpeedyPipelineMessageWithImage} */
                    this.input().read()
                  );
                  const width = image.width, height = image.height;
                  const outputTexture = this._tex[0];
                  const ksize = this._kernel.rows;
                  const conv = CONVOLUTION[ksize];
                  const kernel = this._kernel.read();
                  gpu2.programs.filters[conv].outputs(width, height, outputTexture)(image, kernel);
                  this.output().swrite(outputTexture, format);
                }
              }
              ;
              class SpeedyPipelineNodeNightvision extends SpeedyPipelineNode {
                /**
                 * Constructor
                 * @param {string} [name] name of the node
                 */
                constructor(name = void 0) {
                  super(name, 3, [InputPort().expects(SpeedyPipelineMessageType.Image).satisfying((msg) => msg.format === types.f5.RGBA || msg.format === types.f5.GREY), OutputPort().expects(SpeedyPipelineMessageType.Image)]);
                  this._gain = 0.5;
                  this._offset = 0.5;
                  this._decay = 0;
                  this._quality = "medium";
                }
                /**
                 * Gain, a value typically in [0,1]: larger number => higher contrast
                 * @returns {number}
                 */
                get gain() {
                  return this._gain;
                }
                /**
                 * Gain, a value typically in [0,1]: larger number => higher contrast
                 * @param {number} gain
                 */
                set gain(gain) {
                  this._gain = +gain;
                }
                /**
                 * Offset, a value typically in [0,1] that controls the brightness
                 * @returns {number}
                 */
                get offset() {
                  return this._offset;
                }
                /**
                 * Offset, a value typically in [0,1] that controls the brightness
                 * @param {number} offset
                 */
                set offset(offset) {
                  this._offset = +offset;
                }
                /**
                 * Gain decay, a value in [0,1] that controls how the gain decays from the center of the image
                 * @returns {number}
                 */
                get decay() {
                  return this._decay;
                }
                /**
                 * Gain decay, a value in [0,1] that controls how the gain decays from the center of the image
                 * @param {number} decay
                 */
                set decay(decay) {
                  this._decay = Math.max(0, Math.min(+decay, 1));
                }
                /**
                 * Quality level of the filter
                 * @returns {NightvisionQualityLevel}
                 */
                get quality() {
                  return this._quality;
                }
                /**
                 * Quality level of the filter
                 * @param {NightvisionQualityLevel} quality
                 */
                set quality(quality) {
                  if (quality === "high" || quality === "medium" || quality === "low") this._quality = quality;
                  else throw new utils_errors.qw(`Invalid quality level for the Nightvision filter: "${quality}"`);
                }
                /**
                 * Run the specific task of this node
                 * @param {SpeedyGPU} gpu
                 * @returns {void|SpeedyPromise<void>}
                 */
                _run(gpu2) {
                  const {
                    image,
                    format
                  } = (
                    /** @type {SpeedyPipelineMessageWithImage} */
                    this.input().read()
                  );
                  const width = image.width, height = image.height;
                  const gain = this._gain;
                  const offset = this._offset;
                  const decay = this._decay;
                  const quality = this._quality;
                  const filters = gpu2.programs.filters;
                  const tmp = this._tex[0];
                  const illuminationMap = this._tex[1];
                  const outputTexture = this._tex[2];
                  if (quality == "medium") {
                    filters.illuminationMapX.outputs(width, height, tmp);
                    filters.illuminationMapY.outputs(width, height, illuminationMap);
                    filters.illuminationMapX(image);
                    filters.illuminationMapY(tmp);
                  } else if (quality == "high") {
                    filters.illuminationMapHiX.outputs(width, height, tmp);
                    filters.illuminationMapHiY.outputs(width, height, illuminationMap);
                    filters.illuminationMapHiX(image);
                    filters.illuminationMapHiY(tmp);
                  } else if (quality == "low") {
                    filters.illuminationMapLoX.outputs(width, height, tmp);
                    filters.illuminationMapLoY.outputs(width, height, illuminationMap);
                    filters.illuminationMapLoX(image);
                    filters.illuminationMapLoY(tmp);
                  }
                  if (format === types.f5.GREY) {
                    filters.nightvisionGreyscale.outputs(width, height, outputTexture);
                    filters.nightvisionGreyscale(image, illuminationMap, gain, offset, decay);
                  } else if (format === types.f5.RGBA) {
                    filters.nightvision.outputs(width, height, outputTexture);
                    filters.nightvision(image, illuminationMap, gain, offset, decay);
                  }
                  this.output().swrite(outputTexture, format);
                }
              }
              ;
              class SpeedyPipelineNodeNormalize extends SpeedyPipelineNode {
                /**
                 * Constructor
                 * @param {string} [name] name of the node
                 */
                constructor(name = void 0) {
                  super(name, 4, [InputPort().expects(SpeedyPipelineMessageType.Image).satisfying((msg) => msg.format === types.f5.GREY), OutputPort().expects(SpeedyPipelineMessageType.Image)]);
                  this._minValue = 0;
                  this._maxValue = 255;
                }
                /**
                 * Minimum intensity in the output image, a value in [0,255]
                 * @returns {number}
                 */
                get minValue() {
                  return this._minValue;
                }
                /**
                 * Minimum intensity in the output image, a value in [0,255]
                 * @param {number} minValue
                 */
                set minValue(minValue) {
                  this._minValue = Math.max(0, Math.min(+minValue, 255));
                }
                /**
                 * Maximum intensity in the output image, a value in [0,255]
                 * @returns {number}
                 */
                get maxValue() {
                  return this._maxValue;
                }
                /**
                 * Maximum intensity in the output image, a value in [0,255]
                 * @param {number} maxValue
                 */
                set maxValue(maxValue) {
                  this._maxValue = Math.max(0, Math.min(+maxValue, 255));
                }
                /**
                 * Run the specific task of this node
                 * @param {SpeedyGPU} gpu
                 * @returns {void|SpeedyPromise<void>}
                 */
                _run(gpu2) {
                  const {
                    image,
                    format
                  } = (
                    /** @type {SpeedyPipelineMessageWithImage} */
                    this.input().read()
                  );
                  const width = image.width, height = image.height;
                  const outputTexture = this._tex[3];
                  let minValue = this._minValue;
                  let maxValue = this._maxValue;
                  if (minValue > maxValue) minValue = maxValue = (minValue + maxValue) / 2;
                  const minmax = this._scanMinMax(gpu2, image, types.kQ.GREEN);
                  gpu2.programs.filters.normalizeGreyscale.outputs(width, height, outputTexture);
                  gpu2.programs.filters.normalizeGreyscale(minmax, minValue, maxValue);
                  this.output().swrite(outputTexture, format);
                }
                /**
                 * Scan a single component in all pixels of the image and find the min & max intensities
                 * @param {SpeedyGPU} gpu
                 * @param {SpeedyTexture} image input image
                 * @param {PixelComponent} pixelComponent a single PixelComponent flag
                 * @returns {SpeedyDrawableTexture} RGBA = (max, min, max - min, original_pixel)
                 */
                _scanMinMax(gpu2, image, pixelComponent) {
                  const tex = this._tex;
                  const program = gpu2.programs.utils;
                  const width = image.width, height = image.height;
                  const numIterations = Math.ceil(Math.log2(Math.max(width, height))) | 0;
                  utils.A.assert(types.kg[pixelComponent] !== void 0);
                  program.copyComponents.outputs(width, height, tex[2]);
                  program.scanMinMax2D.outputs(width, height, tex[0], tex[1]);
                  let texture = program.copyComponents(image, image, types.kQ.ALL, types.kg[pixelComponent]);
                  for (let i = 0; i < numIterations; i++) texture = program.scanMinMax2D(texture, i);
                  return texture;
                }
              }
              ;
              class SpeedyPipelineFilterFactory extends speedy_namespace.Q {
                /**
                 * Convert image to greyscale
                 * @param {string} [name]
                 * @returns {SpeedyPipelineNodeGreyscale}
                 */
                static Greyscale(name = void 0) {
                  return new SpeedyPipelineNodeGreyscale(name);
                }
                /**
                 * Gaussian Blur
                 * @param {string} [name]
                 * @returns {SpeedyPipelineNodeGaussianBlur}
                 */
                static GaussianBlur(name = void 0) {
                  return new SpeedyPipelineNodeGaussianBlur(name);
                }
                /**
                 * Simple Blur (Box Filter)
                 * @param {string} [name]
                 * @returns {SpeedyPipelineNodeSimpleBlur}
                 */
                static SimpleBlur(name = void 0) {
                  return new SpeedyPipelineNodeSimpleBlur(name);
                }
                /**
                 * Median Blur
                 * @param {string} [name]
                 * @returns {SpeedyPipelineNodeMedianBlur}
                 */
                static MedianBlur(name = void 0) {
                  return new SpeedyPipelineNodeMedianBlur(name);
                }
                /**
                 * Image Convolution
                 * @param {string} [name]
                 * @returns {SpeedyPipelineNodeConvolution}
                 */
                static Convolution(name = void 0) {
                  return new SpeedyPipelineNodeConvolution(name);
                }
                /**
                 * Nightvision
                 * @param {string} [name]
                 * @returns {SpeedyPipelineNodeNightvision}
                 */
                static Nightvision(name = void 0) {
                  return new SpeedyPipelineNodeNightvision(name);
                }
                /**
                 * Normalize image
                 * @param {string} [name]
                 * @returns {SpeedyPipelineNodeNormalize}
                 */
                static Normalize(name = void 0) {
                  return new SpeedyPipelineNodeNormalize(name);
                }
              }
              ;
              const SINGULAR_MATRIX = [0, 0, 0, 0, 0, 0, 0, 0, 1];
              class SpeedyPipelineNodePerspectiveWarp extends SpeedyPipelineNode {
                /**
                 * Constructor
                 * @param {string} [name] name of the node
                 */
                constructor(name = void 0) {
                  super(name, 1, [InputPort().expects(SpeedyPipelineMessageType.Image), OutputPort().expects(SpeedyPipelineMessageType.Image)]);
                  this._transform = speedy_matrix.SpeedyMatrix.Create(3, 3, [1, 0, 0, 0, 1, 0, 0, 0, 1]);
                }
                /**
                 * Perspective transform, a 3x3 homography matrix
                 * @returns {SpeedyMatrix}
                 */
                get transform() {
                  return this._transform;
                }
                /**
                 * Perspective transform, a 3x3 homography matrix
                 * @param {SpeedyMatrix} transform
                 */
                set transform(transform) {
                  if (!(transform.rows == 3 && transform.columns == 3)) throw new utils_errors.qw(`Not a 3x3 transformation matrix: ${transform}`);
                  this._transform = transform;
                }
                /**
                 * Run the specific task of this node
                 * @param {SpeedyGPU} gpu
                 * @returns {void|SpeedyPromise<void>}
                 */
                _run(gpu2) {
                  const {
                    image,
                    format
                  } = (
                    /** @type {SpeedyPipelineMessageWithImage} */
                    this.input().read()
                  );
                  const width = image.width, height = image.height;
                  const outputTexture = this._tex[0];
                  const homography = this._transform.read();
                  const inverseHomography = this._inverse3(homography);
                  const isValidHomography = !Number.isNaN(inverseHomography[0]);
                  gpu2.programs.transforms.warpPerspective.outputs(width, height, outputTexture);
                  gpu2.programs.transforms.warpPerspective(image, isValidHomography ? inverseHomography : SINGULAR_MATRIX);
                  this.output().swrite(outputTexture, format);
                }
                /**
                 * Compute the inverse of a 3x3 matrix IN-PLACE (do it fast!)
                 * @param {number[]} mat 3x3 matrix in column-major format
                 * @param {number} [eps] epsilon
                 * @returns {number[]} 3x3 inverse matrix in column-major format
                 */
                _inverse3(mat, eps = 1e-6) {
                  const a11 = mat[0];
                  const a21 = mat[1];
                  const a31 = mat[2];
                  const a12 = mat[3];
                  const a22 = mat[4];
                  const a32 = mat[5];
                  const a13 = mat[6];
                  const a23 = mat[7];
                  const a33 = mat[8];
                  const b1 = a33 * a22 - a32 * a23;
                  const b2 = a33 * a12 - a32 * a13;
                  const b3 = a23 * a12 - a22 * a13;
                  const det = a11 * b1 - a21 * b2 + a31 * b3;
                  if (!(Math.abs(det) < eps)) {
                    const d = 1 / det;
                    mat[0] = b1 * d;
                    mat[1] = -(a33 * a21 - a31 * a23) * d;
                    mat[2] = (a32 * a21 - a31 * a22) * d;
                    mat[3] = -b2 * d;
                    mat[4] = (a33 * a11 - a31 * a13) * d;
                    mat[5] = -(a32 * a11 - a31 * a12) * d;
                    mat[6] = b3 * d;
                    mat[7] = -(a23 * a11 - a21 * a13) * d;
                    mat[8] = (a22 * a11 - a21 * a12) * d;
                  } else mat.fill(Number.NaN, 0, 9);
                  return mat;
                }
              }
              ;
              class SpeedyPipelineNodeResize extends SpeedyPipelineNode {
                /**
                 * Constructor
                 * @param {string} [name] name of the node
                 */
                constructor(name = void 0) {
                  super(name, 1, [InputPort().expects(SpeedyPipelineMessageType.Image), OutputPort().expects(SpeedyPipelineMessageType.Image)]);
                  this._size = new SpeedySize(0, 0);
                  this._scale = new SpeedyVector2(1, 1);
                  this._method = "bilinear";
                }
                /**
                 * Size of the output image, in pixels (use 0 to use scale)
                 * @returns {SpeedySize}
                 */
                get size() {
                  return this._size;
                }
                /**
                 * Size of the output image, in pixels (use 0 to use scale)
                 * @param {SpeedySize} size
                 */
                set size(size) {
                  this._size = size;
                }
                /**
                 * Size of the output image relative to the size of the input image
                 * @returns {SpeedyVector2}
                 */
                get scale() {
                  return this._scale;
                }
                /**
                 * Size of the output image relative to the size of the input image
                 * @param {SpeedyVector2} scale
                 */
                set scale(scale) {
                  this._scale = scale;
                }
                /**
                 * Interpolation method
                 * @returns {SpeedyPipelineNodeResizeMethod}
                 */
                get method() {
                  return this._method;
                }
                /**
                 * Interpolation method
                 * @param {SpeedyPipelineNodeResizeMethod} method
                 */
                set method(method) {
                  if (method !== "nearest" && method !== "bilinear") throw new utils_errors.qw(`Invalid method method: "${method}"`);
                  this._method = method;
                }
                /**
                 * Run the specific task of this node
                 * @param {SpeedyGPU} gpu
                 * @returns {void|SpeedyPromise<void>}
                 */
                _run(gpu2) {
                  const {
                    image,
                    format
                  } = (
                    /** @type {SpeedyPipelineMessageWithImage} */
                    this.input().read()
                  );
                  const width = image.width, height = image.height;
                  const outputTexture = this._tex[0];
                  const method = this._method;
                  const newWidth = this._size.width || Math.max(1, this._scale.x * width);
                  const newHeight = this._size.height || Math.max(1, this._scale.y * height);
                  if (method == "bilinear") {
                    gpu2.programs.transforms.resizeBilinear.outputs(newWidth, newHeight, outputTexture)(image);
                  } else if (method == "nearest") {
                    gpu2.programs.transforms.resizeNearest.outputs(newWidth, newHeight, outputTexture)(image);
                  }
                  this.output().swrite(outputTexture, format);
                }
              }
              ;
              class SpeedyPipelineTransformFactory extends speedy_namespace.Q {
                /**
                 * Resize image
                 * @param {string} [name]
                 * @returns {SpeedyPipelineNodeResize}
                 */
                static Resize(name = void 0) {
                  return new SpeedyPipelineNodeResize(name);
                }
                /**
                 * Warp an image using a perspective transformation
                 * @param {string} [name]
                 * @returns {SpeedyPipelineNodePerspectiveWarp}
                 */
                static PerspectiveWarp(name = void 0) {
                  return new SpeedyPipelineNodePerspectiveWarp(name);
                }
              }
              ;
              const MAX_CAPACITY = globals.MAX_ENCODER_CAPACITY;
              const detector_DEFAULT_CAPACITY = globals.DEFAULT_ENCODER_CAPACITY;
              const DEFAULT_SCALE_FACTOR = 1.4142135623730951;
              const NUMBER_OF_RGBA16_TEXTURES = 2;
              const NUMBER_OF_INTERNAL_TEXTURES = 0;
              const ENCODER_PASSES = 4;
              const LONG_SKIP_OFFSET_PASSES = 2;
              class SpeedyPipelineNodeKeypointDetector extends SpeedyPipelineNode {
                /**
                 * Constructor
                 * @param {string} [name] name of the node
                 * @param {number} [texCount] number of work textures
                 * @param {SpeedyPipelinePortBuilder[]} [portBuilders] port builders
                 */
                constructor(name = void 0, texCount = 0, portBuilders = void 0) {
                  super(name, texCount + NUMBER_OF_INTERNAL_TEXTURES, portBuilders);
                  this._capacity = detector_DEFAULT_CAPACITY;
                  this._oldWrapS = 0;
                  this._tex16 = new Array(NUMBER_OF_RGBA16_TEXTURES).fill(null);
                }
                /**
                 * Initialize this node
                 * @param {SpeedyGPU} gpu
                 */
                init(gpu2) {
                  super.init(gpu2);
                  this._oldWrapS = this._setupSpecialTexture(gpu2.gl.TEXTURE_WRAP_S, gpu2.gl.REPEAT);
                  this._allocateTex16(gpu2);
                  gpu2.subscribe(this._allocateTex16, this, gpu2);
                }
                /**
                 * Release this node
                 * @param {SpeedyGPU} gpu
                 */
                release(gpu2) {
                  gpu2.unsubscribe(this._allocateTex16, this);
                  this._deallocateTex16(gpu2);
                  this._setupSpecialTexture(gpu2.gl.TEXTURE_WRAP_S, this._oldWrapS);
                  super.release(gpu2);
                }
                /**
                 * Set a parameter of the special texture
                 * @param {GLenum} pname
                 * @param {GLint} param new value
                 * @returns {GLint} old value of param
                 */
                _setupSpecialTexture(pname, param) {
                  if (NUMBER_OF_INTERNAL_TEXTURES == 0) return;
                  const texture = this._tex[this._tex.length - 1];
                  const gl = texture.gl;
                  gl.bindTexture(gl.TEXTURE_2D, texture.glTexture);
                  const oldval = gl.getTexParameter(gl.TEXTURE_2D, pname);
                  gl.texParameteri(gl.TEXTURE_2D, pname, param);
                  gl.bindTexture(gl.TEXTURE_2D, null);
                  return oldval;
                }
                /**
                 * We can encode up to this many keypoints. If you find a
                 * tight bound for this, download times will be faster.
                 * @returns {number}
                 */
                get capacity() {
                  return this._capacity;
                }
                /**
                 * We can encode up to this many keypoints. If you find a
                 * tight bound for this, download times will be faster.
                 * @param {number} capacity
                 */
                set capacity(capacity) {
                  this._capacity = Math.min(Math.max(0, capacity | 0), MAX_CAPACITY);
                }
                /**
                 * Create a tiny texture with encoded keypoints out of
                 * an encoded corners texture
                 * @param {SpeedyGPU} gpu
                 * @param {SpeedyTexture} corners input
                 * @param {SpeedyDrawableTexture} encodedKeypoints output
                 * @param {number} [descriptorSize] in bytes
                 * @param {number} [extraSize] in bytes
                 * @returns {SpeedyDrawableTexture} encodedKeypoints
                 */
                _encodeKeypoints(gpu2, corners, encodedKeypoints, descriptorSize = 0, extraSize = 0) {
                  const encoderCapacity = this._capacity;
                  const encoderLength = SpeedyPipelineNodeKeypointDetector.encoderLength(encoderCapacity, descriptorSize, extraSize);
                  const width = 1 << (Math.ceil(Math.log2(corners.width * corners.height)) >>> 1);
                  const height = Math.ceil(corners.width * corners.height / width);
                  const maxSize = Math.max(width, height);
                  const keypoints = gpu2.programs.keypoints;
                  keypoints.initLookupTable.outputs(width, height, this._tex16[1]);
                  keypoints.sortLookupTable.outputs(width, height, this._tex16[0], this._tex16[1]);
                  keypoints.encodeKeypoints.outputs(encoderLength, encoderLength, encodedKeypoints);
                  let lookupTable = keypoints.initLookupTable(corners);
                  for (let b = 1; b < maxSize; b *= 2) lookupTable = keypoints.sortLookupTable(lookupTable, b, width, height);
                  return keypoints.encodeKeypoints(corners, lookupTable, width, descriptorSize, extraSize, encoderLength, encoderCapacity);
                }
                _encodeKeypointsOLD(gpu2, corners, encodedKeypoints, descriptorSize = 0, extraSize = 0) {
                  const capacity = this._capacity;
                  const encoderLength = SpeedyPipelineNodeKeypointDetector.encoderLength(capacity, descriptorSize, extraSize);
                  const width = corners.width, height = corners.height;
                  const imageSize = [width, height];
                  const tex = this._tex.slice(this._tex.length - NUMBER_OF_INTERNAL_TEXTURES);
                  const keypoints = gpu2.programs.keypoints;
                  const specialTexture = tex.pop();
                  keypoints.encodeKeypointSkipOffsets.outputs(width, height, tex[0]);
                  keypoints.encodeKeypointLongSkipOffsets.outputs(width, height, tex[1], tex[0]);
                  keypoints.encodeKeypointPositions.outputs(encoderLength, encoderLength, tex[2], tex[3]);
                  keypoints.encodeKeypointProperties.outputs(encoderLength, encoderLength, encodedKeypoints);
                  corners = gpu2.programs.utils.copy.outputs(width, height, specialTexture)(corners);
                  let offsets = keypoints.encodeKeypointSkipOffsets(corners, imageSize);
                  for (let i = 0; i < LONG_SKIP_OFFSET_PASSES; i++) {
                    offsets = keypoints.encodeKeypointLongSkipOffsets(offsets, imageSize);
                  }
                  let encodedKps = tex[3].clear();
                  for (let j = 0; j < ENCODER_PASSES; j++) encodedKps = keypoints.encodeKeypointPositions(offsets, imageSize, j, ENCODER_PASSES, capacity, encodedKps, descriptorSize, extraSize, encoderLength);
                  return keypoints.encodeKeypointProperties(corners, encodedKps, descriptorSize, extraSize, encoderLength);
                }
                /**
                 * Create a tiny texture with zero encoded keypoints
                 * @param {SpeedyGPU} gpu
                 * @param {SpeedyDrawableTexture} encodedKeypoints output texture
                 * @param {number} [descriptorSize] in bytes
                 * @param {number} [extraSize] in bytes
                 * @returns {SpeedyDrawableTexture} encodedKeypoints
                 */
                _encodeZeroKeypoints(gpu2, encodedKeypoints, descriptorSize = 0, extraSize = 0) {
                  const capacity = 0;
                  const encoderLength = SpeedyPipelineNodeKeypointDetector.encoderLength(capacity, descriptorSize, extraSize);
                  const keypoints = gpu2.programs.keypoints;
                  keypoints.encodeNullKeypoints.outputs(encoderLength, encoderLength, encodedKeypoints);
                  return keypoints.encodeNullKeypoints();
                }
                /**
                 * Allocate RGBA16 textures
                 * @param {SpeedyGPU} gpu
                 */
                _allocateTex16(gpu2) {
                  const gl = gpu2.gl;
                  for (let i = 0; i < this._tex16.length; i++) this._tex16[i] = new SpeedyDrawableTexture(gl, 1, 1, gl.RGBA_INTEGER, gl.RGBA16UI, gl.UNSIGNED_SHORT, gl.NEAREST, gl.CLAMP_TO_EDGE);
                }
                /**
                 * Deallocate RGBA16 textures
                 * @param {SpeedyGPU} gpu
                 */
                _deallocateTex16(gpu2) {
                  for (let i = 0; i < this._tex16.length; i++) this._tex16[i] = this._tex16[i].release();
                }
                /**
                 * Compute the length of the keypoint encoder, given its capacity
                 * @param {number} encoderCapacity how many keypoints can we fit?
                 * @param {number} descriptorSize in bytes
                 * @param {number} extraSize in bytes
                 */
                static encoderLength(encoderCapacity, descriptorSize, extraSize) {
                  const pixelsPerKeypoint = Math.ceil((globals.MIN_KEYPOINT_SIZE + descriptorSize + extraSize) / 4);
                  const numberOfPixels = encoderCapacity * pixelsPerKeypoint;
                  return Math.max(globals.MIN_ENCODER_LENGTH, Math.ceil(Math.sqrt(numberOfPixels)));
                }
                /**
                 * The maximum number of keypoints we can store using
                 * a particular configuration of a keypoint encoder
                 * @param {number} descriptorSize in bytes
                 * @param {number} extraSize in bytes
                 * @param {number} encoderLength
                 */
                static encoderCapacity(descriptorSize, extraSize, encoderLength) {
                  const pixelsPerKeypoint = Math.ceil((globals.MIN_KEYPOINT_SIZE + descriptorSize + extraSize) / 4);
                  const numberOfPixels = encoderLength * encoderLength;
                  return Math.floor(numberOfPixels / pixelsPerKeypoint);
                }
              }
              class SpeedyPipelineNodeMultiscaleKeypointDetector extends SpeedyPipelineNodeKeypointDetector {
                /**
                 * Constructor
                 * @param {string} [name] name of the node
                 * @param {number} [texCount] number of work textures
                 * @param {SpeedyPipelinePortBuilder[]} [portBuilders] port builders
                 */
                constructor(name = void 0, texCount = void 0, portBuilders = void 0) {
                  super(name, texCount, portBuilders);
                  this._levels = 1;
                  this._scaleFactor = DEFAULT_SCALE_FACTOR;
                }
                /**
                 * Number of pyramid levels
                 * @returns {number}
                 */
                get levels() {
                  return this._levels;
                }
                /**
                 * Number of pyramid levels
                 * @param {number} levels
                 */
                set levels(levels) {
                  this._levels = Math.max(1, levels | 0);
                }
                /**
                 * Scale factor between two pyramid levels
                 * @returns {number}
                 */
                get scaleFactor() {
                  return this._scaleFactor;
                }
                /**
                 * Scale factor between two pyramid levels
                 * @param {number} scaleFactor should be greater than 1
                 */
                set scaleFactor(scaleFactor) {
                  this._scaleFactor = Math.max(1, Math.min(+scaleFactor, 2));
                }
              }
              ;
              const UBO_MAX_BYTES = 16384;
              const BUFFER_SIZE = 1024;
              const SIZEOF_VEC4 = Float32Array.BYTES_PER_ELEMENT * 4;
              class SpeedyPipelineNodeKeypointSource extends SpeedyPipelineSourceNode {
                /**
                 * Constructor
                 * @param {string} [name] name of the node
                 */
                constructor(name = void 0) {
                  super(name, 2, [OutputPort().expects(SpeedyPipelineMessageType.Keypoints)]);
                  this._keypoints = [];
                  this._buffer = SpeedyPipelineNodeKeypointSource._createUploadBuffer(BUFFER_SIZE);
                  this._capacity = globals.DEFAULT_ENCODER_CAPACITY;
                }
                /**
                 * Keypoints to be uploaded
                 * @returns {SpeedyKeypoint[]}
                 */
                get keypoints() {
                  return this._keypoints;
                }
                /**
                 * Keypoints to be uploaded
                 * @param {SpeedyKeypoint[]} keypoints
                 */
                set keypoints(keypoints) {
                  if (!Array.isArray(keypoints)) throw new utils_errors.qw(`Not an array of keypoints`);
                  this._keypoints = keypoints;
                }
                /**
                 * The maximum number of keypoints we'll accept.
                 * This should be a tight bound for better performance.
                 * @returns {number}
                 */
                get capacity() {
                  return this._capacity;
                }
                /**
                 * The maximum number of keypoints we'll accept.
                 * This should be a tight bound for better performance.
                 * @param {number} capacity
                 */
                set capacity(capacity) {
                  this._capacity = Math.min(Math.max(0, capacity | 0), globals.MAX_ENCODER_CAPACITY);
                }
                /**
                 * Run the specific task of this node
                 * @param {SpeedyGPU} gpu
                 * @returns {void|SpeedyPromise<void>}
                 */
                _run(gpu2) {
                  const descriptorSize = 0, extraSize = 0;
                  const keypoints = this._keypoints;
                  const maxKeypoints = this._capacity;
                  const numKeypoints = Math.min(keypoints.length, maxKeypoints);
                  const numPasses = Math.max(1, Math.ceil(numKeypoints / BUFFER_SIZE));
                  const buffer = this._buffer;
                  const uploadKeypoints2 = gpu2.programs.keypoints.uploadKeypoints;
                  const encoderLength = SpeedyPipelineNodeKeypointDetector.encoderLength(maxKeypoints, descriptorSize, extraSize);
                  uploadKeypoints2.outputs(encoderLength, encoderLength, this._tex[0], this._tex[1]);
                  let startIndex = 0, encodedKeypoints = uploadKeypoints2.clear();
                  for (let i = 0; i < numPasses; i++) {
                    const n = Math.min(BUFFER_SIZE, numKeypoints - startIndex);
                    const endIndex = startIndex + n;
                    uploadKeypoints2.setUBO("KeypointBuffer", SpeedyPipelineNodeKeypointSource._fillUploadBuffer(buffer, keypoints, startIndex, endIndex));
                    encodedKeypoints = uploadKeypoints2(encodedKeypoints, startIndex, endIndex, descriptorSize, extraSize, encoderLength);
                    startIndex = endIndex;
                  }
                  this.output().swrite(encodedKeypoints, descriptorSize, extraSize, encoderLength);
                }
                /**
                 * Create an upload buffer
                 * @param {number} bufferSize number of keypoints
                 * @returns {Float32Array}
                 */
                static _createUploadBuffer(bufferSize) {
                  const internalBuffer = new ArrayBuffer(SIZEOF_VEC4 * bufferSize);
                  utils.A.assert(internalBuffer.byteLength <= UBO_MAX_BYTES);
                  return new Float32Array(internalBuffer);
                }
                /**
                 * Fill upload buffer with keypoint data
                 * @param {Float32Array} buffer
                 * @param {SpeedyKeypoint[]} keypoints 
                 * @param {number} start index, inclusive
                 * @param {number} end index, exclusive
                 * @returns {Float32Array} buffer
                 */
                static _fillUploadBuffer(buffer, keypoints, start, end) {
                  const n = end - start;
                  for (let i = 0; i < n; i++) {
                    const keypoint = keypoints[start + i];
                    const hasPos = keypoint.position !== void 0;
                    const j = i * 4;
                    buffer[j] = +(hasPos ? keypoint.position.x : keypoint.x) || 0;
                    buffer[j + 1] = +(hasPos ? keypoint.position.y : keypoint.y) || 0;
                    buffer[j + 2] = +keypoint.lod || 0;
                    buffer[j + 3] = +keypoint.score || 0;
                  }
                  return buffer;
                }
              }
              ;
              class SpeedyKeypointDescriptor {
                /**
                 * Constructor
                 * @param {Uint8Array} data descriptor bytes
                 */
                constructor(data) {
                  this._data = data;
                  return Object.freeze(this);
                }
                /**
                 * Descriptor data
                 * @returns {Uint8Array}
                 */
                get data() {
                  return this._data;
                }
                /**
                 * The size of the descriptor, in bytes
                 * @returns {number}
                 */
                get size() {
                  return this._data.byteLength;
                }
                /**
                 * A string representation of the keypoint descriptor
                 * @returns {string}
                 */
                toString() {
                  return `SpeedyKeypointDescriptor(${this._data.join(",")})`;
                }
              }
              ;
              const sink_nextPot = (x) => x > 1 ? 1 << Math.ceil(Math.log2(x)) : 1;
              const ZERO_BYTES = new Uint8Array([]);
              class SpeedyPipelineNodeAbstractKeypointSink extends SpeedyPipelineSinkNode {
                /**
                 * Constructor
                 * @param {string} [name] name of the node
                 * @param {number} [texCount]
                 * @param {SpeedyPipelinePortBuilder[]} [portBuilders]
                 */
                constructor(name = "keypoints", texCount = 0, portBuilders = []) {
                  super(name, texCount + 2, portBuilders);
                  this._keypoints = [];
                  this._textureReader = new SpeedyTextureReader();
                  this._page = 0;
                  this._turbo = false;
                  this._includeDiscarded = false;
                }
                /**
                 * Accelerate GPU-CPU transfers
                 * @returns {boolean}
                 */
                get turbo() {
                  return this._turbo;
                }
                /**
                 * Accelerate GPU-CPU transfers
                 * @param {boolean} value
                 */
                set turbo(value) {
                  this._turbo = Boolean(value);
                }
                /**
                 * Should discarded keypoints be exported as null or dropped altogether?
                 * @returns {boolean}
                 */
                get includeDiscarded() {
                  return this._includeDiscarded;
                }
                /**
                 * Should discarded keypoints be exported as null or dropped altogether?
                 * @param {boolean} value
                 */
                set includeDiscarded(value) {
                  this._includeDiscarded = Boolean(value);
                }
                /**
                 * Initializes this node
                 * @param {SpeedyGPU} gpu
                 */
                init(gpu2) {
                  super.init(gpu2);
                  this._textureReader.init(gpu2);
                }
                /**
                 * Releases this node
                 * @param {SpeedyGPU} gpu
                 */
                release(gpu2) {
                  this._textureReader.release(gpu2);
                  super.release(gpu2);
                }
                /**
                 * Export data from this node to the user
                 * @returns {SpeedyPromise<Array<T|null>>}
                 */
                export() {
                  return speedy_promise.i.resolve(this._keypoints);
                }
                /**
                 * Run the specific task of this node
                 * @param {SpeedyGPU} gpu
                 * @returns {void|SpeedyPromise<void>}
                 */
                _run(gpu2) {
                  const {
                    encodedKeypoints,
                    descriptorSize,
                    extraSize,
                    encoderLength
                  } = (
                    /** @type {SpeedyPipelineMessageWithKeypoints} */
                    this.input().read()
                  );
                  return this._download(gpu2, encodedKeypoints, descriptorSize, extraSize, encoderLength);
                }
                /**
                 * Download and decode keypoints from the GPU
                 * @param {SpeedyGPU} gpu
                 * @param {SpeedyDrawableTexture} encodedKeypoints
                 * @param {number} descriptorSize
                 * @param {number} extraSize
                 * @param {number} encoderLength
                 * @returns {SpeedyPromise<void>}
                 */
                _download(gpu2, encodedKeypoints, descriptorSize, extraSize, encoderLength) {
                  const useBufferedDownloads = this._turbo;
                  const encoderWidth = sink_nextPot(encoderLength);
                  const encoderHeight = Math.ceil(encoderLength * encoderLength / encoderWidth);
                  const copiedTexture = this._tex[this._tex.length - 1 - this._page];
                  gpu2.programs.utils.copyKeypoints.outputs(encoderWidth, encoderHeight, copiedTexture)(encodedKeypoints);
                  this._page = 1 - this._page;
                  return this._textureReader.readPixelsAsync(copiedTexture, 0, 0, copiedTexture.width, copiedTexture.height, useBufferedDownloads).then((pixels) => {
                    this._keypoints = this._decode(pixels, descriptorSize, extraSize, encoderWidth, encoderHeight);
                  });
                }
                /**
                 * Decode a sequence of keypoints, given a flattened image of encoded pixels
                 * @param {Uint8Array} pixels pixels in the [r,g,b,a,...] format
                 * @param {number} descriptorSize in bytes
                 * @param {number} extraSize in bytes
                 * @param {number} encoderWidth
                 * @param {number} encoderHeight
                 * @returns {Array<T|null>} keypoints
                 */
                _decode(pixels, descriptorSize, extraSize, encoderWidth, encoderHeight) {
                  const bytesPerKeypoint = globals.MIN_KEYPOINT_SIZE + descriptorSize + extraSize;
                  const m = globals.LOG2_PYRAMID_MAX_SCALE, h = globals.PYRAMID_MAX_LEVELS;
                  const piOver255 = Math.PI / 255;
                  const keypoints = (
                    /** @type {Array<T|null>} */
                    []
                  );
                  const includeDiscarded = this._includeDiscarded;
                  let descriptorBytes = ZERO_BYTES, extraBytes = ZERO_BYTES;
                  let x, y, z, w, lod, rotation, score;
                  let keypoint;
                  if (descriptorSize % 4 != 0 || extraSize % 4 != 0) throw new utils_errors.qw(`Invalid descriptorSize (${descriptorSize}) / extraSize (${extraSize})`);
                  const e2 = encoderWidth * encoderHeight * 4;
                  const size = pixels.byteLength;
                  if (size != e2) utils.A.warning(`Expected ${e2} bytes when decoding a set of keypoints, found ${size}`);
                  if (descriptorSize + extraSize > 0) pixels = new Uint8Array(pixels);
                  for (let i = 0; i < size; i += bytesPerKeypoint) {
                    x = pixels[i + 1] << 8 | pixels[i];
                    y = pixels[i + 3] << 8 | pixels[i + 2];
                    z = pixels[i + 5] << 8 | pixels[i + 4];
                    w = pixels[i + 7] << 8 | pixels[i + 6];
                    if (x == 65535 && y == 65535) break;
                    if (x + y + z + w == 0) {
                      if (includeDiscarded) keypoints.push(null);
                      continue;
                    }
                    if (extraSize > 0) {
                      extraBytes = pixels.subarray(8 + i, 8 + i + extraSize);
                      if (extraBytes.byteLength < extraSize) {
                        utils.A.warning(`KeypointSink: expected ${extraSize} extra bytes when decoding the ${i / bytesPerKeypoint}-th keypoint, found ${extraBytes.byteLength} instead`);
                        continue;
                      }
                    }
                    if (descriptorSize > 0) {
                      descriptorBytes = pixels.subarray(8 + i + extraSize, 8 + i + extraSize + descriptorSize);
                      if (descriptorBytes.byteLength < descriptorSize) {
                        utils.A.warning(`KeypointSink: expected ${descriptorSize} descriptor bytes when decoding the ${i / bytesPerKeypoint}-th keypoint, found ${descriptorBytes.byteLength} instead`);
                        continue;
                      }
                    }
                    x /= globals.FIX_RESOLUTION;
                    y /= globals.FIX_RESOLUTION;
                    lod = pixels[i + 4] < 255 ? -m + (m + h) * pixels[i + 4] / 255 : 0;
                    rotation = (2 * pixels[i + 5] - 255) * piOver255;
                    score = utils.A.decodeFloat16(w);
                    keypoint = this._createKeypoint(x, y, lod, rotation, score, descriptorBytes, extraBytes);
                    keypoints.push(keypoint);
                  }
                  return keypoints;
                }
                /**
                 * Instantiate a new keypoint
                 * @param {number} x
                 * @param {number} y
                 * @param {number} lod
                 * @param {number} rotation
                 * @param {number} score
                 * @param {Uint8Array} descriptorBytes
                 * @param {Uint8Array} extraBytes
                 * @returns {T}
                 */
                _createKeypoint(x, y, lod, rotation, score, descriptorBytes, extraBytes) {
                  throw new utils_errors.aQ();
                }
                /**
                 * Allocate extra space
                 * @param {SpeedyGPU} gpu
                 * @param {SpeedyDrawableTexture} output output texture
                 * @param {SpeedyTexture} inputEncodedKeypoints input with no extra space
                 * @param {number} inputDescriptorSize in bytes, must be positive
                 * @param {number} inputExtraSize must be 0
                 * @param {number} outputDescriptorSize must be inputDescriptorSize
                 * @param {number} outputExtraSize in bytes, must be positive and a multiple of 4
                 * @returns {SpeedyDrawableTexture} encodedKeypoints with extra space
                 */
                _allocateExtra(gpu2, output, inputEncodedKeypoints, inputDescriptorSize, inputExtraSize, outputDescriptorSize, outputExtraSize) {
                  utils.A.assert(inputExtraSize === 0);
                  utils.A.assert(outputDescriptorSize === inputDescriptorSize && outputExtraSize > 0 && outputExtraSize % 4 === 0);
                  const inputEncoderLength = inputEncodedKeypoints.width;
                  const inputEncoderCapacity = SpeedyPipelineNodeKeypointDetector.encoderCapacity(inputDescriptorSize, inputExtraSize, inputEncoderLength);
                  const outputEncoderCapacity = inputEncoderCapacity;
                  const outputEncoderLength = SpeedyPipelineNodeKeypointDetector.encoderLength(outputEncoderCapacity, outputDescriptorSize, outputExtraSize);
                  return gpu2.programs.keypoints.allocateExtra.outputs(outputEncoderLength, outputEncoderLength, output)(inputEncodedKeypoints, inputDescriptorSize, inputExtraSize, inputEncoderLength, outputDescriptorSize, outputExtraSize, outputEncoderLength);
                }
              }
              class SpeedyPipelineNodeKeypointSink extends SpeedyPipelineNodeAbstractKeypointSink {
                /**
                 * Constructor
                 * @param {string} [name] name of the node
                 */
                constructor(name = "keypoints") {
                  super(name, 0, [InputPort().expects(SpeedyPipelineMessageType.Keypoints)]);
                }
                /**
                 * Instantiate a new keypoint
                 * @param {number} x
                 * @param {number} y
                 * @param {number} lod
                 * @param {number} rotation
                 * @param {number} score
                 * @param {Uint8Array} descriptorBytes
                 * @param {Uint8Array} extraBytes
                 * @returns {SpeedyKeypoint}
                 */
                _createKeypoint(x, y, lod, rotation, score, descriptorBytes, extraBytes) {
                  const descriptorSize = descriptorBytes.byteLength;
                  const descriptor = descriptorSize > 0 ? new SpeedyKeypointDescriptor(descriptorBytes) : null;
                  return new SpeedyKeypoint(x, y, lod, rotation, score, descriptor);
                }
              }
              class SpeedyPipelineNodeTrackedKeypointSink extends SpeedyPipelineNodeAbstractKeypointSink {
                /**
                 * Constructor
                 * @param {string} [name] name of the node
                 */
                constructor(name = "keypoints") {
                  super(name, 2, [InputPort().expects(SpeedyPipelineMessageType.Keypoints).satisfying((msg) => msg.extraSize == 0), InputPort("flow").expects(SpeedyPipelineMessageType.Vector2)]);
                }
                /**
                 * Run the specific task of this node
                 * @param {SpeedyGPU} gpu
                 * @returns {void|SpeedyPromise<void>}
                 */
                _run(gpu2) {
                  const {
                    encodedKeypoints,
                    descriptorSize,
                    extraSize,
                    encoderLength
                  } = (
                    /** @type {SpeedyPipelineMessageWithKeypoints} */
                    this.input().read()
                  );
                  const {
                    vectors
                  } = (
                    /** @type {SpeedyPipelineMessageWith2DVectors} */
                    this.input("flow").read()
                  );
                  const newDescriptorSize = descriptorSize;
                  const newExtraSize = 4;
                  const encodedKeypointsWithExtraSpace = this._allocateExtra(gpu2, this._tex[0], encodedKeypoints, descriptorSize, extraSize, newDescriptorSize, newExtraSize);
                  const newEncoderLength = encodedKeypointsWithExtraSpace.width;
                  const newEncodedKeypoints = gpu2.programs.keypoints.transferToExtra.outputs(newEncoderLength, newEncoderLength, this._tex[1])(vectors, vectors.width, encodedKeypointsWithExtraSpace, newDescriptorSize, newExtraSize, newEncoderLength);
                  return this._download(gpu2, newEncodedKeypoints, newDescriptorSize, newExtraSize, newEncoderLength);
                }
                /**
                 * Instantiate a new keypoint
                 * @param {number} x
                 * @param {number} y
                 * @param {number} lod
                 * @param {number} rotation
                 * @param {number} score
                 * @param {Uint8Array} descriptorBytes
                 * @param {Uint8Array} extraBytes
                 * @returns {SpeedyTrackedKeypoint}
                 */
                _createKeypoint(x, y, lod, rotation, score, descriptorBytes, extraBytes) {
                  const descriptorSize = descriptorBytes.byteLength;
                  const extraSize = extraBytes.byteLength;
                  const descriptor = descriptorSize > 0 ? new SpeedyKeypointDescriptor(descriptorBytes) : null;
                  const fx = utils.A.decodeFloat16(extraBytes[1] << 8 | extraBytes[0]);
                  const fy = utils.A.decodeFloat16(extraBytes[3] << 8 | extraBytes[2]);
                  const flow = new SpeedyVector2(fx, fy);
                  return new SpeedyTrackedKeypoint(x, y, lod, rotation, score, descriptor, flow);
                }
              }
              class SpeedyPipelineNodeMatchedKeypointSink extends SpeedyPipelineNodeAbstractKeypointSink {
                /**
                 * Constructor
                 * @param {string} [name] name of the node
                 */
                constructor(name = "keypoints") {
                  super(name, 2, [InputPort().expects(SpeedyPipelineMessageType.Keypoints).satisfying((msg) => msg.extraSize == 0), InputPort("matches").expects(SpeedyPipelineMessageType.KeypointMatches)]);
                }
                /**
                 * Run the specific task of this node
                 * @param {SpeedyGPU} gpu
                 * @returns {void|SpeedyPromise<void>}
                 */
                _run(gpu2) {
                  const {
                    encodedKeypoints,
                    descriptorSize,
                    extraSize,
                    encoderLength
                  } = (
                    /** @type {SpeedyPipelineMessageWithKeypoints} */
                    this.input().read()
                  );
                  const {
                    encodedMatches,
                    matchesPerKeypoint
                  } = (
                    /** @type {SpeedyPipelineMessageWithKeypointMatches} */
                    this.input("matches").read()
                  );
                  const newDescriptorSize = descriptorSize;
                  const newExtraSize = matchesPerKeypoint * 4;
                  const encodedKeypointsWithExtraSpace = this._allocateExtra(gpu2, this._tex[0], encodedKeypoints, descriptorSize, extraSize, newDescriptorSize, newExtraSize);
                  const newEncoderLength = encodedKeypointsWithExtraSpace.width;
                  const newEncodedKeypoints = gpu2.programs.keypoints.transferToExtra.outputs(newEncoderLength, newEncoderLength, this._tex[1])(encodedMatches, encodedMatches.width, encodedKeypointsWithExtraSpace, newDescriptorSize, newExtraSize, newEncoderLength);
                  return this._download(gpu2, newEncodedKeypoints, newDescriptorSize, newExtraSize, newEncoderLength);
                }
                /**
                 * Instantiate a new keypoint
                 * @param {number} x
                 * @param {number} y
                 * @param {number} lod
                 * @param {number} rotation
                 * @param {number} score
                 * @param {Uint8Array} descriptorBytes
                 * @param {Uint8Array} extraBytes
                 * @returns {SpeedyMatchedKeypoint}
                 */
                _createKeypoint(x, y, lod, rotation, score, descriptorBytes, extraBytes) {
                  const descriptorSize = descriptorBytes.byteLength;
                  const extraSize = extraBytes.byteLength;
                  const descriptor = descriptorSize > 0 ? new SpeedyKeypointDescriptor(descriptorBytes) : null;
                  const matchesPerKeypoint = extraSize / 4;
                  const matches = (
                    /** @type {SpeedyKeypointMatch[]} */
                    new Array(matchesPerKeypoint)
                  );
                  for (let matchIndex = 0; matchIndex < matchesPerKeypoint; matchIndex++) {
                    const base = matchIndex * 4;
                    const u32 = extraBytes[base] | extraBytes[base + 1] << 8 | extraBytes[base + 2] << 16 | extraBytes[base + 3] << 24;
                    const match = new SpeedyKeypointMatch(u32 & globals.MATCH_INDEX_MASK, u32 >>> globals.MATCH_INDEX_BITS);
                    matches[matchIndex] = match;
                  }
                  return new SpeedyMatchedKeypoint(x, y, lod, rotation, score, descriptor, matches);
                }
              }
              ;
              const LOG2_STRIDE = 5;
              const MAX_SIZE = globals.MAX_ENCODER_CAPACITY;
              class SpeedyPipelineNodeKeypointClipper extends SpeedyPipelineNode {
                /**
                 * Constructor
                 * @param {string} [name] name of the node
                 */
                constructor(name = void 0) {
                  super(name, 4, [InputPort().expects(SpeedyPipelineMessageType.Keypoints), OutputPort().expects(SpeedyPipelineMessageType.Keypoints)]);
                  this._size = MAX_SIZE;
                }
                /**
                 * The maximum number of keypoints in the output
                 * @returns {number}
                 */
                get size() {
                  return this._size;
                }
                /**
                 * The maximum number of keypoints in the output
                 * @param {number} size
                 */
                set size(size) {
                  this._size = Math.max(0, Math.min(size | 0, MAX_SIZE));
                }
                /**
                 * Run the specific task of this node
                 * @param {SpeedyGPU} gpu
                 * @returns {void|SpeedyPromise<void>}
                 */
                _run(gpu2) {
                  const {
                    encodedKeypoints,
                    descriptorSize,
                    extraSize,
                    encoderLength
                  } = (
                    /** @type {SpeedyPipelineMessageWithKeypoints} */
                    this.input().read()
                  );
                  const keypoints = gpu2.programs.keypoints;
                  const clipValue = this._size;
                  const tex = this._tex;
                  const outputTexture = this._tex[3];
                  const capacity = SpeedyPipelineNodeKeypointDetector.encoderCapacity(descriptorSize, extraSize, encoderLength);
                  const stride = 1 << LOG2_STRIDE;
                  const height = Math.ceil(capacity / stride);
                  const numberOfPixels = stride * height;
                  const newCapacity = Math.min(capacity, clipValue);
                  const newEncoderLength = SpeedyPipelineNodeKeypointDetector.encoderLength(newCapacity, descriptorSize, extraSize);
                  keypoints.sortCreatePermutation.outputs(stride, height, tex[0]);
                  let permutation = keypoints.sortCreatePermutation(encodedKeypoints, descriptorSize, extraSize, encoderLength);
                  const numPasses = Math.ceil(Math.log2(numberOfPixels));
                  keypoints.sortMergePermutation.outputs(stride, height, tex[1], tex[2]);
                  for (let i = 1; i <= numPasses; i++) {
                    const blockSize = 1 << i;
                    const dblLog2BlockSize = i << 1;
                    permutation = keypoints.sortMergePermutation(permutation, blockSize, dblLog2BlockSize);
                  }
                  keypoints.sortApplyPermutation.outputs(newEncoderLength, newEncoderLength, outputTexture);
                  keypoints.sortApplyPermutation(permutation, newCapacity, encodedKeypoints, descriptorSize, extraSize);
                  this.output().swrite(outputTexture, descriptorSize, extraSize, newEncoderLength);
                }
              }
              ;
              class SpeedyPipelineNodeKeypointBorderClipper extends SpeedyPipelineNode {
                /**
                 * Constructor
                 * @param {string} [name] name of the node
                 */
                constructor(name = void 0) {
                  super(name, 5, [InputPort().expects(SpeedyPipelineMessageType.Keypoints), OutputPort().expects(SpeedyPipelineMessageType.Keypoints)]);
                  this._imageSize = new SpeedySize(0, 0);
                  this._borderSize = new SpeedyVector2(0, 0);
                }
                /**
                 * Image size, in pixels
                 * @returns {SpeedySize}
                 */
                get imageSize() {
                  return this._imageSize;
                }
                /**
                 * Image size, in pixels
                 * @param {SpeedySize} imageSize
                 */
                set imageSize(imageSize) {
                  this._imageSize = imageSize;
                }
                /**
                 * Border size, in pixels
                 * @returns {SpeedyVector2}
                 */
                get borderSize() {
                  return this._borderSize;
                }
                /**
                 * Border size, in pixels
                 * @param {SpeedyVector2} borderSize
                 */
                set borderSize(borderSize) {
                  this._borderSize = borderSize;
                }
                /**
                 * Run the specific task of this node
                 * @param {SpeedyGPU} gpu
                 * @returns {void|SpeedyPromise<void>}
                 */
                _run(gpu2) {
                  const {
                    encodedKeypoints,
                    descriptorSize,
                    extraSize,
                    encoderLength
                  } = (
                    /** @type {SpeedyPipelineMessageWithKeypoints} */
                    this.input().read()
                  );
                  const keypoints = gpu2.programs.keypoints;
                  const imageSize = this._imageSize;
                  const borderSize = this._borderSize;
                  const imageWidth = imageSize.width, imageHeight = imageSize.height;
                  const borderLeft = borderSize.x, borderRight = borderSize.x;
                  const borderTop = borderSize.y, borderBottom = borderSize.y;
                  const tex = this._tex;
                  if (imageWidth == 0 || imageHeight == 0) throw new utils_errors.Er(`BorderClipper: did you forget to set the image size?`);
                  const capacity = SpeedyPipelineNodeKeypointDetector.encoderCapacity(descriptorSize, extraSize, encoderLength);
                  const mixEncoderLength = Math.max(1, Math.ceil(Math.sqrt(capacity)));
                  keypoints.clipBorder.outputs(encoderLength, encoderLength, tex[0]);
                  keypoints.mixKeypointsInit.outputs(mixEncoderLength, mixEncoderLength, tex[1]);
                  keypoints.mixKeypointsSort.outputs(mixEncoderLength, mixEncoderLength, tex[2], tex[3]);
                  keypoints.mixKeypointsApply.outputs(encoderLength, encoderLength, tex[4]);
                  let clippedKeypoints = keypoints.clipBorder(imageWidth, imageHeight, borderTop, borderRight, borderBottom, borderLeft, encodedKeypoints, descriptorSize, extraSize, encoderLength);
                  let sortedKeypoints = keypoints.mixKeypointsInit(clippedKeypoints, descriptorSize, extraSize, encoderLength, capacity);
                  for (let b = 1; b < capacity; b *= 2) sortedKeypoints = keypoints.mixKeypointsSort(sortedKeypoints, b);
                  clippedKeypoints = keypoints.mixKeypointsApply(sortedKeypoints, clippedKeypoints, descriptorSize, extraSize, encoderLength);
                  this.output().swrite(clippedKeypoints, descriptorSize, extraSize, encoderLength);
                }
              }
              ;
              class SpeedyPipelineNodeKeypointBuffer extends SpeedyPipelineNode {
                /**
                 * Constructor
                 * @param {string} [name] name of the node
                 */
                constructor(name = void 0) {
                  super(name, 2, [InputPort().expects(SpeedyPipelineMessageType.Keypoints), OutputPort().expects(SpeedyPipelineMessageType.Keypoints)]);
                  this._pageIndex = 0;
                  this._initialized = false;
                  this._previousDescriptorSize = 0;
                  this._previousExtraSize = 0;
                  this._previousEncoderLength = 0;
                  this._frozen = false;
                }
                /**
                 * A frozen buffer discards the input, effectively increasing the buffering time
                 * @returns {boolean}
                 */
                get frozen() {
                  return this._frozen;
                }
                /**
                 * A frozen buffer discards the input, effectively increasing the buffering time
                 * @param {boolean} value
                 */
                set frozen(value) {
                  this._frozen = Boolean(value);
                }
                /**
                 * Releases this node
                 * @param {SpeedyGPU} gpu
                 */
                release(gpu2) {
                  this._initialized = false;
                  super.release(gpu2);
                }
                /**
                 * Run the specific task of this node
                 * @param {SpeedyGPU} gpu
                 * @returns {void|SpeedyPromise<void>}
                 */
                _run(gpu2) {
                  const {
                    encodedKeypoints,
                    descriptorSize,
                    extraSize,
                    encoderLength
                  } = (
                    /** @type {SpeedyPipelineMessageWithKeypoints} */
                    this.input().read()
                  );
                  const previousDescriptorSize = this._previousDescriptorSize;
                  const previousExtraSize = this._previousExtraSize;
                  const previousEncoderLength = this._previousEncoderLength;
                  const page = this._tex;
                  const previousInputTexture = page[1 - this._pageIndex];
                  const outputTexture = page[this._pageIndex];
                  if (!this._frozen || !this._initialized) {
                    this._previousDescriptorSize = descriptorSize;
                    this._previousExtraSize = extraSize;
                    this._previousEncoderLength = encoderLength;
                    previousInputTexture.resize(encoderLength, encoderLength);
                    encodedKeypoints.copyTo(previousInputTexture);
                    this._pageIndex = 1 - this._pageIndex;
                  }
                  if (!this._initialized) {
                    this._initialized = true;
                    this.output().swrite(previousInputTexture, descriptorSize, extraSize, encoderLength);
                    return;
                  }
                  this.output().swrite(outputTexture, previousDescriptorSize, previousExtraSize, previousEncoderLength);
                }
              }
              ;
              class SpeedyPipelineNodeKeypointMixer extends SpeedyPipelineNode {
                /**
                 * Constructor
                 * @param {string} [name] name of the node
                 */
                constructor(name = void 0) {
                  super(name, 5, [InputPort("in0").expects(SpeedyPipelineMessageType.Keypoints), InputPort("in1").expects(SpeedyPipelineMessageType.Keypoints), OutputPort().expects(SpeedyPipelineMessageType.Keypoints)]);
                }
                /**
                 * Run the specific task of this node
                 * @param {SpeedyGPU} gpu
                 * @returns {void|SpeedyPromise<void>}
                 */
                _run(gpu2) {
                  const kps0 = (
                    /** @type {SpeedyPipelineMessageWithKeypoints} */
                    this.input("in0").read()
                  );
                  const kps1 = (
                    /** @type {SpeedyPipelineMessageWithKeypoints} */
                    this.input("in1").read()
                  );
                  const descriptorSize = kps0.descriptorSize;
                  const extraSize = kps0.extraSize;
                  const keypoints = gpu2.programs.keypoints;
                  const tex = this._tex;
                  if (!(kps0.descriptorSize === kps1.descriptorSize && kps0.extraSize === kps0.extraSize)) throw new utils_errors.Er(`Can't merge two sets of keypoints that have different formats`);
                  const cap0 = SpeedyPipelineNodeKeypointDetector.encoderCapacity(kps0.descriptorSize, kps0.extraSize, kps0.encoderLength);
                  const cap1 = SpeedyPipelineNodeKeypointDetector.encoderCapacity(kps1.descriptorSize, kps1.extraSize, kps1.encoderLength);
                  const capacity = cap0 + cap1;
                  const encoderLength = SpeedyPipelineNodeKeypointDetector.encoderLength(capacity, descriptorSize, extraSize);
                  const mixEncoderLength = Math.max(1, Math.ceil(Math.sqrt(capacity)));
                  keypoints.mixKeypointsPreInit.outputs(encoderLength, encoderLength, tex[0]);
                  keypoints.mixKeypointsInit.outputs(mixEncoderLength, mixEncoderLength, tex[1]);
                  keypoints.mixKeypointsSort.outputs(mixEncoderLength, mixEncoderLength, tex[2], tex[3]);
                  keypoints.mixKeypointsApply.outputs(encoderLength, encoderLength, tex[4]);
                  let mixedKeypoints = keypoints.mixKeypointsPreInit(kps0.encodedKeypoints, kps1.encodedKeypoints, kps0.encoderLength, kps1.encoderLength, cap0, cap1, descriptorSize, extraSize, encoderLength);
                  let sortedKeypoints = keypoints.mixKeypointsInit(mixedKeypoints, descriptorSize, extraSize, encoderLength, capacity);
                  for (let b = 1; b < capacity; b *= 2) sortedKeypoints = keypoints.mixKeypointsSort(sortedKeypoints, b);
                  mixedKeypoints = keypoints.mixKeypointsApply(sortedKeypoints, mixedKeypoints, descriptorSize, extraSize, encoderLength);
                  this.output().swrite(mixedKeypoints, descriptorSize, extraSize, encoderLength);
                }
              }
              ;
              class SpeedyPipelineNodeKeypointShuffler extends SpeedyPipelineNode {
                /**
                 * Constructor
                 * @param {string} [name] name of the node
                 */
                constructor(name = void 0) {
                  super(name, 6, [InputPort().expects(SpeedyPipelineMessageType.Keypoints), OutputPort().expects(SpeedyPipelineMessageType.Keypoints)]);
                  this._maxKeypoints = Number.NaN;
                }
                /**
                 * Maximum number of keypoints (optional)
                 * @returns {number}
                 */
                get maxKeypoints() {
                  return this._maxKeypoints;
                }
                /**
                 * Maximum number of keypoints (optional)
                 * @param {number} value
                 */
                set maxKeypoints(value) {
                  if (!Number.isNaN(value)) this._maxKeypoints = Math.max(0, value | 0);
                  else this._maxKeypoints = Number.NaN;
                }
                /**
                 * Run the specific task of this node
                 * @param {SpeedyGPU} gpu
                 * @returns {void|SpeedyPromise<void>}
                 */
                _run(gpu2) {
                  let {
                    encodedKeypoints,
                    descriptorSize,
                    extraSize,
                    encoderLength
                  } = (
                    /** @type {SpeedyPipelineMessageWithKeypoints} */
                    this.input().read()
                  );
                  const capacity = SpeedyPipelineNodeKeypointDetector.encoderCapacity(descriptorSize, extraSize, encoderLength);
                  const maxKeypoints = this._maxKeypoints;
                  const permutationMaxLength = gpu2.programs.keypoints.shuffle.definedConstant("PERMUTATION_MAXLEN");
                  const permutationLength = Math.min(permutationMaxLength, capacity);
                  const permutation = this._generatePermutation(permutationLength, permutationMaxLength);
                  encodedKeypoints = gpu2.programs.keypoints.shuffle.setUBO("Permutation", permutation).outputs(encoderLength, encoderLength, this._tex[0])(encodedKeypoints, descriptorSize, extraSize, encoderLength);
                  gpu2.programs.keypoints.mixKeypointsInit.outputs(encoderLength, encoderLength, this._tex[1]);
                  gpu2.programs.keypoints.mixKeypointsSort.outputs(encoderLength, encoderLength, this._tex[2], this._tex[3]);
                  gpu2.programs.keypoints.mixKeypointsApply.outputs(encoderLength, encoderLength, this._tex[4]);
                  let sortedKeypoints = gpu2.programs.keypoints.mixKeypointsInit(encodedKeypoints, descriptorSize, extraSize, encoderLength, capacity);
                  for (let b = 1; b < capacity; b *= 2) sortedKeypoints = gpu2.programs.keypoints.mixKeypointsSort(sortedKeypoints, b);
                  encodedKeypoints = gpu2.programs.keypoints.mixKeypointsApply(sortedKeypoints, encodedKeypoints, descriptorSize, extraSize, encoderLength);
                  if (!Number.isNaN(maxKeypoints) && maxKeypoints < capacity) {
                    const newEncoderLength = SpeedyPipelineNodeKeypointDetector.encoderLength(maxKeypoints, descriptorSize, extraSize);
                    encodedKeypoints = gpu2.programs.keypoints.clip.outputs(newEncoderLength, newEncoderLength, this._tex[5])(encodedKeypoints, descriptorSize, extraSize, encoderLength, maxKeypoints);
                    encoderLength = newEncoderLength;
                  }
                  this.output().swrite(encodedKeypoints, descriptorSize, extraSize, encoderLength);
                }
                /**
                 * Generate a permutation p of { 0, 1, ..., n-1 } such that p(p(x)) = x for all x
                 * @param {number} n positive integer
                 * @param {number} [bufsize] size of the output array
                 * @returns {Int32Array} permutation
                 */
                _generatePermutation(n, bufsize = n) {
                  const array = new Int32Array(bufsize);
                  const p = array.subarray(0, n).fill(-1);
                  const q = utils.A.shuffle(utils.A.range(n));
                  for (let i = 0, j = 0; i < n; i++) {
                    if (p[i] < 0) {
                      do {
                        p[i] = q[j++];
                      } while (p[i] < i);
                      p[p[i]] = i;
                    }
                  }
                  return array;
                }
              }
              ;
              const multiplexer_INPUT_PORT = ["in0", "in1"];
              class SpeedyPipelineNodeKeypointMultiplexer extends SpeedyPipelineNode {
                /**
                 * Constructor
                 * @param {string} [name] name of the node
                 */
                constructor(name = void 0) {
                  super(name, 0, [...multiplexer_INPUT_PORT.map((portName) => InputPort(portName).expects(SpeedyPipelineMessageType.Keypoints)), OutputPort().expects(SpeedyPipelineMessageType.Keypoints)]);
                  this._port = 0;
                }
                /**
                 * The number of the port that should be linked to the output
                 * @returns {number}
                 */
                get port() {
                  return this._port;
                }
                /**
                 * The number of the port that should be linked to the output
                 * @param {number} port
                 */
                set port(port) {
                  if (port < 0 || port >= multiplexer_INPUT_PORT.length) throw new utils_errors.qw(`Invalid port: ${port}`);
                  this._port = port | 0;
                }
                /**
                 * Run the specific task of this node
                 * @param {SpeedyGPU} gpu
                 * @returns {void|SpeedyPromise<void>}
                 */
                _run(gpu2) {
                  const message = this.input(multiplexer_INPUT_PORT[this._port]).read();
                  this.output().write(message);
                }
              }
              ;
              class SpeedyPipelineNodeKeypointTransformer extends SpeedyPipelineNode {
                /**
                 * Constructor
                 * @param {string} [name] name of the node
                 */
                constructor(name = void 0) {
                  super(name, 1, [InputPort().expects(SpeedyPipelineMessageType.Keypoints), OutputPort().expects(SpeedyPipelineMessageType.Keypoints)]);
                  this._transform = speedy_matrix.SpeedyMatrix.Create(3, 3, [1, 0, 0, 0, 1, 0, 0, 0, 1]);
                }
                /**
                 * Transformation matrix
                 * @returns {SpeedyMatrix}
                 */
                get transform() {
                  return this._transform;
                }
                /**
                 * Transformation matrix. Must be 3x3
                 * @param {SpeedyMatrix} transform
                 */
                set transform(transform) {
                  if (!(transform.rows == 3 && transform.columns == 3)) throw new utils_errors.qw(`Not a 3x3 transformation matrix: ${transform}`);
                  this._transform = transform;
                }
                /**
                 * Run the specific task of this node
                 * @param {SpeedyGPU} gpu
                 * @returns {void|SpeedyPromise<void>}
                 */
                _run(gpu2) {
                  const {
                    encodedKeypoints,
                    descriptorSize,
                    extraSize,
                    encoderLength
                  } = (
                    /** @type {SpeedyPipelineMessageWithKeypoints} */
                    this.input().read()
                  );
                  const outputTexture = this._tex[0];
                  const homography = this._transform.read();
                  gpu2.programs.keypoints.applyHomography.outputs(encodedKeypoints.width, encodedKeypoints.height, outputTexture)(homography, encodedKeypoints, descriptorSize, extraSize, encoderLength);
                  this.output().swrite(outputTexture, descriptorSize, extraSize, encoderLength);
                }
              }
              ;
              const METHOD2PROGRAM = Object.freeze({
                "quadratic1d": "subpixelQuadratic1d",
                "taylor2d": "subpixelTaylor2d",
                "bicubic-upsample": "subpixelBicubic",
                "bilinear-upsample": "subpixelBilinear"
              });
              class SpeedyPipelineNodeKeypointSubpixelRefiner extends SpeedyPipelineNode {
                /**
                 * Constructor
                 * @param {string} [name] name of the node
                 */
                constructor(name = void 0) {
                  super(name, 2, [InputPort("image").expects(SpeedyPipelineMessageType.Image).satisfying((msg) => msg.format === types.f5.GREY), InputPort("keypoints").expects(SpeedyPipelineMessageType.Keypoints), OutputPort().expects(SpeedyPipelineMessageType.Keypoints), OutputPort("displacements").expects(SpeedyPipelineMessageType.Vector2)]);
                  this._method = "quadratic1d";
                  this._maxIterations = 6;
                  this._epsilon = 0.1;
                }
                /**
                 * Subpixel refinement method
                 * @returns {SubpixelRefinementMethod}
                 */
                get method() {
                  return this._method;
                }
                /**
                 * Subpixel refinement method
                 * @param {SubpixelRefinementMethod} name
                 */
                set method(name) {
                  if (!Object.prototype.hasOwnProperty.call(METHOD2PROGRAM, name)) throw new utils_errors.qw(`Invalid method: "${name}"`);
                  this._method = name;
                }
                /**
                 * Max. iterations for the upsampling methods
                 * @returns {number}
                 */
                get maxIterations() {
                  return this._maxIterations;
                }
                /**
                 * Max. iterations for the upsampling methods
                 * @param {number} value
                 */
                set maxIterations(value) {
                  this._maxIterations = Math.max(0, +value);
                }
                /**
                 * Convergence threshold for the upsampling methods
                 * @returns {number}
                 */
                get epsilon() {
                  return this._epsilon;
                }
                /**
                 * Convergence threshold for the upsampling methods
                 * @param {number} value
                 */
                set epsilon(value) {
                  this._epsilon = Math.max(0, +value);
                }
                /**
                 * Run the specific task of this node
                 * @param {SpeedyGPU} gpu
                 * @returns {void|SpeedyPromise<void>}
                 */
                _run(gpu2) {
                  const {
                    encodedKeypoints,
                    descriptorSize,
                    extraSize,
                    encoderLength
                  } = (
                    /** @type {SpeedyPipelineMessageWithKeypoints} */
                    this.input("keypoints").read()
                  );
                  const {
                    image,
                    format
                  } = (
                    /** @type {SpeedyPipelineMessageWithImage} */
                    this.input("image").read()
                  );
                  const tex = this._tex;
                  const program = METHOD2PROGRAM[this._method];
                  const maxIterations = this._maxIterations;
                  const epsilon = this._epsilon;
                  const capacity = SpeedyPipelineNodeKeypointDetector.encoderCapacity(descriptorSize, extraSize, encoderLength);
                  const offsetEncoderLength = Math.max(1, Math.ceil(Math.sqrt(capacity)));
                  const offsets = gpu2.programs.keypoints[program].outputs(offsetEncoderLength, offsetEncoderLength, tex[0])(image, encodedKeypoints, descriptorSize, extraSize, encoderLength, maxIterations, epsilon);
                  const refinedKeypoints = gpu2.programs.keypoints.transferFlow.outputs(encoderLength, encoderLength, tex[1])(offsets, encodedKeypoints, descriptorSize, extraSize, encoderLength);
                  this.output().swrite(refinedKeypoints, descriptorSize, extraSize, encoderLength);
                  this.output("displacements").swrite(offsets);
                }
              }
              ;
              const DEFAULT_THRESHOLD = 20;
              class SpeedyPipelineNodeFASTKeypointDetector extends SpeedyPipelineNodeMultiscaleKeypointDetector {
                /**
                 * Constructor
                 * @param {string} [name] name of the node
                 */
                constructor(name = void 0) {
                  super(name, 5, [InputPort().expects(SpeedyPipelineMessageType.Image).satisfying((msg) => msg.format === types.f5.GREY), OutputPort().expects(SpeedyPipelineMessageType.Keypoints)]);
                  this._threshold = DEFAULT_THRESHOLD;
                }
                /**
                 * FAST threshold in [0,255]
                 * @returns {number}
                 */
                get threshold() {
                  return this._threshold;
                }
                /**
                 * FAST threshold in [0,255]
                 * @param {number} threshold
                 */
                set threshold(threshold) {
                  this._threshold = Math.max(0, Math.min(threshold | 0, 255));
                }
                /**
                 * Run the specific task of this node
                 * @param {SpeedyGPU} gpu
                 * @returns {void|SpeedyPromise<void>}
                 */
                _run(gpu2) {
                  const {
                    image,
                    format
                  } = (
                    /** @type {SpeedyPipelineMessageWithImage} */
                    this.input().read()
                  );
                  const width = image.width, height = image.height;
                  const tex = this._tex;
                  const capacity = this._capacity;
                  const threshold = this._threshold;
                  const lodStep = Math.log2(this.scaleFactor);
                  const levels = this.levels;
                  if (!(levels == 1 || image.hasMipmaps())) throw new utils_errors.Er(`Expected a pyramid in ${this.fullName}`);
                  if (capacity == 0) {
                    const encodedKeypoints2 = this._encodeZeroKeypoints(gpu2, tex[4]);
                    const encoderLength2 = encodedKeypoints2.width;
                    this.output().swrite(encodedKeypoints2, 0, 0, encoderLength2);
                    return;
                  }
                  gpu2.programs.keypoints.fast9_16.outputs(width, height, tex[0], tex[1]);
                  gpu2.programs.keypoints.nonmaxSpace.outputs(width, height, tex[2]);
                  let corners = tex[1].clear();
                  let numPasses = Math.max(1, Math.min(levels, globals.PYRAMID_MAX_LEVELS / lodStep | 0));
                  for (let lod = lodStep * (numPasses - 1); numPasses-- > 0; lod -= lodStep) {
                    corners = gpu2.programs.keypoints.fast9_16(corners, image, lod, threshold);
                  }
                  corners = gpu2.programs.keypoints.nonmaxSpace(corners);
                  if (levels > 1) {
                    corners = gpu2.programs.keypoints.nonmaxScaleSimple.outputs(width, height, tex[1])(corners, image, lodStep);
                  }
                  let encodedKeypoints = this._encodeKeypoints(gpu2, corners, tex[3]);
                  const encoderLength = encodedKeypoints.width;
                  if (levels > 1) {
                    encodedKeypoints = gpu2.programs.keypoints.refineScaleFAST916.outputs(encoderLength, encoderLength, tex[4])(image, lodStep, encodedKeypoints, 0, 0, encoderLength, threshold);
                  }
                  this.output().swrite(encodedKeypoints, 0, 0, encoderLength);
                }
              }
              ;
              const HARRIS = Object.freeze({
                1: "harris1",
                3: "harris3",
                5: "harris5",
                7: "harris7"
              });
              class SpeedyPipelineNodeHarrisKeypointDetector extends SpeedyPipelineNodeMultiscaleKeypointDetector {
                /**
                 * Constructor
                 * @param {string} [name] name of the node
                 */
                constructor(name = void 0) {
                  super(name, 6, [InputPort().expects(SpeedyPipelineMessageType.Image).satisfying((msg) => msg.format === types.f5.GREY), OutputPort().expects(SpeedyPipelineMessageType.Keypoints)]);
                  this._windowSize = new SpeedySize(3, 3);
                  this._quality = 0.1;
                }
                /**
                 * Minimum corner quality in [0,1] - this is a fraction of
                 * the largest min. eigenvalue of the autocorrelation matrix
                 * over the entire image
                 * @returns {number}
                 */
                get quality() {
                  return this._quality;
                }
                /**
                 * Minimum corner quality in [0,1]
                 * @param {number} quality
                 */
                set quality(quality) {
                  this._quality = Math.max(0, Math.min(+quality, 1));
                }
                /**
                 * Neighborhood size
                 * @returns {SpeedySize}
                 */
                get windowSize() {
                  return this._windowSize;
                }
                /**
                 * Neighborhood size
                 * @param {SpeedySize} windowSize
                 */
                set windowSize(windowSize) {
                  const d = windowSize.width;
                  if (!(d == windowSize.height && (d == 1 || d == 3 || d == 5 || d == 7))) throw new utils_errors.qw(`Invalid window: ${windowSize}. Acceptable sizes: 1x1, 3x3, 5x5, 7x7`);
                  this._windowSize = windowSize;
                }
                /**
                 * Run the specific task of this node
                 * @param {SpeedyGPU} gpu
                 * @returns {void|SpeedyPromise<void>}
                 */
                _run(gpu2) {
                  const {
                    image,
                    format
                  } = (
                    /** @type {SpeedyPipelineMessageWithImage} */
                    this.input().read()
                  );
                  const width = image.width, height = image.height;
                  const capacity = this._capacity;
                  const quality = this._quality;
                  const windowSize = this._windowSize.width;
                  const levels = this.levels;
                  const lodStep = Math.log2(this.scaleFactor);
                  const intFactor = levels > 1 ? this.scaleFactor : 1;
                  const harris2 = gpu2.programs.keypoints[HARRIS[windowSize]];
                  const tex = this._tex;
                  if (!(levels == 1 || image.hasMipmaps())) throw new utils_errors.Er(`Expected a pyramid in ${this.fullName}`);
                  if (capacity == 0) {
                    const encodedKeypoints2 = this._encodeZeroKeypoints(gpu2, tex[5]);
                    const encoderLength2 = encodedKeypoints2.width;
                    this.output().swrite(encodedKeypoints2, 0, 0, encoderLength2);
                    return;
                  }
                  harris2.outputs(width, height, tex[0], tex[1]);
                  gpu2.programs.utils.sobelDerivatives.outputs(width, height, tex[2]);
                  gpu2.programs.keypoints.nonmaxSpace.outputs(width, height, tex[3]);
                  let corners = tex[1].clear();
                  let numPasses = Math.max(1, Math.min(levels, globals.PYRAMID_MAX_LEVELS / lodStep | 0));
                  for (let lod = lodStep * (numPasses - 1); numPasses-- > 0; lod -= lodStep) {
                    const gaussian2 = utils.A.gaussianKernel(intFactor * (1 + lod), windowSize);
                    const derivatives = gpu2.programs.utils.sobelDerivatives(image, lod);
                    corners = harris2(corners, image, derivatives, lod, lodStep, gaussian2);
                    corners = gpu2.programs.keypoints.nonmaxSpace(corners);
                  }
                  if (levels > 1) {
                    const laplacian2 = gpu2.programs.keypoints.laplacian.outputs(width, height, tex[0])(corners, image, lodStep, 0);
                    corners = gpu2.programs.keypoints.nonmaxScale.outputs(width, height, tex[2])(corners, image, laplacian2, lodStep);
                  }
                  gpu2.programs.keypoints.harrisScoreFindMax.outputs(width, height, tex[0], tex[1]);
                  numPasses = Math.ceil(Math.log2(Math.max(width, height)));
                  let maxScore = corners;
                  for (let j = 0; j < numPasses; j++) maxScore = gpu2.programs.keypoints.harrisScoreFindMax(maxScore, j);
                  corners = gpu2.programs.keypoints.harrisScoreCutoff.outputs(width, height, maxScore == tex[0] ? tex[1] : tex[0])(corners, maxScore, quality);
                  let encodedKeypoints = this._encodeKeypoints(gpu2, corners, tex[4]);
                  const encoderLength = encodedKeypoints.width;
                  if (levels > 1) {
                    encodedKeypoints = gpu2.programs.keypoints.refineScaleLoG.outputs(encoderLength, encoderLength, tex[5])(image, lodStep, encodedKeypoints, 0, 0, encoderLength);
                  }
                  this.output().swrite(encodedKeypoints, 0, 0, encoderLength);
                }
              }
              ;
              class SpeedyPipelineNodeKeypointDescriptor extends SpeedyPipelineNode {
                /**
                 * Constructor
                 * @param {string} [name] name of the node
                 * @param {number} [texCount] number of work textures
                 * @param {SpeedyPipelinePortBuilder[]} [portBuilders] port builders
                 */
                constructor(name = void 0, texCount = 0, portBuilders = void 0) {
                  super(name, texCount + 1, portBuilders);
                }
                /**
                 * 
                 * Allocate space for keypoint descriptors
                 * @param {SpeedyGPU} gpu
                 * @param {number} inputDescriptorSize should be 0
                 * @param {number} inputExtraSize must be non-negative
                 * @param {number} outputDescriptorSize in bytes, must be a multiple of 4
                 * @param {number} outputExtraSize must be inputExtraSize
                 * @param {SpeedyTexture} inputEncodedKeypoints input with no descriptors
                 * @returns {SpeedyDrawableTexture} encodedKeypoints
                 */
                _allocateDescriptors(gpu2, inputDescriptorSize, inputExtraSize, outputDescriptorSize, outputExtraSize, inputEncodedKeypoints) {
                  utils.A.assert(inputDescriptorSize >= 0 && inputExtraSize >= 0);
                  utils.A.assert(outputDescriptorSize >= 0 && outputDescriptorSize % 4 === 0 && outputExtraSize === inputExtraSize);
                  const inputEncoderLength = inputEncodedKeypoints.width;
                  const inputEncoderCapacity = SpeedyPipelineNodeKeypointDetector.encoderCapacity(inputDescriptorSize, inputExtraSize, inputEncoderLength);
                  const outputEncoderCapacity = inputEncoderCapacity;
                  const outputEncoderLength = SpeedyPipelineNodeKeypointDetector.encoderLength(outputEncoderCapacity, outputDescriptorSize, outputExtraSize);
                  const tex = this._tex[this._tex.length - 1];
                  return gpu2.programs.keypoints.allocateDescriptors.outputs(outputEncoderLength, outputEncoderLength, tex)(inputEncodedKeypoints, inputDescriptorSize, inputExtraSize, inputEncoderLength, outputDescriptorSize, outputExtraSize, outputEncoderLength);
                }
              }
              ;
              const DESCRIPTOR_SIZE = 32;
              class SpeedyPipelineNodeORBKeypointDescriptor extends SpeedyPipelineNodeKeypointDescriptor {
                /**
                 * Constructor
                 * @param {string} [name] name of the node
                 */
                constructor(name = void 0) {
                  super(name, 3, [InputPort("image").expects(SpeedyPipelineMessageType.Image).satisfying((msg) => msg.format === types.f5.GREY), InputPort("keypoints").expects(SpeedyPipelineMessageType.Keypoints), OutputPort().expects(SpeedyPipelineMessageType.Keypoints)]);
                }
                /**
                 * Run the specific task of this node
                 * @param {SpeedyGPU} gpu
                 * @returns {void|SpeedyPromise<void>}
                 */
                _run(gpu2) {
                  const {
                    encodedKeypoints,
                    descriptorSize,
                    extraSize,
                    encoderLength
                  } = (
                    /** @type {SpeedyPipelineMessageWithKeypoints} */
                    this.input("keypoints").read()
                  );
                  const image = (
                    /** @type {SpeedyPipelineMessageWithImage} */
                    this.input("image").read().image
                  );
                  const tex = this._tex;
                  const outputTexture = this._tex[2];
                  const capacity = SpeedyPipelineNodeKeypointDetector.encoderCapacity(descriptorSize, extraSize, encoderLength);
                  const orientationEncoderLength = Math.max(1, Math.ceil(Math.sqrt(capacity)));
                  const encodedOrientations = gpu2.programs.keypoints.orbOrientation.outputs(orientationEncoderLength, orientationEncoderLength, tex[0])(image, encodedKeypoints, descriptorSize, extraSize, encoderLength);
                  const orientedKeypoints = gpu2.programs.keypoints.transferOrientation.outputs(encoderLength, encoderLength, tex[1])(encodedOrientations, encodedKeypoints, descriptorSize, extraSize, encoderLength);
                  const encodedKps = this._allocateDescriptors(gpu2, descriptorSize, extraSize, DESCRIPTOR_SIZE, extraSize, orientedKeypoints);
                  const newEncoderLength = encodedKps.width;
                  const describedKeypoints = gpu2.programs.keypoints.orbDescriptor.outputs(newEncoderLength, newEncoderLength, outputTexture)(image, encodedKps, extraSize, newEncoderLength);
                  this.output().swrite(describedKeypoints, DESCRIPTOR_SIZE, extraSize, newEncoderLength);
                }
              }
              ;
              const DEFAULT_WINDOW_SIZE = new SpeedySize(11, 11);
              const DEFAULT_DEPTH = Math.min(3, globals.PYRAMID_MAX_LEVELS);
              const DEFAULT_NUMBER_OF_ITERATIONS = 30;
              const DEFAULT_DISCARD_THRESHOLD = 1e-4;
              const DEFAULT_EPSILON = 0.01;
              const LK_PROGRAM = {
                3: "lk3",
                5: "lk5",
                7: "lk7",
                9: "lk9",
                11: "lk11",
                13: "lk13",
                15: "lk15",
                17: "lk17",
                19: "lk19",
                21: "lk21"
              };
              class SpeedyPipelineNodeLKKeypointTracker extends SpeedyPipelineNode {
                /**
                 * Constructor
                 * @param {string} [name] name of the node
                 */
                constructor(name = void 0) {
                  super(name, 3, [InputPort("previousImage").expects(SpeedyPipelineMessageType.Image).satisfying((msg) => msg.format === types.f5.GREY), InputPort("nextImage").expects(SpeedyPipelineMessageType.Image).satisfying((msg) => msg.format === types.f5.GREY), InputPort("previousKeypoints").expects(SpeedyPipelineMessageType.Keypoints), OutputPort().expects(SpeedyPipelineMessageType.Keypoints), OutputPort("flow").expects(SpeedyPipelineMessageType.Vector2)]);
                  this._windowSize = DEFAULT_WINDOW_SIZE;
                  this._levels = DEFAULT_DEPTH;
                  this._discardThreshold = DEFAULT_DISCARD_THRESHOLD;
                  this._numberOfIterations = DEFAULT_NUMBER_OF_ITERATIONS;
                  this._epsilon = DEFAULT_EPSILON;
                }
                /**
                 * Window size (use odd numbers)
                 * @returns {SpeedySize}
                 */
                get windowSize() {
                  return this._windowSize;
                }
                /**
                 * Window size (use odd numbers)
                 * @param {SpeedySize} windowSize must be a square window
                 */
                set windowSize(windowSize) {
                  if (windowSize.width != windowSize.height) {
                    throw new utils_errors.EM(`LK: window ${this._windowSize.toString()} is not square!`);
                  } else if (!Object.prototype.hasOwnProperty.call(LK_PROGRAM, windowSize.width)) {
                    const SUPPORTED_WINDOWS = Object.keys(LK_PROGRAM).sort((a, b) => a - b).map((k) => k + "x" + k).join(", ");
                    throw new utils_errors.EM(`LK: window of size ${this._windowSize.toString()} is not supported! Supported sizes: ${SUPPORTED_WINDOWS}`);
                  }
                  this._windowSize = windowSize;
                }
                /**
                 * Number of pyramid levels to use
                 * @returns {number}
                 */
                get levels() {
                  return this._levels;
                }
                /**
                 * Number of pyramid levels to use
                 * @param {number} levels
                 */
                set levels(levels) {
                  utils.A.assert(levels >= 1 && levels <= globals.PYRAMID_MAX_LEVELS);
                  this._levels = levels | 0;
                }
                /**
                 * Get the discard threshold, used to discard "bad" keypoints
                 * @returns {number}
                 */
                get discardThreshold() {
                  return this._discardThreshold;
                }
                /**
                 * Set the discard threshold, used to discard "bad" keypoints
                 * @param {number} value typically 10^(-4) - increase to discard more
                 */
                set discardThreshold(value) {
                  utils.A.assert(value >= 0);
                  this._discardThreshold = +value;
                }
                /**
                 * Get the maximum number of iterations of the pyramidal LK algorithm
                 * @returns {number}
                 */
                get numberOfIterations() {
                  return this._numberOfIterations;
                }
                /**
                 * Set the maximum number of iterations of the pyramidal LK algorithm
                 * @param {number} value
                 */
                set numberOfIterations(value) {
                  utils.A.assert(value >= 1);
                  this._numberOfIterations = value | 0;
                }
                /**
                 * Get the accuracy threshold, used to stop LK iterations
                 * @returns {number}
                 */
                get epsilon() {
                  return this._epsilon;
                }
                /**
                 * Get the accuracy threshold, used to stop LK iterations
                 * @param {number} value typically 0.01
                 */
                set epsilon(value) {
                  utils.A.assert(value >= 0);
                  this._epsilon = +value;
                }
                /**
                 * Run the specific task of this node
                 * @param {SpeedyGPU} gpu
                 * @returns {void|SpeedyPromise<void>}
                 */
                _run(gpu2) {
                  const {
                    encodedKeypoints,
                    descriptorSize,
                    extraSize,
                    encoderLength
                  } = (
                    /** @type {SpeedyPipelineMessageWithKeypoints} */
                    this.input("previousKeypoints").read()
                  );
                  const previousImage = (
                    /** @type {SpeedyPipelineMessageWithImage} */
                    this.input("previousImage").read().image
                  );
                  const nextImage = (
                    /** @type {SpeedyPipelineMessageWithImage} */
                    this.input("nextImage").read().image
                  );
                  const previousKeypoints = encodedKeypoints;
                  const levels = this._levels;
                  const windowSize = this._windowSize;
                  const wsize = windowSize.width;
                  const numberOfIterations = this._numberOfIterations;
                  const discardThreshold = this._discardThreshold;
                  const epsilon = this._epsilon;
                  const keypoints = gpu2.programs.keypoints;
                  const tex = this._tex;
                  if (!(levels == 1 || previousImage.hasMipmaps() && nextImage.hasMipmaps())) throw new utils_errors.Er(`LK: a pyramid is required if levels > 1`);
                  else if (previousImage.width !== nextImage.width || previousImage.height !== nextImage.height) throw new utils_errors.Er(`LK: can't use input images of different size`);
                  const lk2 = keypoints[LK_PROGRAM[wsize]];
                  const numKeypoints = SpeedyPipelineNodeKeypointDetector.encoderCapacity(descriptorSize, extraSize, encoderLength);
                  const lkEncoderLength = Math.max(1, Math.ceil(Math.sqrt(numKeypoints)));
                  lk2.outputs(lkEncoderLength, lkEncoderLength, tex[0], tex[1]);
                  let flow = lk2.clear();
                  for (let lod = levels - 1; lod >= 0; lod--) flow = lk2(flow, previousKeypoints, nextImage, previousImage, lod, levels, numberOfIterations, discardThreshold, epsilon, descriptorSize, extraSize, encoderLength);
                  keypoints.transferFlow.outputs(encoderLength, encoderLength, tex[2]);
                  const nextKeypoints = keypoints.transferFlow(flow, previousKeypoints, descriptorSize, extraSize, encoderLength);
                  this.output().swrite(nextKeypoints, descriptorSize, extraSize, encoderLength);
                  this.output("flow").swrite(flow);
                }
              }
              ;
              class SpeedyPipelineNodeStaticLSHTables extends SpeedyPipelineSourceNode {
                /**
                 * Constructor
                 * @param {string} [name] name of the node
                 */
                constructor(name = void 0) {
                  super(name, 2, [OutputPort().expects(SpeedyPipelineMessageType.LSHTables)]);
                  this._keypoints = [];
                  this._keypointsCopy = [];
                  this._numberOfTables = LSH_DEFAULT_NUMBER_OF_TABLES;
                  this._hashSize = LSH_DEFAULT_HASH_SIZE;
                  this._lsh = null;
                }
                /**
                 * "Training" keypoints
                 * @returns {SpeedyKeypoint[]}
                 */
                get keypoints() {
                  return this._keypoints;
                }
                /**
                 * "Training" keypoints
                 * @param {SpeedyKeypoint[]} keypoints
                 */
                set keypoints(keypoints) {
                  if (!Array.isArray(keypoints) || keypoints.find((keypoint) => !(keypoint instanceof SpeedyKeypoint))) throw new utils_errors.qw(`Static LSH tables: an invalid set of keypoints has been provided`);
                  if (this._keypoints !== keypoints) {
                    this._keypoints = keypoints;
                    this._keypointsCopy = keypoints.slice(0);
                    this._lsh = null;
                  }
                }
                /**
                 * Number of tables in the LSH data structure
                 * @returns {number}
                 */
                get numberOfTables() {
                  return this._numberOfTables;
                }
                /**
                 * Number of tables in the LSH data structure
                 * @param {number} n
                 */
                set numberOfTables(n) {
                  if (!LSH_ACCEPTABLE_NUMBER_OF_TABLES.includes(n)) throw new utils_errors.qw(`Invalid number of tables: ${n}. Acceptable values: ${LSH_ACCEPTABLE_NUMBER_OF_TABLES.join(", ")}`);
                  if (n !== this._numberOfTables) {
                    this._numberOfTables = n | 0;
                    this._lsh = null;
                  }
                }
                /**
                 * Number of bits of a hash
                 * @returns {number}
                 */
                get hashSize() {
                  return this._hashSize;
                }
                /**
                 * Number of bits of a hash
                 * @param {number} h
                 */
                set hashSize(h) {
                  if (!LSH_ACCEPTABLE_HASH_SIZES.includes(h)) throw new utils_errors.qw(`Invalid hash size: ${h}. Acceptable values: ${LSH_ACCEPTABLE_HASH_SIZES.join(", ")}`);
                  if (h !== this._hashSize) {
                    this._hashSize = h | 0;
                    this._lsh = null;
                  }
                }
                /**
                 * Run the specific task of this node
                 * @param {SpeedyGPU} gpu
                 * @returns {void|SpeedyPromise<void>}
                 */
                _run(gpu2) {
                  if (this._lsh == null) {
                    this._lsh = this._train();
                  }
                  this.output().swrite(this._lsh);
                }
                /**
                 * Train the model
                 * @returns {SpeedyLSH}
                 */
                _train() {
                  const keypoints = this._keypointsCopy;
                  const numberOfTables = this._numberOfTables;
                  const hashSize = this._hashSize;
                  if (keypoints.find((keypoint) => keypoint.descriptor == null)) throw new utils_errors.Er(`Static LSH tables: can't train the model with no keypoint descriptors!`);
                  const descriptors = keypoints.map((keypoint) => keypoint.descriptor.data);
                  const lshTables = this._tex[0];
                  const descriptorDB = this._tex[1];
                  return new SpeedyLSH(lshTables, descriptorDB, descriptors, numberOfTables, hashSize);
                }
              }
              ;
              const DEFAULT_K = 1;
              const DEFAULT_QUALITY = "default";
              const NUMBER_OF_BIT_SWAPS = {
                "fastest": 0,
                "default": 1,
                "demanding": 2
              };
              const LSH_KNN = ((fd) => LSH_ACCEPTABLE_DESCRIPTOR_SIZES.reduce((o, d) => (o[d] = fd(d), o), {}))((d) => ((fh) => LSH_ACCEPTABLE_HASH_SIZES.reduce((o, h) => (o[h] = fh(h), o), {}))((h) => ((fl) => [0, 1, 2].reduce((o, l) => (o[l] = fl(l), o), {}))((l) => `lshKnn${d}h${h}lv${l}`)));
              class SpeedyPipelineNodeLSHKNNKeypointMatcher extends SpeedyPipelineNode {
                /**
                 * Constructor
                 * @param {string} [name] name of the node
                 */
                constructor(name = void 0) {
                  super(name, 6, [InputPort("keypoints").expects(SpeedyPipelineMessageType.Keypoints).satisfying((msg) => msg.descriptorSize > 0), InputPort("lsh").expects(SpeedyPipelineMessageType.LSHTables), OutputPort().expects(SpeedyPipelineMessageType.KeypointMatches)]);
                  this._k = DEFAULT_K;
                  this._quality = DEFAULT_QUALITY;
                }
                /**
                 * How many neighbors do you want?
                 * @returns {number}
                 */
                get k() {
                  return this._k;
                }
                /**
                 * How many neighbors do you want?
                 * @param {number} k number of neighbors
                 */
                set k(k) {
                  this._k = Math.max(1, k | 0);
                }
                /**
                 * Quality of the matching
                 * @returns {LSHKNNQualityLevel}
                 */
                get quality() {
                  return this._quality;
                }
                /**
                 * Quality of the matching
                 * @param {LSHKNNQualityLevel} quality
                 */
                set quality(quality) {
                  if (!Object.prototype.hasOwnProperty.call(NUMBER_OF_BIT_SWAPS, quality)) throw new utils_errors.qw(`Invalid quality level: "${quality}"`);
                  this._quality = quality;
                }
                /**
                 * Run the specific task of this node
                 * @param {SpeedyGPU} gpu
                 * @returns {void|SpeedyPromise<void>}
                 */
                _run(gpu2) {
                  const {
                    encodedKeypoints,
                    descriptorSize,
                    extraSize,
                    encoderLength
                  } = (
                    /** @type {SpeedyPipelineMessageWithKeypoints} */
                    this.input("keypoints").read()
                  );
                  const lsh = this.input("lsh").read().lsh;
                  const keypoints = gpu2.programs.keypoints;
                  const tables = lsh.tables;
                  const descriptorDB = lsh.descriptorDB;
                  const tablesStride = tables.width;
                  const descriptorDBStride = descriptorDB.width;
                  const tableCount = lsh.tableCount;
                  const hashSize = lsh.hashSize;
                  const bucketCapacity = lsh.bucketCapacity;
                  const bucketsPerTable = lsh.bucketsPerTable;
                  const sequences = lsh.sequences;
                  const candidatesA = this._tex[0];
                  const candidatesB = this._tex[1];
                  const candidatesC = this._tex[2];
                  const filters = this._tex[3];
                  const transferA = this._tex[4];
                  const transferB = this._tex[5];
                  const level = NUMBER_OF_BIT_SWAPS[this._quality];
                  const matchesPerKeypoint = this._k;
                  if (descriptorSize !== lsh.descriptorSize) throw new utils_errors.qw(`Can't match different types of descriptors in ${this.fullName}`);
                  utils.A.assert(LSH_KNN[descriptorSize] != void 0);
                  utils.A.assert(LSH_KNN[descriptorSize][hashSize] != void 0);
                  utils.A.assert(LSH_KNN[descriptorSize][hashSize][level] != void 0);
                  const capacity = SpeedyPipelineNodeKeypointDetector.encoderCapacity(descriptorSize, extraSize, encoderLength);
                  const matcherLength = Math.max(1, Math.ceil(Math.sqrt(capacity * matchesPerKeypoint)));
                  let encodedMatches = transferB;
                  keypoints.lshKnnTransfer.outputs(matcherLength, matcherLength, transferA, transferB);
                  const kthMatcherLength = Math.max(1, Math.ceil(Math.sqrt(capacity)));
                  keypoints.lshKnnInitCandidates.outputs(kthMatcherLength, kthMatcherLength, candidatesA);
                  keypoints.lshKnnInitFilters.outputs(kthMatcherLength, kthMatcherLength, filters);
                  const lshKnn2 = keypoints[LSH_KNN[descriptorSize][hashSize][level]];
                  lshKnn2.outputs(kthMatcherLength, kthMatcherLength, candidatesB, candidatesC);
                  lshKnn2.setUBO("LSHSequences", sequences);
                  encodedMatches.clear();
                  keypoints.lshKnnInitFilters();
                  for (let i = 0; i < matchesPerKeypoint; i++) {
                    let candidates = keypoints.lshKnnInitCandidates();
                    for (let tableIndex = 0; tableIndex < tableCount; tableIndex++) {
                      candidates = lshKnn2(candidates, filters, kthMatcherLength, tables, descriptorDB, tableIndex, bucketCapacity, bucketsPerTable, tablesStride, descriptorDBStride, encodedKeypoints, descriptorSize, extraSize, encoderLength);
                      gpu2.gl.flush();
                    }
                    candidates.copyTo(filters);
                    encodedMatches = keypoints.lshKnnTransfer(encodedMatches, candidates, matchesPerKeypoint, i);
                  }
                  this.output().swrite(encodedMatches, matchesPerKeypoint);
                }
              }
              ;
              const PROGRAM_NAME = {
                32: "bfMatcher32",
                64: "bfMatcher64"
              };
              class SpeedyPipelineNodeBruteForceKNNKeypointMatcher extends SpeedyPipelineNode {
                /**
                 * Constructor
                 * @param {string} [name] name of the node
                 */
                constructor(name = void 0) {
                  super(name, 6, [InputPort("keypoints").expects(SpeedyPipelineMessageType.Keypoints).satisfying((msg) => msg.descriptorSize > 0), InputPort("database").expects(SpeedyPipelineMessageType.Keypoints).satisfying((msg) => msg.descriptorSize > 0), OutputPort().expects(SpeedyPipelineMessageType.KeypointMatches)]);
                  this._matchesPerKeypoint = 1;
                }
                /**
                 * Number of matches per keypoint
                 * @returns {number}
                 */
                get k() {
                  return this._matchesPerKeypoint;
                }
                /**
                 * Number of matches per keypoint
                 * @param {number} value
                 */
                set k(value) {
                  this._matchesPerKeypoint = Math.max(1, value | 0);
                }
                /**
                 * Run the specific task of this node
                 * @param {SpeedyGPU} gpu
                 * @returns {void|SpeedyPromise<void>}
                 */
                _run(gpu2) {
                  const {
                    encodedKeypoints,
                    descriptorSize,
                    extraSize,
                    encoderLength
                  } = (
                    /** @type {SpeedyPipelineMessageWithKeypoints} */
                    this.input("keypoints").read()
                  );
                  const database = (
                    /** @type {SpeedyPipelineMessageWithKeypoints} */
                    this.input("database").read()
                  );
                  const candidatesA = this._tex[0];
                  const candidatesB = this._tex[1];
                  const candidatesC = this._tex[2];
                  const encodedFiltersA = this._tex[3];
                  const encodedMatchesA = this._tex[4];
                  const encodedMatchesB = this._tex[5];
                  const matchesPerKeypoint = this._matchesPerKeypoint;
                  const keypoints = gpu2.programs.keypoints;
                  if (descriptorSize !== database.descriptorSize) throw new utils_errors.qw(`Incompatible descriptors in ${this.fullName}`);
                  else if (!Object.prototype.hasOwnProperty.call(PROGRAM_NAME, descriptorSize)) throw new utils_errors.EM(`Unsupported descriptor size (${descriptorSize}) in ${this.fullName}`);
                  const bfMatcher = keypoints[PROGRAM_NAME[descriptorSize]];
                  const capacity = SpeedyPipelineNodeKeypointDetector.encoderCapacity(descriptorSize, extraSize, encoderLength);
                  const dbCapacity = SpeedyPipelineNodeKeypointDetector.encoderCapacity(database.descriptorSize, database.extraSize, database.encoderLength);
                  const numberOfKeypointsPerPass = bfMatcher.definedConstant("NUMBER_OF_KEYPOINTS_PER_PASS");
                  const numberOfPasses = Math.ceil(dbCapacity / numberOfKeypointsPerPass);
                  const partialMatcherLength = Math.max(1, Math.ceil(Math.sqrt(capacity)));
                  const matcherLength = Math.max(1, Math.ceil(Math.sqrt(capacity * matchesPerKeypoint)));
                  keypoints.bfMatcherTransfer.outputs(matcherLength, matcherLength, encodedMatchesA, encodedMatchesB);
                  keypoints.bfMatcherInitCandidates.outputs(partialMatcherLength, partialMatcherLength, candidatesC);
                  keypoints.bfMatcherInitFilters.outputs(partialMatcherLength, partialMatcherLength, encodedFiltersA);
                  bfMatcher.outputs(partialMatcherLength, partialMatcherLength, candidatesA, candidatesB);
                  let encodedMatches = encodedMatchesB.clear();
                  let encodedFilters = keypoints.bfMatcherInitFilters();
                  for (let k = 0; k < matchesPerKeypoint; k++) {
                    let encodedPartialMatches = keypoints.bfMatcherInitCandidates();
                    for (let passId = 0; passId < numberOfPasses; passId++) {
                      encodedPartialMatches = bfMatcher(encodedPartialMatches, encodedFilters, partialMatcherLength, database.encodedKeypoints, database.descriptorSize, database.extraSize, database.encoderLength, encodedKeypoints, descriptorSize, extraSize, encoderLength, passId);
                      gpu2.gl.flush();
                    }
                    if (matchesPerKeypoint > 1) encodedPartialMatches.copyTo(encodedFilters);
                    encodedMatches = keypoints.bfMatcherTransfer(encodedMatches, encodedPartialMatches, matchesPerKeypoint, k);
                  }
                  this.output().swrite(encodedMatches, matchesPerKeypoint);
                }
              }
              ;
              class SpeedyPipelineNodeKeypointDistanceFilter extends SpeedyPipelineNode {
                /**
                 * Constructor
                 * @param {string} [name] name of the node
                 */
                constructor(name = void 0) {
                  super(name, 1, [InputPort("in").expects(SpeedyPipelineMessageType.Keypoints), InputPort("reference").expects(SpeedyPipelineMessageType.Keypoints), OutputPort().expects(SpeedyPipelineMessageType.Keypoints)]);
                  this._threshold = globals.MAX_TEXTURE_LENGTH + 1;
                }
                /**
                 * Maximum accepted distance
                 * @returns {number}
                 */
                get threshold() {
                  return this._threshold;
                }
                /**
                 * Maximum accepted distance
                 * @param {number} value
                 */
                set threshold(value) {
                  this._threshold = Math.max(0, +value);
                }
                /**
                 * Run the specific task of this node
                 * @param {SpeedyGPU} gpu
                 * @returns {void|SpeedyPromise<void>}
                 */
                _run(gpu2) {
                  const set0 = (
                    /** @type {SpeedyPipelineMessageWithKeypoints} */
                    this.input("in").read()
                  );
                  const set1 = (
                    /** @type {SpeedyPipelineMessageWithKeypoints} */
                    this.input("reference").read()
                  );
                  const threshold = this._threshold;
                  if (set0.descriptorSize != set1.descriptorSize || set0.extraSize != set1.extraSize) throw new utils_errors.Er(`The distance filter requires two compatible shapes of keypoint streams`);
                  const outputTexture = this._tex[0];
                  const encoderLength = Math.max(set0.encoderLength, set1.encoderLength);
                  const descriptorSize = set0.descriptorSize;
                  const extraSize = set0.extraSize;
                  gpu2.programs.keypoints.distanceFilter.outputs(encoderLength, encoderLength, outputTexture)(set0.encodedKeypoints, set0.encoderLength, set1.encodedKeypoints, set1.encoderLength, descriptorSize, extraSize, encoderLength, threshold);
                  this.output().swrite(outputTexture, descriptorSize, extraSize, encoderLength);
                }
              }
              ;
              const hamming_distance_filter_PROGRAM_NAME = {
                32: "hammingDistanceFilter32",
                64: "hammingDistanceFilter64"
              };
              class SpeedyPipelineNodeKeypointHammingDistanceFilter extends SpeedyPipelineNode {
                /**
                 * Constructor
                 * @param {string} [name] name of the node
                 */
                constructor(name = void 0) {
                  super(name, 1, [InputPort("in").expects(SpeedyPipelineMessageType.Keypoints).satisfying((msg) => msg.descriptorSize > 0), InputPort("reference").expects(SpeedyPipelineMessageType.Keypoints).satisfying((msg) => msg.descriptorSize > 0), OutputPort().expects(SpeedyPipelineMessageType.Keypoints)]);
                  this._threshold = globals.MAX_DESCRIPTOR_SIZE * 8;
                }
                /**
                 * Distance threshold, an integer
                 * @returns {number}
                 */
                get threshold() {
                  return this._threshold;
                }
                /**
                 * Distance threshold, an integer
                 * @param {number} value
                 */
                set threshold(value) {
                  this._threshold = Math.max(0, value | 0);
                }
                /**
                 * Run the specific task of this node
                 * @param {SpeedyGPU} gpu
                 * @returns {void|SpeedyPromise<void>}
                 */
                _run(gpu2) {
                  const set0 = (
                    /** @type {SpeedyPipelineMessageWithKeypoints} */
                    this.input("in").read()
                  );
                  const set1 = (
                    /** @type {SpeedyPipelineMessageWithKeypoints} */
                    this.input("reference").read()
                  );
                  const threshold = this._threshold;
                  if (set0.descriptorSize != set1.descriptorSize || set0.extraSize != set1.extraSize) throw new utils_errors.Er(`The Hamming distance filter requires two compatible shapes of keypoint streams`);
                  if (!Object.prototype.hasOwnProperty.call(hamming_distance_filter_PROGRAM_NAME, set0.descriptorSize)) throw new utils_errors.EM(`Hamming distance filter - invalid descriptor size: ${set0.descriptorSize}`);
                  const outputTexture = this._tex[0];
                  const encoderLength = Math.max(set0.encoderLength, set1.encoderLength);
                  const descriptorSize = set0.descriptorSize;
                  const extraSize = set0.extraSize;
                  const program = hamming_distance_filter_PROGRAM_NAME[set0.descriptorSize];
                  gpu2.programs.keypoints[program].outputs(encoderLength, encoderLength, outputTexture)(set0.encodedKeypoints, set0.encoderLength, set1.encodedKeypoints, set1.encoderLength, descriptorSize, extraSize, encoderLength, threshold);
                  this.output().swrite(outputTexture, descriptorSize, extraSize, encoderLength);
                }
              }
              ;
              class SpeedyPipelineNodeKeypointPortalSink extends SpeedyPipelineNode {
                /**
                 * Constructor
                 * @param {string} [name] name of the node
                 */
                constructor(name = void 0) {
                  super(name, 1, [InputPort().expects(SpeedyPipelineMessageType.Keypoints)]);
                  this._descriptorSize = 0;
                  this._extraSize = 0;
                  this._encoderLength = 0;
                  this._initialized = false;
                }
                /**
                 * Encoded keypoints
                 * @returns {SpeedyTexture}
                 */
                get encodedKeypoints() {
                  if (!this._initialized) throw new utils_errors.Er(`Portal error: ${this.fullName} holds no data`);
                  return this._tex[0];
                }
                /**
                 * Descriptor size, in bytes
                 * @returns {number}
                 */
                get descriptorSize() {
                  if (!this._initialized) throw new utils_errors.Er(`Portal error: ${this.fullName} holds no data`);
                  return this._descriptorSize;
                }
                /**
                 * Extra size, in bytes
                 * @returns {number}
                 */
                get extraSize() {
                  if (!this._initialized) throw new utils_errors.Er(`Portal error: ${this.fullName} holds no data`);
                  return this._extraSize;
                }
                /**
                 * Encoder length
                 * @returns {number}
                 */
                get encoderLength() {
                  if (!this._initialized) throw new utils_errors.Er(`Portal error: ${this.fullName} holds no data`);
                  return this._encoderLength;
                }
                /**
                 * Initializes this node
                 * @param {SpeedyGPU} gpu
                 */
                init(gpu2) {
                  super.init(gpu2);
                  const encoderLength = SpeedyPipelineNodeKeypointDetector.encoderLength(0, 0, 0);
                  this._tex[0].resize(encoderLength, encoderLength).clearToColor(1, 1, 1, 1);
                  this._descriptorSize = this._extraSize = 0;
                  this._encoderLength = encoderLength;
                  this._initialized = true;
                }
                /**
                 * Releases this node
                 * @param {SpeedyGPU} gpu
                 */
                release(gpu2) {
                  this._initialized = false;
                  super.release(gpu2);
                }
                /**
                 * Run the specific task of this node
                 * @param {SpeedyGPU} gpu
                 * @returns {void|SpeedyPromise<void>}
                 */
                _run(gpu2) {
                  const {
                    encodedKeypoints,
                    descriptorSize,
                    extraSize,
                    encoderLength
                  } = (
                    /** @type {SpeedyPipelineMessageWithKeypoints} */
                    this.input().read()
                  );
                  const tex = this._tex[0];
                  tex.resize(encodedKeypoints.width, encodedKeypoints.height);
                  encodedKeypoints.copyTo(tex);
                  this._descriptorSize = descriptorSize;
                  this._extraSize = extraSize;
                  this._encoderLength = encoderLength;
                }
              }
              class SpeedyPipelineNodeKeypointPortalSource extends SpeedyPipelineSourceNode {
                /**
                 * Constructor
                 * @param {string} [name] name of the node
                 */
                constructor(name = void 0) {
                  super(name, 0, [OutputPort().expects(SpeedyPipelineMessageType.Keypoints)]);
                  this._source = null;
                }
                /**
                 * Data source
                 * @returns {SpeedyPipelineNodeKeypointPortalSink|null}
                 */
                get source() {
                  return this._source;
                }
                /**
                 * Data source
                 * @param {SpeedyPipelineNodeKeypointPortalSink|null} node
                 */
                set source(node) {
                  if (node !== null && !(node instanceof SpeedyPipelineNodeKeypointPortalSink)) throw new utils_errors.qw(`Incompatible source for ${this.fullName}`);
                  this._source = node;
                }
                /**
                 * Run the specific task of this node
                 * @param {SpeedyGPU} gpu
                 * @returns {void|SpeedyPromise<void>}
                 */
                _run(gpu2) {
                  if (this._source == null) throw new utils_errors.Er(`${this.fullName} has no source`);
                  this.output().swrite(this._source.encodedKeypoints, this._source.descriptorSize, this._source.extraSize, this._source.encoderLength);
                }
              }
              ;
              class SpeedyPipelineKeypointDetectorFactory extends speedy_namespace.Q {
                /**
                 * FAST corner detector
                 * @param {string} [name]
                 * @returns {SpeedyPipelineNodeFASTKeypointDetector}
                 */
                static FAST(name = void 0) {
                  return new SpeedyPipelineNodeFASTKeypointDetector(name);
                }
                /**
                 * Harris corner detector
                 * @param {string} [name]
                 * @returns {SpeedyPipelineNodeHarrisKeypointDetector}
                 */
                static Harris(name = void 0) {
                  return new SpeedyPipelineNodeHarrisKeypointDetector(name);
                }
              }
              class SpeedyPipelineKeypointDescriptorFactory extends speedy_namespace.Q {
                /**
                 * ORB descriptors
                 * @param {string} [name]
                 * @returns {SpeedyPipelineNodeORBKeypointDescriptor}
                 */
                static ORB(name = void 0) {
                  return new SpeedyPipelineNodeORBKeypointDescriptor(name);
                }
              }
              class SpeedyPipelineKeypointTrackerFactory extends speedy_namespace.Q {
                /**
                 * LK optical-flow
                 * @param {string} [name]
                 * @returns {SpeedyPipelineNodeLKKeypointTracker}
                 */
                static LK(name = void 0) {
                  return new SpeedyPipelineNodeLKKeypointTracker(name);
                }
              }
              class SpeedyPipelineKeypointMatcherFactory extends speedy_namespace.Q {
                /**
                 * Static LSH tables
                 * @param {string} [name]
                 * @returns {SpeedyPipelineNodeStaticLSHTables}
                 */
                static StaticLSHTables(name = void 0) {
                  return new SpeedyPipelineNodeStaticLSHTables(name);
                }
                /**
                 * LSH-based K-approximate nearest neighbors
                 * @param {string} [name]
                 * @returns {SpeedyPipelineNodeLSHKNNKeypointMatcher}
                 */
                static LSHKNN(name = void 0) {
                  return new SpeedyPipelineNodeLSHKNNKeypointMatcher(name);
                }
                /**
                 * Brute-force K-nearest neighbors keypoint matcher
                 * @param {string} [name]
                 * @returns {SpeedyPipelineNodeBruteForceKNNKeypointMatcher}
                 */
                static BFKNN(name = void 0) {
                  return new SpeedyPipelineNodeBruteForceKNNKeypointMatcher(name);
                }
              }
              class SpeedyPipelineKeypointPortalFactory extends speedy_namespace.Q {
                /**
                 * Create an image portal source
                 * @param {string} [name] name of the node
                 * @returns {SpeedyPipelineNodeKeypointPortalSource}
                 */
                static Source(name = void 0) {
                  return new SpeedyPipelineNodeKeypointPortalSource(name);
                }
                /**
                 * Create an image portal sink
                 * @param {string} [name] name of the node
                 * @returns {SpeedyPipelineNodeKeypointPortalSink}
                 */
                static Sink(name = void 0) {
                  return new SpeedyPipelineNodeKeypointPortalSink(name);
                }
              }
              class SpeedyPipelineKeypointFactory extends speedy_namespace.Q {
                /**
                 * Keypoint detectors
                 * @returns {typeof SpeedyPipelineKeypointDetectorFactory}
                 */
                static get Detector() {
                  return SpeedyPipelineKeypointDetectorFactory;
                }
                /**
                 * Keypoint descriptors
                 * @returns {typeof SpeedyPipelineKeypointDescriptorFactory}
                 */
                static get Descriptor() {
                  return SpeedyPipelineKeypointDescriptorFactory;
                }
                /**
                 * Keypoint trackers
                 * @returns {typeof SpeedyPipelineKeypointTrackerFactory}
                 */
                static get Tracker() {
                  return SpeedyPipelineKeypointTrackerFactory;
                }
                /**
                 * Keypoint matchers
                 * @returns {typeof SpeedyPipelineKeypointMatcherFactory}
                 */
                static get Matcher() {
                  return SpeedyPipelineKeypointMatcherFactory;
                }
                /**
                 * Keypoint Portals
                 * @returns {typeof SpeedyPipelineKeypointPortalFactory}
                 */
                static get Portal() {
                  return SpeedyPipelineKeypointPortalFactory;
                }
                /**
                 * Create a keypoint source
                 * @param {string} [name]
                 * @returns {SpeedyPipelineNodeKeypointSource}
                 */
                static Source(name = void 0) {
                  return new SpeedyPipelineNodeKeypointSource(name);
                }
                /**
                 * Create a keypoint sink
                 * @param {string} [name]
                 * @returns {SpeedyPipelineNodeKeypointSink}
                 */
                static Sink(name = void 0) {
                  return new SpeedyPipelineNodeKeypointSink(name);
                }
                /**
                 * Create a sink of tracked keypoints
                 * @param {string} [name]
                 * @returns {SpeedyPipelineNodeTrackedKeypointSink}
                 */
                static SinkOfTrackedKeypoints(name = void 0) {
                  return new SpeedyPipelineNodeTrackedKeypointSink(name);
                }
                /**
                 * Create a sink of matched keypoints
                 * @param {string} [name]
                 * @returns {SpeedyPipelineNodeMatchedKeypointSink}
                 */
                static SinkOfMatchedKeypoints(name = void 0) {
                  return new SpeedyPipelineNodeMatchedKeypointSink(name);
                }
                /**
                 * Keypoint clipper
                 * @param {string} [name]
                 * @returns {SpeedyPipelineNodeKeypointClipper}
                 */
                static Clipper(name = void 0) {
                  return new SpeedyPipelineNodeKeypointClipper(name);
                }
                /**
                 * Border Clipper
                 * @param {string} [name]
                 * @returns {SpeedyPipelineNodeKeypointBorderClipper}
                 */
                static BorderClipper(name = void 0) {
                  return new SpeedyPipelineNodeKeypointBorderClipper(name);
                }
                /**
                 * Create a keypoint buffer
                 * @param {string} [name]
                 * @returns {SpeedyPipelineNodeKeypointBuffer}
                 */
                static Buffer(name = void 0) {
                  return new SpeedyPipelineNodeKeypointBuffer(name);
                }
                /**
                 * Create a keypoint mixer
                 * @param {string} [name]
                 * @returns {SpeedyPipelineNodeKeypointMixer}
                 */
                static Mixer(name = void 0) {
                  return new SpeedyPipelineNodeKeypointMixer(name);
                }
                /**
                 * Create a keypoint shuffler
                 * @param {string} [name]
                 * @returns {SpeedyPipelineNodeKeypointShuffler}
                 */
                static Shuffler(name = void 0) {
                  return new SpeedyPipelineNodeKeypointShuffler(name);
                }
                /**
                 * Create a keypoint multiplexer
                 * @param {string} [name]
                 * @returns {SpeedyPipelineNodeKeypointMultiplexer}
                 */
                static Multiplexer(name = void 0) {
                  return new SpeedyPipelineNodeKeypointMultiplexer(name);
                }
                /**
                 * Create a keypoint transformer
                 * @param {string} [name]
                 * @returns {SpeedyPipelineNodeKeypointTransformer}
                 */
                static Transformer(name = void 0) {
                  return new SpeedyPipelineNodeKeypointTransformer(name);
                }
                /**
                 * Create a subpixel refiner of keypoint locations
                 * @param {string} [name]
                 * @returns {SpeedyPipelineNodeKeypointSubpixelRefiner}
                 */
                static SubpixelRefiner(name = void 0) {
                  return new SpeedyPipelineNodeKeypointSubpixelRefiner(name);
                }
                /**
                 * Distance filter
                 * @param {string} [name]
                 * @returns {SpeedyPipelineNodeDistanceFilter}
                 */
                static DistanceFilter(name = void 0) {
                  return new SpeedyPipelineNodeKeypointDistanceFilter(name);
                }
                /**
                 * Hamming distance filter
                 * @param {string} [name]
                 * @returns {SpeedyPipelineNodeHammingDistanceFilter}
                 */
                static HammingDistanceFilter(name = void 0) {
                  return new SpeedyPipelineNodeKeypointHammingDistanceFilter(name);
                }
              }
              ;
              const vector2_sink_nextPot = (x) => x > 1 ? 1 << Math.ceil(Math.log2(x)) : 1;
              class SpeedyPipelineNodeVector2Sink extends SpeedyPipelineSinkNode {
                /**
                 * Constructor
                 * @param {string} [name] name of the node
                 */
                constructor(name = "vec2") {
                  super(name, 2, [InputPort().expects(SpeedyPipelineMessageType.Vector2)]);
                  this._vectors = [];
                  this._textureReader = new SpeedyTextureReader();
                  this._page = 0;
                  this._turbo = false;
                }
                /**
                 * Accelerate GPU-CPU transfers
                 * @returns {boolean}
                 */
                get turbo() {
                  return this._turbo;
                }
                /**
                 * Accelerate GPU-CPU transfers
                 * @param {boolean} value
                 */
                set turbo(value) {
                  this._turbo = Boolean(value);
                }
                /**
                 * Initializes this node
                 * @param {SpeedyGPU} gpu
                 */
                init(gpu2) {
                  super.init(gpu2);
                  this._textureReader.init(gpu2);
                }
                /**
                 * Releases this node
                 * @param {SpeedyGPU} gpu
                 */
                release(gpu2) {
                  this._textureReader.release(gpu2);
                  super.release(gpu2);
                }
                /**
                 * Export data from this node to the user
                 * @returns {SpeedyPromise<SpeedyVector2[]>}
                 */
                export() {
                  return speedy_promise.i.resolve(this._vectors);
                }
                /**
                 * Run the specific task of this node
                 * @param {SpeedyGPU} gpu
                 * @returns {void|SpeedyPromise<void>}
                 */
                _run(gpu2) {
                  const {
                    vectors
                  } = (
                    /** @type {SpeedyPipelineMessageWith2DVectors} */
                    this.input().read()
                  );
                  const useBufferedDownloads = this._turbo;
                  const encoderLength = vectors.width;
                  const encoderWidth = vector2_sink_nextPot(encoderLength);
                  const encoderHeight = vector2_sink_nextPot(Math.ceil(encoderLength * encoderLength / encoderWidth));
                  const copiedTexture = this._tex[this._page];
                  gpu2.programs.utils.copy2DVectors.outputs(encoderWidth, encoderHeight, copiedTexture)(vectors);
                  this._page = 1 - this._page;
                  return this._textureReader.readPixelsAsync(copiedTexture, 0, 0, copiedTexture.width, copiedTexture.height, useBufferedDownloads).then((pixels) => {
                    this._vectors = SpeedyPipelineNodeVector2Sink._decode(pixels, encoderWidth, encoderHeight);
                  });
                }
                /**
                 * Decode a sequence of vectors, given a flattened image of encoded pixels
                 * @param {Uint8Array} pixels pixels in the [r,g,b,a,...] format
                 * @param {number} encoderWidth
                 * @param {number} encoderHeight
                 * @returns {SpeedyVector2[]} vectors
                 */
                static _decode(pixels, encoderWidth, encoderHeight) {
                  const bytesPerVector = 4;
                  const vectors = [];
                  let hi = 0, lo = 0;
                  let x = 0, y = 0;
                  const e2 = encoderWidth * encoderHeight * bytesPerVector;
                  const size = Math.min(pixels.length, e2);
                  for (let i = 0; i < size; i += bytesPerVector) {
                    lo = pixels[i + 1] << 8 | pixels[i];
                    hi = pixels[i + 3] << 8 | pixels[i + 2];
                    if (lo == 65535 && hi == 65535) break;
                    if (lo == 65280 && hi == 65280) continue;
                    x = utils.A.decodeFloat16(lo);
                    y = utils.A.decodeFloat16(hi);
                    vectors.push(new SpeedyVector2(x, y));
                  }
                  return vectors;
                }
              }
              ;
              class SpeedyPipelineVector2Factory extends Function {
                /**
                 * Constructor
                 */
                constructor() {
                  super("...args", "return this._create(...args)");
                  return this.bind(this);
                }
                /**
                 * @private
                 *
                 * Create a 2D vector
                 * @param {number} x x-coordinate
                 * @param {number} y y-coordinate
                 * @returns {SpeedyVector2}
                 */
                _create(x, y) {
                  return new SpeedyVector2(x, y);
                }
                /**
                 * Create a Vector2 sink
                 * @param {string} [name]
                 * @returns {SpeedyPipelineNodeVector2Sink}
                 */
                Sink(name = void 0) {
                  return new SpeedyPipelineNodeVector2Sink(name);
                }
              }
              ;
              const UPDATE_INTERVAL3 = 500;
              let instance = null;
              class FPSCounter {
                /**
                 * Creates a new FPSCounter
                 * @private
                 */
                constructor() {
                  this._fps = 60;
                  this._frames = 0;
                  this._updateInterval = UPDATE_INTERVAL3;
                  this._lastUpdate = performance.now();
                  this._boundUpdate = this._update.bind(this);
                  if (instance !== null) throw new utils_errors.Er(`Can't have multiple instances of FPSCounter`);
                  this._boundUpdate();
                }
                /**
                 * Gets an instance of the FPS counter.
                 * We use lazy loading, i.e., we will not
                 * create a FPS counter unless we need to!
                 * @returns {FPSCounter}
                 */
                static get instance() {
                  if (instance === null) instance = new FPSCounter();
                  return instance;
                }
                /**
                 * Get the FPS rate
                 * @returns {number} frames per second
                 */
                get fps() {
                  return this._fps;
                }
                /**
                 * Updates the FPS counter
                 */
                _update() {
                  const now = performance.now();
                  const deltaTime = now - this._lastUpdate;
                  if (deltaTime >= this._updateInterval) {
                    this._fps = Math.round(this._frames / (deltaTime * 1e-3));
                    this._frames = 0;
                    this._lastUpdate = now;
                  }
                  this._frames++;
                  requestAnimationFrame(this._boundUpdate);
                }
              }
              ;
              const matrixFactory = new SpeedyMatrixFactory();
              const vector2Factory = new SpeedyPipelineVector2Factory();
              class Speedy29 {
                /**
                 * The version of the library
                 * @returns {string}
                 */
                static get version() {
                  if (false) {
                  } else return "0.9.1";
                }
                /**
                 * Checks if Speedy can be executed in this machine & browser
                 * @returns {boolean}
                 */
                static isSupported() {
                  return typeof WebAssembly !== "undefined" && typeof WebGL2RenderingContext !== "undefined" && speedy_gl.c.instance.gl != null;
                }
                /**
                 * Global settings
                 * @returns {typeof Settings}
                 */
                static get Settings() {
                  return settings.w;
                }
                /**
                 * Create a 2D vector
                 * @returns {SpeedyPipelineVector2Factory & ((x: number, y: number) => SpeedyVector2)}
                 */
                static get Vector2() {
                  return vector2Factory;
                }
                /**
                 * Create a 2D point
                 * @param {number} x
                 * @param {number} y
                 * @returns {SpeedyPoint2}
                 */
                static Point2(x, y) {
                  return new SpeedyPoint2(x, y);
                }
                /**
                 * Create a new size object
                 * @param {number} width
                 * @param {number} height
                 * @returns {SpeedySize}
                 */
                static Size(width, height) {
                  return new SpeedySize(width, height);
                }
                /**
                 * Create a Matrix (entries are given in column-major format)
                 * @returns {SpeedyMatrixFactory & ((rows: number, columns: number, entries: number[]) => SpeedyMatrix) & ((expr: SpeedyMatrixExpr) => SpeedyMatrix)}
                 */
                static get Matrix() {
                  return matrixFactory;
                }
                /**
                 * Speedy Promises
                 * @returns {typeof SpeedyPromise}
                 */
                static get Promise() {
                  return speedy_promise.i;
                }
                /**
                 * Create a new Pipeline
                 * @returns {SpeedyPipeline}
                 */
                static Pipeline() {
                  return new SpeedyPipeline();
                }
                /**
                 * Image-related nodes
                 * @returns {typeof SpeedyPipelineImageFactory}
                 */
                static get Image() {
                  return SpeedyPipelineImageFactory;
                }
                /**
                 * Image filters
                 * @returns {typeof SpeedyPipelineFilterFactory}
                 */
                static get Filter() {
                  return SpeedyPipelineFilterFactory;
                }
                /**
                 * Image transforms
                 * @returns {typeof SpeedyPipelineTransformFactory}
                 */
                static get Transform() {
                  return SpeedyPipelineTransformFactory;
                }
                /**
                 * Keypoint-related nodes
                 * @returns {typeof SpeedyPipelineKeypointFactory}
                 */
                static get Keypoint() {
                  return SpeedyPipelineKeypointFactory;
                }
                /**
                 * Loads a SpeedyMedia object based on the provided source element
                 * @param {SpeedyMediaSourceNativeElement} sourceElement The source media
                 * @param {SpeedyMediaOptions} [options] Additional options for advanced configuration
                 * @returns {SpeedyPromise<SpeedyMedia>}
                 */
                static load(sourceElement, options = {}) {
                  return SpeedyMedia.load(sourceElement, options);
                }
                /**
                 * Loads a camera stream
                 * @param {number | MediaStreamConstraints} [widthOrConstraints] width of the stream or contraints object
                 * @param {number} [height] height of the stream
                 * @returns {SpeedyPromise<SpeedyMedia>}
                 */
                static camera(widthOrConstraints = 640, height = 360) {
                  const constraints = typeof widthOrConstraints === "object" ? widthOrConstraints : {
                    audio: false,
                    video: {
                      width: widthOrConstraints | 0,
                      height: height | 0
                    }
                  };
                  return utils.A.requestCameraStream(constraints).then((video) => SpeedyMedia.load(video));
                }
                /**
                 * Utilities to query information about the graphics driver
                 * @returns {typeof SpeedyPlatform}
                 */
                static get Platform() {
                  return SpeedyPlatform;
                }
                /**
                 * The FPS rate
                 * @returns {number} Frames per second (FPS)
                 */
                static get fps() {
                  return FPSCounter.instance.fps;
                }
              }
              Object.freeze(Speedy29);
              utils.A.log(`Speedy Vision version ${Speedy29.version}. GPU-accelerated Computer Vision for JavaScript by Alexandre Martins. https://github.com/alemart/speedy-vision`);
              if (!globals.LITTLE_ENDIAN) utils.A.warning("Running on a big-endian machine");
            })();
            __webpack_exports__ = __webpack_exports__["default"];
            return __webpack_exports__;
          })()
        );
      });
    }
  });

  // src/utils/errors.ts
  var ARError, IllegalArgumentError, IllegalOperationError, NotSupportedError, AccessDeniedError, TimeoutError, AssertionError, NumericalError, TrackingError, DetectionError, TrainingError;
  var init_errors = __esm({
    "src/utils/errors.ts"() {
      "use strict";
      ARError = class extends Error {
        /**
         * Constructor
         * @param message error message
         * @param cause cause of the error
         */
        constructor(message = "", cause = null) {
          super(message);
          this.cause = cause;
        }
        /*{
            // incorrect when minified
            //return this.constructor.name;
        }*/
        /**
         * Convert to string
         */
        toString() {
          const extendedMessage = this.cause ? "\n-> " + this.cause.toString() : "";
          if (this.message != "")
            return this.name + ": " + this.message + extendedMessage;
          else
            return this.name + extendedMessage;
        }
      };
      IllegalArgumentError = class extends ARError {
        get name() {
          return "IllegalArgumentError";
        }
      };
      IllegalOperationError = class extends ARError {
        get name() {
          return "IllegalOperationError";
        }
      };
      NotSupportedError = class extends ARError {
        get name() {
          return "NotSupportedError";
        }
      };
      AccessDeniedError = class extends ARError {
        get name() {
          return "AccessDeniedError";
        }
      };
      TimeoutError = class extends ARError {
        get name() {
          return "TimeoutError";
        }
      };
      AssertionError = class extends ARError {
        get name() {
          return "AssertionError";
        }
      };
      NumericalError = class extends ARError {
        get name() {
          return "NumericalError";
        }
      };
      TrackingError = class extends ARError {
        get name() {
          return "TrackingError";
        }
      };
      DetectionError = class extends ARError {
        get name() {
          return "DetectionError";
        }
      };
      TrainingError = class extends ARError {
        get name() {
          return "TrainingError";
        }
      };
    }
  });

  // src/utils/resolution.ts
  function computeResolution(resolution, aspectRatio) {
    const referenceHeight = parseHeight(resolution);
    let width = 0, height = 0;
    if (Number.isNaN(referenceHeight))
      throw new IllegalArgumentError("Invalid resolution: " + resolution);
    else if (aspectRatio <= 0)
      throw new IllegalArgumentError("Invalid aspect ratio: " + aspectRatio);
    if (aspectRatio >= 1) {
      height = referenceHeight;
      width = Math.floor(height * aspectRatio);
      width += width % 2;
    } else {
      width = referenceHeight;
      height = Math.floor(width / aspectRatio);
      height += height % 2;
    }
    return import_speedy_vision.default.Size(width, height);
  }
  function parseHeight(resolution) {
    if (ALIAS_TO_HEIGHT.hasOwnProperty(resolution))
      return ALIAS_TO_HEIGHT[resolution];
    if (resolution.endsWith("p")) {
      const r = resolution[0];
      if (r >= "1" && r <= "9")
        return parseInt(resolution);
    }
    return Number.NaN;
  }
  var import_speedy_vision, ALIAS_TO_HEIGHT;
  var init_resolution = __esm({
    "src/utils/resolution.ts"() {
      "use strict";
      import_speedy_vision = __toESM(require_speedy_vision(), 1);
      init_errors();
      ALIAS_TO_HEIGHT = {
        "xs": 120,
        "xs+": 144,
        "sm": 240,
        "sm+": 288,
        "md": 320,
        "md+": 360,
        "lg": 480,
        "lg+": 600,
        "xl": 720,
        "xl+": 900,
        "xxl": 1080
      };
    }
  });

  // src/utils/utils.ts
  var import_speedy_vision2, Utils;
  var init_utils = __esm({
    "src/utils/utils.ts"() {
      "use strict";
      import_speedy_vision2 = __toESM(require_speedy_vision(), 1);
      init_errors();
      init_resolution();
      Utils = class _Utils {
        /**
         * Log a message
         * @param message
         * @param args optional additional messages
         */
        static log(message, ...args2) {
          console.log("[encantar-js]", message, ...args2);
        }
        /**
         * Display a warning
         * @param message
         * @param args optional additional messages
         */
        static warning(message, ...args2) {
          console.warn("[encantar-js]", message, ...args2);
        }
        /**
         * Display an error message
         * @param message
         * @param args optional additional messages
         */
        static error(message, ...args2) {
          console.error("[encantar-js]", message, ...args2);
        }
        /**
         * Assertion
         * @param expr expression
         * @param errorMessage optional error message
         * @throws {AssertionError}
         */
        static assert(expr, errorMessage = "") {
          if (!expr)
            throw new AssertionError(errorMessage);
        }
        /**
         * Returns a range [0, 1, ..., n-1]
         * @param n non-negative integer
         * @returns range from 0 to n-1, inclusive
         */
        static range(n) {
          if ((n |= 0) < 0)
            throw new IllegalArgumentError();
          return Array.from({ length: n }, (_, i) => i);
        }
        /**
         * Wait a few milliseconds
         * @param milliseconds how long should we wait?
         * @returns a promise that is resolved soon after the specified time
         */
        static wait(milliseconds) {
          return new import_speedy_vision2.default.Promise((resolve) => {
            setTimeout(resolve, milliseconds);
          });
        }
        /**
         * Run SpeedyPromises sequentially
         * @param promises an array of SpeedyPromises
         * @returns a promise that is resolved as soon as all input promises are
         * resolved, or that is rejected as soon as an input promise is rejected
         */
        static runInSequence(promises) {
          return promises.reduce(
            (prev, curr) => prev.then(() => curr),
            import_speedy_vision2.default.Promise.resolve()
          );
        }
        /**
         * Convert a resolution type to a resolution measured in pixels
         * @param resolution resolution type
         * @param aspectRatio width / height ratio
         * @returns resolution measured in pixels
         */
        static resolution(resolution, aspectRatio) {
          return computeResolution(resolution, aspectRatio);
        }
        /**
         * Returns a string containing platform brand information
         * @returns platform brand information
         */
        static platformString() {
          return ((navigator2) => typeof navigator2.userAgentData === "object" ? (
            // prefer the NavigatorUAData interface
            navigator2.userAgentData.platform
          ) : (
            // use only low entropy data
            navigator2.platform
          ))(navigator);
        }
        /**
         * Checks if we're on iOS
         * @returns true if we're on iOS
         */
        static isIOS() {
          if (/(iOS|iPhone|iPad|iPod)/i.test(navigator.platform))
            return true;
          if (/Mac/i.test(navigator.platform) && navigator.maxTouchPoints !== void 0)
            return navigator.maxTouchPoints > 2;
          return false;
        }
        /**
         * Checks if we're on a WebKit-based browser
         * @returns true if we're on a WebKit-based browser
         */
        static isWebKit() {
          if (/Apple/.test(navigator.vendor))
            return true;
          if (/AppleWebKit\/.* Version\//.test(navigator.userAgent))
            return true;
          if (/(CriOS\/|FxiOS\/|EdgiOS\/)/.test(navigator.userAgent))
            return true;
          return false;
        }
        /**
         * Device-specific information for debugging purposes
         */
        static deviceInfo() {
          return "Device info: " + JSON.stringify({
            isIOS: _Utils.isIOS(),
            isWebKit: _Utils.isWebKit(),
            renderer: import_speedy_vision2.default.Platform.renderer,
            vendor: import_speedy_vision2.default.Platform.vendor,
            screen: [screen.width, screen.height].join("x"),
            platform: [navigator.platform, navigator.vendor].join("; "),
            userAgent: navigator.userAgent,
            userAgentData: navigator.userAgentData || null
          }, null, 2);
        }
      };
    }
  });

  // src/utils/ar-events.ts
  var AREvent, AREventTarget;
  var init_ar_events = __esm({
    "src/utils/ar-events.ts"() {
      "use strict";
      AREvent = class extends Event {
        /**
         * Constructor
         * @param type event type
         */
        constructor(type) {
          super(type);
        }
        /**
         * Event type
         */
        get type() {
          return super.type;
        }
      };
      AREventTarget = class {
        /**
         * Constructor
         */
        constructor() {
          this._delegate = new EventTarget();
        }
        /**
         * Add event listener
         * @param type event type
         * @param callback
         */
        addEventListener(type, callback) {
          this._delegate.addEventListener(type, callback);
        }
        /**
         * Remove event listener
         * @param type event type
         * @param callback
         */
        removeEventListener(type, callback) {
          this._delegate.removeEventListener(type, callback);
        }
        /**
         * Synchronously trigger an event
         * @param event
         * @returns same value as a standard event target
         * @internal
         */
        dispatchEvent(event) {
          return this._delegate.dispatchEvent(event);
        }
      };
    }
  });

  // src/core/stats.ts
  var UPDATE_INTERVAL, Stats;
  var init_stats = __esm({
    "src/core/stats.ts"() {
      "use strict";
      UPDATE_INTERVAL = 0.5;
      Stats = class {
        /**
         * Constructor
         */
        constructor() {
          this._timeOfLastUpdate = this._now();
          this._partialCycleCount = 0;
          this._cyclesPerSecond = 0;
        }
        /**
         * Update stats - call every frame
         */
        update() {
          const now = this._now();
          ++this._partialCycleCount;
          if (now >= this._timeOfLastUpdate + 1e3 * UPDATE_INTERVAL) {
            this._cyclesPerSecond = this._partialCycleCount / UPDATE_INTERVAL;
            this._partialCycleCount = 0;
            this._timeOfLastUpdate = now;
          }
        }
        /**
         * Reset stats
         */
        reset() {
          this._timeOfLastUpdate = this._now();
          this._partialCycleCount = 0;
          this._cyclesPerSecond = 0;
        }
        /**
         * Number of cycles per second
         */
        get cyclesPerSecond() {
          return this._cyclesPerSecond;
        }
        /**
         * A measurement of time, in milliseconds
         * @returns time in ms
         */
        _now() {
          return performance.now();
        }
      };
    }
  });

  // src/ui/stats-panel.ts
  var UPDATE_INTERVAL2, POWER_ICON, BUTTON_ICONS, StatsPanel;
  var init_stats_panel = __esm({
    "src/ui/stats-panel.ts"() {
      "use strict";
      init_settings2();
      init_main();
      UPDATE_INTERVAL2 = 500;
      POWER_ICON = Object.freeze({
        "default": "",
        "low-power": "&#x1F50B",
        "high-performance": "&#x26A1"
      });
      BUTTON_ICONS = "data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAACAAAAAQCAYAAAB3AH1ZAAAAVUlEQVRIS2NkGGDAOMD2M4w6YDQE8IbAfyBgBAJSEipIDy712MzCaTiyQdRwBC4zsDoAmy8ocQQ+vRgOIDUI8UUPMVFIUvySkhaIVTvqgNEQGPAQAABSNiARgz5LggAAAABJRU5ErkJggg==";
      StatsPanel = class {
        /**
         * Constructor
         * @param viewport Viewport
         */
        constructor(viewport) {
          this._viewport = viewport;
          this._lastUpdate = 0;
          this._container = this._createContainer();
          viewport.hud.container.appendChild(this._container);
        }
        /**
         * Release the panel
         */
        release() {
          this._container.remove();
        }
        /**
         * A method to be called in the update loop
         * @param time current time in ms
         * @param sources the sources of media linked to the session
         * @param trackers the trackers attached to the session
         * @param viewport the viewport
         * @param gpu GPU cycles per second
         * @param fps frames per second
         */
        update(time, sources, trackers, viewport, gpu, fps) {
          if (time >= this._lastUpdate + UPDATE_INTERVAL2) {
            this._lastUpdate = time;
            this._update(sources, trackers, viewport, fps, gpu);
          }
        }
        /**
         * Visibility of the panel
         */
        get visible() {
          return !this._container.hidden;
        }
        /**
         * Visibility of the panel
         */
        set visible(visible) {
          this._container.hidden = !visible;
        }
        /**
         * Update the contents of the panel
         * @param sources the sources of media linked to the session
         * @param trackers the trackers attached to the session
         * @param viewport the viewport
         * @param fps frames per second
         * @param gpu GPU cycles per second
         */
        _update(sources, trackers, viewport, fps, gpu) {
          const lfps = this._label("_ar_fps");
          if (lfps !== null) {
            lfps.style.color = this._color(fps);
            lfps.innerText = String(fps);
          }
          const lgpu = this._label("_ar_gpu");
          if (lgpu !== null) {
            lgpu.style.color = this._color(gpu);
            lgpu.innerText = String(gpu);
          }
          const lpower = this._label("_ar_power");
          if (lpower !== null)
            lpower.innerHTML = POWER_ICON[Settings.powerPreference];
          const lin = this._label("_ar_in");
          if (lin !== null) {
            const sourceStats = sources.map((source) => source._stats).join(", ");
            lin.innerText = sourceStats;
          }
          const lout = this._label("_ar_out");
          if (lout !== null) {
            const trackerStats = trackers.map((tracker) => tracker._stats).join(", ");
            lout.innerText = trackerStats;
          }
          const lview = this._label("_ar_view");
          if (lview !== null) {
            const size = viewport.virtualSize;
            lview.innerText = `${size.width}x${size.height} rendering`;
          }
        }
        /**
         * Get a label of the panel
         * @param className
         * @returns the HTML element, or null if it doesn't exist
         */
        _label(className) {
          return this._container.getElementsByClassName(className).item(0);
        }
        /**
         * Associate a color to a frequency number
         * @param f frequency given in cycles per second
         * @returns colorized number (HTML)
         */
        _color(f) {
          const GREEN = "#0f0", YELLOW = "#ff0", RED = "#f33";
          const color3 = f >= 50 ? GREEN : f >= 30 ? YELLOW : RED;
          const color2 = f >= 30 ? GREEN : RED;
          const color = Settings.powerPreference != "low-power" ? color3 : color2;
          return color;
        }
        /**
         * Create the container for the panel
         * @returns a container
         */
        _createContainer() {
          const container = document.createElement("div");
          container.style.position = "absolute";
          container.style.left = container.style.top = "0px";
          container.style.zIndex = "1000000";
          container.style.padding = "0px";
          container.appendChild(this._createTitle());
          container.appendChild(this._createContent());
          return container;
        }
        /**
         * Create a title
         * @returns a title
         */
        _createTitle() {
          const title = document.createElement("div");
          const button = document.createElement("button");
          title.style.display = "flex";
          title.style.backgroundColor = "#7e56c2";
          title.style.color = "white";
          title.style.fontFamily = "monospace";
          title.style.fontSize = "14px";
          title.style.fontWeight = "bold";
          title.style.paddingRight = "4px";
          title.innerText = "encantar.js " + AR.version;
          button.style.width = "18px";
          button.style.height = "18px";
          button.style.marginRight = "4px";
          button.style.backgroundColor = "#7e56c2";
          button.style.backgroundImage = "url(" + BUTTON_ICONS + ")";
          button.style.backgroundRepeat = "no-repeat";
          button.style.backgroundPosition = "0 0";
          button.style.borderWidth = "2px";
          button.style.borderColor = "#b588fb #46346a #46346a #b588fb";
          title.insertBefore(button, title.firstChild);
          button.addEventListener("click", () => {
            const container = title.parentNode;
            const details = container && container.querySelector("._ar_details");
            if (!details)
              return;
            details.hidden = !details.hidden;
            button.style.backgroundPosition = details.hidden ? "0 0 " : "-16px 0";
          });
          return title;
        }
        /**
         * Create a content container
         * @returns a content container
         */
        _createContent() {
          const content = document.createElement("div");
          const details = document.createElement("div");
          content.style.backgroundColor = "rgba(0,0,0,0.5)";
          content.style.color = "white";
          content.style.fontFamily = "monospace";
          content.style.fontSize = "14px";
          content.style.padding = "2px";
          content.style.whiteSpace = "pre-line";
          details.classList.add("_ar_details");
          details.hidden = true;
          const append = (div, html) => div.insertAdjacentHTML("beforeend", html);
          append(content, 'FPS: <span class="_ar_fps"></span> | ');
          append(content, 'GPU: <span class="_ar_gpu"></span> ');
          append(content, '<span class="_ar_power"></span>');
          append(details, 'IN: <span class="_ar_in"></span><br>');
          append(details, 'OUT: <span class="_ar_out"></span><br>');
          append(details, 'VIEW: <span class="_ar_view"></span>');
          content.appendChild(details);
          return content;
        }
      };
    }
  });

  // src/trackers/image-tracker/settings.ts
  var TRAIN_MAX_KEYPOINTS, TRAIN_IMAGE_SCALE, NIS_SIZE, SCAN_MATCH_RATIO, SCAN_MAX_KEYPOINTS, SCAN_PYRAMID_LEVELS, SCAN_PYRAMID_SCALEFACTOR, SCAN_FAST_THRESHOLD, SCAN_MIN_MATCHES, SCAN_CONSECUTIVE_FRAMES, SCAN_RANSAC_REPROJECTIONERROR_NIS, SCAN_RANSAC_REPROJECTIONERROR_NDC, SCAN_LSH_TABLES, SCAN_LSH_HASHSIZE, SCAN_WITH_NIGHTVISION, NIGHTVISION_GAIN, NIGHTVISION_OFFSET, NIGHTVISION_DECAY, NIGHTVISION_QUALITY, ORB_GAUSSIAN_KSIZE, ORB_GAUSSIAN_SIGMA, SUBPIXEL_GAUSSIAN_KSIZE, SUBPIXEL_GAUSSIAN_SIGMA, SUBPIXEL_METHOD, PRE_TRACK_MIN_MATCHES, PRE_TRACK_MAX_ITERATIONS, PRE_TRACK_RANSAC_REPROJECTIONERROR_NIS, PRE_TRACK_RANSAC_REPROJECTIONERROR_NDC, TRACK_MIN_MATCHES, TRACK_MAX_KEYPOINTS, TRACK_DETECTOR_CAPACITY, TRACK_HARRIS_QUALITY, TRACK_WITH_NIGHTVISION, TRACK_RECTIFIED_BORDER, TRACK_CLIPPING_BORDER, TRACK_RECTIFIED_SCALE, TRACK_RANSAC_REPROJECTIONERROR_NIS, TRACK_RANSAC_REPROJECTIONERROR_NDC, TRACK_GRID_GRANULARITY, TRACK_MATCH_RATIO, TRACK_LOST_TOLERANCE;
  var init_settings = __esm({
    "src/trackers/image-tracker/settings.ts"() {
      "use strict";
      TRAIN_MAX_KEYPOINTS = 1024;
      TRAIN_IMAGE_SCALE = 0.8;
      NIS_SIZE = 1024;
      SCAN_MATCH_RATIO = 0.7;
      SCAN_MAX_KEYPOINTS = 512;
      SCAN_PYRAMID_LEVELS = 4;
      SCAN_PYRAMID_SCALEFACTOR = 1.19;
      SCAN_FAST_THRESHOLD = 60;
      SCAN_MIN_MATCHES = 20;
      SCAN_CONSECUTIVE_FRAMES = 30;
      SCAN_RANSAC_REPROJECTIONERROR_NIS = NIS_SIZE * 0.0125 | 0;
      SCAN_RANSAC_REPROJECTIONERROR_NDC = SCAN_RANSAC_REPROJECTIONERROR_NIS / (NIS_SIZE / 2);
      SCAN_LSH_TABLES = 8;
      SCAN_LSH_HASHSIZE = 15;
      SCAN_WITH_NIGHTVISION = true;
      NIGHTVISION_GAIN = 0.3;
      NIGHTVISION_OFFSET = 0.5;
      NIGHTVISION_DECAY = 0;
      NIGHTVISION_QUALITY = "low";
      ORB_GAUSSIAN_KSIZE = 9;
      ORB_GAUSSIAN_SIGMA = 2;
      SUBPIXEL_GAUSSIAN_KSIZE = 5;
      SUBPIXEL_GAUSSIAN_SIGMA = 1;
      SUBPIXEL_METHOD = "bilinear-upsample";
      PRE_TRACK_MIN_MATCHES = 4;
      PRE_TRACK_MAX_ITERATIONS = 3;
      PRE_TRACK_RANSAC_REPROJECTIONERROR_NIS = NIS_SIZE * 0.0125 * 0.5 | 0;
      PRE_TRACK_RANSAC_REPROJECTIONERROR_NDC = PRE_TRACK_RANSAC_REPROJECTIONERROR_NIS / (NIS_SIZE / 2);
      TRACK_MIN_MATCHES = 4;
      TRACK_MAX_KEYPOINTS = 200;
      TRACK_DETECTOR_CAPACITY = 2048;
      TRACK_HARRIS_QUALITY = 5e-3;
      TRACK_WITH_NIGHTVISION = false;
      TRACK_RECTIFIED_BORDER = 0.15;
      TRACK_CLIPPING_BORDER = TRACK_RECTIFIED_BORDER * 1.2;
      TRACK_RECTIFIED_SCALE = 1 - 2 * TRACK_RECTIFIED_BORDER;
      TRACK_RANSAC_REPROJECTIONERROR_NIS = NIS_SIZE * 0.0125 | 0;
      TRACK_RANSAC_REPROJECTIONERROR_NDC = TRACK_RANSAC_REPROJECTIONERROR_NIS / (NIS_SIZE / 2);
      TRACK_GRID_GRANULARITY = 10;
      TRACK_MATCH_RATIO = 0.75;
      TRACK_LOST_TOLERANCE = 15;
    }
  });

  // src/ui/gizmos.ts
  var Gizmos, ImageTrackerGizmos;
  var init_gizmos = __esm({
    "src/ui/gizmos.ts"() {
      "use strict";
      init_settings();
      Gizmos = class {
        /**
         * Constructor
         */
        constructor() {
          this._visible = false;
          this._imageTrackerGizmos = new ImageTrackerGizmos();
        }
        /**
         * Whether or not the gizmos will be rendered
         */
        get visible() {
          return this._visible;
        }
        /**
         * Whether or not the gizmos will be rendered
         */
        set visible(visible) {
          this._visible = visible;
        }
        /**
         * Render gizmos
         * @param viewport
         * @param trackers
         * @internal
         */
        _render(viewport, trackers) {
          if (!this._visible)
            return;
          for (let i = 0; i < trackers.length; i++) {
            if (trackers[i].type == "image-tracker") {
              const output = trackers[i]._output;
              this._imageTrackerGizmos.render(viewport, output);
            }
          }
        }
      };
      ImageTrackerGizmos = class {
        /**
         * Render gizmos
         * @param viewport viewport
         * @param output tracker output
         */
        render(viewport, output) {
          const canvas = viewport._backgroundCanvas;
          const ctx = canvas.getContext("2d", { alpha: false });
          if (!ctx)
            return;
          const viewportSize = viewport._realSize;
          const keypointsNIS = output.keypointsNIS;
          const polylineNDC = output.polylineNDC;
          const camera = output.camera;
          if (keypointsNIS !== void 0)
            this._splitAndRenderKeypointsNIS(ctx, keypointsNIS, viewportSize);
          if (polylineNDC !== void 0)
            this._renderPolylineNDC(ctx, polylineNDC, viewportSize);
          if (camera !== void 0)
            this._renderAxes(ctx, camera, viewportSize);
        }
        /**
         * Split keypoints in matched/unmatched categories and
         * render them for testing & development purposes
         * @param ctx canvas 2D context
         * @param keypoints keypoints in Normalized Image Space (NIS)
         * @param viewportSize viewport size
         * @param size base keypoint rendering size
         */
        _splitAndRenderKeypointsNIS(ctx, keypoints, viewportSize, size = 1) {
          if (keypoints.length == 0)
            return;
          if (!Object.prototype.hasOwnProperty.call(keypoints[0], "_matches")) {
            this._renderKeypointsNIS(ctx, keypoints, viewportSize, "#f00", size);
            return;
          }
          const goodMatches = [], badMatches = [];
          for (let i = 0; i < keypoints.length; i++) {
            const keypoint = keypoints[i];
            if (this._isGoodMatch(keypoint))
              goodMatches.push(keypoint);
            else
              badMatches.push(keypoint);
          }
          this._renderKeypointsNIS(ctx, badMatches, viewportSize, "#f00", size);
          this._renderKeypointsNIS(ctx, goodMatches, viewportSize, "#0f0", size);
        }
        /**
         * Check if a matched keypoint is "good enough"
         * @param keypoint matched keypoint
         * @returns a boolean
         */
        _isGoodMatch(keypoint) {
          const GOOD_MATCH_THRESHOLD = 0.7;
          const n = keypoint.matches.length;
          if (n > 1) {
            return keypoint.matches[0].index >= 0 && keypoint.matches[1].index >= 0 && keypoint.matches[0].distance <= GOOD_MATCH_THRESHOLD * keypoint.matches[1].distance;
          } else if (n == 1)
            return keypoint.matches[0].index >= 0;
          return false;
        }
        /**
         * Render keypoints for testing & development purposes
         * @param ctx canvas 2D context
         * @param keypoints keypoints in Normalized Image Space (NIS)
         * @param viewportSize viewport size
         * @param color color of the rendered keypoints
         * @param size base keypoint rendering size
         */
        _renderKeypointsNIS(ctx, keypoints, viewportSize, color = "red", size = 1) {
          const sx = viewportSize.width / NIS_SIZE;
          const sy = viewportSize.height / NIS_SIZE;
          ctx.beginPath();
          for (let i = keypoints.length - 1; i >= 0; i--) {
            const keypoint = keypoints[i];
            const x = keypoint.x * sx + 0.5 | 0;
            const y = keypoint.y * sy + 0.5 | 0;
            const r = size * keypoint.scale + 0.5 | 0;
            ctx.rect(x - r, y - r, 2 * r, 2 * r);
          }
          ctx.strokeStyle = color;
          ctx.lineWidth = 1;
          ctx.stroke();
        }
        /**
         * Render a polyline for testing & development purposes
         * @param ctx canvas 2D context
         * @param polyline vertices in NDC
         * @param viewportSize viewport size
         * @param color color of the rendered polyline
         * @param lineWidth
         */
        _renderPolylineNDC(ctx, polyline, viewportSize, color = "#0f0", lineWidth = 2) {
          const n = polyline.length;
          const w = viewportSize.width;
          const h = viewportSize.height;
          if (n == 0)
            return;
          ctx.beginPath();
          ctx.moveTo((polyline[n - 1].x * 0.5 + 0.5) * w, (polyline[n - 1].y * -0.5 + 0.5) * h);
          for (let j = 0; j < n; j++)
            ctx.lineTo((polyline[j].x * 0.5 + 0.5) * w, (polyline[j].y * -0.5 + 0.5) * h);
          ctx.strokeStyle = color;
          ctx.lineWidth = lineWidth;
          ctx.stroke();
        }
        /**
         * Render the axes of a 3D coordinate system
         * @param ctx canvas 2D context
         * @param camera camera model
         * @param viewportSize viewport size
         * @param lineWidth
         */
        _renderAxes(ctx, camera, viewportSize, lineWidth = 4) {
          const RED = "#f00", GREEN = "#0f0", BLUE = "#00f";
          const color = [RED, GREEN, BLUE];
          const length = 1;
          const w = viewportSize.width;
          const h = viewportSize.height;
          const iw = 1 / (camera.imageSize.width / 2);
          const ih = -1 / (camera.imageSize.height / 2);
          const p = camera.matrix.read();
          const l = length;
          const o = [p[9], p[10], p[11]];
          const x = [l * p[0] + p[9], l * p[1] + p[10], l * p[2] + p[11]];
          const y = [l * p[3] + p[9], l * p[4] + p[10], l * p[5] + p[11]];
          const z = [l * p[6] + p[9], l * p[7] + p[10], l * p[8] + p[11]];
          const axis = [x, y, z];
          const ox = o[0] / o[2], oy = o[1] / o[2];
          for (let i = 0; i < 3; i++) {
            const q = axis[i];
            const x2 = q[0] / q[2], y2 = q[1] / q[2];
            ctx.beginPath();
            ctx.moveTo((ox * iw * 0.5 + 0.5) * w, (oy * ih * 0.5 + 0.5) * h);
            ctx.lineTo((x2 * iw * 0.5 + 0.5) * w, (y2 * ih * 0.5 + 0.5) * h);
            ctx.strokeStyle = color[i];
            ctx.lineWidth = lineWidth;
            ctx.stroke();
          }
        }
      };
    }
  });

  // src/core/frame.ts
  var Frame;
  var init_frame = __esm({
    "src/core/frame.ts"() {
      "use strict";
      Frame = class {
        /**
         * Constructor
         * @param session
         * @param results
         */
        constructor(session, results) {
          this._session = session;
          this._results = results;
        }
        /**
         * The session of which this frame holds data
         */
        get session() {
          return this._session;
        }
        /**
         * The results of all trackers in this frame
         */
        get results() {
          return this._results[Symbol.iterator]();
        }
      };
    }
  });

  // src/core/time-manager.ts
  var TimeManager;
  var init_time_manager = __esm({
    "src/core/time-manager.ts"() {
      "use strict";
      TimeManager = class {
        constructor() {
          /** time scale */
          this._scale = 1;
          /** time since the start of the session, in milliseconds */
          this._time = 0;
          /** unscaled time since the start of the session, in milliseconds */
          this._unscaledTime = 0;
          /** elapsed time between the current and the previous frame, in milliseconds */
          this._delta = 0;
          /** time of the first update call, in milliseconds */
          this._firstUpdate = 0;
          /** time of the last update call, in milliseconds */
          this._lastUpdate = Number.POSITIVE_INFINITY;
        }
        /**
         * Update the Time Manager
         * @param timestamp in milliseconds
         * @internal
         */
        _update(timestamp) {
          if (timestamp < this._lastUpdate) {
            this._firstUpdate = this._lastUpdate = timestamp;
            return;
          }
          this._delta = (timestamp - this._lastUpdate) * this._scale;
          this._time += this._delta;
          this._unscaledTime = timestamp - this._firstUpdate;
          this._lastUpdate = timestamp;
        }
        /**
         * Elapsed time since the start of the session, measured at the
         * beginning of the current animation frame and given in seconds
         */
        get elapsed() {
          return this._time * 1e-3;
        }
        /**
         * Elapsed time between the current and the previous animation
         * frame, given in seconds
         */
        get delta() {
          return this._delta * 1e-3;
        }
        /**
         * Time scale (defaults to 1)
         */
        get scale() {
          return this._scale;
        }
        /**
         * Time scale (defaults to 1)
         */
        set scale(scale) {
          this._scale = Math.max(0, +scale);
        }
        /**
         * Time scale independent elapsed time since the start of the session,
         * measured at the beginning of the current animation frame and given
         * in seconds
         */
        get unscaled() {
          return this._unscaledTime * 1e-3;
        }
      };
    }
  });

  // src/utils/asap.ts
  function asap(fn, ...params) {
    callbacks.unshift(fn);
    args.unshift(params);
    window.postMessage(ASAP_KEY, "*");
  }
  var callbacks, args, ASAP_KEY;
  var init_asap = __esm({
    "src/utils/asap.ts"() {
      "use strict";
      callbacks = [];
      args = [];
      ASAP_KEY = "asap" + Math.random().toString(36).substr(1);
      window.addEventListener("message", (event) => {
        if (event.source !== window || event.data !== ASAP_KEY)
          return;
        event.stopPropagation();
        if (callbacks.length == 0)
          return;
        const fn = callbacks.pop();
        const argArray = args.pop();
        fn.apply(void 0, argArray);
      }, true);
    }
  });

  // src/core/session.ts
  var import_speedy_vision3, SessionEvent, DEFAULT_OPTIONS, _Session, Session;
  var init_session = __esm({
    "src/core/session.ts"() {
      "use strict";
      import_speedy_vision3 = __toESM(require_speedy_vision(), 1);
      init_utils();
      init_ar_events();
      init_errors();
      init_settings2();
      init_stats();
      init_stats_panel();
      init_gizmos();
      init_frame();
      init_time_manager();
      init_asap();
      SessionEvent = class extends AREvent {
      };
      DEFAULT_OPTIONS = {
        mode: "immersive",
        trackers: [],
        sources: [],
        viewport: null,
        stats: false,
        gizmos: false
      };
      _Session = class _Session extends AREventTarget {
        /**
         * Constructor
         * @param sources previously initialized sources of data
         * @param mode session mode
         * @param viewport viewport
         * @param stats render stats panel?
         * @param gizmos render gizmos?
         */
        constructor(sources, mode, viewport, stats, gizmos) {
          super();
          this._mode = mode;
          this._trackers = [];
          this._sources = sources;
          this._updateStats = new Stats();
          this._renderStats = new Stats();
          this._active = true;
          this._frameReady = true;
          this._rafQueue = [];
          this._time = new TimeManager();
          this._gizmos = new Gizmos();
          this._gizmos.visible = gizmos;
          if (mode != "immersive" && mode != "inline")
            throw new IllegalArgumentError(`Invalid session mode "${mode}"`);
          this._primarySource = this._findPrimarySource(sources);
          this._viewport = viewport;
          if (this._primarySource !== null)
            this._viewport._init(() => this._primarySource._internalMedia.size, mode);
          else
            this._viewport._init(() => Utils.resolution("sm", window.innerWidth / window.innerHeight), mode);
          this._setupUpdateLoop();
          this._setupRenderLoop();
          this._statsPanel = new StatsPanel(this._viewport);
          this._statsPanel.visible = stats;
          _Session._count++;
          Utils.log(`The ${mode} session is now active!`);
        }
        /**
         * Checks if the engine can be run in the browser the client is using
         * @returns true if the engine is compatible with the browser
         */
        static isSupported() {
          if (/(Mac|iOS|iPhone|iPad|iPod)/i.test(Utils.platformString())) {
            const ios = /(iPhone|iPad|iPod).* (CPU[\s\w]* OS|CPU iPhone|iOS) ([\d\._]+)/.exec(navigator.userAgent);
            const safari = /(AppleWebKit)\/.* (Version)\/([\d\.]+)/.exec(navigator.userAgent);
            const matches = safari || ios;
            if (matches !== null) {
              const version = matches[3] || "0.0";
              const [x, y] = version.split(/[\._]/).map((v) => parseInt(v) | 0);
              if (x < 15 || x == 15 && y < 2) {
                Utils.error(`${matches === safari ? "Safari" : "iOS"} version ${version} is not supported! User agent: ${navigator.userAgent}`);
                return false;
              }
            } else
              Utils.warning(`Unrecognized user agent: ${navigator.userAgent}`);
          }
          return import_speedy_vision3.default.isSupported();
        }
        /** 
         * Instantiate a session
         * @param options options
         * @returns a promise that resolves to a new session
         */
        static instantiate(options = DEFAULT_OPTIONS) {
          const {
            mode = DEFAULT_OPTIONS.mode,
            sources = DEFAULT_OPTIONS.sources,
            trackers = DEFAULT_OPTIONS.trackers,
            viewport = DEFAULT_OPTIONS.viewport,
            stats = DEFAULT_OPTIONS.stats,
            gizmos = DEFAULT_OPTIONS.gizmos
          } = options;
          Utils.log(`Starting a new ${mode} session...`);
          return import_speedy_vision3.default.Promise.resolve().then(() => {
            if (!_Session.isSupported())
              throw new NotSupportedError("You need a browser/device compatible with WebGL2 and WebAssembly in order to experience Augmented Reality with encantar.js");
            if (mode !== "inline" && _Session.count > 0)
              throw new IllegalOperationError(`Can't start more than one immersive session`);
            return import_speedy_vision3.default.Matrix.ready();
          }).then(() => {
            for (let i = sources.length - 1; i >= 0; i--) {
              if (sources.indexOf(sources[i]) < i)
                throw new IllegalArgumentError(`Found repeated sources of data`);
            }
            return import_speedy_vision3.default.Promise.all(
              sources.map((source) => source._init())
            );
          }).then(() => {
            if (!viewport)
              throw new IllegalArgumentError(`Can't create a session without a viewport`);
            return new _Session(sources, mode, viewport, stats, gizmos);
          }).then((session) => {
            if (trackers.length == 0)
              Utils.warning(`No trackers have been attached to the session!`);
            for (let i = trackers.length - 1; i >= 0; i--) {
              if (trackers.indexOf(trackers[i]) < i)
                throw new IllegalArgumentError(`Found repeated trackers`);
            }
            return import_speedy_vision3.default.Promise.all(
              trackers.map((tracker) => session._attachTracker(tracker))
            ).then(() => session).catch((err) => {
              throw err;
            });
          }).catch((err) => {
            Utils.error(`Can't start session: ${err.message}`);
            throw err;
          });
        }
        /**
         * Number of active sessions
         */
        static get count() {
          return this._count;
        }
        /**
         * End the session
         * @returns promise that resolves after the session is shut down
         */
        end() {
          if (!this._active)
            return import_speedy_vision3.default.Promise.resolve();
          Utils.log("Shutting down the session...");
          this._active = false;
          return Utils.wait(100).then(() => import_speedy_vision3.default.Promise.all(
            // release trackers
            this._trackers.map((tracker) => tracker._release())
          )).then(() => import_speedy_vision3.default.Promise.all(
            // release input sources
            this._sources.map((source) => source._release())
          )).then(() => {
            this._sources.length = 0;
            this._trackers.length = 0;
            this._updateStats.reset();
            this._renderStats.reset();
            this._statsPanel.release();
            this._viewport._release();
            _Session._count--;
            const event = new SessionEvent("end");
            this.dispatchEvent(event);
            Utils.log("Session ended.");
          });
        }
        /**
         * Analogous to window.requestAnimationFrame()
         * @param callback
         * @returns a handle
         */
        requestAnimationFrame(callback) {
          const handle = Symbol("raf-handle");
          if (this._active) {
            this._rafQueue.push([handle, callback]);
          } else {
          }
          return handle;
        }
        /**
         * Analogous to window.cancelAnimationFrame()
         * @param handle a handle returned by this.requestAnimationFrame()
         */
        cancelAnimationFrame(handle) {
          for (let i = this._rafQueue.length - 1; i >= 0; i--) {
            if (this._rafQueue[i][0] === handle) {
              this._rafQueue.splice(i, 1);
              break;
            }
          }
        }
        /**
         * Session mode
         */
        get mode() {
          return this._mode;
        }
        /**
         * Whether or not the session has been ended
         */
        get ended() {
          return !this._active;
        }
        /**
         * Time Manager
         */
        get time() {
          return this._time;
        }
        /**
         * Visual cues for testing & debugging
         */
        get gizmos() {
          return this._gizmos;
        }
        /**
         * Rendering viewport
         */
        get viewport() {
          return this._viewport;
        }
        /**
         * Attached trackers
         */
        get trackers() {
          return this._trackers[Symbol.iterator]();
        }
        /**
         * Sources of data
         */
        get sources() {
          return this._sources[Symbol.iterator]();
        }
        /**
         * Find the primary source of data (generally a camera stream)
         * @param sources
         * @returns the primary source, or null if there isn't any
         */
        _findPrimarySource(sources) {
          for (let i = 0; i < sources.length; i++) {
            if (sources[i]._type == "video")
              return sources[i];
          }
          for (let i = 0; i < sources.length; i++) {
            if (sources[i]._type == "canvas")
              return sources[i];
          }
          Utils.warning(`No primary source of data was found!`);
          return null;
        }
        /**
         * Attach a tracker to the session
         * @param tracker
         * @returns a promise that resolves as soon as the tracker is attached and initialized
         */
        _attachTracker(tracker) {
          if (this._trackers.indexOf(tracker) >= 0)
            return import_speedy_vision3.default.Promise.reject(new IllegalArgumentError(`Duplicate tracker attached to the session`));
          else if (!this._active)
            return import_speedy_vision3.default.Promise.reject(new IllegalOperationError(`Inactive session`));
          this._trackers.push(tracker);
          return tracker._init(this);
        }
        /**
         * Render content to the background canvas
         */
        _renderBackground() {
          const canvas = this._viewport._backgroundCanvas;
          const ctx = canvas.getContext("2d", { alpha: false });
          if (!ctx)
            return;
          ctx.imageSmoothingEnabled = false;
          if (this._primarySource !== null) {
            const media = this._primarySource._internalMedia;
            this._renderMedia(ctx, media, true);
          }
          for (let i = 0; i < this._trackers.length; i++) {
            const media = this._trackers[i]._output.image;
            if (media !== void 0)
              this._renderMedia(ctx, media, false);
          }
          this._gizmos._render(this._viewport, this._trackers);
        }
        /**
         * Render a SpeedyMedia
         * @param ctx rendering context
         * @param media
         * @param stretch
         */
        _renderMedia(ctx, media, stretch) {
          const canvas = ctx.canvas;
          const width = stretch ? canvas.width : media.width;
          const height = stretch ? canvas.height : media.height;
          if (media.type != "data") {
            const image = media.source;
            ctx.drawImage(image, 0, 0, width, height);
          } else {
            const image = media.source;
            ctx.putImageData(image, 0, 0, 0, 0, width, height);
          }
        }
        /**
         * Setup the update loop
         */
        _setupUpdateLoop() {
          const scheduleNextFrame = () => {
            if (this._active) {
              if (Settings.powerPreference == "high-performance")
                asap(repeat);
              else
                window.requestAnimationFrame(repeat);
            }
          };
          const update = () => {
            this._update().then(scheduleNextFrame).turbocharge();
          };
          function repeat() {
            if (Settings.powerPreference == "low-power")
              window.requestAnimationFrame(update);
            else
              update();
          }
          window.requestAnimationFrame(update);
        }
        /**
         * The core of the update loop
         */
        _update() {
          if (this._active) {
            return import_speedy_vision3.default.Promise.all(
              // update trackers
              this._trackers.map((tracker) => tracker._update().turbocharge())
            ).then(() => {
              this._updateStats.update();
              this._frameReady = true;
            }).catch((err) => {
              Utils.error("Tracking error: " + err.toString(), err);
              const cause = err.cause;
              if (err.name == "GLError") {
                alert(err.message);
                alert(Utils.deviceInfo());
                throw err;
              } else if (typeof cause == "object" && cause.name == "GLError") {
                alert(err.message);
                alert(cause.message);
                alert(Utils.deviceInfo());
                throw err;
              }
            });
          } else {
            this._updateStats.reset();
            return import_speedy_vision3.default.Promise.resolve();
          }
        }
        /**
         * Setup the render loop
         */
        _setupRenderLoop() {
          let skip = false, toggle = false;
          const render = (timestamp) => {
            const enableFrameSkipping = Settings.powerPreference == "low-power";
            const highPerformance = Settings.powerPreference == "high-performance";
            this._time._update(timestamp);
            if (!enableFrameSkipping || !(skip = !skip))
              this._render(timestamp, false);
            if (this._active)
              window.requestAnimationFrame(render);
          };
          window.requestAnimationFrame(render);
        }
        /**
         * Render a frame (RAF callback)
         * @param time current time, in ms
         * @param skipUserMedia skip copying the pixels of the user media to the background canvas in order to reduce the processing load (video stream is probably at 30fps?)
         */
        _render(time, skipUserMedia) {
          if (this._active) {
            if (this._frameReady) {
              const results = this._trackers.map(
                (tracker) => tracker._output.exports || {
                  tracker,
                  trackables: []
                }
              );
              const frame = new Frame(this, results);
              const rafQueue = this._rafQueue.slice(0);
              this._rafQueue.length = 0;
              if (!skipUserMedia)
                this._renderBackground();
              for (let i = 0; i < rafQueue.length; i++)
                rafQueue[i][1].call(void 0, time, frame);
              this._renderStats.update();
              this._statsPanel.update(time, this._sources, this._trackers, this._viewport, this._updateStats.cyclesPerSecond, this._renderStats.cyclesPerSecond);
              this._frameReady = false;
            } else {
              ;
              this._renderStats.update();
            }
          } else {
            this._renderStats.reset();
          }
        }
      };
      /** Number of active sessions */
      _Session._count = 0;
      Session = _Session;
    }
  });

  // src/core/settings.ts
  var import_speedy_vision4, Settings;
  var init_settings2 = __esm({
    "src/core/settings.ts"() {
      "use strict";
      import_speedy_vision4 = __toESM(require_speedy_vision(), 1);
      init_session();
      init_errors();
      init_utils();
      Settings = class {
        /**
         * Power preference (may impact performance x battery life)
         */
        static get powerPreference() {
          return this._powerPreference;
        }
        /**
         * Power preference (may impact performance x battery life)
         * Note: this setting should be the very first thing you set
         * (before the WebGL context is created by Speedy)
         */
        static set powerPreference(value) {
          if (Session.count > 0)
            throw new IllegalOperationError(`Can't change the powerPreference while there are active sessions going on`);
          else if (!("low-power" == value || "default" == value || "high-performance" == value))
            throw new IllegalArgumentError(`Invalid powerPreference: "${value}"`);
          if (value == "high-performance")
            import_speedy_vision4.default.Settings.gpuPollingMode = "asap";
          else
            import_speedy_vision4.default.Settings.gpuPollingMode = "raf";
          this._powerPreference = value;
          Utils.log(`Changed the powerPreference to "${this._powerPreference}"`);
        }
      };
      Settings._powerPreference = "default";
    }
  });

  // src/trackers/image-tracker/reference-image.ts
  var ReferenceImageWithMedia;
  var init_reference_image = __esm({
    "src/trackers/image-tracker/reference-image.ts"() {
      "use strict";
      ReferenceImageWithMedia = class {
        /**
         * Constructor
         * @param referenceImage
         * @param media
         */
        constructor(referenceImage, media) {
          this._referenceImage = Object.assign({}, referenceImage);
          this._media = media;
          if (this._referenceImage.name === void 0)
            this._referenceImage.name = this._generateUniqueName();
          this._aspectRatio = media.width / media.height;
        }
        /**
         * Getter of the name of the reference image
         */
        get name() {
          return this._referenceImage.name;
        }
        /**
         * Setter of the name of the reference image
         */
        set name(name) {
          this._referenceImage.name = name;
        }
        /**
         * Image data
         */
        get image() {
          return this._referenceImage.image;
        }
        /**
         * A SpeedyMedia corresponding to the reference media
         */
        get media() {
          return this._media;
        }
        /**
         * The aspect ratio of the reference image
         */
        get aspectRatio() {
          return this._aspectRatio;
        }
        /**
         * Generate a unique name for a reference image
         * @returns a unique name
         */
        _generateUniqueName() {
          return "target-" + Math.random().toString(16).substr(2);
        }
      };
    }
  });

  // src/trackers/image-tracker/reference-image-database.ts
  var import_speedy_vision5, DEFAULT_CAPACITY, ReferenceImageDatabase;
  var init_reference_image_database = __esm({
    "src/trackers/image-tracker/reference-image-database.ts"() {
      "use strict";
      import_speedy_vision5 = __toESM(require_speedy_vision(), 1);
      init_reference_image();
      init_utils();
      init_errors();
      DEFAULT_CAPACITY = 100;
      ReferenceImageDatabase = class {
        /**
         * Constructor
         */
        constructor() {
          this._capacity = DEFAULT_CAPACITY;
          this._entries = /* @__PURE__ */ new Map();
          this._locked = false;
        }
        /**
         * The number of reference images stored in this database
         */
        get count() {
          return this._entries.size;
        }
        /**
         * Maximum number of elements
         */
        get capacity() {
          return this._capacity;
        }
        /**
         * Maximum number of elements
         * Increasing the capacity is considered experimental
         */
        set capacity(value) {
          const capacity = Math.max(0, value | 0);
          if (this.count > capacity)
            throw new IllegalArgumentError(`Can't set the capacity of the database to ${capacity}: it currently stores ${this.count} entries`);
          this._capacity = capacity;
        }
        /**
         * Iterates over the collection
         */
        [Symbol.iterator]() {
          return this._entries.values();
        }
        /**
         * Add reference images to this database
         * Add only the images you actually need to track!
         * (each image take up storage space)
         * @param referenceImages one or more reference images with unique names (a unique name will
         *                        be generated automatically if you don't specify one)
         * @returns a promise that resolves as soon as the images are loaded and added to this database
         */
        add(referenceImages) {
          return this._preloadMany(referenceImages).then((referenceImagesWithMedia) => {
            referenceImagesWithMedia.forEach((referenceImageWithMedia) => {
              this._addOne(referenceImageWithMedia);
            });
          });
        }
        /**
         * Add a single preloaded reference image to the database
         * @param referenceImage
         */
        _addOne(referenceImage) {
          const name = referenceImage.name;
          if (this._locked)
            throw new IllegalOperationError(`Can't add reference image "${name}" to the database: it's locked`);
          if (this.count >= this.capacity)
            throw new IllegalOperationError(`Can't add reference image "${name}" to the database: the capacity of ${this.capacity} images has been exceeded.`);
          if (!(referenceImage.image instanceof HTMLImageElement) && !(referenceImage.image instanceof ImageBitmap) && !(referenceImage.image instanceof ImageData))
            throw new IllegalArgumentError(`Can't add reference image "${name}" to the database: invalid image`);
          if (this._entries.has(name))
            throw new IllegalArgumentError(`Can't add reference image "${name}" to the database: found duplicated name`);
          Utils.log(`Adding reference image "${name}" to the database...`);
          this._entries.set(name, referenceImage);
        }
        /**
         * Lock the database, so that new reference images can no longer be added to it
         * @internal
         */
        _lock() {
          this._locked = true;
        }
        /**
         * Get reference image by name
         * @param name
         * @returns the reference image with the given name, or null if there isn't any
         * @internal
         */
        _find(name) {
          return this._entries.get(name) || null;
        }
        /**
         * Load a reference image
         * @param referenceImage
         * @returns a promise that resolves to a corresponding ReferenceImageWithMedia
         */
        _preloadOne(referenceImage) {
          if (referenceImage.name !== void 0)
            Utils.log(`Loading reference image "${referenceImage.name}"...`);
          else
            Utils.log(`Loading reference image...`);
          if (!referenceImage.image)
            return import_speedy_vision5.default.Promise.reject(new IllegalArgumentError("The reference image was not provided!"));
          return import_speedy_vision5.default.load(referenceImage.image).then((media) => {
            return new ReferenceImageWithMedia(referenceImage, media);
          });
        }
        /**
         * Load multiple reference images
         * @param referenceImages
         * @returns a promise that resolves to corresponding ReferenceImageWithMedia objects
         */
        _preloadMany(referenceImages) {
          const n = referenceImages.length;
          Utils.log(`Loading ${n} reference image${n != 1 ? "s" : ""}...`);
          const promises = referenceImages.map((referenceImage) => this._preloadOne(referenceImage));
          return import_speedy_vision5.default.Promise.all(promises);
        }
      };
    }
  });

  // src/trackers/image-tracker/states/state.ts
  var import_speedy_vision6, ImageTrackerState;
  var init_state = __esm({
    "src/trackers/image-tracker/states/state.ts"() {
      "use strict";
      import_speedy_vision6 = __toESM(require_speedy_vision(), 1);
      init_errors();
      ImageTrackerState = class {
        /**
         * Constructor
         * @param name
         * @param imageTracker
         */
        constructor(name, imageTracker) {
          this._name = name;
          this._imageTracker = imageTracker;
          this._pipeline = this._createPipeline();
          this._pipelineReleased = false;
        }
        /**
         * State name
         */
        get name() {
          return this._name;
        }
        /**
         * AR screen size
         * It may change over time, as when flipping a phone
         */
        get screenSize() {
          const screen2 = this._pipeline.node("screen");
          if (!screen2)
            throw new IllegalOperationError();
          return screen2.size;
        }
        /**
         * Initialize the state
         */
        init() {
        }
        /**
         * Release resources
         */
        release() {
          if (!this._pipelineReleased) {
            this._pipeline.release();
            this._pipelineReleased = true;
          }
          return null;
        }
        /**
         * Update the state
         * @param media user media
         * @param screenSize AR screen size for image processing
         * @param state all states
         * @returns promise
         */
        update(media, screenSize) {
          const source = this._pipeline.node("source");
          const screen2 = this._pipeline.node("screen");
          if (!source || !screen2)
            throw new IllegalOperationError();
          source.media = media;
          screen2.size = screenSize;
          return this._beforeUpdate().then(
            () => this._gpuUpdate()
          ).then(
            (result) => this._afterUpdate(result)
          );
        }
        /**
         * Called as soon as this becomes the active state, just before update() runs for the first time
         * @param settings
         */
        onEnterState(settings) {
        }
        /**
         * Called when leaving the state, after update()
         */
        onLeaveState() {
        }
        /**
         * Called just before the GPU processing
         * @returns promise
         */
        _beforeUpdate() {
          return import_speedy_vision6.default.Promise.resolve();
        }
        /**
         * GPU processing
         * @returns promise with the pipeline results
         */
        _gpuUpdate() {
          return this._pipeline.run();
        }
      };
    }
  });

  // src/trackers/image-tracker/states/initial.ts
  var import_speedy_vision7, ImageTrackerInitialState;
  var init_initial = __esm({
    "src/trackers/image-tracker/states/initial.ts"() {
      "use strict";
      import_speedy_vision7 = __toESM(require_speedy_vision(), 1);
      init_state();
      init_settings();
      init_utils();
      ImageTrackerInitialState = class extends ImageTrackerState {
        /**
         * Constructor
         * @param imageTracker
         */
        constructor(imageTracker) {
          super("initial", imageTracker);
        }
        /**
         * Called just before the GPU processing
         * @returns promise
         */
        _beforeUpdate() {
          const source = this._pipeline.node("source");
          const media = source.media;
          const mediaSize = media.size;
          if (mediaSize.area() < this.screenSize.area())
            Utils.warning("The resolution of the tracker is larger than the resolution of the video. This is inefficient.");
          return import_speedy_vision7.default.Promise.resolve();
        }
        /**
         * Post processing that takes place just after the GPU processing
         * @param result pipeline results
         * @returns state output
         */
        _afterUpdate(result) {
          return import_speedy_vision7.default.Promise.resolve({
            nextState: "training",
            trackerOutput: {}
          });
        }
        /**
         * Called when leaving the state, after update()
         */
        onLeaveState() {
          this._pipeline.release();
          this._pipelineReleased = true;
        }
        /**
         * Create & setup the pipeline
         * @returns pipeline
         */
        _createPipeline() {
          const pipeline = import_speedy_vision7.default.Pipeline();
          const source = import_speedy_vision7.default.Image.Source("source");
          const screen2 = import_speedy_vision7.default.Transform.Resize("screen");
          const greyscale = import_speedy_vision7.default.Filter.Greyscale();
          const imageRectifier = import_speedy_vision7.default.Transform.PerspectiveWarp();
          const nightvision = import_speedy_vision7.default.Filter.Nightvision();
          const nightvisionMux = import_speedy_vision7.default.Image.Multiplexer();
          const detector = import_speedy_vision7.default.Keypoint.Detector.Harris();
          const descriptor = import_speedy_vision7.default.Keypoint.Descriptor.ORB();
          const blur = import_speedy_vision7.default.Filter.GaussianBlur();
          const clipper = import_speedy_vision7.default.Keypoint.Clipper();
          const borderClipper = import_speedy_vision7.default.Keypoint.BorderClipper();
          const denoiser = import_speedy_vision7.default.Filter.GaussianBlur();
          const subpixel = import_speedy_vision7.default.Keypoint.SubpixelRefiner();
          const matcher = import_speedy_vision7.default.Keypoint.Matcher.BFKNN();
          const keypointRectifier = import_speedy_vision7.default.Keypoint.Transformer();
          const keypointPortalSink = import_speedy_vision7.default.Keypoint.Portal.Sink();
          const keypointPortalSource = import_speedy_vision7.default.Keypoint.Portal.Source();
          const muxOfReferenceKeypoints = import_speedy_vision7.default.Keypoint.Multiplexer();
          const bufferOfReferenceKeypoints = import_speedy_vision7.default.Keypoint.Buffer();
          const muxOfBufferOfReferenceKeypoints = import_speedy_vision7.default.Keypoint.Multiplexer();
          const keypointSink = import_speedy_vision7.default.Keypoint.SinkOfMatchedKeypoints();
          source.media = null;
          screen2.size = import_speedy_vision7.default.Size(0, 0);
          imageRectifier.transform = import_speedy_vision7.default.Matrix.Eye(3);
          nightvision.quality = NIGHTVISION_QUALITY;
          subpixel.method = SUBPIXEL_METHOD;
          borderClipper.imageSize = import_speedy_vision7.default.Size(100, 100);
          borderClipper.borderSize = import_speedy_vision7.default.Vector2(0, 0);
          matcher.k = 1;
          keypointRectifier.transform = import_speedy_vision7.default.Matrix.Eye(3);
          keypointPortalSource.source = keypointPortalSink;
          muxOfReferenceKeypoints.port = 0;
          muxOfBufferOfReferenceKeypoints.port = 0;
          bufferOfReferenceKeypoints.frozen = false;
          keypointSink.turbo = false;
          source.output().connectTo(screen2.input());
          screen2.output().connectTo(greyscale.input());
          greyscale.output().connectTo(imageRectifier.input());
          imageRectifier.output().connectTo(nightvisionMux.input("in0"));
          imageRectifier.output().connectTo(nightvision.input());
          nightvision.output().connectTo(nightvisionMux.input("in1"));
          nightvisionMux.output().connectTo(blur.input());
          nightvisionMux.output().connectTo(detector.input());
          detector.output().connectTo(borderClipper.input());
          borderClipper.output().connectTo(clipper.input());
          imageRectifier.output().connectTo(denoiser.input());
          denoiser.output().connectTo(subpixel.input("image"));
          clipper.output().connectTo(subpixel.input("keypoints"));
          blur.output().connectTo(descriptor.input("image"));
          subpixel.output().connectTo(descriptor.input("keypoints"));
          descriptor.output().connectTo(muxOfReferenceKeypoints.input("in0"));
          muxOfBufferOfReferenceKeypoints.output().connectTo(muxOfReferenceKeypoints.input("in1"));
          muxOfReferenceKeypoints.output().connectTo(matcher.input("database"));
          descriptor.output().connectTo(matcher.input("keypoints"));
          keypointPortalSource.output().connectTo(muxOfBufferOfReferenceKeypoints.input("in0"));
          bufferOfReferenceKeypoints.output().connectTo(muxOfBufferOfReferenceKeypoints.input("in1"));
          keypointPortalSource.output().connectTo(bufferOfReferenceKeypoints.input());
          descriptor.output().connectTo(keypointPortalSink.input());
          descriptor.output().connectTo(keypointRectifier.input());
          keypointRectifier.output().connectTo(keypointSink.input());
          matcher.output().connectTo(keypointSink.input("matches"));
          pipeline.init(
            source,
            screen2,
            greyscale,
            imageRectifier,
            nightvision,
            nightvisionMux,
            blur,
            detector,
            subpixel,
            clipper,
            borderClipper,
            denoiser,
            descriptor,
            keypointPortalSource,
            muxOfReferenceKeypoints,
            matcher,
            bufferOfReferenceKeypoints,
            muxOfBufferOfReferenceKeypoints,
            keypointRectifier,
            keypointSink,
            keypointPortalSink
          );
          return pipeline;
        }
      };
    }
  });

  // src/trackers/image-tracker/image-tracker-utils.ts
  var import_speedy_vision8, ImageTrackerUtils;
  var init_image_tracker_utils = __esm({
    "src/trackers/image-tracker/image-tracker-utils.ts"() {
      "use strict";
      import_speedy_vision8 = __toESM(require_speedy_vision(), 1);
      init_utils();
      init_errors();
      init_settings();
      ImageTrackerUtils = class {
        /**
         * Find a transformation that converts a raster space to NIS
         * @param size size of the raster space
         * @returns a 3x3 matrix
         */
        static rasterToNIS(size) {
          const sx = NIS_SIZE / size.width;
          const sy = NIS_SIZE / size.height;
          return import_speedy_vision8.default.Matrix(3, 3, [
            sx,
            0,
            0,
            0,
            sy,
            0,
            0,
            0,
            1
          ]);
        }
        /**
         * Find a transformation that converts a raster space to NDC
         * @param size size of the raster space
         * @returns a 3x3 matrix
         */
        static rasterToNDC(size) {
          const w = size.width, h = size.height;
          return import_speedy_vision8.default.Matrix(3, 3, [
            2 / w,
            0,
            0,
            0,
            -2 / h,
            0,
            -1,
            1,
            1
          ]);
        }
        /**
         * Find a transformation that converts NDC to a raster space
         * @param size size of the raster space
         * @returns a 3x3 matrix
         */
        static NDCToRaster(size) {
          const w = size.width, h = size.height;
          return import_speedy_vision8.default.Matrix(3, 3, [
            w / 2,
            0,
            0,
            0,
            -h / 2,
            0,
            w / 2,
            h / 2,
            1
          ]);
        }
        /**
         * Find a transformation that scales points in NDC
         * @param sx horizontal scale factor
         * @param sy vertical scale factor
         * @returns a 3x3 matrix
         */
        static scaleNDC(sx, sy = sx) {
          return import_speedy_vision8.default.Matrix(3, 3, [
            sx,
            0,
            0,
            0,
            sy,
            0,
            0,
            0,
            1
          ]);
        }
        /**
         * Find a scale transformation in NDC such that the output has a desired aspect ratio
         * @param aspectRatio desired aspect ratio
         * @param scale optional scale factor in both axes
         * @returns a 3x3 matrix
         */
        static bestFitScaleNDC(aspectRatio, scale = 1) {
          if (aspectRatio >= 1)
            return this.scaleNDC(scale, scale / aspectRatio);
          else
            return this.scaleNDC(scale * aspectRatio, scale);
        }
        /**
         * Find the inverse matrix of bestFitScaleNDC()
         * @param aspectRatio as given to bestFitScaleNDC()
         * @param scale optional, as given to bestFitScaleNDC()
         * @returns a 3x3 matrix
         */
        static inverseBestFitScaleNDC(aspectRatio, scale = 1) {
          if (aspectRatio >= 1)
            return this.scaleNDC(1 / scale, aspectRatio / scale);
          else
            return this.scaleNDC(1 / (scale * aspectRatio), 1 / scale);
        }
        /**
         * Find the best-fit aspect ratio for the rectification of the reference image in NDC
         * @param screenSize
         * @param referenceImage
         * @returns a best-fit aspect ratio
         */
        static bestFitAspectRatioNDC(screenSize, referenceImage) {
          const screenAspectRatio = screenSize.width / screenSize.height;
          return referenceImage.aspectRatio / screenAspectRatio;
        }
        /**
         * Given n > 0 pairs (src_i, dest_i) of keypoints in NIS,
         * convert them to NDC and output a 2 x 2n matrix of the form:
         * [ src_0.x  src_1.x  ... | dest_0.x  dest_1.x  ... ]
         * [ src_0.y  src_1.y  ... | dest_0.y  dest_1.y  ... ]
         * @param pairs pairs of keypoints in NIS
         * @returns 2 x 2n matrix with two 2 x n blocks: [ src | dest ]
         * @throws
         */
        static compilePairsOfKeypointsNDC(pairs) {
          const n = pairs.length;
          if (n == 0)
            throw new IllegalArgumentError();
          const scale = 2 / NIS_SIZE;
          const data = new Array(2 * 2 * n);
          for (let i = 0, j = 0, k = 2 * n; i < n; i++, j += 2, k += 2) {
            const src = pairs[i][0];
            const dest = pairs[i][1];
            data[j] = src.x * scale - 1;
            data[j + 1] = 1 - src.y * scale;
            data[k] = dest.x * scale - 1;
            data[k + 1] = 1 - dest.y * scale;
          }
          return import_speedy_vision8.default.Matrix(2, 2 * n, data);
        }
        /**
         * Given n > 0 pairs of keypoints in NDC as a 2 x 2n [ src | dest ] matrix,
         * find a perspective warp (homography) from src to dest in NDC
         * @param points compiled pairs of keypoints in NDC
         * @param options to be passed to speedy-vision
         * @returns a pair [ 3x3 transformation matrix, quality score ]
         */
        static findPerspectiveWarpNDC(points, options) {
          const n = points.columns / 2;
          if (n < 4) {
            return import_speedy_vision8.default.Promise.reject(
              new IllegalArgumentError(`Too few data points to compute a perspective warp`)
            );
          }
          const src = points.block(0, 1, 0, n - 1);
          const dest = points.block(0, 1, n, 2 * n - 1);
          const mask = import_speedy_vision8.default.Matrix.Zeros(1, n);
          return import_speedy_vision8.default.Matrix.findHomography(
            import_speedy_vision8.default.Matrix.Zeros(3),
            src,
            dest,
            Object.assign({ mask }, options)
          ).then((homography) => {
            const a00 = homography.at(0, 0);
            if (Number.isNaN(a00))
              throw new NumericalError(`Can't compute a perspective warp: bad keypoints`);
            const inliers = mask.read();
            let inlierCount = 0;
            for (let i = inliers.length - 1; i >= 0; i--)
              inlierCount += inliers[i];
            const score = inlierCount / inliers.length;
            return [homography, score];
          });
        }
        /**
         * Given n > 0 pairs of keypoints in NDC as a 2 x 2n [ src | dest ] matrix,
         * find an affine warp from src to dest in NDC. The affine warp is given as
         * a 3x3 matrix whose last row is [0 0 1]
         * @param points compiled pairs of keypoints in NDC
         * @param options to be passed to speedy-vision
         * @returns a pair [ 3x3 transformation matrix, quality score ]
         */
        static findAffineWarpNDC(points, options) {
          const n = points.columns / 2;
          if (n < 3) {
            return import_speedy_vision8.default.Promise.reject(
              new IllegalArgumentError(`Too few data points to compute an affine warp`)
            );
          }
          const model = import_speedy_vision8.default.Matrix.Eye(3);
          const src = points.block(0, 1, 0, n - 1);
          const dest = points.block(0, 1, n, 2 * n - 1);
          const mask = import_speedy_vision8.default.Matrix.Zeros(1, n);
          return import_speedy_vision8.default.Matrix.findAffineTransform(
            model.block(0, 1, 0, 2),
            // 2x3 submatrix
            src,
            dest,
            Object.assign({ mask }, options)
          ).then((_) => {
            const a00 = model.at(0, 0);
            if (Number.isNaN(a00))
              throw new NumericalError(`Can't compute an affine warp: bad keypoints`);
            const inliers = mask.read();
            let inlierCount = 0;
            for (let i = inliers.length - 1; i >= 0; i--)
              inlierCount += inliers[i];
            const score = inlierCount / inliers.length;
            return [model, score];
          });
        }
        /**
         * Find a polyline in Normalized Device Coordinates (NDC)
         * @param homography maps the corners of NDC to a quadrilateral in NDC
         * @returns 4 points in NDC
         */
        static findPolylineNDC(homography) {
          const h = homography.read();
          const uv = [-1, 1, -1, -1, 1, -1, 1, 1];
          const polyline = new Array(4);
          for (let i = 0, j = 0; i < 4; i++, j += 2) {
            const u = uv[j], v = uv[j + 1];
            const x = h[0] * u + h[3] * v + h[6];
            const y = h[1] * u + h[4] * v + h[7];
            const w = h[2] * u + h[5] * v + h[8];
            polyline[i] = import_speedy_vision8.default.Point2(x / w, y / w);
          }
          return polyline;
        }
        /**
         * Find a better spatial distribution of the input matches
         * @param pairs in the [src, dest] format
         * @returns refined pairs of quality matches
         */
        static refineMatchingPairs(pairs) {
          const m = pairs.length;
          const destKeypoints = new Array(m);
          for (let j = 0; j < m; j++)
            destKeypoints[j] = pairs[j][1];
          const indices = this._distributeKeypoints(destKeypoints);
          const n = indices.length;
          const result = new Array(n);
          for (let i = 0; i < n; i++)
            result[i] = pairs[indices[i]];
          return result;
        }
        /**
         * Spatially distribute keypoints over a grid
         * @param keypoints keypoints to be distributed
         * @returns a list of indices of keypoints[]
         */
        static _distributeKeypoints(keypoints) {
          const gridCells = TRACK_GRID_GRANULARITY;
          const numberOfCells = gridCells * gridCells;
          const n = keypoints.length;
          const points = new Array(2 * n);
          for (let i = 0, j = 0; i < n; i++, j += 2) {
            points[j] = keypoints[i].x;
            points[j + 1] = keypoints[i].y;
          }
          this._normalizePoints(points);
          const grid = new Array(numberOfCells).fill(-1);
          for (let i = 0, j = 0; i < n; i++, j += 2) {
            const xg = Math.floor(points[j] * gridCells);
            const yg = Math.floor(points[j + 1] * gridCells);
            const k = yg * gridCells + xg;
            if (grid[k] < 0)
              grid[k] = i;
          }
          let m = 0;
          const indices = new Array(numberOfCells);
          for (let g = 0; g < numberOfCells; g++) {
            if (grid[g] >= 0)
              indices[m++] = grid[g];
          }
          indices.length = m;
          return indices;
        }
        /**
         * Normalize points to [0,1)^2
         * @param points 2 x n matrix of points in column-major format
         * @returns points
         */
        static _normalizePoints(points) {
          Utils.assert(points.length % 2 == 0);
          const n = points.length / 2;
          if (n == 0)
            return points;
          let xmin = Number.POSITIVE_INFINITY, xmax = Number.NEGATIVE_INFINITY;
          let ymin = Number.POSITIVE_INFINITY, ymax = Number.NEGATIVE_INFINITY;
          for (let i = 0, j = 0; i < n; i++, j += 2) {
            const x = points[j], y = points[j + 1];
            xmin = x < xmin ? x : xmin;
            ymin = y < ymin ? y : ymin;
            xmax = x > xmax ? x : xmax;
            ymax = y > ymax ? y : ymax;
          }
          const xlen = xmax - xmin + 1;
          const ylen = ymax - ymin + 1;
          for (let i = 0, j = 0; i < n; i++, j += 2) {
            points[j] = (points[j] - xmin) / xlen;
            points[j + 1] = (points[j + 1] - ymin) / ylen;
          }
          return points;
        }
      };
    }
  });

  // src/trackers/image-tracker/states/training.ts
  var import_speedy_vision9, ImageTrackerTrainingState;
  var init_training = __esm({
    "src/trackers/image-tracker/states/training.ts"() {
      "use strict";
      import_speedy_vision9 = __toESM(require_speedy_vision(), 1);
      init_image_tracker_utils();
      init_state();
      init_utils();
      init_errors();
      init_settings();
      ImageTrackerTrainingState = class extends ImageTrackerState {
        /**
         * Constructor
         * @param imageTracker
         */
        constructor(imageTracker) {
          super("training", imageTracker);
          /** index of the image being used to train the tracker */
          this._currentImageIndex = 0;
          this._trainingMap = {
            keypoints: [],
            referenceImageIndex: [],
            referenceImages: []
          };
        }
        /**
         * Called as soon as this becomes the active state, just before update() runs for the first time
         * @param settings
         */
        onEnterState(settings) {
          const database = this._imageTracker.database;
          if (database.count == 0)
            throw new TrainingError(`Can't train the Image Tracker: the Reference Image Database is empty`);
          this._currentImageIndex = 0;
          this._trainingMap.keypoints.length = 0;
          this._trainingMap.referenceImageIndex.length = 0;
          this._trainingMap.referenceImages.length = 0;
          Utils.log(`Image Tracker: training using ${database.count} reference image${database.count != 1 ? "s" : ""}`);
          database._lock();
          for (const referenceImage of database)
            this._trainingMap.referenceImages.push(referenceImage);
        }
        /**
         * Called when leaving the state, after update()
         */
        onLeaveState() {
          this._pipeline.release();
          this._pipelineReleased = true;
        }
        /**
         * Called just before the GPU processing
         * @returns promise
         */
        _beforeUpdate() {
          const source = this._pipeline.node("source");
          const screen2 = this._pipeline.node("screen");
          const keypointScaler = this._pipeline.node("keypointScaler");
          const referenceImage = this._trainingMap.referenceImages[this._currentImageIndex];
          source.media = referenceImage.media;
          const resolution = this._imageTracker.resolution;
          const scale = TRAIN_IMAGE_SCALE;
          const aspectRatioOfTrainingImage = referenceImage.aspectRatio;
          screen2.size = Utils.resolution(resolution, aspectRatioOfTrainingImage);
          screen2.size.width = Math.round(screen2.size.width * scale);
          screen2.size.height = Math.round(screen2.size.height * scale);
          keypointScaler.transform = ImageTrackerUtils.rasterToNIS(screen2.size);
          Utils.log(`Image Tracker: training using reference image "${referenceImage.name}" at ${screen2.size.width}x${screen2.size.height}...`);
          return import_speedy_vision9.default.Promise.resolve();
        }
        /**
         * Post processing that takes place just after the GPU processing
         * @param result pipeline results
         * @returns state output
         */
        _afterUpdate(result) {
          const referenceImage = this._trainingMap.referenceImages[this._currentImageIndex];
          const keypoints = result.keypoints;
          const image = result.image;
          Utils.log(`Image Tracker: found ${keypoints.length} keypoints in reference image "${referenceImage.name}"`);
          const trackerOutput = {
            keypointsNIS: image !== void 0 ? keypoints : void 0,
            // debug only
            image
          };
          for (let i = 0; i < keypoints.length; i++) {
            this._trainingMap.keypoints.push(keypoints[i]);
            this._trainingMap.referenceImageIndex.push(this._currentImageIndex);
          }
          ++this._currentImageIndex;
          if (this._currentImageIndex < this._trainingMap.referenceImages.length) {
            return import_speedy_vision9.default.Promise.resolve({
              nextState: "training",
              trackerOutput
            });
          }
          return import_speedy_vision9.default.Promise.resolve({
            nextState: "scanning",
            trackerOutput,
            nextStateSettings: {
              database: this._trainingMap.keypoints
            }
          });
        }
        /**
         * Create & setup the pipeline
         * @returns pipeline
         */
        _createPipeline() {
          const pipeline = import_speedy_vision9.default.Pipeline();
          const source = import_speedy_vision9.default.Image.Source("source");
          const screen2 = import_speedy_vision9.default.Transform.Resize("screen");
          const greyscale = import_speedy_vision9.default.Filter.Greyscale();
          const blur = import_speedy_vision9.default.Filter.GaussianBlur();
          const nightvision = import_speedy_vision9.default.Filter.Nightvision();
          const nightvisionMux = import_speedy_vision9.default.Image.Multiplexer("nightvisionMux");
          const pyramid = import_speedy_vision9.default.Image.Pyramid();
          const detector = import_speedy_vision9.default.Keypoint.Detector.FAST("fast");
          const descriptor = import_speedy_vision9.default.Keypoint.Descriptor.ORB();
          const subpixel = import_speedy_vision9.default.Keypoint.SubpixelRefiner();
          const blurredPyramid = import_speedy_vision9.default.Image.Pyramid();
          const denoiser = import_speedy_vision9.default.Filter.GaussianBlur();
          const clipper = import_speedy_vision9.default.Keypoint.Clipper();
          const keypointScaler = import_speedy_vision9.default.Keypoint.Transformer("keypointScaler");
          const keypointSink = import_speedy_vision9.default.Keypoint.Sink("keypoints");
          source.media = null;
          screen2.size = import_speedy_vision9.default.Size(0, 0);
          blur.kernelSize = import_speedy_vision9.default.Size(ORB_GAUSSIAN_KSIZE, ORB_GAUSSIAN_KSIZE);
          blur.sigma = import_speedy_vision9.default.Vector2(ORB_GAUSSIAN_SIGMA, ORB_GAUSSIAN_SIGMA);
          nightvision.gain = NIGHTVISION_GAIN;
          nightvision.offset = NIGHTVISION_OFFSET;
          nightvision.decay = NIGHTVISION_DECAY;
          nightvision.quality = NIGHTVISION_QUALITY;
          nightvisionMux.port = SCAN_WITH_NIGHTVISION ? 1 : 0;
          detector.levels = SCAN_PYRAMID_LEVELS;
          detector.scaleFactor = SCAN_PYRAMID_SCALEFACTOR;
          detector.threshold = SCAN_FAST_THRESHOLD;
          detector.capacity = 8192;
          subpixel.method = SUBPIXEL_METHOD;
          denoiser.kernelSize = import_speedy_vision9.default.Size(SUBPIXEL_GAUSSIAN_KSIZE, SUBPIXEL_GAUSSIAN_KSIZE);
          denoiser.sigma = import_speedy_vision9.default.Vector2(SUBPIXEL_GAUSSIAN_SIGMA, SUBPIXEL_GAUSSIAN_SIGMA);
          clipper.size = TRAIN_MAX_KEYPOINTS;
          keypointScaler.transform = import_speedy_vision9.default.Matrix.Eye(3);
          keypointSink.turbo = false;
          source.output().connectTo(screen2.input());
          screen2.output().connectTo(greyscale.input());
          greyscale.output().connectTo(nightvisionMux.input("in0"));
          greyscale.output().connectTo(nightvision.input());
          nightvision.output().connectTo(nightvisionMux.input("in1"));
          nightvisionMux.output().connectTo(pyramid.input());
          pyramid.output().connectTo(detector.input());
          detector.output().connectTo(clipper.input());
          greyscale.output().connectTo(denoiser.input());
          denoiser.output().connectTo(blurredPyramid.input());
          clipper.output().connectTo(subpixel.input("keypoints"));
          blurredPyramid.output().connectTo(subpixel.input("image"));
          greyscale.output().connectTo(blur.input());
          blur.output().connectTo(descriptor.input("image"));
          subpixel.output().connectTo(descriptor.input("keypoints"));
          descriptor.output().connectTo(keypointScaler.input());
          keypointScaler.output().connectTo(keypointSink.input());
          pipeline.init(
            source,
            screen2,
            greyscale,
            nightvision,
            nightvisionMux,
            pyramid,
            detector,
            blur,
            descriptor,
            clipper,
            denoiser,
            blurredPyramid,
            subpixel,
            keypointScaler,
            keypointSink
            //imageSink
          );
          return pipeline;
        }
        /**
         * Get the reference image associated with a keypoint index in the training map
         * @param keypointIndex -1 if not found
         * @returns reference image
         */
        referenceImageOfKeypoint(keypointIndex) {
          const imageIndex = this.referenceImageIndexOfKeypoint(keypointIndex);
          if (imageIndex < 0)
            return null;
          return this._trainingMap.referenceImages[imageIndex];
        }
        /**
         * Get the reference image index associated with a keypoint index in the training map
         * @param keypointIndex -1 if not found
         * @returns reference image index, or -1 if not found
         */
        referenceImageIndexOfKeypoint(keypointIndex) {
          const n = this._trainingMap.referenceImageIndex.length;
          if (keypointIndex < 0 || keypointIndex >= n)
            return -1;
          const imageIndex = this._trainingMap.referenceImageIndex[keypointIndex];
          if (imageIndex < 0 || imageIndex >= this._trainingMap.referenceImages.length)
            return -1;
          return imageIndex;
        }
        /**
         * Get a keypoint of the trained set
         * @param keypointIndex -1 if not found
         * @returns a keypoint
         */
        referenceKeypoint(keypointIndex) {
          if (keypointIndex < 0 || keypointIndex >= this._trainingMap.keypoints.length)
            return null;
          return this._trainingMap.keypoints[keypointIndex];
        }
      };
    }
  });

  // src/trackers/image-tracker/states/scanning.ts
  var import_speedy_vision10, PORT_CAMERA, PORT_MEMORY, ImageTrackerScanningState;
  var init_scanning = __esm({
    "src/trackers/image-tracker/states/scanning.ts"() {
      "use strict";
      import_speedy_vision10 = __toESM(require_speedy_vision(), 1);
      init_image_tracker_utils();
      init_state();
      init_utils();
      init_errors();
      init_settings();
      PORT_CAMERA = 0;
      PORT_MEMORY = 1;
      ImageTrackerScanningState = class extends ImageTrackerState {
        /**
         * Constructor
         * @param imageTracker
         */
        constructor(imageTracker) {
          super("scanning", imageTracker);
          this._counter = 0;
          this._bestScore = 0;
          this._bestHomography = import_speedy_vision10.default.Matrix.Eye(3);
        }
        /**
         * Called as soon as this becomes the active state, just before update() runs for the first time
         * @param settings
         */
        onEnterState(settings) {
          const imagePortalMux = this._pipeline.node("imagePortalMux");
          const lshTables = this._pipeline.node("lshTables");
          const database = settings.database;
          this._counter = 0;
          this._bestScore = 0;
          imagePortalMux.port = PORT_CAMERA;
          if (database !== void 0)
            lshTables.keypoints = database;
        }
        /**
         * Called just before the GPU processing
         * @returns promise
         */
        _beforeUpdate() {
          const keypointScaler = this._pipeline.node("keypointScaler");
          const screenSize = this.screenSize;
          keypointScaler.transform = ImageTrackerUtils.rasterToNIS(screenSize);
          return import_speedy_vision10.default.Promise.resolve();
        }
        /**
         * Post processing that takes place just after the GPU processing
         * @param result pipeline results
         * @returns state output
         */
        _afterUpdate(result) {
          const imagePortalMux = this._pipeline.node("imagePortalMux");
          const keypoints = result.keypoints;
          const image = result.image;
          const trackerOutput = {
            keypointsNIS: keypoints,
            polylineNDC: [],
            image
          };
          imagePortalMux.port = PORT_MEMORY;
          const matchedKeypoints = this._selectGoodMatches(keypoints);
          if (matchedKeypoints.length < SCAN_MIN_MATCHES) {
            this._counter = 0;
            this._bestScore = 0;
            return import_speedy_vision10.default.Promise.resolve({
              nextState: "scanning",
              trackerOutput
            });
          }
          const pairs = this._findMatchingPairs(matchedKeypoints);
          const points = ImageTrackerUtils.compilePairsOfKeypointsNDC(pairs);
          return this._findHomographyNDC(points).then(([homography, score]) => {
            if (score >= this._bestScore) {
              if (this._counter < SCAN_CONSECUTIVE_FRAMES - 1) {
                this._bestScore = score;
                this._bestHomography = homography;
                imagePortalMux.port = PORT_CAMERA;
              }
            }
            const polylineNDC = ImageTrackerUtils.findPolylineNDC(homography);
            trackerOutput.polylineNDC.push(...polylineNDC);
            if (++this._counter < SCAN_CONSECUTIVE_FRAMES) {
              return {
                nextState: "scanning",
                trackerOutput
              };
            }
            const snapshot = this._pipeline.node("imagePortalSink");
            const referenceImage = this._imageTracker._referenceImageOfKeypoint(
              matchedKeypoints[0].matches[0].index
            );
            if (!referenceImage)
              throw new DetectionError(`Can't track an unknown reference image`);
            return {
              nextState: "pre-tracking-a",
              nextStateSettings: {
                homography: this._bestHomography,
                snapshot,
                referenceImage
              },
              trackerOutput
            };
          }).catch((err) => {
            Utils.warning(`Error when scanning: ${err.toString()}`);
            return {
              nextState: "scanning",
              trackerOutput
            };
          });
        }
        /**
         * Select high quality matches of a single reference image
         * @param keypoints matched keypoints of any quality, to any reference image
         * @returns high quality matches of a single reference image
         */
        _selectGoodMatches(keypoints) {
          const matchedKeypointsPerImageIndex = /* @__PURE__ */ Object.create(null);
          for (let j = keypoints.length - 1; j >= 0; j--) {
            const keypoint = keypoints[j];
            if (keypoint.matches[0].index >= 0 && keypoint.matches[1].index >= 0) {
              const d1 = keypoint.matches[0].distance, d2 = keypoint.matches[1].distance;
              if (d1 <= SCAN_MATCH_RATIO * d2) {
                const idx1 = this._imageTracker._referenceImageIndexOfKeypoint(keypoint.matches[0].index);
                if (idx1 >= 0) {
                  if (!Object.prototype.hasOwnProperty.call(matchedKeypointsPerImageIndex, idx1))
                    matchedKeypointsPerImageIndex[idx1] = [];
                  matchedKeypointsPerImageIndex[idx1].push(keypoint);
                }
              }
            }
          }
          let matchedKeypoints = [];
          for (const imageIndex in matchedKeypointsPerImageIndex) {
            if (matchedKeypointsPerImageIndex[imageIndex].length > matchedKeypoints.length)
              matchedKeypoints = matchedKeypointsPerImageIndex[imageIndex];
          }
          return matchedKeypoints;
        }
        /**
         * Find a homography matrix using matched keypoints in NDC
         * @param points compiled pairs of keypoints in NDC
         * @returns homography (from reference to matched, NDC) & "quality" score
         */
        _findHomographyNDC(points) {
          return ImageTrackerUtils.findPerspectiveWarpNDC(points, {
            method: "pransac",
            reprojectionError: SCAN_RANSAC_REPROJECTIONERROR_NDC,
            numberOfHypotheses: 512 * 2,
            bundleSize: 128
          });
        }
        /**
         * Find matching pairs of keypoints from reference image (src) to matched image (dest)
         * @param matchedKeypoints
         * @returns an array of matching pairs [src, dest]
         */
        _findMatchingPairs(matchedKeypoints) {
          const pairs = new Array(matchedKeypoints.length);
          for (let i = matchedKeypoints.length - 1; i >= 0; i--) {
            const matchedKeypoint = matchedKeypoints[i];
            const referenceKeypoint = this._imageTracker._referenceKeypoint(matchedKeypoint.matches[0].index);
            if (referenceKeypoint == null)
              throw new DetectionError(`Invalid keypoint match index: ${matchedKeypoint.matches[0].index} from ${matchedKeypoint.toString()}`);
            pairs[i] = [referenceKeypoint, matchedKeypoint];
          }
          return pairs;
        }
        /**
         * Create & setup the pipeline
         * @returns pipeline
         */
        _createPipeline() {
          const pipeline = import_speedy_vision10.default.Pipeline();
          const source = import_speedy_vision10.default.Image.Source("source");
          const screen2 = import_speedy_vision10.default.Transform.Resize("screen");
          const greyscale = import_speedy_vision10.default.Filter.Greyscale();
          const blur = import_speedy_vision10.default.Filter.GaussianBlur();
          const nightvision = import_speedy_vision10.default.Filter.Nightvision();
          const nightvisionMux = import_speedy_vision10.default.Image.Multiplexer("nightvisionMux");
          const pyramid = import_speedy_vision10.default.Image.Pyramid();
          const detector = import_speedy_vision10.default.Keypoint.Detector.FAST();
          const descriptor = import_speedy_vision10.default.Keypoint.Descriptor.ORB();
          const clipper = import_speedy_vision10.default.Keypoint.Clipper();
          const lshTables = import_speedy_vision10.default.Keypoint.Matcher.StaticLSHTables("lshTables");
          const knn = import_speedy_vision10.default.Keypoint.Matcher.LSHKNN();
          const keypointScaler = import_speedy_vision10.default.Keypoint.Transformer("keypointScaler");
          const keypointSink = import_speedy_vision10.default.Keypoint.SinkOfMatchedKeypoints("keypoints");
          const imagePortalSink = import_speedy_vision10.default.Image.Portal.Sink("imagePortalSink");
          const imagePortalSource = import_speedy_vision10.default.Image.Portal.Source("imagePortalSource");
          const imagePortalMux = import_speedy_vision10.default.Image.Multiplexer("imagePortalMux");
          const imagePortalBuffer = import_speedy_vision10.default.Image.Buffer();
          const imagePortalCopy = import_speedy_vision10.default.Transform.Resize();
          source.media = null;
          screen2.size = import_speedy_vision10.default.Size(0, 0);
          blur.kernelSize = import_speedy_vision10.default.Size(ORB_GAUSSIAN_KSIZE, ORB_GAUSSIAN_KSIZE);
          blur.sigma = import_speedy_vision10.default.Vector2(ORB_GAUSSIAN_SIGMA, ORB_GAUSSIAN_SIGMA);
          nightvision.gain = NIGHTVISION_GAIN;
          nightvision.offset = NIGHTVISION_OFFSET;
          nightvision.decay = NIGHTVISION_DECAY;
          nightvision.quality = NIGHTVISION_QUALITY;
          nightvisionMux.port = SCAN_WITH_NIGHTVISION ? 1 : 0;
          detector.levels = SCAN_PYRAMID_LEVELS;
          detector.scaleFactor = SCAN_PYRAMID_SCALEFACTOR;
          detector.threshold = SCAN_FAST_THRESHOLD;
          detector.capacity = 2048;
          clipper.size = SCAN_MAX_KEYPOINTS;
          lshTables.keypoints = [];
          lshTables.numberOfTables = SCAN_LSH_TABLES;
          lshTables.hashSize = SCAN_LSH_HASHSIZE;
          knn.k = 2;
          knn.quality = "default";
          imagePortalSource.source = imagePortalSink;
          imagePortalMux.port = PORT_CAMERA;
          imagePortalCopy.size = import_speedy_vision10.default.Size(0, 0);
          imagePortalCopy.scale = import_speedy_vision10.default.Vector2(1, 1);
          keypointScaler.transform = import_speedy_vision10.default.Matrix.Eye(3);
          keypointSink.turbo = true;
          source.output().connectTo(screen2.input());
          screen2.output().connectTo(greyscale.input());
          greyscale.output().connectTo(blur.input());
          greyscale.output().connectTo(nightvisionMux.input("in0"));
          greyscale.output().connectTo(nightvision.input());
          nightvision.output().connectTo(nightvisionMux.input("in1"));
          nightvisionMux.output().connectTo(pyramid.input());
          pyramid.output().connectTo(detector.input());
          detector.output().connectTo(clipper.input());
          blur.output().connectTo(descriptor.input("image"));
          clipper.output().connectTo(descriptor.input("keypoints"));
          descriptor.output().connectTo(knn.input("keypoints"));
          lshTables.output().connectTo(knn.input("lsh"));
          clipper.output().connectTo(keypointScaler.input());
          keypointScaler.output().connectTo(keypointSink.input());
          knn.output().connectTo(keypointSink.input("matches"));
          source.output().connectTo(imagePortalBuffer.input());
          imagePortalBuffer.output().connectTo(imagePortalMux.input("in0"));
          imagePortalSource.output().connectTo(imagePortalCopy.input());
          imagePortalCopy.output().connectTo(imagePortalMux.input("in1"));
          imagePortalMux.output().connectTo(imagePortalSink.input());
          pipeline.init(
            source,
            screen2,
            greyscale,
            blur,
            nightvision,
            nightvisionMux,
            pyramid,
            detector,
            descriptor,
            clipper,
            lshTables,
            knn,
            keypointScaler,
            keypointSink,
            imagePortalSink,
            imagePortalSource,
            imagePortalMux,
            imagePortalBuffer,
            imagePortalCopy
            //, imageSink
          );
          return pipeline;
        }
      };
    }
  });

  // src/trackers/image-tracker/states/pre-tracking-a.ts
  var import_speedy_vision11, ImageTrackerPreTrackingAState;
  var init_pre_tracking_a = __esm({
    "src/trackers/image-tracker/states/pre-tracking-a.ts"() {
      "use strict";
      import_speedy_vision11 = __toESM(require_speedy_vision(), 1);
      init_image_tracker_utils();
      init_state();
      init_utils();
      init_settings();
      ImageTrackerPreTrackingAState = class extends ImageTrackerState {
        /**
         * Constructor
         * @param imageTracker
         */
        constructor(imageTracker) {
          super("pre-tracking-a", imageTracker);
          this._homography = import_speedy_vision11.default.Matrix.Eye(3);
          this._referenceImage = null;
          this._snapshot = null;
        }
        /**
         * Called as soon as this becomes the active state, just before update() runs for the first time
         * @param settings
         */
        onEnterState(settings) {
          const homography = settings.homography;
          const referenceImage = settings.referenceImage;
          const snapshot = settings.snapshot;
          this._homography = homography;
          this._referenceImage = referenceImage;
          this._snapshot = snapshot;
        }
        /**
         * Called just before the GPU processing
         * @returns promise
         */
        _beforeUpdate() {
          const screenSize = this.screenSize;
          const source = this._pipeline.node("source");
          const imageRectifier = this._pipeline.node("imageRectifier");
          const keypointScaler = this._pipeline.node("keypointScaler");
          const borderClipper = this._pipeline.node("borderClipper");
          source.media = this._referenceImage.media;
          borderClipper.imageSize = screenSize;
          borderClipper.borderSize = import_speedy_vision11.default.Vector2(
            screenSize.width * TRACK_CLIPPING_BORDER,
            screenSize.height * TRACK_CLIPPING_BORDER
          );
          keypointScaler.transform = ImageTrackerUtils.rasterToNIS(screenSize);
          const scale = TRACK_RECTIFIED_SCALE;
          const aspectRatio = ImageTrackerUtils.bestFitAspectRatioNDC(screenSize, this._referenceImage);
          const shrink = ImageTrackerUtils.bestFitScaleNDC(aspectRatio, scale);
          const toScreen = ImageTrackerUtils.NDCToRaster(screenSize);
          const toNDC = ImageTrackerUtils.rasterToNDC(screenSize);
          return imageRectifier.transform.setTo(
            toScreen.times(shrink).times(toNDC)
          ).then(() => void 0);
        }
        /**
         * Post processing that takes place just after the GPU processing
         * @param result pipeline results
         * @returns state output
         */
        _afterUpdate(result) {
          const referenceImage = this._referenceImage;
          const keypointPortalSink = this._pipeline.node("keypointPortalSink");
          const keypoints = result.keypoints;
          const image = result.image;
          const trackerOutput = {
            keypointsNIS: image !== void 0 ? keypoints : void 0,
            // debug only
            image
          };
          if (keypoints.length < PRE_TRACK_MIN_MATCHES) {
            Utils.warning(`Can't pre-track "${referenceImage.name}" in ${this.name}!`);
            return import_speedy_vision11.default.Promise.resolve({
              nextState: "scanning",
              trackerOutput
            });
          }
          return import_speedy_vision11.default.Promise.resolve({
            nextState: "pre-tracking-b",
            trackerOutput,
            nextStateSettings: {
              referenceKeypointPortalSink: keypointPortalSink,
              referenceImage: this._referenceImage,
              snapshot: this._snapshot,
              homography: this._homography
            }
          });
        }
        /**
         * Create & setup the pipeline
         * @returns pipeline
         */
        _createPipeline() {
          const pipeline = import_speedy_vision11.default.Pipeline();
          const source = import_speedy_vision11.default.Image.Source("source");
          const screen2 = import_speedy_vision11.default.Transform.Resize("screen");
          const greyscale = import_speedy_vision11.default.Filter.Greyscale();
          const imageRectifier = import_speedy_vision11.default.Transform.PerspectiveWarp("imageRectifier");
          const nightvision = import_speedy_vision11.default.Filter.Nightvision();
          const nightvisionMux = import_speedy_vision11.default.Image.Multiplexer();
          const detector = import_speedy_vision11.default.Keypoint.Detector.Harris();
          const descriptor = import_speedy_vision11.default.Keypoint.Descriptor.ORB();
          const blur = import_speedy_vision11.default.Filter.GaussianBlur();
          const clipper = import_speedy_vision11.default.Keypoint.Clipper();
          const borderClipper = import_speedy_vision11.default.Keypoint.BorderClipper("borderClipper");
          const denoiser = import_speedy_vision11.default.Filter.GaussianBlur();
          const subpixel = import_speedy_vision11.default.Keypoint.SubpixelRefiner();
          const keypointScaler = import_speedy_vision11.default.Keypoint.Transformer("keypointScaler");
          const keypointPortalSink = import_speedy_vision11.default.Keypoint.Portal.Sink("keypointPortalSink");
          const keypointSink = import_speedy_vision11.default.Keypoint.Sink("keypoints");
          source.media = null;
          imageRectifier.transform = import_speedy_vision11.default.Matrix.Eye(3);
          screen2.size = import_speedy_vision11.default.Size(0, 0);
          nightvision.gain = NIGHTVISION_GAIN;
          nightvision.offset = NIGHTVISION_OFFSET;
          nightvision.decay = NIGHTVISION_DECAY;
          nightvision.quality = NIGHTVISION_QUALITY;
          nightvisionMux.port = TRACK_WITH_NIGHTVISION ? 1 : 0;
          blur.kernelSize = import_speedy_vision11.default.Size(ORB_GAUSSIAN_KSIZE, ORB_GAUSSIAN_KSIZE);
          blur.sigma = import_speedy_vision11.default.Vector2(ORB_GAUSSIAN_SIGMA, ORB_GAUSSIAN_SIGMA);
          denoiser.kernelSize = import_speedy_vision11.default.Size(SUBPIXEL_GAUSSIAN_KSIZE, SUBPIXEL_GAUSSIAN_KSIZE);
          denoiser.sigma = import_speedy_vision11.default.Vector2(SUBPIXEL_GAUSSIAN_SIGMA, SUBPIXEL_GAUSSIAN_SIGMA);
          detector.quality = TRACK_HARRIS_QUALITY;
          detector.capacity = TRACK_DETECTOR_CAPACITY;
          subpixel.method = SUBPIXEL_METHOD;
          clipper.size = TRACK_MAX_KEYPOINTS;
          borderClipper.imageSize = screen2.size;
          borderClipper.borderSize = import_speedy_vision11.default.Vector2(0, 0);
          keypointScaler.transform = import_speedy_vision11.default.Matrix.Eye(3);
          keypointSink.turbo = false;
          source.output().connectTo(screen2.input());
          screen2.output().connectTo(greyscale.input());
          greyscale.output().connectTo(imageRectifier.input());
          imageRectifier.output().connectTo(nightvisionMux.input("in0"));
          imageRectifier.output().connectTo(nightvision.input());
          nightvision.output().connectTo(nightvisionMux.input("in1"));
          nightvisionMux.output().connectTo(detector.input());
          detector.output().connectTo(borderClipper.input());
          borderClipper.output().connectTo(clipper.input());
          imageRectifier.output().connectTo(denoiser.input());
          denoiser.output().connectTo(subpixel.input("image"));
          clipper.output().connectTo(subpixel.input("keypoints"));
          nightvisionMux.output().connectTo(blur.input());
          blur.output().connectTo(descriptor.input("image"));
          subpixel.output().connectTo(descriptor.input("keypoints"));
          descriptor.output().connectTo(keypointScaler.input());
          keypointScaler.output().connectTo(keypointSink.input());
          keypointScaler.output().connectTo(keypointPortalSink.input());
          pipeline.init(
            source,
            screen2,
            greyscale,
            imageRectifier,
            nightvision,
            nightvisionMux,
            detector,
            borderClipper,
            clipper,
            denoiser,
            subpixel,
            blur,
            descriptor,
            keypointScaler,
            keypointSink,
            keypointPortalSink
            //imageSink
          );
          return pipeline;
        }
      };
    }
  });

  // src/trackers/image-tracker/states/pre-tracking-b.ts
  var import_speedy_vision12, PORT_PORTAL, PORT_CAMERA2, ImageTrackerPreTrackingBState;
  var init_pre_tracking_b = __esm({
    "src/trackers/image-tracker/states/pre-tracking-b.ts"() {
      "use strict";
      import_speedy_vision12 = __toESM(require_speedy_vision(), 1);
      init_image_tracker_utils();
      init_state();
      init_utils();
      init_errors();
      init_settings();
      PORT_PORTAL = 0;
      PORT_CAMERA2 = 1;
      ImageTrackerPreTrackingBState = class extends ImageTrackerState {
        /**
         * Constructor
         * @param imageTracker
         */
        constructor(imageTracker) {
          super("pre-tracking-b", imageTracker);
          this._homography = import_speedy_vision12.default.Matrix.Eye(3);
          this._referenceImage = null;
          this._snapshot = null;
          this._referenceKeypointPortalSink = null;
          this._iterations = 0;
        }
        /**
         * Called as soon as this becomes the active state, just before update() runs for the first time
         * @param settings
         */
        onEnterState(settings) {
          const homography = settings.homography;
          const referenceImage = settings.referenceImage;
          const snapshot = settings.snapshot;
          const referenceKeypointPortalSink = settings.referenceKeypointPortalSink;
          const sourceMux = this._pipeline.node("sourceMux");
          const sourceBuffer = this._pipeline.node("sourceBuffer");
          this._homography = homography;
          this._referenceImage = referenceImage;
          this._snapshot = snapshot;
          this._referenceKeypointPortalSink = referenceKeypointPortalSink;
          this._iterations = 0;
          sourceMux.port = PORT_PORTAL;
          sourceBuffer.frozen = false;
        }
        /**
         * Called just before the GPU processing
         * @returns promise
         */
        _beforeUpdate() {
          const screenSize = this.screenSize;
          const imageRectifier = this._pipeline.node("imageRectifier");
          const keypointScaler = this._pipeline.node("keypointScaler");
          const borderClipper = this._pipeline.node("borderClipper");
          const imagePortalSource = this._pipeline.node("imagePortalSource");
          const referenceKeypointPortalSource = this._pipeline.node("referenceKeypointPortalSource");
          imagePortalSource.source = this._snapshot;
          referenceKeypointPortalSource.source = this._referenceKeypointPortalSink;
          borderClipper.imageSize = screenSize;
          borderClipper.borderSize = import_speedy_vision12.default.Vector2(
            screenSize.width * TRACK_CLIPPING_BORDER,
            screenSize.height * TRACK_CLIPPING_BORDER
          );
          keypointScaler.transform = ImageTrackerUtils.rasterToNIS(screenSize);
          const scale = TRACK_RECTIFIED_SCALE;
          const aspectRatio = ImageTrackerUtils.bestFitAspectRatioNDC(screenSize, this._referenceImage);
          const shrink = ImageTrackerUtils.bestFitScaleNDC(aspectRatio, scale);
          const undistort = this._homography.inverse();
          const toScreen = ImageTrackerUtils.NDCToRaster(screenSize);
          const toNDC = ImageTrackerUtils.rasterToNDC(screenSize);
          return imageRectifier.transform.setTo(
            toScreen.times(shrink.times(undistort)).times(toNDC)
          ).then(() => void 0);
        }
        /**
         * Post processing that takes place just after the GPU processing
         * @param result pipeline results
         * @returns state output
         */
        _afterUpdate(result) {
          const referenceImage = this._referenceImage;
          const referenceKeypoints = result.referenceKeypoints;
          const keypoints = result.keypoints;
          const image = result.image;
          const keypointPortalSink = this._pipeline.node("keypointPortalSink");
          const sourceMux = this._pipeline.node("sourceMux");
          const sourceBuffer = this._pipeline.node("sourceBuffer");
          const trackerOutput = {
            keypointsNIS: image !== void 0 ? keypoints : void 0,
            // debug only
            image
          };
          return import_speedy_vision12.default.Promise.resolve().then(() => {
            const pairs = this._findMatchingPairs(referenceKeypoints, keypoints);
            if (pairs.length < PRE_TRACK_MIN_MATCHES)
              throw new TrackingError("Not enough data points");
            const points = ImageTrackerUtils.compilePairsOfKeypointsNDC(pairs);
            return this._findMotionNDC(points);
          }).then((warp) => {
            sourceMux.port = PORT_CAMERA2;
            sourceBuffer.frozen = true;
            return this._homography.setTo(warp.times(this._homography));
          }).then((_) => ({
            nextState: ++this._iterations < PRE_TRACK_MAX_ITERATIONS ? "pre-tracking-b" : "tracking",
            trackerOutput,
            nextStateSettings: {
              // we export keypoints obtained in Pre-Tracking B, not in A.
              templateKeypoints: keypoints,
              templateKeypointPortalSink: keypointPortalSink,
              referenceImage: this._referenceImage,
              homography: this._homography,
              initialScreenSize: this.screenSize
            }
          })).catch((err) => {
            Utils.warning(`Can't pre-track "${referenceImage.name}" in ${this.name}! ${err.toString()}`);
            return {
              nextState: "scanning",
              trackerOutput
            };
          });
        }
        /**
         * Find a motion model in NDC between pairs of keypoints in NDC
         * given as a 2 x 2n [ src | dest ] matrix
         * @param points compiled pairs of keypoints in NDC
         * @returns a promise that resolves to a 3x3 warp in NDC that maps source to destination
         */
        _findMotionNDC(points) {
          return ImageTrackerUtils.findPerspectiveWarpNDC(points, {
            method: "pransac",
            reprojectionError: PRE_TRACK_RANSAC_REPROJECTIONERROR_NDC,
            numberOfHypotheses: 512 * 8,
            // we want a really good homography
            bundleSize: 128,
            mask: void 0
            // score is not needed
          }).then(([warp, score]) => {
            const scale = TRACK_RECTIFIED_SCALE;
            const aspectRatio = ImageTrackerUtils.bestFitAspectRatioNDC(this.screenSize, this._referenceImage);
            const shrink = ImageTrackerUtils.bestFitScaleNDC(aspectRatio, scale);
            const grow = ImageTrackerUtils.inverseBestFitScaleNDC(aspectRatio, scale);
            const scaledWarp = grow.times(warp).times(shrink);
            const distort = this._homography;
            const undistort = distort.inverse();
            const correctedWarp = distort.times(scaledWarp).times(undistort);
            return correctedWarp;
          });
        }
        /**
         * Find matching pairs of two sets of keypoints matched via brute force
         * @param srcKeypoints source (database)
         * @param destKeypoints destination
         * @returns an array of matching pairs [src, dest]
         */
        _findMatchingPairs(srcKeypoints, destKeypoints) {
          const pairs = [];
          for (let i = 0; i < destKeypoints.length; i++) {
            const destKeypoint = destKeypoints[i];
            if (destKeypoint.matches[0].index >= 0 && destKeypoint.matches[1].index >= 0) {
              const d1 = destKeypoint.matches[0].distance;
              const d2 = destKeypoint.matches[1].distance;
              if (d1 <= TRACK_MATCH_RATIO * d2) {
                const srcKeypoint = srcKeypoints[destKeypoint.matches[0].index];
                pairs.push([srcKeypoint, destKeypoint]);
              }
            }
          }
          return pairs;
        }
        /**
         * Create & setup the pipeline
         * @returns pipeline
         */
        _createPipeline() {
          const pipeline = import_speedy_vision12.default.Pipeline();
          const source = import_speedy_vision12.default.Image.Source("source");
          const imagePortalSource = import_speedy_vision12.default.Image.Portal.Source("imagePortalSource");
          const sourceMux = import_speedy_vision12.default.Image.Multiplexer("sourceMux");
          const sourceBuffer = import_speedy_vision12.default.Image.Buffer("sourceBuffer");
          const referenceKeypointPortalSource = import_speedy_vision12.default.Keypoint.Portal.Source("referenceKeypointPortalSource");
          const screen2 = import_speedy_vision12.default.Transform.Resize("screen");
          const greyscale = import_speedy_vision12.default.Filter.Greyscale();
          const imageRectifier = import_speedy_vision12.default.Transform.PerspectiveWarp("imageRectifier");
          const nightvision = import_speedy_vision12.default.Filter.Nightvision();
          const nightvisionMux = import_speedy_vision12.default.Image.Multiplexer();
          const detector = import_speedy_vision12.default.Keypoint.Detector.Harris();
          const descriptor = import_speedy_vision12.default.Keypoint.Descriptor.ORB();
          const blur = import_speedy_vision12.default.Filter.GaussianBlur();
          const clipper = import_speedy_vision12.default.Keypoint.Clipper();
          const borderClipper = import_speedy_vision12.default.Keypoint.BorderClipper("borderClipper");
          const denoiser = import_speedy_vision12.default.Filter.GaussianBlur();
          const subpixel = import_speedy_vision12.default.Keypoint.SubpixelRefiner();
          const matcher = import_speedy_vision12.default.Keypoint.Matcher.BFKNN();
          const keypointScaler = import_speedy_vision12.default.Keypoint.Transformer("keypointScaler");
          const keypointSink = import_speedy_vision12.default.Keypoint.SinkOfMatchedKeypoints("keypoints");
          const keypointPortalSink = import_speedy_vision12.default.Keypoint.Portal.Sink("keypointPortalSink");
          const referenceKeypointSink = import_speedy_vision12.default.Keypoint.Sink("referenceKeypoints");
          source.media = null;
          imagePortalSource.source = null;
          sourceMux.port = PORT_PORTAL;
          sourceBuffer.frozen = false;
          referenceKeypointPortalSource.source = null;
          imageRectifier.transform = import_speedy_vision12.default.Matrix.Eye(3);
          screen2.size = import_speedy_vision12.default.Size(0, 0);
          nightvision.gain = NIGHTVISION_GAIN;
          nightvision.offset = NIGHTVISION_OFFSET;
          nightvision.decay = NIGHTVISION_DECAY;
          nightvision.quality = NIGHTVISION_QUALITY;
          nightvisionMux.port = TRACK_WITH_NIGHTVISION ? 1 : 0;
          blur.kernelSize = import_speedy_vision12.default.Size(ORB_GAUSSIAN_KSIZE, ORB_GAUSSIAN_KSIZE);
          blur.sigma = import_speedy_vision12.default.Vector2(ORB_GAUSSIAN_SIGMA, ORB_GAUSSIAN_SIGMA);
          denoiser.kernelSize = import_speedy_vision12.default.Size(SUBPIXEL_GAUSSIAN_KSIZE, SUBPIXEL_GAUSSIAN_KSIZE);
          denoiser.sigma = import_speedy_vision12.default.Vector2(SUBPIXEL_GAUSSIAN_SIGMA, SUBPIXEL_GAUSSIAN_SIGMA);
          detector.quality = TRACK_HARRIS_QUALITY;
          detector.capacity = TRACK_DETECTOR_CAPACITY;
          subpixel.method = SUBPIXEL_METHOD;
          clipper.size = TRACK_MAX_KEYPOINTS;
          borderClipper.imageSize = screen2.size;
          borderClipper.borderSize = import_speedy_vision12.default.Vector2(0, 0);
          matcher.k = 2;
          keypointScaler.transform = import_speedy_vision12.default.Matrix.Eye(3);
          keypointSink.turbo = false;
          imagePortalSource.output().connectTo(sourceMux.input("in0"));
          source.output().connectTo(sourceBuffer.input());
          sourceBuffer.output().connectTo(sourceMux.input("in1"));
          sourceMux.output().connectTo(screen2.input());
          screen2.output().connectTo(greyscale.input());
          greyscale.output().connectTo(imageRectifier.input());
          imageRectifier.output().connectTo(nightvisionMux.input("in0"));
          imageRectifier.output().connectTo(nightvision.input());
          nightvision.output().connectTo(nightvisionMux.input("in1"));
          nightvisionMux.output().connectTo(detector.input());
          detector.output().connectTo(borderClipper.input());
          borderClipper.output().connectTo(clipper.input());
          imageRectifier.output().connectTo(denoiser.input());
          denoiser.output().connectTo(subpixel.input("image"));
          clipper.output().connectTo(subpixel.input("keypoints"));
          nightvisionMux.output().connectTo(blur.input());
          blur.output().connectTo(descriptor.input("image"));
          subpixel.output().connectTo(descriptor.input("keypoints"));
          descriptor.output().connectTo(matcher.input("keypoints"));
          referenceKeypointPortalSource.output().connectTo(matcher.input("database"));
          descriptor.output().connectTo(keypointScaler.input());
          keypointScaler.output().connectTo(keypointPortalSink.input());
          keypointScaler.output().connectTo(keypointSink.input());
          matcher.output().connectTo(keypointSink.input("matches"));
          referenceKeypointPortalSource.output().connectTo(referenceKeypointSink.input());
          pipeline.init(
            source,
            imagePortalSource,
            sourceBuffer,
            sourceMux,
            screen2,
            referenceKeypointPortalSource,
            greyscale,
            imageRectifier,
            nightvision,
            nightvisionMux,
            detector,
            borderClipper,
            clipper,
            denoiser,
            subpixel,
            blur,
            descriptor,
            matcher,
            keypointScaler,
            keypointSink,
            keypointPortalSink,
            referenceKeypointSink
            //imageSink
          );
          return pipeline;
        }
      };
    }
  });

  // src/trackers/image-tracker/image-tracker-event.ts
  var ImageTrackerEvent;
  var init_image_tracker_event = __esm({
    "src/trackers/image-tracker/image-tracker-event.ts"() {
      "use strict";
      init_ar_events();
      ImageTrackerEvent = class extends AREvent {
        /**
         * Constructor
         * @param type event type
         * @param referenceImage optional reference image
         */
        constructor(type, referenceImage) {
          super(type);
          this._referenceImage = referenceImage;
        }
        /**
         * Reference image
         */
        get referenceImage() {
          return this._referenceImage;
        }
      };
    }
  });

  // src/geometry/quaternion.ts
  var import_speedy_vision13, EPSILON, Quaternion;
  var init_quaternion = __esm({
    "src/geometry/quaternion.ts"() {
      "use strict";
      import_speedy_vision13 = __toESM(require_speedy_vision(), 1);
      init_errors();
      EPSILON = 1e-6;
      Quaternion = class _Quaternion {
        /**
         * Constructor
         * @param x x coordinate (imaginary)
         * @param y y coordinate (imaginary)
         * @param z z coordinate (imaginary)
         * @param w w coordinate (real)
         */
        constructor(x = 0, y = 0, z = 0, w = 1) {
          this._x = +x;
          this._y = +y;
          this._z = +z;
          this._w = +w;
        }
        /**
         * Instantiate an identity quaternion q = 1
         * @returns a new identity quaternion
         */
        static Identity() {
          return new _Quaternion(0, 0, 0, 1);
        }
        /**
         * The x coordinate of the quaternion (imaginary)
         */
        get x() {
          return this._x;
        }
        /**
         * The y coordinate of the quaternion (imaginary)
         */
        get y() {
          return this._y;
        }
        /**
         * The z coordinate of the quaternion (imaginary)
         */
        get z() {
          return this._z;
        }
        /**
         * The w coordinate of the quaternion (real)
         */
        get w() {
          return this._w;
        }
        /**
         * The length of this quaternion
         * @returns sqrt(x^2 + y^2 + z^2 + w^2)
         */
        length() {
          const x = this._x;
          const y = this._y;
          const z = this._z;
          const w = this._w;
          return Math.sqrt(x * x + y * y + z * z + w * w);
        }
        /**
         * Check if this and q have the same coordinates
         * @param q a quaternion
         * @returns true if this and q have the same coordinates
         */
        equals(q) {
          return this._w === q._w && this._x === q._x && this._y === q._y && this._z === q._z;
        }
        /**
         * Convert to string
         * @returns a string
         */
        toString() {
          const x = this._x.toFixed(4);
          const y = this._y.toFixed(4);
          const z = this._z.toFixed(4);
          const w = this._w.toFixed(4);
          return `Quaternion(${x},${y},${z},${w})`;
        }
        /**
         * Normalize this quaternion
         * @returns this quaternion, normalized
         * @internal
         */
        _normalize() {
          const length = this.length();
          if (length < EPSILON)
            return this;
          this._x /= length;
          this._y /= length;
          this._z /= length;
          this._w /= length;
          return this;
        }
        /**
         * Conjugate this quaternion
         * @returns this quaternion, conjugated
         * @internal
         */
        _conjugate() {
          this._x = -this._x;
          this._y = -this._y;
          this._z = -this._z;
          return this;
        }
        /**
         * Set the coordinates of this quaternion
         * @param x x-coordinate
         * @param y y-coordinate
         * @param z z-coordinate
         * @param w w-coordinate
         * @returns this quaternion
         * @internal
         */
        _set(x, y, z, w) {
          this._x = +x;
          this._y = +y;
          this._z = +z;
          this._w = +w;
          return this;
        }
        /**
         * Copy q to this
         * @param q a quaternion
         * @returns this quaternion
         * @internal
         */
        _copyFrom(q) {
          this._x = q._x;
          this._y = q._y;
          this._z = q._z;
          this._w = q._w;
          return this;
        }
        /**
         * Convert a quaternion to a 3x3 rotation matrix
         * @returns a 3x3 rotation matrix
         * @internal
         */
        _toRotationMatrix() {
          const length = this.length();
          if (length < EPSILON)
            return import_speedy_vision13.default.Matrix.Eye(3);
          const x = this._x / length;
          const y = this._y / length;
          const z = this._z / length;
          const w = this._w / length;
          const x2 = x * x, y2 = y * y, z2 = z * z;
          const xy = 2 * x * y, xz = 2 * x * z, yz = 2 * y * z;
          const wx = 2 * w * x, wy = 2 * w * y, wz = 2 * w * z;
          return import_speedy_vision13.default.Matrix(3, 3, [
            1 - 2 * (y2 + z2),
            xy + wz,
            xz - wy,
            xy - wz,
            1 - 2 * (x2 + z2),
            yz + wx,
            xz + wy,
            yz - wx,
            1 - 2 * (x2 + y2)
          ]);
        }
        /**
         * Convert a 3x3 rotation matrix to a unit quaternion
         * @param m a 3x3 rotation matrix. You should ensure that it is a rotation matrix
         * @returns this quaternion
         * @internal
         */
        _fromRotationMatrix(m) {
          if (m.rows != 3 || m.columns != 3)
            throw new IllegalArgumentError();
          const data = m.read();
          const m11 = data[0], m21 = data[1], m31 = data[2], m12 = data[3], m22 = data[4], m32 = data[5], m13 = data[6], m23 = data[7], m33 = data[8];
          const tr = 1 + m11 + m22 + m33;
          const sx = +(m32 >= m23) - +(m32 < m23);
          const sy = +(m13 >= m31) - +(m13 < m31);
          const sz = +(m21 >= m12) - +(m21 < m12);
          const w = 0.5 * Math.sqrt(Math.max(0, tr));
          const x = 0.5 * Math.sqrt(Math.max(0, tr - 2 * (m22 + m33)));
          const y = 0.5 * Math.sqrt(Math.max(0, tr - 2 * (m11 + m33)));
          const z = 0.5 * Math.sqrt(Math.max(0, tr - 2 * (m11 + m22)));
          const length = Math.sqrt(x * x + y * y + z * z + w * w);
          this._x = x * sx / length;
          this._y = y * sy / length;
          this._z = z * sz / length;
          this._w = w / length;
          return this;
        }
        /**
         * Clone this quaternion
         * @returns a clone of this quaternion
         * @internal
         */
        _clone() {
          return new _Quaternion(this._x, this._y, this._z, this._w);
        }
      };
    }
  });

  // src/geometry/vector3.ts
  var EPSILON2, ZERO, Vector3;
  var init_vector3 = __esm({
    "src/geometry/vector3.ts"() {
      "use strict";
      EPSILON2 = 1e-6;
      ZERO = null;
      Vector3 = class _Vector3 {
        /**
         * Constructor
         */
        constructor(x = 0, y = 0, z = 0) {
          this._x = +x;
          this._y = +y;
          this._z = +z;
        }
        /**
         * Instantiate a zero vector
         * @returns a new zero vector
         */
        static Zero() {
          return new _Vector3(0, 0, 0);
        }
        /**
         * Immutable zero vector
         * @returns an immutable zero vector
         */
        static get ZERO() {
          return ZERO || (ZERO = Object.freeze(_Vector3.Zero()));
        }
        /**
         * The x coordinate of the vector
         */
        get x() {
          return this._x;
        }
        /**
         * The y coordinate of the vector
         */
        get y() {
          return this._y;
        }
        /**
         * The z coordinate of the vector
         */
        get z() {
          return this._z;
        }
        /**
         * The length of this vector
         * @returns sqrt(x^2 + y^2 + z^2)
         */
        length() {
          const x = this._x;
          const y = this._y;
          const z = this._z;
          return Math.sqrt(x * x + y * y + z * z);
        }
        /**
         * Compute the dot product of this and v
         * @param v a vector
         * @returns the dot product of the vectors
         */
        dot(v) {
          return this._x * v._x + this._y * v._y + this._z * v._z;
        }
        /**
         * Compute the distance between points this and v
         * @param v a vector / point
         * @returns the distance between the points
         */
        distanceTo(v) {
          const dx = this._x - v._x;
          const dy = this._y - v._y;
          const dz = this._z - v._z;
          return Math.sqrt(dx * dx + dy * dy + dz * dz);
        }
        /**
         * Compute the direction from this to v
         * @param v a vector
         * @returns a new unit vector pointing to v from this
         */
        directionTo(v) {
          return v._clone()._subtract(this)._normalize();
        }
        /**
         * The cross product of this and v
         * @param v a vector
         * @returns the cross product this x v
         */
        cross(v) {
          const x = this._y * v._z - this._z * v._y;
          const y = this._z * v._x - this._x * v._z;
          const z = this._x * v._y - this._y * v._x;
          return new _Vector3(x, y, z);
        }
        /**
         * Compute a unit vector with the same direction as this
         * @returns a new unit vector with the same direction as this
         */
        normalized() {
          return this._clone()._normalize();
        }
        /**
         * Compute the sum between this vector and v
         * @param v a vector
         * @returns a new vector equal to the sum between this and v
         */
        plus(v) {
          return this._clone()._add(v);
        }
        /**
         * Compute the difference between this vector and v
         * @param v a vector
         * @returns a new vector equal to the difference this - v
         */
        minus(v) {
          return this._clone()._subtract(v);
        }
        /**
         * Compute the multiplication between this vector and a scale factor
         * @param scale scalar quantity
         * @returns a new vector equal to the multiplication between this and the scale factor
         */
        times(scale) {
          return this._clone()._scale(scale);
        }
        /**
         * Check if this and v have the same coordinates
         * @param v a vector
         * @returns true if this and v have the same coordinates
         */
        equals(v) {
          return this._x === v._x && this._y === v._y && this._z === v._z;
        }
        /**
         * Convert to string
         * @returns a string
         */
        toString() {
          const x = this._x.toFixed(5);
          const y = this._y.toFixed(5);
          const z = this._z.toFixed(5);
          return `Vector3(${x},${y},${z})`;
        }
        /**
         * Set the coordinates of this vector
         * @param x x-coordinate
         * @param y y-coordinate
         * @param z z-coordinate
         * @returns this vector
         * @internal
         */
        _set(x, y, z) {
          this._x = +x;
          this._y = +y;
          this._z = +z;
          return this;
        }
        /**
         * Copy v to this
         * @param v a vector
         * @returns this vector
         * @internal
         */
        _copyFrom(v) {
          this._x = v._x;
          this._y = v._y;
          this._z = v._z;
          return this;
        }
        /**
         * Normalize this vector
         * @returns this vector, normalized
         * @internal
         */
        _normalize() {
          const length = this.length();
          if (length < EPSILON2)
            return this;
          this._x /= length;
          this._y /= length;
          this._z /= length;
          return this;
        }
        /**
         * Add v to this vector
         * @param v a vector
         * @returns this vector
         * @internal
         */
        _add(v) {
          this._x += v._x;
          this._y += v._y;
          this._z += v._z;
          return this;
        }
        /**
         * Subtract v from this vector
         * @param v a vector
         * @returns this vector
         * @internal
         */
        _subtract(v) {
          this._x -= v._x;
          this._y -= v._y;
          this._z -= v._z;
          return this;
        }
        /**
         * Scale this vector by a scalar
         * @param s scalar
         * @returns this vector
         * @internal
         */
        _scale(s) {
          this._x *= s;
          this._y *= s;
          this._z *= s;
          return this;
        }
        /**
         * Compute the rotation q p q* in place, where q is a unit quaternion,
         * q* is its conjugate and multiplicative inverse, and p is this vector
         * @param q unit quaternion
         * @returns this vector
         * @internal
         */
        _applyRotationQuaternion(q) {
          const x = q.x, y = q.y, z = q.z, w = q.w;
          const vx = this._x, vy = this._y, vz = this._z;
          const x2 = x * x, y2 = y * y, z2 = z * z;
          const xy = 2 * x * y, xz = 2 * x * z, yz = 2 * y * z;
          const wx = 2 * w * x, wy = 2 * w * y, wz = 2 * w * z;
          this._x = (1 - 2 * (y2 + z2)) * vx + (xy - wz) * vy + (xz + wy) * vz;
          this._y = (xy + wz) * vx + (1 - 2 * (x2 + z2)) * vy + (yz - wx) * vz;
          this._z = (xz - wy) * vx + (yz + wx) * vy + (1 - 2 * (x2 + y2)) * vz;
          return this;
        }
        /**
         * Clone this vector
         * @returns a clone of this vector
         * @internal
         */
        _clone() {
          return new _Vector3(this._x, this._y, this._z);
        }
      };
    }
  });

  // src/geometry/pose-filter.ts
  var import_speedy_vision14, TRANSLATION_SAMPLES, ROTATION_SAMPLES, NO_TRANSLATION, NO_ROTATION, ZERO_QUATERNION, PoseFilter;
  var init_pose_filter = __esm({
    "src/geometry/pose-filter.ts"() {
      "use strict";
      import_speedy_vision14 = __toESM(require_speedy_vision(), 1);
      init_settings2();
      init_quaternion();
      init_vector3();
      init_errors();
      TRANSLATION_SAMPLES = 5;
      ROTATION_SAMPLES = 12;
      NO_TRANSLATION = Vector3.Zero();
      NO_ROTATION = Quaternion.Identity();
      ZERO_QUATERNION = new Quaternion(0, 0, 0, 0);
      PoseFilter = class {
        /**
         * Constructor
         */
        constructor() {
          this._smoothRotation = Quaternion.Identity();
          this._smoothTranslation = Vector3.Zero();
          this._rotationSample = Array.from({ length: ROTATION_SAMPLES }, () => Quaternion.Identity());
          this._translationSample = Array.from({ length: TRANSLATION_SAMPLES }, () => Vector3.Zero());
          this._isEmpty = true;
        }
        /**
         * Reset the filter
         */
        reset() {
          this._rotationSample.forEach((q) => q._copyFrom(NO_ROTATION));
          this._translationSample.forEach((t) => t._copyFrom(NO_TRANSLATION));
          this._isEmpty = true;
        }
        /**
         * Feed the filter with a sample
         * @param sample 3x4 [ R | t ] matrix
         * @returns true on success
         */
        feed(sample) {
          const data = sample.read();
          if (sample.rows != 3 || sample.columns != 4)
            throw new IllegalArgumentError();
          if (Number.isNaN(data[0] * data[9]))
            return false;
          const q = this._rotationSample[ROTATION_SAMPLES - 1];
          for (let i = ROTATION_SAMPLES - 1; i > 0; i--)
            this._rotationSample[i] = this._rotationSample[i - 1];
          this._rotationSample[0] = q._fromRotationMatrix(sample.block(0, 2, 0, 2));
          const t = this._translationSample[TRANSLATION_SAMPLES - 1];
          for (let i = TRANSLATION_SAMPLES - 1; i > 0; i--)
            this._translationSample[i] = this._translationSample[i - 1];
          this._translationSample[0] = t._set(data[9], data[10], data[11]);
          if (this._isEmpty) {
            this._rotationSample.forEach((q2, i) => i > 0 && q2._copyFrom(this._rotationSample[0]));
            this._translationSample.forEach((t2, i) => i > 0 && t2._copyFrom(this._translationSample[0]));
            this._isEmpty = false;
          }
          return true;
        }
        /**
         * Run the filter
         * @returns a 3x4 [ R | t ] matrix
         */
        output() {
          const div = Settings.powerPreference == "low-power" ? 1.5 : 1;
          const T = Math.ceil(TRANSLATION_SAMPLES / div);
          const R = Math.ceil(ROTATION_SAMPLES / div);
          const t = this._smoothTranslation._copyFrom(NO_TRANSLATION);
          const q = this._smoothRotation._copyFrom(ZERO_QUATERNION);
          for (let i = 0, d = 2 / (T * T + T); i < T; i++) {
            const ti = this._translationSample[i];
            const w = (T - i) * d;
            t._set(
              t.x + ti.x * w,
              t.y + ti.y * w,
              t.z + ti.z * w
            );
          }
          for (let i = 0; i < R; i++) {
            const qi = this._rotationSample[i];
            const w = 1 / R;
            if (qi.w < 0) {
              qi._set(
                -qi.x,
                -qi.y,
                -qi.z,
                -qi.w
              );
            }
            q._set(
              q.x + qi.x * w,
              q.y + qi.y * w,
              q.z + qi.z * w,
              q.w + qi.w * w
            );
          }
          const entries = q._toRotationMatrix().read();
          entries.push(t.x, t.y, t.z);
          return import_speedy_vision14.default.Matrix(3, 4, entries);
        }
      };
    }
  });

  // src/geometry/camera-model.ts
  var import_speedy_vision15, HFOV_GUESS, DEFAULT_SCALE, DEG2RAD, EPSILON3, FX, FY, U0, V0, POSE_REFINEMENT_ITERATIONS, TRANSLATION_REFINEMENT_ITERATIONS, TRANSLATION_REFINEMENT_TOLERANCE, TRANSLATION_REFINEMENT_GRIDSIZE, CameraModel;
  var init_camera_model = __esm({
    "src/geometry/camera-model.ts"() {
      "use strict";
      import_speedy_vision15 = __toESM(require_speedy_vision(), 1);
      init_utils();
      init_pose_filter();
      init_errors();
      HFOV_GUESS = 60;
      DEFAULT_SCALE = 2;
      DEG2RAD = 0.017453292519943295;
      EPSILON3 = 1e-6;
      FX = 0;
      FY = 4;
      U0 = 6;
      V0 = 7;
      POSE_REFINEMENT_ITERATIONS = 30;
      TRANSLATION_REFINEMENT_ITERATIONS = 15;
      TRANSLATION_REFINEMENT_TOLERANCE = DEFAULT_SCALE * 0.01;
      TRANSLATION_REFINEMENT_GRIDSIZE = 5;
      CameraModel = class {
        /**
         * Constructor
         */
        constructor() {
          this._imageSize = import_speedy_vision15.default.Size(0, 0);
          this._matrix = import_speedy_vision15.default.Matrix.Eye(3, 4);
          this._intrinsics = [1, 0, 0, 0, 1, 0, 0, 0, 1];
          this._extrinsics = [1, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0];
          this._filter = new PoseFilter();
          this._flipZ = import_speedy_vision15.default.Matrix(4, 4, [
            1,
            0,
            0,
            0,
            0,
            1,
            0,
            0,
            0,
            0,
            -1,
            0,
            0,
            0,
            0,
            1
          ]);
        }
        /**
         * Initialize the model
         * @param aspectRatio aspect ratio of the image plane
         * @param scale optional scale factor of the image plane
         */
        init(aspectRatio, scale = DEFAULT_SCALE) {
          Utils.log(`Initializing the camera model...`);
          Utils.assert(aspectRatio > 0 && scale > 1e-5);
          if (aspectRatio >= 1) {
            this._imageSize.width = aspectRatio * scale;
            this._imageSize.height = scale;
          } else {
            this._imageSize.width = scale;
            this._imageSize.height = scale / aspectRatio;
          }
          this.reset();
        }
        /**
         * Release the model
         */
        release() {
          this.reset();
          return null;
        }
        /**
         * Update the camera model
         * @param homographyNDC 3x3 perspective transform
         * @returns a promise that resolves to a camera matrix
         */
        update(homographyNDC) {
          Utils.assert(homographyNDC.rows == 3 && homographyNDC.columns == 3);
          const homography = this._convertToImageSpace(homographyNDC);
          const h = homography.read();
          const h11 = h[0], h12 = h[3], h13 = h[6], h21 = h[1], h22 = h[4], h23 = h[7], h31 = h[2], h32 = h[5], h33 = h[8];
          const det = h13 * (h21 * h32 - h22 * h31) - h23 * (h11 * h32 - h12 * h31) + h33 * (h11 * h22 - h12 * h21);
          if (Math.abs(det) < EPSILON3 || Number.isNaN(det))
            return import_speedy_vision15.default.Promise.reject(new NumericalError(`Can't update the camera model using an invalid homography matrix`));
          const pose = this._estimatePose(homography);
          if (this._filter.feed(pose))
            this._extrinsics = this._filter.output().read();
          const Z = this._flipZ;
          const K = import_speedy_vision15.default.Matrix(3, 3, this._intrinsics);
          const E = import_speedy_vision15.default.Matrix(3, 4, this._extrinsics);
          this._matrix.setToSync(K.times(E).times(Z));
          return import_speedy_vision15.default.Promise.resolve(this._matrix);
        }
        /**
         * Reset the camera model
         */
        reset() {
          this._resetIntrinsics();
          this._resetExtrinsics();
        }
        /**
         * The 3x4 camera matrix
         */
        get matrix() {
          return this._matrix;
        }
        /**
         * The size of the image plane
         */
        get imageSize() {
          return this._imageSize;
        }
        /**
         * The aspect ratio of the image
         */
        get aspectRatio() {
          return this._imageSize.width / this._imageSize.height;
        }
        /**
         * Focal length in "pixels" (projection distance in the pinhole camera model)
         * same as (focal length in mm) * (number of "pixels" per world unit in "pixels"/mm)
         * "pixels" means image plane units
         */
        get focalLength() {
          return this._intrinsics[FX];
        }
        /**
         * Horizontal field-of-view, given in radians
         */
        get fovx() {
          const halfWidth = this._imageSize.width / 2;
          return 2 * Math.atan(halfWidth / this._intrinsics[FX]);
        }
        /**
         * Vertical field-of-view, given in radians
         */
        get fovy() {
          const halfHeight = this._imageSize.height / 2;
          return 2 * Math.atan(halfHeight / this._intrinsics[FY]);
        }
        /**
         * Compute the view matrix. This 4x4 matrix moves 3D points from
         * world space to view space. We want the camera looking in the
         * direction of the negative z-axis (WebGL-friendly)
         * @returns a view matrix
         */
        computeViewMatrix() {
          const E = this._extrinsics;
          return import_speedy_vision15.default.Matrix(4, 4, [
            E[0],
            E[1],
            -E[2],
            0,
            // r1
            E[3],
            E[4],
            -E[5],
            0,
            // r2
            -E[6],
            -E[7],
            +E[8],
            0,
            // r3
            E[9],
            E[10],
            -E[11],
            1
            // t
          ]);
        }
        /**
         * Compute a perspective projection matrix for WebGL
         * @param near distance of the near plane
         * @param far distance of the far plane
         */
        computeProjectionMatrix(near, far) {
          const fx = this._intrinsics[FX];
          const fy = this._intrinsics[FY];
          const halfWidth = this._imageSize.width / 2;
          const halfHeight = this._imageSize.height / 2;
          const right = near * (halfWidth / fx);
          const top = near * (halfHeight / fy);
          const bottom = -top, left = -right;
          return import_speedy_vision15.default.Matrix(4, 4, [
            2 * near / (right - left),
            0,
            0,
            0,
            0,
            2 * near / (top - bottom),
            0,
            0,
            (right + left) / (right - left),
            (top + bottom) / (top - bottom),
            -(far + near) / (far - near),
            -1,
            0,
            0,
            -2 * far * near / (far - near),
            0
          ]);
        }
        /**
         * Reset camera extrinsics
         */
        _resetExtrinsics() {
          this._extrinsics.fill(0);
          this._extrinsics[0] = this._extrinsics[4] = this._extrinsics[8] = 1;
          this._filter.reset();
        }
        /**
         * Reset camera intrinsics
         */
        _resetIntrinsics() {
          const cameraWidth = Math.max(this._imageSize.width, this._imageSize.height);
          const u0 = 0;
          const v0 = 0;
          const fx = cameraWidth / 2 / Math.tan(DEG2RAD * HFOV_GUESS / 2);
          const fy = fx;
          this._intrinsics[FX] = fx;
          this._intrinsics[FY] = fy;
          this._intrinsics[U0] = u0;
          this._intrinsics[V0] = v0;
        }
        /**
         * Convert a homography from NDC to image space
         * @param homographyNDC
         * @returns a new homography
         */
        _convertToImageSpace(homographyNDC) {
          const w = this._imageSize.width / 2;
          const h = this._imageSize.height / 2;
          const fromNDC = import_speedy_vision15.default.Matrix(3, 3, [
            w,
            0,
            0,
            0,
            h,
            0,
            0,
            0,
            1
          ]);
          return import_speedy_vision15.default.Matrix(fromNDC.times(homographyNDC));
        }
        /**
         * Compute a normalized homography H^ = K^(-1) * H for an
         * ideal pinhole with f = 1 and principal point = (0,0)
         * @param homography homography H to be normalized
         * @returns normalized homography H^
         */
        _normalizeHomography(homography) {
          const u0 = this._intrinsics[U0];
          const v0 = this._intrinsics[V0];
          const fx = this._intrinsics[FX];
          const fy = this._intrinsics[FY];
          const u0fx = u0 / fx;
          const v0fy = v0 / fy;
          const h = homography.read();
          const h11 = h[0] / fx - u0fx * h[2], h12 = h[3] / fx - u0fx * h[5], h13 = h[6] / fx - u0fx * h[8];
          const h21 = h[1] / fy - v0fy * h[2], h22 = h[4] / fy - v0fy * h[5], h23 = h[7] / fy - v0fy * h[8];
          const h31 = h[2], h32 = h[5], h33 = h[8];
          return import_speedy_vision15.default.Matrix(3, 3, [
            h11,
            h21,
            h31,
            h12,
            h22,
            h32,
            h13,
            h23,
            h33
          ]);
        }
        /**
         * Estimate [ r1 | r2 | t ], where r1, r2 are orthonormal and t is a translation vector
         * @param normalizedHomography based on the ideal pinhole (where calibration K = I)
         * @returns a 3x3 matrix
         */
        _estimatePartialPose(normalizedHomography) {
          const h = normalizedHomography.read();
          const h11 = h[0], h12 = h[3], h13 = h[6];
          const h21 = h[1], h22 = h[4], h23 = h[7];
          const h31 = h[2], h32 = h[5], h33 = h[8];
          const h1norm2 = h11 * h11 + h21 * h21 + h31 * h31;
          const h2norm2 = h12 * h12 + h22 * h22 + h32 * h32;
          const h1norm = Math.sqrt(h1norm2);
          const h2norm = Math.sqrt(h2norm2);
          const hnorm = Math.max(h1norm, h2norm);
          const sign = h33 >= 0 ? 1 : -1;
          let scale = sign / hnorm;
          if (Number.isNaN(scale))
            return import_speedy_vision15.default.Matrix(3, 3, new Array(9).fill(Number.NaN));
          let r = new Array(6);
          r[0] = scale * h11;
          r[1] = scale * h21;
          r[2] = scale * h31;
          r[3] = scale * h12;
          r[4] = scale * h22;
          r[5] = scale * h32;
          r = this._refineRotation(r);
          scale = r[0] * h11 + r[1] * h21 + r[2] * h31;
          scale += r[3] * h12 + r[4] * h22 + r[5] * h32;
          scale /= h1norm2 + h2norm2;
          let t = new Array(3);
          t[0] = scale * h13;
          t[1] = scale * h23;
          t[2] = scale * h33;
          return import_speedy_vision15.default.Matrix(3, 3, r.concat(t));
        }
        /**
         * Make two non-zero and non-parallel input vectors, r1 and r2, orthonormal
         * @param rot rotation vectors [ r1 | r2 ] in column-major format
         * @returns a 3x2 matrix R such that R'R = I (column-major format)
         */
        _refineRotation(rot) {
          const [r11, r21, r31, r12, r22, r32] = rot;
          const r1tr1 = r11 * r11 + r21 * r21 + r31 * r31;
          const r2tr2 = r12 * r12 + r22 * r22 + r32 * r32;
          const r1tr2 = r11 * r12 + r21 * r22 + r31 * r32;
          const delta = (r1tr1 - r2tr2) * (r1tr1 - r2tr2) + 4 * r1tr2 * r1tr2;
          const sqrt = Math.sqrt(delta);
          const eigval1 = (r1tr1 + r2tr2 + sqrt) / 2;
          const eigval2 = (r1tr1 + r2tr2 - sqrt) / 2;
          const alpha1 = r2tr2 - eigval1 - r1tr2 * (1 + r1tr2) / (r1tr1 - eigval1);
          const x1 = Math.sqrt(alpha1 * alpha1 / (1 + alpha1 * alpha1));
          const y1 = x1 / alpha1;
          const alpha2 = r2tr2 - eigval2 - r1tr2 * (1 + r1tr2) / (r1tr1 - eigval2);
          const x2 = Math.sqrt(alpha2 * alpha2 / (1 + alpha2 * alpha2));
          const y2 = x2 / alpha2;
          const s1 = Math.sqrt(eigval1), s2 = Math.sqrt(eigval2);
          const a = x1 * x1 / s1 + x2 * x2 / s2;
          const b = x1 * y1 / s1 + x2 * y2 / s2;
          const c = y1 * y1 / s1 + y2 * y2 / s2;
          return [
            a * r11 + b * r12,
            a * r21 + b * r22,
            a * r31 + b * r32,
            b * r11 + c * r12,
            b * r21 + c * r22,
            b * r31 + c * r32
          ];
        }
        /**
         * Compute a refined translation vector
         * @param normalizedHomography ideal pinhole K = I
         * @param rot rotation vectors [ r1 | r2 ] in column-major format
         * @param t0 initial estimate for the translation vector
         * @returns 3x1 translation vector in column-major format
         */
        _refineTranslation(normalizedHomography, rot, t0) {
          const h = normalizedHomography.read();
          const h11 = h[0], h12 = h[3], h13 = h[6];
          const h21 = h[1], h22 = h[4], h23 = h[7];
          const h31 = h[2], h32 = h[5], h33 = h[8];
          const r11 = rot[0], r12 = rot[3];
          const r21 = rot[1], r22 = rot[4];
          const r31 = rot[2], r32 = rot[5];
          const g = TRANSLATION_REFINEMENT_GRIDSIZE;
          const x = new Array(g * g);
          const y = new Array(g * g);
          const halfWidth = this._imageSize.width / 2;
          const halfHeight = this._imageSize.height / 2;
          for (let k = 0, i = 0; i < g; i++) {
            for (let j = 0; j < g; j++, k++) {
              x[k] = i / (g - 1) * 2 - 1;
              y[k] = j / (g - 1) * 2 - 1;
              x[k] *= halfWidth;
              y[k] *= halfHeight;
            }
          }
          const n = x.length;
          const a1 = new Array(n);
          const a2 = new Array(n);
          const a3 = new Array(n);
          for (let i = 0; i < n; i++) {
            a1[i] = x[i] * h11 + y[i] * h12 + h13;
            a2[i] = x[i] * h21 + y[i] * h22 + h23;
            a3[i] = x[i] * h31 + y[i] * h32 + h33;
          }
          const n3 = 3 * n;
          const m = new Array(n3 * 3);
          const v = new Array(n3);
          for (let i = 0, k = 0; k < n; i += 3, k++) {
            m[i] = m[i + n3 + 1] = m[i + n3 + n3 + 2] = 0;
            m[i + n3] = -(m[i + 1] = a3[k]);
            m[i + 2] = -(m[i + n3 + n3] = a2[k]);
            m[i + n3 + n3 + 1] = -(m[i + n3 + 2] = a1[k]);
            v[i] = a3[k] * (x[k] * r21 + y[k] * r22) - a2[k] * (x[k] * r31 + y[k] * r32);
            v[i + 1] = -a3[k] * (x[k] * r11 + y[k] * r12) + a1[k] * (x[k] * r31 + y[k] * r32);
            v[i + 2] = a2[k] * (x[k] * r11 + y[k] * r12) - a1[k] * (x[k] * r21 + y[k] * r22);
          }
          const r = new Array(3 * n);
          const c = new Array(3);
          const Mc = new Array(3 * n);
          const t = new Array(3);
          t[0] = t0[0];
          t[1] = t0[1];
          t[2] = t0[2];
          for (let it = 0; it < TRANSLATION_REFINEMENT_ITERATIONS; it++) {
            for (let i = 0; i < n3; i++) {
              r[i] = 0;
              for (let j = 0; j < 3; j++)
                r[i] += m[j * n3 + i] * t[j];
              r[i] -= v[i];
            }
            for (let i = 0; i < 3; i++) {
              c[i] = 0;
              for (let j = 0; j < n3; j++)
                c[i] += m[i * n3 + j] * r[j];
            }
            for (let i = 0; i < n3; i++) {
              Mc[i] = 0;
              for (let j = 0; j < 3; j++)
                Mc[i] += m[j * n3 + i] * c[j];
            }
            let num = 0;
            for (let i = 0; i < 3; i++)
              num += c[i] * c[i];
            if (num < TRANSLATION_REFINEMENT_TOLERANCE)
              break;
            let den = 0;
            for (let i = 0; i < n3; i++)
              den += Mc[i] * Mc[i];
            const frc = num / den;
            if (Number.isNaN(frc))
              break;
            for (let i = 0; i < 3; i++)
              t[i] -= frc * c[i];
          }
          return t;
        }
        /**
         * Find a 3x3 rotation matrix R given two orthonormal vectors [ r1 | r2 ]
         * @param partialRotation partial rotation matrix [ r1 | r2 ] in column-major format
         * @returns a rotation matrix R in column-major format
         */
        _computeFullRotation(partialRotation) {
          const r11 = partialRotation[0], r12 = partialRotation[3];
          const r21 = partialRotation[1], r22 = partialRotation[4];
          const r31 = partialRotation[2], r32 = partialRotation[5];
          let r13 = r21 * r32 - r31 * r22;
          let r23 = r31 * r12 - r11 * r32;
          let r33 = r11 * r22 - r21 * r12;
          const det = r11 * (r22 * r33 - r23 * r32) - r21 * (r12 * r33 - r13 * r32) + r31 * (r12 * r23 - r13 * r22);
          if (det < 0) {
            r13 = -r13;
            r23 = -r23;
            r33 = -r33;
          }
          return [
            r11,
            r21,
            r31,
            r12,
            r22,
            r32,
            r13,
            r23,
            r33
          ];
        }
        /**
         * Estimate the pose [ R | t ] given a homography in sensor space
         * @param homography must be valid
         * @returns 3x4 matrix
         */
        _estimatePose(homography) {
          const normalizedHomography = this._normalizeHomography(homography);
          const partialPose = import_speedy_vision15.default.Matrix.Eye(3);
          const residual = import_speedy_vision15.default.Matrix(normalizedHomography);
          for (let k = 0; k < POSE_REFINEMENT_ITERATIONS; k++) {
            const rt = this._estimatePartialPose(residual);
            partialPose.setToSync(rt.times(partialPose));
            residual.setToSync(residual.times(rt.inverse()));
          }
          const mat = partialPose.read();
          const r0 = mat.slice(0, 6);
          const t0 = mat.slice(6, 9);
          const t = this._refineTranslation(normalizedHomography, r0, t0);
          const r = this._computeFullRotation(r0);
          return import_speedy_vision15.default.Matrix(3, 4, r.concat(t));
        }
      };
    }
  });

  // src/geometry/pose.ts
  var Pose;
  var init_pose = __esm({
    "src/geometry/pose.ts"() {
      "use strict";
      Pose = class {
        /**
         * Constructor
         * @param transform usually a rigid transform in a 3D space (e.g., world space, viewer space or other)
         */
        constructor(transform) {
          this._transform = transform;
        }
        /**
         * A transform describing the position and the orientation
         * of the pose relative to the 3D space to which it belongs
         */
        get transform() {
          return this._transform;
        }
      };
    }
  });

  // src/geometry/transform.ts
  var import_speedy_vision16, EPSILON4, Transform;
  var init_transform = __esm({
    "src/geometry/transform.ts"() {
      "use strict";
      import_speedy_vision16 = __toESM(require_speedy_vision(), 1);
      init_errors();
      init_vector3();
      init_quaternion();
      EPSILON4 = 1e-6;
      Transform = class _Transform {
        /**
         * Constructor
         * @param matrix a 4x4 transformation matrix. You should ensure that its form is T * R * S (translation * rotation * scale).
         */
        constructor(matrix) {
          if (matrix.rows != 4 || matrix.columns != 4)
            throw new IllegalArgumentError("A Transform expects a 4x4 transformation matrix");
          this._matrix = matrix;
          this._inverse = null;
          this._position = Vector3.Zero();
          this._orientation = Quaternion.Identity();
          this._scale = new Vector3(1, 1, 1);
          this._isDecomposed = false;
          this._isPositionComputed = false;
          this._right = Vector3.ZERO;
          this._up = Vector3.ZERO;
          this._forward = Vector3.ZERO;
        }
        /**
         * The 4x4 transformation matrix
         * This matrix is not meant to be changed. Changing it will not update the
         * previously computed components of the transform!
         */
        get matrix() {
          return this._matrix;
        }
        /**
         * The inverse transform
         */
        get inverse() {
          if (this._inverse === null)
            this._inverse = new _Transform(this._inverseMatrix());
          return this._inverse;
        }
        /**
         * The 3D position encoded by the transform
         */
        get position() {
          if (!this._isPositionComputed)
            this._computePosition();
          return this._position;
        }
        /**
         * A unit quaternion describing the rotational component of the transform
         */
        get orientation() {
          if (!this._isDecomposed)
            this._decompose();
          return this._orientation;
        }
        /**
         * The scale encoded by the transform
         */
        get scale() {
          if (!this._isDecomposed)
            this._decompose();
          return this._scale;
        }
        /**
         * Unit right vector of the local space
         */
        get right() {
          if (this._right === Vector3.ZERO)
            this._right = this._scaleAndRotate(new Vector3(1, 0, 0))._normalize();
          return this._right;
        }
        /**
         * Unit up vector of the local space
         */
        get up() {
          if (this._up === Vector3.ZERO)
            this._up = this._scaleAndRotate(new Vector3(0, 1, 0))._normalize();
          return this._up;
        }
        /**
         * Unit forward vector of the local space
         */
        get forward() {
          if (this._forward === Vector3.ZERO) {
            this._forward = this._scaleAndRotate(new Vector3(0, 0, -1))._normalize();
          }
          return this._forward;
        }
        /**
         * Use this transform to scale and rotate a vector
         * The translation component of the transform is ignored
         * @param v a vector
         * @returns input vector v
         */
        _scaleAndRotate(v) {
          const m = this._matrix.read();
          const h = Math.abs(m[15]) < EPSILON4 ? Number.NaN : 1 / m[15];
          const vx = v.x, vy = v.y, vz = v.z;
          const x = m[0] * vx + m[4] * vy + m[8] * vz;
          const y = m[1] * vx + m[5] * vy + m[9] * vz;
          const z = m[2] * vx + m[6] * vy + m[10] * vz;
          return v._set(x * h, y * h, z * h);
        }
        /**
         * Decompose this transform
         */
        _decompose() {
          const m = this._matrix.read();
          const h = Math.abs(m[15]) < EPSILON4 ? Number.NaN : 1 / m[15];
          const tx = m[12] * h;
          const ty = m[13] * h;
          const tz = m[14] * h;
          const rs11 = m[0] * h;
          const rs21 = m[1] * h;
          const rs31 = m[2] * h;
          const rs12 = m[4] * h;
          const rs22 = m[5] * h;
          const rs32 = m[6] * h;
          const rs13 = m[8] * h;
          const rs23 = m[9] * h;
          const rs33 = m[10] * h;
          const det = rs13 * (rs21 * rs32 - rs22 * rs31) + rs33 * (rs11 * rs22 - rs12 * rs21) - rs23 * (rs11 * rs32 - rs12 * rs31);
          const sign = +(det >= 0) - +(det < 0);
          const sx = Math.sqrt(rs11 * rs11 + rs12 * rs12 + rs13 * rs13);
          const sy = Math.sqrt(rs21 * rs21 + rs22 * rs22 + rs23 * rs23);
          const sz = Math.sqrt(rs31 * rs31 + rs32 * rs32 + rs33 * rs33) * sign;
          if (sx < EPSILON4 || sy < EPSILON4 || sz * sign < EPSILON4) {
            this._position._set(tx, ty, tz);
            this._scale._set(sx, sy, sz);
            this._orientation._copyFrom(Quaternion.Identity());
            this._isDecomposed = true;
            this._isPositionComputed = true;
            return;
          }
          const zx = 1 / sx;
          const zy = 1 / sy;
          const zz = 1 / sz;
          const r11 = rs11 * zx;
          const r21 = rs21 * zx;
          const r31 = rs31 * zx;
          const r12 = rs12 * zy;
          const r22 = rs22 * zy;
          const r32 = rs32 * zy;
          const r13 = rs13 * zz;
          const r23 = rs23 * zz;
          const r33 = rs33 * zz;
          this._position._set(tx, ty, tz);
          this._scale._set(sx, sy, sz);
          this._orientation._fromRotationMatrix(import_speedy_vision16.default.Matrix(3, 3, [
            r11,
            r21,
            r31,
            r12,
            r22,
            r32,
            r13,
            r23,
            r33
          ]));
          this._isDecomposed = true;
          this._isPositionComputed = true;
        }
        /**
         * A simpler decomposition routine.
         * Sometimes we just need the position.
         */
        _computePosition() {
          const m = this._matrix.read();
          const h = Math.abs(m[15]) < EPSILON4 ? Number.NaN : 1 / m[15];
          this._position._set(m[12] * h, m[13] * h, m[14] * h);
          this._isPositionComputed = true;
        }
        /**
         * Compute the inverse matrix of this transform
         * @returns the inverse matrix
         */
        _inverseMatrix() {
          return import_speedy_vision16.default.Matrix(this._matrix.inverse());
        }
      };
    }
  });

  // src/geometry/viewer-pose.ts
  var import_speedy_vision17, ViewerPose;
  var init_viewer_pose = __esm({
    "src/geometry/viewer-pose.ts"() {
      "use strict";
      import_speedy_vision17 = __toESM(require_speedy_vision(), 1);
      init_pose();
      init_transform();
      ViewerPose = class extends Pose {
        /**
         * Constructor
         * @param camera camera model
         */
        constructor(camera) {
          const viewMatrix = camera.computeViewMatrix();
          const modelMatrix = import_speedy_vision17.default.Matrix(viewMatrix.inverse());
          const transform = new Transform(modelMatrix);
          super(transform);
          this._viewMatrix = viewMatrix;
        }
        /**
         * This 4x4 matrix moves 3D points from world space to view space.
         * We assume that the camera is looking in the direction of the
         * negative z-axis (WebGL-friendly)
         */
        get viewMatrix() {
          return this._viewMatrix;
        }
      };
    }
  });

  // src/geometry/view.ts
  var import_speedy_vision18, DEFAULT_NEAR, DEFAULT_FAR, PerspectiveView;
  var init_view = __esm({
    "src/geometry/view.ts"() {
      "use strict";
      import_speedy_vision18 = __toESM(require_speedy_vision(), 1);
      init_errors();
      DEFAULT_NEAR = 0.1;
      DEFAULT_FAR = 1e4 * DEFAULT_NEAR;
      PerspectiveView = class {
        /**
         * Constructor
         * @param camera camera model
         * @param near distance of the near plane
         * @param far distance of the far plane
         */
        constructor(camera, near = DEFAULT_NEAR, far = DEFAULT_FAR) {
          this._near = +near;
          this._far = +far;
          if (this._near >= this._far)
            throw new IllegalArgumentError(`View expects near < far (found near = ${this._near} and far = ${this._far})`);
          else if (this._near <= 0)
            throw new IllegalArgumentError(`View expects a positive near (found ${this._near})`);
          this._camera = camera;
          this._projectionMatrix = camera.computeProjectionMatrix(this._near, this._far);
          this._inverseProjection = null;
        }
        /**
         * A 4x4 projection matrix for WebGL
         */
        get projectionMatrix() {
          return this._projectionMatrix;
        }
        /**
         * The inverse of the projection matrix
         * @internal
         */
        get _projectionMatrixInverse() {
          if (this._inverseProjection === null)
            this._inverseProjection = import_speedy_vision18.default.Matrix(this._projectionMatrix.inverse());
          return this._inverseProjection;
        }
        /**
         * Aspect ratio of the frustum
         */
        get aspect() {
          return this._camera.aspectRatio;
        }
        /**
         * Horizontal field-of-view of the frustum, measured in radians
         */
        get fovx() {
          return this._camera.fovx;
        }
        /**
         * Vertical field-of-view of the frustum, measured in radians
         */
        get fovy() {
          return this._camera.fovy;
        }
        /**
         * Distance of the near plane
         */
        get near() {
          return this._near;
        }
        /**
         * Distance of the far plane
         */
        get far() {
          return this._far;
        }
      };
    }
  });

  // src/geometry/ray.ts
  var Ray;
  var init_ray = __esm({
    "src/geometry/ray.ts"() {
      "use strict";
      Ray = class {
        /**
         * Constructor
         * @param origin a point
         * @param direction a unit vector
         */
        constructor(origin, direction) {
          this._origin = origin;
          this._direction = direction;
        }
        /**
         * The origin point of the ray
         */
        get origin() {
          return this._origin;
        }
        /**
         * The direction of the ray, a unit vector
         */
        get direction() {
          return this._direction;
        }
      };
    }
  });

  // src/geometry/viewer.ts
  var import_speedy_vision19, Viewer;
  var init_viewer = __esm({
    "src/geometry/viewer.ts"() {
      "use strict";
      import_speedy_vision19 = __toESM(require_speedy_vision(), 1);
      init_pose();
      init_viewer_pose();
      init_view();
      init_transform();
      init_vector3();
      init_ray();
      Viewer = class {
        /**
         * Constructor
         * @param camera camera model
         */
        constructor(camera) {
          this._pose = new ViewerPose(camera);
          this._views = [new PerspectiveView(camera)];
        }
        /**
         * The pose of this viewer
         */
        get pose() {
          return this._pose;
        }
        /**
         * The view of this viewer (only for monoscopic rendering)
         */
        get view() {
          return this._views[0];
        }
        /**
         * The views of this viewer
         */
        /*
        get views(): View[]
        {
            return this._views.concat([]);
        }
        */
        /**
         * Convert a pose from world space to viewer space
         * @param pose a pose in world space
         * @returns a pose in viewer space
         */
        convertToViewerSpace(pose) {
          const modelMatrix = pose.transform.matrix;
          const viewMatrix = this._pose.viewMatrix;
          const modelViewMatrix = import_speedy_vision19.default.Matrix(viewMatrix.times(modelMatrix));
          const transform = new Transform(modelViewMatrix);
          return new Pose(transform);
        }
        /**
         * Cast a ray from a point in the image space associated with this Viewer
         * @param position a point in image space, given in normalized units [-1,1]x[-1,1]
         * @returns a ray in world space that corresponds to the given point
         */
        raycast(position) {
          const projectionMatrixInverse = this.view._projectionMatrixInverse;
          const viewMatrixInverse = this._pose.transform.matrix;
          const pointInClipSpace = import_speedy_vision19.default.Matrix(4, 1, [
            // Normalized Device Coordinates (NDC)
            position.x,
            position.y,
            0,
            // (*)
            1
            // homogeneous coordinates
          ]);
          const pointInViewSpace = projectionMatrixInverse.times(pointInClipSpace);
          const pointInWorldSpace = viewMatrixInverse.times(pointInViewSpace);
          const p = import_speedy_vision19.default.Matrix(pointInWorldSpace).read();
          const origin = this._pose.transform.position;
          const direction = new Vector3(p[0] / p[3], p[1] / p[3], p[2] / p[3])._subtract(origin)._normalize();
          return new Ray(origin, direction);
        }
        /**
         * Compute a ray in the forward direction from the viewer
         * @returns a new ray in world space
         */
        forwardRay() {
          const origin = this._pose.transform.position;
          const direction = this._pose.transform.forward;
          return new Ray(origin, direction);
        }
      };
    }
  });

  // src/trackers/image-tracker/states/tracking.ts
  var import_speedy_vision20, USE_TURBO, NUMBER_OF_PBOS, ImageTrackerTrackingState;
  var init_tracking = __esm({
    "src/trackers/image-tracker/states/tracking.ts"() {
      "use strict";
      import_speedy_vision20 = __toESM(require_speedy_vision(), 1);
      init_image_tracker_utils();
      init_image_tracker_event();
      init_state();
      init_utils();
      init_camera_model();
      init_viewer();
      init_pose();
      init_transform();
      init_errors();
      init_settings();
      init_settings2();
      USE_TURBO = true;
      NUMBER_OF_PBOS = 2;
      ImageTrackerTrackingState = class extends ImageTrackerState {
        /**
         * Constructor
         * @param imageTracker
         */
        constructor(imageTracker) {
          super("tracking", imageTracker);
          this._referenceImage = null;
          this._warpHomography = import_speedy_vision20.default.Matrix.Eye(3);
          this._poseHomography = import_speedy_vision20.default.Matrix.Eye(3);
          this._templateKeypoints = [];
          this._initialScreenSize = import_speedy_vision20.default.Size(1, 1);
          this._lastOutput = {};
          this._lastPipelineOutput = { keypoints: [] };
          this._skipCounter = 0;
          this._counter = 0;
          this._lostCounter = 0;
          this._camera = new CameraModel();
          this._fixedCamera = new CameraModel();
        }
        /**
         * Called as soon as this becomes the active state, just before update() runs for the first time
         * @param settings
         */
        onEnterState(settings) {
          const homography = settings.homography;
          const referenceImage = settings.referenceImage;
          const templateKeypoints = settings.templateKeypoints;
          const templateKeypointPortalSink = settings.templateKeypointPortalSink;
          const initialScreenSize = settings.initialScreenSize;
          const keypointPortalSource = this._pipeline.node("keypointPortalSource");
          if (!referenceImage)
            throw new IllegalOperationError(`Can't track a null reference image`);
          this._referenceImage = referenceImage;
          this._warpHomography = import_speedy_vision20.default.Matrix(homography);
          this._poseHomography = import_speedy_vision20.default.Matrix(homography);
          this._templateKeypoints = templateKeypoints;
          this._initialScreenSize = import_speedy_vision20.default.Size(initialScreenSize.width, initialScreenSize.height);
          this._lastOutput = {};
          this._lastPipelineOutput = { keypoints: [] };
          this._skipCounter = 0;
          this._counter = 0;
          this._lostCounter = 0;
          keypointPortalSource.source = templateKeypointPortalSink;
          const aspectRatio = initialScreenSize.width / initialScreenSize.height;
          this._camera.init(aspectRatio);
          this._fixedCamera.init(aspectRatio);
          const ev = new ImageTrackerEvent("targetfound", referenceImage);
          this._imageTracker.dispatchEvent(ev);
          Utils.log(`Tracking image "${referenceImage.name}"...`);
        }
        /**
         * Called when leaving the state
         */
        onLeaveState() {
          Utils.log(`No longer tracking image "${this._referenceImage.name}"!`);
          this._fixedCamera.release();
          this._camera.release();
          const ev = new ImageTrackerEvent("targetlost", this._referenceImage);
          this._imageTracker.dispatchEvent(ev);
        }
        /**
         * Called just before the GPU processing
         * @returns promise
         */
        _beforeUpdate() {
          const imageRectifier = this._pipeline.node("imageRectifier");
          const borderClipper = this._pipeline.node("borderClipper");
          const keypointScaler = this._pipeline.node("keypointScaler");
          const screenSize = this.screenSize;
          borderClipper.imageSize = screenSize;
          borderClipper.borderSize = import_speedy_vision20.default.Vector2(
            screenSize.width * TRACK_CLIPPING_BORDER,
            screenSize.height * TRACK_CLIPPING_BORDER
          );
          keypointScaler.transform = ImageTrackerUtils.rasterToNIS(screenSize);
          const scale = TRACK_RECTIFIED_SCALE;
          const aspectRatio = ImageTrackerUtils.bestFitAspectRatioNDC(screenSize, this._referenceImage);
          const shrink = ImageTrackerUtils.bestFitScaleNDC(aspectRatio, scale);
          const undistort = this._warpHomography.inverse();
          const toScreen = ImageTrackerUtils.NDCToRaster(screenSize);
          const toNDC = ImageTrackerUtils.rasterToNDC(screenSize);
          return imageRectifier.transform.setTo(
            toScreen.times(shrink.times(undistort)).times(toNDC)
          ).then(() => void 0);
        }
        /**
         * GPU processing
         * @returns promise with the pipeline results
         */
        _gpuUpdate() {
          if (!USE_TURBO || Settings.powerPreference == "low-power")
            return super._gpuUpdate();
          if (0 == (this._skipCounter = 1 - this._skipCounter)) {
            const templateKeypoints = this._templateKeypoints;
            const previousKeypoints = this._lastPipelineOutput.keypoints;
            const currentKeypoints = previousKeypoints;
            this._lastPipelineOutput.keypoints = currentKeypoints;
            return import_speedy_vision20.default.Promise.resolve(this._lastPipelineOutput);
          }
          return super._gpuUpdate().then((result) => {
            this._lastPipelineOutput = result;
            return result;
          });
        }
        /**
         * Post processing that takes place just after the GPU processing
         * @param result pipeline results
         * @returns state output
         */
        _afterUpdate(result) {
          const keypoints = result.keypoints;
          const image = result.image;
          const referenceImage = this._referenceImage;
          const screenSize = this.screenSize;
          return import_speedy_vision20.default.Promise.resolve().then(() => {
            if (!screenSize.equals(this._initialScreenSize))
              throw new TrackingError("Detected a change in screen size");
            const allPairs = this._findMatchingPairs(this._templateKeypoints, keypoints);
            const pairs = ImageTrackerUtils.refineMatchingPairs(allPairs);
            if (pairs.length < TRACK_MIN_MATCHES)
              throw new TrackingError("Not enough data points to continue the tracking");
            const points = ImageTrackerUtils.compilePairsOfKeypointsNDC(pairs);
            return import_speedy_vision20.default.Promise.all([
              this._findAffineMotionNDC(points),
              this._findPerspectiveMotionNDC(points)
            ]);
          }).then(([affineMotion, perspectiveMotion]) => {
            const lowPower = Settings.powerPreference == "low-power";
            const delay = NUMBER_OF_PBOS * (!lowPower ? 2 : 1);
            if (!USE_TURBO || this._counter % delay == 1)
              this._warpHomography.setToSync(affineMotion.times(this._warpHomography));
            this._poseHomography.setToSync(perspectiveMotion.times(this._warpHomography));
            if (Number.isNaN(this._poseHomography.at(0, 0)))
              throw new NumericalError("Bad homography");
            this._counter = (this._counter + 1) % delay;
            const scale = ImageTrackerUtils.bestFitScaleNDC(1 / referenceImage.aspectRatio);
            const homography = import_speedy_vision20.default.Matrix(this._poseHomography.times(scale));
            return this._camera.update(homography);
          }).then(() => {
            const modelMatrix = this._camera.computeViewMatrix();
            const transform = new Transform(modelMatrix);
            const pose = new Pose(transform);
            const viewer = new Viewer(this._fixedCamera);
            const trackable = {
              pose,
              referenceImage,
              tracker: this._imageTracker
            };
            const result2 = {
              tracker: this._imageTracker,
              trackables: [trackable],
              viewer
            };
            const trackerOutput = {
              exports: result2,
              keypoints,
              //keypointsNIS: image !== undefined ? keypoints : undefined, // debug only
              image,
              polylineNDC: ImageTrackerUtils.findPolylineNDC(this._poseHomography),
              camera: this._camera
            };
            this._lastOutput = trackerOutput;
            this._lostCounter = 0;
            return {
              nextState: "tracking",
              trackerOutput
            };
          }).catch((err) => {
            if (err instanceof TrackingError) {
              if (++this._lostCounter <= TRACK_LOST_TOLERANCE) {
                return {
                  nextState: "tracking",
                  trackerOutput: this._lastOutput
                };
              }
            }
            Utils.warning(`The target has been lost! ${err.toString()}`);
            return {
              nextState: "scanning",
              trackerOutput: {}
            };
          });
        }
        /**
         * Find an affine motion model in NDC between pairs of keypoints in NDC
         * given as a 2 x 2n [ src | dest ] matrix
         * @param points compiled pairs of keypoints in NDC
         * @returns a promise that resolves to a 3x3 warp in NDC that maps source to destination
         */
        _findAffineMotionNDC(points) {
          return ImageTrackerUtils.findAffineWarpNDC(points, {
            method: "pransac",
            reprojectionError: TRACK_RANSAC_REPROJECTIONERROR_NDC,
            numberOfHypotheses: 512 * 2,
            bundleSize: 128,
            mask: void 0
            // score is not needed
          }).then(([warp, score]) => {
            const scale = TRACK_RECTIFIED_SCALE;
            const aspectRatio = ImageTrackerUtils.bestFitAspectRatioNDC(this.screenSize, this._referenceImage);
            const shrink = ImageTrackerUtils.bestFitScaleNDC(aspectRatio, scale);
            const grow = ImageTrackerUtils.inverseBestFitScaleNDC(aspectRatio, scale);
            const scaledWarp = grow.times(warp).times(shrink);
            const distort = this._warpHomography;
            const undistort = distort.inverse();
            const correctedWarp = distort.times(scaledWarp).times(undistort);
            return correctedWarp;
          }).catch((err) => {
            throw new TrackingError(`Can't find an affine motion`, err);
          });
        }
        /**
         * Find a perspective motion model in NDC between pairs of keypoints in NDC
         * given as a 2 x 2n [ src | dest ] matrix
         * @param points compiled pairs of keypoints in NDC
         * @returns a promise that resolves to a 3x3 warp in NDC that maps source to destination
         */
        _findPerspectiveMotionNDC(points) {
          return ImageTrackerUtils.findPerspectiveWarpNDC(points, {
            method: "pransac",
            reprojectionError: TRACK_RANSAC_REPROJECTIONERROR_NDC,
            numberOfHypotheses: 512 * 2,
            bundleSize: 128,
            //128*4,
            mask: void 0
            // score is not needed
          }).then(([warp, score]) => {
            const scale = TRACK_RECTIFIED_SCALE;
            const aspectRatio = ImageTrackerUtils.bestFitAspectRatioNDC(this.screenSize, this._referenceImage);
            const shrink = ImageTrackerUtils.bestFitScaleNDC(aspectRatio, scale);
            const grow = ImageTrackerUtils.inverseBestFitScaleNDC(aspectRatio, scale);
            const scaledWarp = grow.times(warp).times(shrink);
            const distort = this._poseHomography;
            const undistort = distort.inverse();
            const correctedWarp = distort.times(scaledWarp).times(undistort);
            return correctedWarp;
          }).catch((err) => {
            throw new TrackingError(`Can't find a perspective motion`, err);
          });
        }
        /**
         * Find matching pairs of two sets of keypoints matched via brute force
         * @param srcKeypoints source (database)
         * @param destKeypoints destination
         * @returns an array of matching pairs [src, dest]
         */
        _findMatchingPairs(srcKeypoints, destKeypoints) {
          const pairs = [];
          for (let i = 0; i < destKeypoints.length; i++) {
            const destKeypoint = destKeypoints[i];
            if (destKeypoint.matches[0].index >= 0 && destKeypoint.matches[1].index >= 0) {
              const d1 = destKeypoint.matches[0].distance;
              const d2 = destKeypoint.matches[1].distance;
              if (d1 <= TRACK_MATCH_RATIO * d2) {
                const srcKeypoint = srcKeypoints[destKeypoint.matches[0].index];
                pairs.push([srcKeypoint, destKeypoint]);
              }
            }
          }
          return pairs;
        }
        /**
         * Predict the keypoints without actually looking at the image
         * @param curr keypoints at time t (will modify the contents)
         * @param prev keypoints at time t-1 (not just t = 0)
         * @returns keypoints at time t+1
         */
        /*
            private _predictKeypoints(curr: SpeedyMatchedKeypoint[], prev: SpeedyKeypoint[]): SpeedyMatchedKeypoint[]
            {
                // the target image is likely to be moving roughly in
                // the same manner as it was in the previous frame
                const alpha = 0.8; //0.2;
                const next: SpeedyMatchedKeypoint[] = [];
                const n = curr.length;
        
                for(let i = 0; i < n; i++) {
                    const cur = curr[i];
        
                    if(cur.matches[0].index < 0 || cur.matches[1].index < 0)
                        continue;
                    //else if(cur.matches[0].distance > TRACK_MATCH_RATIO * cur.matches[1].distance)
                    //    continue;
        
                    const prv = prev[cur.matches[0].index];
                    const dx = cur.position.x - prv.position.x;
                    const dy = cur.position.y - prv.position.y;
        
                    // a better mathematical model is needed
                    cur.position.x = prv.position.x + alpha * dx;
                    cur.position.y = prv.position.y + alpha * dy;
                    next.push(cur);
                }
        
                // done!
                return next;
            }
            */
        /**
         * Create & setup the pipeline
         * @returns pipeline
         */
        _createPipeline() {
          const pipeline = import_speedy_vision20.default.Pipeline();
          const source = import_speedy_vision20.default.Image.Source("source");
          const screen2 = import_speedy_vision20.default.Transform.Resize("screen");
          const greyscale = import_speedy_vision20.default.Filter.Greyscale();
          const imageRectifier = import_speedy_vision20.default.Transform.PerspectiveWarp("imageRectifier");
          const nightvision = import_speedy_vision20.default.Filter.Nightvision();
          const nightvisionMux = import_speedy_vision20.default.Image.Multiplexer();
          const blur = import_speedy_vision20.default.Filter.GaussianBlur();
          const detector = import_speedy_vision20.default.Keypoint.Detector.Harris();
          const descriptor = import_speedy_vision20.default.Keypoint.Descriptor.ORB();
          const matcher = import_speedy_vision20.default.Keypoint.Matcher.BFKNN();
          const subpixel = import_speedy_vision20.default.Keypoint.SubpixelRefiner();
          const denoiser = import_speedy_vision20.default.Filter.GaussianBlur();
          const borderClipper = import_speedy_vision20.default.Keypoint.BorderClipper("borderClipper");
          const clipper = import_speedy_vision20.default.Keypoint.Clipper();
          const keypointScaler = import_speedy_vision20.default.Keypoint.Transformer("keypointScaler");
          const keypointPortalSource = import_speedy_vision20.default.Keypoint.Portal.Source("keypointPortalSource");
          const keypointSink = import_speedy_vision20.default.Keypoint.SinkOfMatchedKeypoints("keypoints");
          source.media = null;
          screen2.size = import_speedy_vision20.default.Size(0, 0);
          imageRectifier.transform = import_speedy_vision20.default.Matrix.Eye(3);
          nightvision.gain = NIGHTVISION_GAIN;
          nightvision.offset = NIGHTVISION_OFFSET;
          nightvision.decay = NIGHTVISION_DECAY;
          nightvision.quality = NIGHTVISION_QUALITY;
          nightvisionMux.port = TRACK_WITH_NIGHTVISION ? 1 : 0;
          blur.kernelSize = import_speedy_vision20.default.Size(ORB_GAUSSIAN_KSIZE, ORB_GAUSSIAN_KSIZE);
          blur.sigma = import_speedy_vision20.default.Vector2(ORB_GAUSSIAN_SIGMA, ORB_GAUSSIAN_SIGMA);
          denoiser.kernelSize = import_speedy_vision20.default.Size(SUBPIXEL_GAUSSIAN_KSIZE, SUBPIXEL_GAUSSIAN_KSIZE);
          denoiser.sigma = import_speedy_vision20.default.Vector2(SUBPIXEL_GAUSSIAN_SIGMA, SUBPIXEL_GAUSSIAN_SIGMA);
          detector.quality = TRACK_HARRIS_QUALITY;
          detector.capacity = TRACK_DETECTOR_CAPACITY;
          subpixel.method = SUBPIXEL_METHOD;
          clipper.size = TRACK_MAX_KEYPOINTS;
          borderClipper.imageSize = screen2.size;
          borderClipper.borderSize = import_speedy_vision20.default.Vector2(0, 0);
          keypointScaler.transform = import_speedy_vision20.default.Matrix.Eye(3);
          matcher.k = 2;
          keypointPortalSource.source = null;
          keypointSink.turbo = USE_TURBO;
          source.output().connectTo(screen2.input());
          screen2.output().connectTo(greyscale.input());
          greyscale.output().connectTo(imageRectifier.input());
          imageRectifier.output().connectTo(nightvisionMux.input("in0"));
          imageRectifier.output().connectTo(nightvision.input());
          nightvision.output().connectTo(nightvisionMux.input("in1"));
          nightvisionMux.output().connectTo(detector.input());
          detector.output().connectTo(borderClipper.input());
          borderClipper.output().connectTo(clipper.input());
          imageRectifier.output().connectTo(denoiser.input());
          denoiser.output().connectTo(subpixel.input("image"));
          clipper.output().connectTo(subpixel.input("keypoints"));
          imageRectifier.output().connectTo(blur.input());
          blur.output().connectTo(descriptor.input("image"));
          subpixel.output().connectTo(descriptor.input("keypoints"));
          keypointPortalSource.output().connectTo(matcher.input("database"));
          descriptor.output().connectTo(matcher.input("keypoints"));
          descriptor.output().connectTo(keypointScaler.input());
          keypointScaler.output().connectTo(keypointSink.input());
          matcher.output().connectTo(keypointSink.input("matches"));
          pipeline.init(
            source,
            screen2,
            greyscale,
            imageRectifier,
            nightvision,
            nightvisionMux,
            blur,
            detector,
            subpixel,
            borderClipper,
            clipper,
            denoiser,
            descriptor,
            matcher,
            keypointPortalSource,
            keypointScaler,
            keypointSink
            //imageSink
          );
          return pipeline;
        }
      };
    }
  });

  // src/trackers/image-tracker/image-tracker.ts
  var import_speedy_vision21, DEFAULT_OPTIONS2, ImageTracker;
  var init_image_tracker = __esm({
    "src/trackers/image-tracker/image-tracker.ts"() {
      "use strict";
      import_speedy_vision21 = __toESM(require_speedy_vision(), 1);
      init_errors();
      init_reference_image_database();
      init_initial();
      init_training();
      init_scanning();
      init_pre_tracking_a();
      init_pre_tracking_b();
      init_tracking();
      init_utils();
      init_ar_events();
      DEFAULT_OPTIONS2 = {
        resolution: "sm"
      };
      ImageTracker = class extends AREventTarget {
        /**
         * Constructor
         * @param options
         */
        constructor(options) {
          super();
          this._state = {
            "initial": new ImageTrackerInitialState(this),
            "training": new ImageTrackerTrainingState(this),
            "scanning": new ImageTrackerScanningState(this),
            "pre-tracking-a": new ImageTrackerPreTrackingAState(this),
            "pre-tracking-b": new ImageTrackerPreTrackingBState(this),
            "tracking": new ImageTrackerTrackingState(this)
          };
          this._session = null;
          this._source = null;
          this._activeStateName = "initial";
          this._lastOutput = {};
          this._database = new ReferenceImageDatabase();
          options = Object.assign({}, DEFAULT_OPTIONS2, options);
          this._resolution = options.resolution;
        }
        /**
         * The type of the tracker
         */
        get type() {
          return "image-tracker";
        }
        /**
         * Current state name
         */
        get state() {
          return this._activeStateName;
        }
        /**
         * Reference Image Database
         * Must be configured before training the tracker
         */
        get database() {
          return this._database;
        }
        /**
         * Resolution of the tracker
         */
        get resolution() {
          return this._resolution;
        }
        /**
         * Resolution of the tracker
         * @readonly
         */
        set resolution(resolution) {
        }
        /**
         * Size of the AR screen space, in pixels
         * @internal
         */
        get screenSize() {
          return this._state[this._activeStateName].screenSize;
        }
        /**
         * Last emitted output
         * @internal
         */
        get _output() {
          return this._lastOutput;
        }
        /**
         * Stats related to this tracker
         * @internal
         */
        get _stats() {
          const screenSize = this.screenSize;
          return `${screenSize.width}x${screenSize.height} ${this.state}`;
        }
        /**
         * Initialize this tracker
         * @param session
         * @returns promise that resolves after the tracker has been initialized
         * @internal
         */
        _init(session) {
          this._session = session;
          for (const source of session.sources) {
            if (source._type == "video") {
              this._source = source;
              break;
            } else if (source._type == "canvas")
              this._source = source;
          }
          if (this._source === null)
            throw new IllegalOperationError("The image tracker requires a suitable source of data");
          for (const state of Object.values(this._state))
            state.init();
          return import_speedy_vision21.default.Promise.resolve();
        }
        /**
         * Release this tracker
         * @returns promise that resolves after the tracker has been released
         * @internal
         */
        _release() {
          for (const state of Object.values(this._state))
            state.release();
          this._session = null;
          return import_speedy_vision21.default.Promise.resolve();
        }
        /**
         * Update the tracker
         * @returns promise
         * @internal
         */
        _update() {
          if (this._session == null)
            return import_speedy_vision21.default.Promise.reject(new IllegalOperationError(`Uninitialized tracker`));
          const media = this._source._internalMedia;
          const screenSize = this._computeScreenSize();
          const activeState = this._state[this._activeStateName];
          return activeState.update(media, screenSize).then(({ trackerOutput, nextState, nextStateSettings }) => {
            this._lastOutput = trackerOutput;
            if (this._activeStateName != nextState) {
              activeState.onLeaveState();
              this._activeStateName = nextState;
              this._state[nextState].onEnterState(nextStateSettings || {});
            }
          });
        }
        /**
         * Get reference image
         * @param keypointIndex -1 if not found
         * @returns reference image
         * @internal
         */
        _referenceImageOfKeypoint(keypointIndex) {
          const training = this._state.training;
          return training.referenceImageOfKeypoint(keypointIndex);
        }
        /**
         * Get reference image index
         * @param keypointIndex -1 if not found
         * @returns reference image index, or -1 if not found
         * @internal
         */
        _referenceImageIndexOfKeypoint(keypointIndex) {
          const training = this._state.training;
          return training.referenceImageIndexOfKeypoint(keypointIndex);
        }
        /**
         * Get a keypoint of the trained set
         * @param keypointIndex
         * @returns a keypoint
         * @internal
         */
        _referenceKeypoint(keypointIndex) {
          const training = this._state.training;
          return training.referenceKeypoint(keypointIndex);
        }
        /**
         * Compute the current size of the AR screen space
         * Note that this may change over time
         * @returns size
         */
        _computeScreenSize() {
          const media = this._source._internalMedia;
          const aspectRatio = media.width / media.height;
          const screenSize = Utils.resolution(this._resolution, aspectRatio);
          return screenSize;
        }
      };
    }
  });

  // src/geometry/vector2.ts
  var EPSILON5, ZERO2, Vector2;
  var init_vector2 = __esm({
    "src/geometry/vector2.ts"() {
      "use strict";
      EPSILON5 = 1e-6;
      ZERO2 = null;
      Vector2 = class _Vector2 {
        /**
         * Constructor
         */
        constructor(x = 0, y = 0) {
          this._x = +x;
          this._y = +y;
        }
        /**
         * Instantiate a zero vector
         * @returns a new zero vector
         */
        static Zero() {
          return new _Vector2(0, 0);
        }
        /**
         * Immutable zero vector
         * @returns an immutable zero vector
         */
        static get ZERO() {
          return ZERO2 || (ZERO2 = Object.freeze(_Vector2.Zero()));
        }
        /**
         * The x coordinate of the vector
         */
        get x() {
          return this._x;
        }
        /**
         * The y coordinate of the vector
         */
        get y() {
          return this._y;
        }
        /**
         * The length of this vector
         * @returns sqrt(x^2 + y^2)
         */
        length() {
          const x = this._x;
          const y = this._y;
          return Math.sqrt(x * x + y * y);
        }
        /**
         * Compute the dot product of this and v
         * @param v a vector
         * @returns the dot product of the vectors
         */
        dot(v) {
          return this._x * v._x + this._y * v._y;
        }
        /**
         * Compute the distance between points this and v
         * @param v a vector / point
         * @returns the distance between the points
         */
        distanceTo(v) {
          const dx = this._x - v._x;
          const dy = this._y - v._y;
          return Math.sqrt(dx * dx + dy * dy);
        }
        /**
         * Compute the direction from this to v
         * @param v a vector
         * @returns a new unit vector pointing to v from this
         */
        directionTo(v) {
          return v._clone()._subtract(this)._normalize();
        }
        /**
         * Compute a unit vector with the same direction as this
         * @returns a new unit vector with the same direction as this
         */
        normalized() {
          return this._clone()._normalize();
        }
        /**
         * Compute the sum between this vector and v
         * @param v a vector
         * @returns a new vector equal to the sum between this and v
         */
        plus(v) {
          return this._clone()._add(v);
        }
        /**
         * Compute the difference between this vector and v
         * @param v a vector
         * @returns a new vector equal to the difference this - v
         */
        minus(v) {
          return this._clone()._subtract(v);
        }
        /**
         * Compute the multiplication between this vector and a scale factor
         * @param scale scalar quantity
         * @returns a new vector equal to the multiplication between this and the scale factor
         */
        times(scale) {
          return this._clone()._scale(scale);
        }
        /**
         * Check if this and v have the same coordinates
         * @param v a vector
         * @returns true if this and v have the same coordinates
         */
        equals(v) {
          return this._x === v._x && this._y === v._y;
        }
        /**
         * Convert to string
         * @returns a string
         */
        toString() {
          const x = this._x.toFixed(5);
          const y = this._y.toFixed(5);
          return `Vector2(${x},${y})`;
        }
        /**
         * Set the coordinates of this vector
         * @param x x-coordinate
         * @param y y-coordinate
         * @returns this vector
         * @internal
         */
        _set(x, y) {
          this._x = +x;
          this._y = +y;
          return this;
        }
        /**
         * Copy v to this vector
         * @param v a vector
         * @returns this vector
         * @internal
         */
        _copyFrom(v) {
          this._x = v._x;
          this._y = v._y;
          return this;
        }
        /**
         * Normalize this vector
         * @returns this vector, normalized
         * @internal
         */
        _normalize() {
          const length = this.length();
          if (length < EPSILON5)
            return this;
          this._x /= length;
          this._y /= length;
          return this;
        }
        /**
         * Add v to this vector
         * @param v a vector
         * @returns this vector
         * @internal
         */
        _add(v) {
          this._x += v._x;
          this._y += v._y;
          return this;
        }
        /**
         * Subtract v from this vector
         * @param v a vector
         * @returns this vector
         * @internal
         */
        _subtract(v) {
          this._x -= v._x;
          this._y -= v._y;
          return this;
        }
        /**
         * Scale this vector by a scalar
         * @param s scalar
         * @returns this vector
         * @internal
         */
        _scale(s) {
          this._x *= s;
          this._y *= s;
          return this;
        }
        /**
         * Clone this vector
         * @returns a clone of this vector
         * @internal
         */
        _clone() {
          return new _Vector2(this._x, this._y);
        }
      };
    }
  });

  // src/trackers/pointer-tracker/pointer-tracker.ts
  var import_speedy_vision22, EVENTTYPE2PHASE, DEFAULT_OPTIONS3, PointerTracker;
  var init_pointer_tracker = __esm({
    "src/trackers/pointer-tracker/pointer-tracker.ts"() {
      "use strict";
      import_speedy_vision22 = __toESM(require_speedy_vision(), 1);
      init_vector2();
      init_utils();
      init_errors();
      EVENTTYPE2PHASE = {
        "pointerdown": "began",
        "pointerup": "ended",
        "pointermove": "moved",
        "pointercancel": "canceled",
        "pointerleave": "ended",
        "pointerenter": "began"
      };
      DEFAULT_OPTIONS3 = {
        space: "normalized"
      };
      PointerTracker = class {
        /**
         * Constructor
         * @param options
         */
        constructor(options) {
          const settings = this._buildSettings(options);
          this._source = null;
          this._viewport = null;
          this._space = settings.space;
          this._activePointers = /* @__PURE__ */ new Map();
          this._newPointers = /* @__PURE__ */ new Map();
          this._idMap = /* @__PURE__ */ new Map();
          this._nextId = 1;
          this._previousOutput = this._generateOutput();
          this._previousUpdateTime = Number.POSITIVE_INFINITY;
          this._wantToReset = false;
          this._resetInTheNextUpdate = this._resetInTheNextUpdate.bind(this);
        }
        /**
         * Build a full and validated options object
         * @param options
         * @returns validated options with defaults
         */
        _buildSettings(options) {
          const settings = Object.assign({}, DEFAULT_OPTIONS3, options);
          if (settings.space != "normalized" && settings.space != "adjusted")
            throw new IllegalArgumentError(`Invalid pointer space: "${settings.space}"`);
          return settings;
        }
        /**
         * The type of the tracker
         */
        get type() {
          return "pointer-tracker";
        }
        /**
         * Initialize the tracker
         * @param session
         * @returns a promise that is resolved as soon as the tracker is initialized
         * @internal
         */
        _init(session) {
          Utils.log("Initializing PointerTracker...");
          this._viewport = session.viewport;
          for (const source of session.sources) {
            if (source._type == "pointer-source") {
              this._source = source;
              break;
            }
          }
          if (this._source === null)
            return import_speedy_vision22.default.Promise.reject(new IllegalOperationError("A PointerTracker expects a PointerSource"));
          this._source._setViewport(this._viewport);
          document.addEventListener("visibilitychange", this._resetInTheNextUpdate);
          return import_speedy_vision22.default.Promise.resolve();
        }
        /**
         * Release the tracker
         * @returns a promise that is resolved as soon as the tracker is released
         * @internal
         */
        _release() {
          this._source = null;
          this._viewport = null;
          this._activePointers.clear();
          this._newPointers.clear();
          this._idMap.clear();
          document.removeEventListener("visibilitychange", this._resetInTheNextUpdate);
          return import_speedy_vision22.default.Promise.resolve();
        }
        /**
         * Update the tracker (update cycle)
         * @returns a promise that is resolved as soon as the tracker is updated
         * @internal
         */
        _update() {
          const canvas = this._viewport.canvas;
          const rect = canvas.getBoundingClientRect();
          const deltaTime = this._updateTime();
          const inverseDeltaTime = deltaTime > 1e-5 ? 1 / deltaTime : 60;
          const inactiveTrackables = this._findInactiveTrackables();
          for (let i = inactiveTrackables.length - 1; i >= 0; i--)
            this._activePointers.delete(inactiveTrackables[i].id);
          this._updateAllTrackables({
            phase: "stationary",
            velocity: Vector2.ZERO,
            deltaPosition: Vector2.ZERO
          });
          if (this._wantToReset) {
            this._reset();
            this._wantToReset = false;
          }
          let event;
          while ((event = this._source._consume()) !== null) {
            if (event.target !== canvas)
              return import_speedy_vision22.default.Promise.reject(new IllegalOperationError("Invalid PointerEvent target " + event.target));
            else if (!EVENTTYPE2PHASE.hasOwnProperty(event.type))
              return import_speedy_vision22.default.Promise.reject(new IllegalOperationError("Invalid PointerEvent type " + event.type));
            const id = this._normalizeId(event.pointerId, event.pointerType);
            const previous = this._activePointers.get(id);
            const current = this._newPointers.get(id);
            const phase = EVENTTYPE2PHASE[event.type];
            if (!(event.type == "pointerdown" || event.type == "pointerenter" && event.buttons > 0)) {
              if (!previous && !current)
                continue;
            } else if (previous) {
              continue;
            } else if (event.button != 0 && event.pointerType == "mouse") {
              continue;
            }
            if (!previous) {
              if (phase == "ended" || phase == "canceled") {
                this._newPointers.delete(id);
                continue;
              }
            } else if (phase == "began" && current) {
              if (current.phase == "ended" || current.phase == "canceled") {
                this._newPointers.delete(id);
                continue;
              }
            }
            if (previous?.phase == "canceled")
              continue;
            switch (event.type) {
              case "pointermove":
                if (event.buttons == 0 || current?.phase == "began")
                  continue;
                break;
              case "pointerenter":
                if (event.buttons == 0 || previous?.phase == "began" || current?.phase == "began")
                  continue;
                break;
              case "pointercancel":
                this._reset();
                this._newPointers.clear();
                continue;
            }
            const absX = event.pageX - (rect.left + window.scrollX);
            const absY = event.pageY - (rect.top + window.scrollY);
            const relX = 2 * absX / rect.width - 1;
            const relY = -(2 * absY / rect.height - 1);
            const position = new Vector2(relX, relY);
            if (this._space == "adjusted") {
              const a = this._viewport.aspectRatio;
              if (a >= 1) {
                position._set(relX, relY / a);
              } else {
                position._set(relX * a, relY);
              }
            }
            const deltaPosition = !previous ? Vector2.ZERO : position._clone()._subtract(previous.position);
            const initialPosition = previous ? previous.initialPosition : Object.freeze(position._clone());
            const velocity = deltaPosition._clone()._scale(inverseDeltaTime);
            const duration = previous ? previous.duration + deltaTime : 0;
            const movementLength = previous ? previous.movementLength + deltaPosition.length() : 0;
            const movementDuration = !previous ? 0 : previous.movementDuration + (movementLength > previous.movementLength ? deltaTime : 0);
            const isPrimary = event.isPrimary;
            const kind = event.pointerType;
            this._newPointers.set(id, {
              id,
              phase,
              position,
              deltaPosition,
              initialPosition,
              velocity,
              duration,
              movementDuration,
              movementLength,
              isPrimary,
              kind,
              tracker: this
            });
          }
          this._newPointers.forEach((trackable, id) => this._activePointers.set(id, trackable));
          this._newPointers.clear();
          this._advanceAllStationaryTrackables(deltaTime);
          if (this._activePointers.size == 0 && this._idMap.size > 0)
            this._idMap.clear();
          this._previousOutput = this._generateOutput();
          return import_speedy_vision22.default.Promise.resolve();
        }
        /**
         * Output of the previous frame
         * @internal
         */
        get _output() {
          return this._previousOutput;
        }
        /**
         * Stats info
         * @internal
         */
        get _stats() {
          const n = this._activePointers.size;
          const s = n != 1 ? "s" : "";
          return n + " pointer" + s;
        }
        /**
         * The space in which pointers are located.
         * You may set it when instantiating the tracker.
         */
        get space() {
          return this._space;
        }
        /**
         * Generate tracker output
         * @returns a new PointerTrackerOutput object
         */
        _generateOutput() {
          const trackables = [];
          this._activePointers.forEach((trackable) => trackables.push(trackable));
          return {
            exports: {
              tracker: this,
              trackables: this._sortTrackables(trackables)
            }
          };
        }
        /**
         * Update all active pointers
         * @param fields
         */
        _updateAllTrackables(fields) {
          this._activePointers.forEach((trackable, id) => {
            this._activePointers.set(id, Object.assign({}, trackable, fields));
          });
        }
        /**
         * Advance the elapsed time of all stationary pointers
         * @param deltaTime
         */
        _advanceAllStationaryTrackables(deltaTime) {
          this._activePointers.forEach((trackable, id) => {
            if (trackable.phase == "stationary") {
              trackable.duration += deltaTime;
            }
          });
        }
        /**
         * Normalize pointer IDs across browsers
         * @param pointerId browser-provided pointer ID
         * @param pointerType pointer type
         * @returns a normalized pointer ID
         */
        _normalizeId(pointerId, pointerType) {
          if (pointerType == "mouse")
            return 0;
          if (!this._idMap.has(pointerId))
            this._idMap.set(pointerId, this._nextId++);
          return this._idMap.get(pointerId);
        }
        /**
         * Cancel all active pointers and consume all events
         * @param deltaTime
         */
        _reset() {
          this._updateAllTrackables({
            phase: "canceled",
            velocity: Vector2.ZERO,
            deltaPosition: Vector2.ZERO
          });
          while (this._source._consume() !== null) ;
        }
        /**
         * Reset in the next update of the tracker
         */
        _resetInTheNextUpdate() {
          this._wantToReset = true;
        }
        /**
         * As a convenience, let's make sure that a primary pointer, if any exists,
         * is at the beginning of the trackables array
         * @param trackables
         * @returns sorted trackables
         */
        _sortTrackables(trackables) {
          if (trackables.length <= 1 || trackables[0].isPrimary)
            return trackables;
          for (let j = 1; j < trackables.length; j++) {
            if (trackables[j].isPrimary) {
              const primary = trackables[j];
              trackables[j] = trackables[0];
              trackables[0] = primary;
              break;
            }
          }
          return trackables;
        }
        /**
         * Find trackables to remove
         * @returns a list of trackables to remove
         */
        _findInactiveTrackables() {
          const trackables = [];
          this._activePointers.forEach((trackable) => {
            if (trackable.phase == "ended" || trackable.phase == "canceled")
              trackables.push(trackable);
          });
          return trackables;
        }
        /**
         * Update the time
         * @returns delta time in seconds
         */
        _updateTime() {
          const now = performance.now() * 1e-3;
          if (this._previousUpdateTime > now)
            this._previousUpdateTime = now;
          const prev = this._previousUpdateTime;
          this._previousUpdateTime = now;
          return now - prev;
        }
      };
    }
  });

  // src/trackers/tracker-factory.ts
  var TrackerFactory;
  var init_tracker_factory = __esm({
    "src/trackers/tracker-factory.ts"() {
      "use strict";
      init_image_tracker();
      init_pointer_tracker();
      TrackerFactory = class {
        /**
         * Create an Image Tracker
         * @param options
         */
        static Image(options = {}) {
          return new ImageTracker(options);
        }
        /**
         * Create an Image Tracker with default settings
         * @deprecated
         */
        static ImageTracker() {
          return this.Image();
        }
        /**
         * Create a Pointer Tracker
         * @param options
         */
        static Pointer(options = {}) {
          return new PointerTracker(options);
        }
      };
    }
  });

  // src/sources/video-source.ts
  var import_speedy_vision23, ALERT_MESSAGE, displayedAlertMessage, VideoSource;
  var init_video_source = __esm({
    "src/sources/video-source.ts"() {
      "use strict";
      import_speedy_vision23 = __toESM(require_speedy_vision(), 1);
      init_utils();
      init_errors();
      ALERT_MESSAGE = "Tap on the screen to start";
      displayedAlertMessage = false;
      VideoSource = class {
        /**
         * Constructor
         */
        constructor(video) {
          Utils.assert(video instanceof HTMLVideoElement, "Expected a video element");
          this._video = video;
          this._media = null;
        }
        /**
         * The underlying <video> element
         */
        get video() {
          return this._video;
        }
        /**
         * A type-identifier of the source of data
         * @internal
         */
        get _type() {
          return "video";
        }
        /**
         * Get media
         * @internal
         */
        get _internalMedia() {
          if (this._media == null)
            throw new IllegalOperationError(`The media of the source of data isn't loaded`);
          return this._media;
        }
        /**
         * Stats related to this source of data
         * @internal
         */
        get _stats() {
          const media = this._media;
          if (media != null)
            return `${media.width}x${media.height} video`;
          else
            return "uninitialized video";
        }
        /**
         * Initialize this source of data
         * @returns a promise that resolves as soon as this source of data is initialized
         * @internal
         */
        _init() {
          Utils.log(`Initializing ${this._type} source...`);
          return this._prepareVideo(this._video).then((video) => {
            Utils.log("The video is prepared");
            return import_speedy_vision23.default.load(video).then((media) => {
              Utils.log(`Source of data is a ${media.width}x${media.height} ${this._type}`);
              this._media = media;
            });
          });
        }
        /**
         * Release this source of data
         * @returns a promise that resolves as soon as this source of data is released
         * @internal
         */
        _release() {
          if (this._media)
            this._media.release();
          this._media = null;
          return import_speedy_vision23.default.Promise.resolve();
        }
        /**
         * Handle browser-specific quirks for <video> elements
         * @param video a video element
         * @returns a promise that resolves to the input video
         */
        _prepareVideo(video) {
          video.setAttribute("playsinline", "");
          return this._handleAutoPlay(video).finally(() => {
            if (Utils.isWebKit()) {
              if (video.hidden) {
                video.hidden = false;
                video.style.setProperty("opacity", "0");
                video.style.setProperty("position", "fixed");
                video.style.setProperty("left", "0");
                video.style.setProperty("top", "0");
              }
            }
            return video;
          });
        }
        /**
         * Handle browser-specific quirks for videos marked with autoplay
         * @param video a <video> marked with autoplay
         * @returns a promise that resolves to the input video
         */
        _handleAutoPlay(video) {
          if (!video.autoplay)
            return import_speedy_vision23.default.Promise.resolve(video);
          if (!video.muted) {
            Utils.warning("Videos marked with autoplay should be muted", video);
            video.muted = true;
          }
          return this._waitUntilPlayable(video).then((video2) => {
            const promise = video2.play();
            if (promise === void 0)
              return video2;
            return new import_speedy_vision23.default.Promise((resolve, reject) => {
              promise.then(() => resolve(video2), (error) => {
                Utils.error(`Can't autoplay video!`, error, video2);
                if (error.name == "NotAllowedError") {
                  Utils.warning("Tip: allow manual playback");
                  if (Utils.isIOS())
                    Utils.warning("Is low power mode on?");
                  if (video2.hidden || !video2.controls || video2.parentNode === null) {
                    document.body.addEventListener("pointerdown", () => video2.play());
                    if (!displayedAlertMessage) {
                      alert(ALERT_MESSAGE);
                      displayedAlertMessage = true;
                    }
                  }
                } else if (error.name == "NotSupportedError") {
                  reject(new NotSupportedError("Unsupported video format", error));
                  return;
                }
                resolve(video2);
              });
            });
          });
        }
        /**
         * Wait for the input video to be playable
         * @param video
         * @returns a promise that resolves to the input video when it can be played
         */
        _waitUntilPlayable(video) {
          const TIMEOUT = 15e3, INTERVAL = 500;
          if (video.readyState >= 3)
            return import_speedy_vision23.default.Promise.resolve(video);
          return new import_speedy_vision23.default.Promise((resolve, reject) => {
            let ms = 0, t = setInterval(() => {
              if (video.readyState >= 3) {
                clearInterval(t);
                resolve(video);
              } else if ((ms += INTERVAL) >= TIMEOUT) {
                clearInterval(t);
                reject(new TimeoutError("The video took too long to load"));
              }
            }, INTERVAL);
          });
        }
      };
    }
  });

  // src/sources/canvas-source.ts
  var import_speedy_vision24, CanvasSource;
  var init_canvas_source = __esm({
    "src/sources/canvas-source.ts"() {
      "use strict";
      import_speedy_vision24 = __toESM(require_speedy_vision(), 1);
      init_utils();
      init_errors();
      CanvasSource = class {
        /**
         * Constructor
         */
        constructor(canvas) {
          Utils.assert(canvas instanceof HTMLCanvasElement, "Expected a canvas element");
          this._canvas = canvas;
          this._media = null;
        }
        /**
         * A type-identifier of the source of data
         * @internal
         */
        get _type() {
          return "canvas";
        }
        /**
         * Get media
         * @internal
         */
        get _internalMedia() {
          if (this._media == null)
            throw new IllegalOperationError(`The media of the source of data isn't loaded`);
          return this._media;
        }
        /**
         * Stats related to this source of data
         * @internal
         */
        get _stats() {
          const media = this._media;
          if (media != null)
            return `${media.width}x${media.height} canvas`;
          else
            return "uninitialized canvas";
        }
        /**
         * Initialize this source of data
         * @returns a promise that resolves as soon as this source of data is initialized
         * @internal
         */
        _init() {
          return import_speedy_vision24.default.load(this._canvas).then((media) => {
            Utils.log(`Source of data is a ${media.width}x${media.height} ${this._type}`);
            this._media = media;
          });
        }
        /**
         * Release this source of data
         * @returns a promise that resolves as soon as this source of data is released
         * @internal
         */
        _release() {
          if (this._media)
            this._media.release();
          this._media = null;
          return import_speedy_vision24.default.Promise.resolve();
        }
      };
    }
  });

  // src/sources/camera-source.ts
  var import_speedy_vision25, DEFAULT_CAMERA_OPTIONS, CameraSource;
  var init_camera_source = __esm({
    "src/sources/camera-source.ts"() {
      "use strict";
      import_speedy_vision25 = __toESM(require_speedy_vision(), 1);
      init_utils();
      init_errors();
      init_video_source();
      DEFAULT_CAMERA_OPTIONS = {
        resolution: "md",
        aspectRatio: 16 / 9,
        constraints: { facingMode: "environment" }
      };
      CameraSource = class extends VideoSource {
        /**
         * Constructor
         * @param options
         */
        constructor(options) {
          const video = document.createElement("video");
          super(video);
          this._options = Object.assign({}, DEFAULT_CAMERA_OPTIONS, options);
        }
        /**
         * Camera resolution
         */
        get resolution() {
          return this._options.resolution;
        }
        /**
         * Initialize this source of data
         * @returns a promise that resolves as soon as this source of data is initialized
         * @internal
         */
        _init() {
          Utils.log("Accessing the webcam...");
          if (!navigator.mediaDevices || !navigator.mediaDevices.getUserMedia)
            throw new NotSupportedError("Unsupported browser: no navigator.mediaDevices.getUserMedia()");
          const options = this._options;
          const size = Utils.resolution(options.resolution, options.aspectRatio);
          const constraints = {
            audio: false,
            video: {
              width: size.width,
              height: size.height,
              aspectRatio: options.aspectRatio,
              ...options.constraints
            }
          };
          return new import_speedy_vision25.default.Promise((resolve, reject) => {
            navigator.mediaDevices.getUserMedia(constraints).then((stream) => {
              const video = this.video;
              video.onloadedmetadata = () => {
                const promise = video.play();
                const success = "Access to the webcam has been granted.";
                if (promise === void 0) {
                  Utils.log(success);
                  resolve(video);
                  return;
                }
                promise.then(() => {
                  Utils.log(success);
                  resolve(video);
                }).catch((error) => {
                  reject(new IllegalOperationError(
                    "Webcam error!",
                    error
                  ));
                });
              };
              video.setAttribute("playsinline", "");
              video.setAttribute("autoplay", "");
              video.setAttribute("muted", "");
              video.srcObject = stream;
            }).catch((error) => {
              reject(new AccessDeniedError(
                "Please give access to the webcam and reload the page.",
                error
              ));
            });
          }).then((_) => super._init());
        }
        /**
         * Release this source of data
         * @returns a promise that resolves as soon as this source of data is released
         * @internal
         */
        _release() {
          const video = this.video;
          const stream = video.srcObject;
          const tracks = stream.getTracks();
          tracks.forEach((track) => track.stop());
          video.onloadedmetadata = null;
          video.srcObject = null;
          return super._release();
        }
      };
    }
  });

  // src/sources/pointer-source.ts
  var import_speedy_vision26, PointerSource;
  var init_pointer_source = __esm({
    "src/sources/pointer-source.ts"() {
      "use strict";
      import_speedy_vision26 = __toESM(require_speedy_vision(), 1);
      init_utils();
      PointerSource = class {
        /**
         * Constructor
         */
        constructor() {
          this._queue = [];
          this._viewport = null;
          this._onPointerEvent = this._onPointerEvent.bind(this);
          this._cancelEvent = this._cancelEvent.bind(this);
        }
        /**
         * A type-identifier of the source of data
         * @internal
         */
        get _type() {
          return "pointer-source";
        }
        /**
         * Consume a pointer event
         * @returns the next pointer event to be consumed, or null if there are none
         * @internal
         */
        _consume() {
          return this._queue.shift() || null;
        }
        /**
         * Stats related to this source of data
         * @internal
         */
        get _stats() {
          return "pointer input";
        }
        /**
         * Initialize this source of data
         * @returns a promise that resolves as soon as this source of data is initialized
         * @internal
         */
        _init() {
          Utils.log("Initializing PointerSource...");
          return import_speedy_vision26.default.Promise.resolve();
        }
        /**
         * Release this source of data
         * @returns a promise that resolves as soon as this source of data is released
         * @internal
         */
        _release() {
          this._setViewport(null);
          return import_speedy_vision26.default.Promise.resolve();
        }
        /**
         * Link a viewport to this source of data
         * @param viewport possibly null
         * @internal
         */
        _setViewport(viewport) {
          if (this._viewport !== null) {
            this._viewport.hud.container.style.removeProperty("pointer-events");
            this._viewport._subContainer.style.removeProperty("pointer-events");
            this._viewport.container.style.removeProperty("pointer-events");
            this._viewport.canvas.style.removeProperty("pointer-events");
            this._removeEventListeners(this._viewport.canvas);
          }
          if ((this._viewport = viewport) !== null) {
            this._addEventListeners(this._viewport.canvas);
            this._viewport.canvas.style.pointerEvents = "auto";
            this._viewport.container.style.pointerEvents = "none";
            this._viewport._subContainer.style.pointerEvents = "none";
            this._viewport.hud.container.style.pointerEvents = "none";
            for (const element of this._viewport.hud.container.children) {
              if (element.style.getPropertyValue("pointer-events") == "")
                element.style.pointerEvents = "auto";
            }
          }
        }
        /**
         * Event handler
         * @param event
         */
        _onPointerEvent(event) {
          this._queue.push(event);
          event.preventDefault();
        }
        /**
         * Cancel event
         * @param event
         */
        _cancelEvent(event) {
          if (event.cancelable)
            event.preventDefault();
        }
        /**
         * Add event listeners
         * @param canvas
         */
        _addEventListeners(canvas) {
          canvas.addEventListener("pointerdown", this._onPointerEvent);
          canvas.addEventListener("pointerup", this._onPointerEvent);
          canvas.addEventListener("pointermove", this._onPointerEvent);
          canvas.addEventListener("pointercancel", this._onPointerEvent);
          canvas.addEventListener("pointerleave", this._onPointerEvent);
          canvas.addEventListener("pointerenter", this._onPointerEvent);
          canvas.addEventListener("touchstart", this._cancelEvent, { passive: false });
        }
        /**
         * Remove event listeners
         * @param canvas
         */
        _removeEventListeners(canvas) {
          canvas.removeEventListener("touchstart", this._cancelEvent);
          canvas.removeEventListener("pointerenter", this._onPointerEvent);
          canvas.removeEventListener("pointerleave", this._onPointerEvent);
          canvas.removeEventListener("pointercancel", this._onPointerEvent);
          canvas.removeEventListener("pointermove", this._onPointerEvent);
          canvas.removeEventListener("pointerup", this._onPointerEvent);
          canvas.removeEventListener("pointerdown", this._onPointerEvent);
        }
      };
    }
  });

  // src/sources/source-factory.ts
  var SourceFactory;
  var init_source_factory = __esm({
    "src/sources/source-factory.ts"() {
      "use strict";
      init_video_source();
      init_canvas_source();
      init_camera_source();
      init_pointer_source();
      SourceFactory = class {
        /**
         * Create a <video>-based source of data
         * @param video video element
         * @returns a video source
         */
        static Video(video) {
          return new VideoSource(video);
        }
        /**
         * Create a <canvas>-based source of data
         * @param canvas canvas element
         * @returns a canvas source
         */
        static Canvas(canvas) {
          return new CanvasSource(canvas);
        }
        /**
         * Create a Webcam-based source of data
         * @param options optional options object
         * @returns a camera source
         */
        static Camera(options = {}) {
          return new CameraSource(options);
        }
        /**
         * Create a source of pointer-based input
         * @returns a pointer source
        */
        static Pointer() {
          return new PointerSource();
        }
      };
    }
  });

  // src/core/hud.ts
  var HUD;
  var init_hud = __esm({
    "src/core/hud.ts"() {
      "use strict";
      init_utils();
      HUD = class {
        /**
         * Constructor
         * @param parent parent of the hud container
         * @param hudContainer an existing hud container (optional)
         */
        constructor(parent, hudContainer) {
          this._container = hudContainer || this._createContainer(parent);
          this._isOwnContainer = hudContainer == null;
          if (this._container.parentElement !== parent) {
            this._container.remove();
            parent.insertAdjacentElement("afterbegin", this._container);
          }
          if (!this._container.hidden) {
            Utils.warning(`The container of the HUD should have the hidden attribute`);
            this._container.hidden = true;
          }
        }
        /**
         * The container of the HUD
         */
        get container() {
          return this._container;
        }
        /**
         * Whether or not the HUD is visible
         */
        get visible() {
          return !this._container.hidden;
        }
        /**
         * Whether or not the HUD is visible
         */
        set visible(visible) {
          this._container.hidden = !visible;
        }
        /**
         * Initialize the HUD
         * @param zIndex the z-index of the container
         * @internal
         */
        _init(zIndex) {
          const container = this._container;
          container.style.position = "absolute";
          container.style.left = container.style.top = "0px";
          container.style.right = container.style.bottom = "0px";
          container.style.padding = container.style.margin = "0px";
          container.style.zIndex = String(zIndex);
          container.style.userSelect = "none";
          this.visible = true;
        }
        /**
         * Release the HUD
         * @internal
         */
        _release() {
          this.visible = false;
          if (this._isOwnContainer) {
            this._isOwnContainer = false;
            this._container.remove();
          }
        }
        /**
         * Create a HUD container as an immediate child of the input node
         * @param parent parent container
         * @returns HUD container
         */
        _createContainer(parent) {
          const node = document.createElement("div");
          node.hidden = true;
          parent.insertAdjacentElement("afterbegin", node);
          return node;
        }
      };
    }
  });

  // src/ui/fullscreen-button.ts
  var BUTTON_ICON_OFF, BUTTON_ICON_ON, BUTTON_SIZE, BUTTON_MARGIN, FullscreenButton;
  var init_fullscreen_button = __esm({
    "src/ui/fullscreen-button.ts"() {
      "use strict";
      BUTTON_ICON_OFF = "data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAACAAAAAgCAYAAABzenr0AAAAbUlEQVRYR+2WOQ4AIAgE5f+PVhobDZANBZAsraAwXMoqFil+f9GBj8BW8dIiKt45at/XgShStHgvmfdekwAdIIEyAmh1Z/U5ikmABPoRsLZWtt+5DUlgHgGr6qM1Pf9XnO131L7fJEQjyOqXEzjP1YAhNmUTrgAAAABJRU5ErkJggg==";
      BUTTON_ICON_ON = "data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAACAAAAAgCAYAAABzenr0AAAAZElEQVRYR+2WwRIAEAhE9f8fTQ5OhtkLxbzOyc5rJSvBYcH3FwTIBKpHb5d57Nqm5o0aCIBAPgLDxSunq69APT8RCBdwezTLHjglDAEQgEC+QZR2EqqbjprHRgSB9wjwHX9LoAHP1YAhXF4Z/QAAAABJRU5ErkJggg==";
      BUTTON_SIZE = 64;
      BUTTON_MARGIN = 24;
      FullscreenButton = class {
        /**
         * Constructor
         * @param viewport Viewport
         */
        constructor(viewport) {
          this._viewport = viewport;
          this._button = this._createButton();
          this._boundEventHandler = this._handleFullscreenEvent.bind(this);
        }
        /**
         * Initialize
         */
        init() {
          this._viewport.hud.container.appendChild(this._button);
          this._viewport.addEventListener("fullscreenchange", this._boundEventHandler);
        }
        /**
         * Release
         */
        release() {
          this._viewport.removeEventListener("fullscreenchange", this._boundEventHandler);
          this._button.remove();
        }
        /**
         * Create the <button> element
         */
        _createButton() {
          const button = document.createElement("button");
          button.style.position = "absolute";
          button.style.bottom = BUTTON_MARGIN + "px";
          button.style.right = BUTTON_MARGIN + "px";
          button.style.width = BUTTON_SIZE + "px";
          button.style.height = BUTTON_SIZE + "px";
          button.style.opacity = "0.5";
          button.style.cursor = "pointer";
          button.style.outline = "none";
          button.style["-webkit-tap-highlight-color"] = "transparent";
          button.draggable = false;
          button.style.backgroundColor = "transparent";
          button.style.backgroundImage = "url(" + BUTTON_ICON_OFF + ")";
          button.style.backgroundSize = "cover";
          button.style.imageRendering = "pixelated";
          button.style.borderColor = "white";
          button.style.borderStyle = "solid";
          button.style.borderWidth = "2px";
          button.style.borderRadius = "8px";
          const highlight = () => {
            button.style.backgroundColor = "#ffd500";
            button.style.borderColor = "#ffd500";
            button.style.opacity = "1.0";
          };
          const dehighlight = () => {
            button.style.backgroundColor = "transparent";
            button.style.borderColor = "white";
            button.style.opacity = "0.5";
          };
          button.addEventListener("pointerdown", highlight);
          button.addEventListener("pointerup", dehighlight);
          button.addEventListener("pointerleave", dehighlight);
          button.addEventListener("click", () => {
            if (!this._viewport.fullscreen) {
              this._viewport.requestFullscreen().catch((err) => {
                alert(`Can't enable the fullscreen mode. ` + err.toString());
              });
            } else {
              this._viewport.exitFullscreen();
            }
          });
          return button;
        }
        /**
         * Handle a fullscreenchange event
         */
        _handleFullscreenEvent(event) {
          const img = this._viewport.fullscreen ? BUTTON_ICON_ON : BUTTON_ICON_OFF;
          this._button.style.backgroundImage = "url(" + img + ")";
        }
      };
    }
  });

  // src/core/viewport.ts
  var import_speedy_vision27, ViewportEvent, ViewportEventTarget, DEFAULT_VIEWPORT_SETTINGS, BASE_ZINDEX, BACKGROUND_ZINDEX, FOREGROUND_ZINDEX, HUD_ZINDEX, ViewportContainers, ViewportCanvases, ViewportFullscreenHelper, ViewportResizer, ViewportResizeStrategy, InlineResizeStrategy, ImmersiveResizeStrategy, BestFitResizeStrategy, StretchResizeStrategy, Viewport;
  var init_viewport = __esm({
    "src/core/viewport.ts"() {
      "use strict";
      init_main();
      import_speedy_vision27 = __toESM(require_speedy_vision(), 1);
      init_hud();
      init_fullscreen_button();
      init_vector2();
      init_utils();
      init_ar_events();
      init_errors();
      ViewportEvent = class extends AREvent {
      };
      ViewportEventTarget = class extends AREventTarget {
      };
      DEFAULT_VIEWPORT_SETTINGS = {
        container: null,
        hudContainer: null,
        resolution: "lg",
        style: "best-fit",
        canvas: null,
        fullscreenUI: true
      };
      BASE_ZINDEX = 0;
      BACKGROUND_ZINDEX = BASE_ZINDEX + 0;
      FOREGROUND_ZINDEX = BASE_ZINDEX + 1;
      HUD_ZINDEX = BASE_ZINDEX + 2;
      ViewportContainers = class {
        /**
         * Constructor
         * @param container viewport container
         */
        constructor(container) {
          if (container == null)
            throw new IllegalArgumentError("Unspecified viewport container");
          else if (!(container instanceof HTMLElement))
            throw new IllegalArgumentError("Invalid viewport container");
          this._container = container;
          this._subContainer = document.createElement("div");
          container.appendChild(this._subContainer);
        }
        /**
         * The viewport container
         */
        get container() {
          return this._container;
        }
        /**
         * The sub-container
         */
        get subContainer() {
          return this._subContainer;
        }
        /**
         * Initialize
         */
        init() {
          this._container.style.touchAction = "none";
          this._container.style.backgroundColor = "black";
        }
        /**
         * Release
         */
        release() {
          this._container.style.removeProperty("background-color");
          this._container.style.removeProperty("touch-action");
        }
      };
      ViewportCanvases = class {
        /**
         * Constructor
         * @param parent container for the canvases
         * @param initialSize initial size of the canvases
         * @param fgCanvas optional existing foreground canvas
         */
        constructor(parent, initialSize, fgCanvas = null) {
          if (fgCanvas !== null && !(fgCanvas instanceof HTMLCanvasElement))
            throw new IllegalArgumentError("Not a canvas: " + fgCanvas);
          this._originalCSSTextOfForegroundCanvas = fgCanvas ? fgCanvas.style.cssText : "";
          this._foregroundCanvas = this._styleCanvas(
            fgCanvas || this._createCanvas(initialSize),
            FOREGROUND_ZINDEX
          );
          this._foregroundCanvas.style.background = "transparent";
          this._backgroundCanvas = this._styleCanvas(
            this._createCanvas(initialSize),
            BACKGROUND_ZINDEX
          );
          this._backgroundCanvas.hidden = true;
          this._foregroundCanvas.hidden = true;
          const engineInfo = "encantar.js " + AR.version;
          this._backgroundCanvas.dataset.arEngine = engineInfo;
          this._foregroundCanvas.dataset.arEngine = engineInfo;
          parent.appendChild(this._backgroundCanvas);
          parent.appendChild(this._foregroundCanvas);
        }
        /**
         * The background canvas
         */
        get backgroundCanvas() {
          return this._backgroundCanvas;
        }
        /**
         * The foreground canvas
         */
        get foregroundCanvas() {
          return this._foregroundCanvas;
        }
        /**
         * Initialize
         */
        init() {
          this._backgroundCanvas.hidden = false;
          this._foregroundCanvas.hidden = false;
        }
        /**
         * Release
         */
        release() {
          this._backgroundCanvas.hidden = true;
          this._foregroundCanvas.hidden = true;
          this._backgroundCanvas.style.cssText = "";
          this._foregroundCanvas.style.cssText = this._originalCSSTextOfForegroundCanvas;
        }
        /**
         * Create a canvas
         * @param size size of the drawing buffer
         * @returns a new canvas
         */
        _createCanvas(size) {
          const canvas = document.createElement("canvas");
          canvas.width = size.width;
          canvas.height = size.height;
          return canvas;
        }
        /**
         * Add suitable CSS rules to a canvas
         * @param canvas
         * @param zIndex
         * @returns canvas
         */
        _styleCanvas(canvas, zIndex) {
          canvas.style.position = "absolute";
          canvas.style.left = "0px";
          canvas.style.top = "0px";
          canvas.style.width = "100%";
          canvas.style.height = "100%";
          canvas.style.zIndex = String(zIndex);
          return canvas;
        }
      };
      ViewportFullscreenHelper = class {
        /**
         * Constructor
         * @param viewport Viewport
         */
        constructor(viewport) {
          this._viewport = viewport;
          this._container = viewport.container;
          this._boundEventHandler = this._triggerEvent.bind(this);
        }
        /**
         * Initialize
         */
        init() {
          this._container.addEventListener("fullscreenchange", this._boundEventHandler);
        }
        /**
         * Release
         */
        release() {
          this._container.removeEventListener("fullscreenchange", this._boundEventHandler);
        }
        /**
         * Make a request to the user agent so that the viewport container is
         * displayed in fullscreen mode. The container must be a compatible element[1]
         * and the user must interact with the page in order to comply with browser
         * policies[2]. In case of error, the returned promise is rejected.
         * [1] https://developer.mozilla.org/en-US/docs/Web/API/Element/requestFullscreen#compatible_elements
         * [2] https://developer.mozilla.org/en-US/docs/Web/API/Element/requestFullscreen#security
         * @returns promise
         */
        request() {
          const container = this._container;
          if (container.requestFullscreen === void 0) {
            if (container.webkitRequestFullscreen === void 0)
              return import_speedy_vision27.default.Promise.reject(new NotSupportedError());
            else if (!document.webkitFullscreenEnabled)
              return import_speedy_vision27.default.Promise.reject(new AccessDeniedError());
            container.webkitRequestFullscreen();
            return new import_speedy_vision27.default.Promise((resolve, reject) => {
              setTimeout(() => {
                if (container === document.webkitFullscreenElement) {
                  Utils.log("Entering fullscreen mode...");
                  resolve();
                } else
                  reject(new TypeError());
              }, 100);
            });
          }
          if (!document.fullscreenEnabled)
            return import_speedy_vision27.default.Promise.reject(new AccessDeniedError());
          return new import_speedy_vision27.default.Promise((resolve, reject) => {
            container.requestFullscreen({
              navigationUI: "hide"
            }).then(() => {
              Utils.log("Entering fullscreen mode...");
              resolve();
            }, reject);
          });
        }
        /**
         * Exit fullscreen mode
         * @returns promise
         */
        exit() {
          if (document.exitFullscreen === void 0) {
            const doc = document;
            if (doc.webkitExitFullscreen === void 0)
              return import_speedy_vision27.default.Promise.reject(new NotSupportedError());
            else if (doc.webkitFullscreenElement === null)
              return import_speedy_vision27.default.Promise.reject(new IllegalOperationError("Not in fullscreen mode"));
            doc.webkitExitFullscreen();
            return new import_speedy_vision27.default.Promise((resolve, reject) => {
              setTimeout(() => {
                if (doc.webkitFullscreenElement === null) {
                  Utils.log("Exiting fullscreen mode...");
                  resolve();
                } else
                  reject(new TypeError());
              }, 100);
            });
          }
          if (document.fullscreenElement === null)
            return import_speedy_vision27.default.Promise.reject(new IllegalOperationError("Not in fullscreen mode"));
          return new import_speedy_vision27.default.Promise((resolve, reject) => {
            document.exitFullscreen().then(() => {
              Utils.log("Exiting fullscreen mode...");
              resolve();
            }, reject);
          });
        }
        /**
         * Is the fullscreen mode available in this platform?
         * @returns true if the fullscreen mode is available in this platform
         */
        isAvailable() {
          return document.fullscreenEnabled || !!document.webkitFullscreenEnabled;
        }
        /**
         * Is the container currently being displayed in fullscreen mode?
         * @returns true if the container is currently being displayed in fullscreen mode
         */
        isActivated() {
          if (document.fullscreenElement !== void 0)
            return document.fullscreenElement === this._container;
          else if (document.webkitFullscreenElement !== void 0)
            return document.webkitFullscreenElement === this._container;
          else
            return false;
        }
        /**
         * Trigger a fullscreenchange event
         */
        _triggerEvent() {
          const event = new ViewportEvent("fullscreenchange");
          this._viewport.dispatchEvent(event);
        }
      };
      ViewportResizer = class {
        /**
         * Constructor
         * @param viewport the viewport to be resized
         */
        constructor(viewport) {
          this._viewport = viewport;
          this._timeout = null;
          this._resize = this._onResize.bind(this);
          this._triggerResize = this.triggerResize.bind(this);
          this._resizeStrategy = new InlineResizeStrategy();
          this._viewport.addEventListener("resize", this._resize);
          this.triggerResize(0);
        }
        /**
         * Initialize
         */
        init() {
          window.addEventListener("resize", this._triggerResize);
          if (screen.orientation !== void 0)
            screen.orientation.addEventListener("change", this._triggerResize);
          else
            window.addEventListener("orientationchange", this._triggerResize);
          this.triggerResize(0);
        }
        /**
         * Release
         */
        release() {
          if (screen.orientation !== void 0)
            screen.orientation.removeEventListener("change", this._triggerResize);
          else
            window.removeEventListener("orientationchange", this._triggerResize);
          window.removeEventListener("resize", this._triggerResize);
          this._viewport.removeEventListener("resize", this._resize);
          this._resizeStrategy.clear(this._viewport);
        }
        /**
         * Trigger a resize event after a delay
         * @param delay in milliseconds
         */
        triggerResize(delay = 100) {
          const event = new ViewportEvent("resize");
          if (delay <= 0) {
            this._viewport.dispatchEvent(event);
            return;
          }
          if (this._timeout !== null)
            clearTimeout(this._timeout);
          this._timeout = setTimeout(() => {
            this._timeout = null;
            this._viewport.dispatchEvent(event);
          }, delay);
        }
        /**
         * Change the resize strategy
         * @param strategy new strategy
         */
        setStrategy(strategy) {
          this._resizeStrategy.clear(this._viewport);
          this._resizeStrategy = strategy;
          this.triggerResize(0);
        }
        /**
         * Change the resize strategy
         * @param strategyName name of the new strategy
         */
        setStrategyByName(strategyName) {
          switch (strategyName) {
            case "best-fit":
              this.setStrategy(new BestFitResizeStrategy());
              break;
            case "stretch":
              this.setStrategy(new StretchResizeStrategy());
              break;
            case "inline":
              this.setStrategy(new InlineResizeStrategy());
              break;
            default:
              throw new IllegalArgumentError("Invalid viewport style: " + strategyName);
          }
        }
        /**
         * Resize callback
         */
        _onResize() {
          const viewport = this._viewport;
          const foregroundCanvas = viewport.canvas;
          const virtualSize = viewport.virtualSize;
          foregroundCanvas.width = virtualSize.width;
          foregroundCanvas.height = virtualSize.height;
          const backgroundCanvas = viewport._backgroundCanvas;
          const realSize = viewport._realSize;
          backgroundCanvas.width = realSize.width;
          backgroundCanvas.height = realSize.height;
          this._resizeStrategy.resize(viewport);
        }
      };
      ViewportResizeStrategy = class {
        /**
         * Clear CSS rules
         * @param viewport
         */
        clear(viewport) {
          viewport.container.style.cssText = "";
          viewport._subContainer.style.cssText = "";
        }
      };
      InlineResizeStrategy = class extends ViewportResizeStrategy {
        /**
         * Resize the viewport
         * @param viewport
         */
        resize(viewport) {
          const container = viewport.container;
          const subContainer = viewport._subContainer;
          const virtualSize = viewport.virtualSize;
          container.style.display = "inline-block";
          container.style.position = "relative";
          container.style.left = "0px";
          container.style.top = "0px";
          container.style.width = virtualSize.width + "px";
          container.style.height = virtualSize.height + "px";
          subContainer.style.position = "absolute";
          subContainer.style.left = "0px";
          subContainer.style.top = "0px";
          subContainer.style.width = "100%";
          subContainer.style.height = "100%";
        }
      };
      ImmersiveResizeStrategy = class extends ViewportResizeStrategy {
        /**
         * Resize the viewport
         * @param viewport
         */
        resize(viewport) {
          const CONTAINER_ZINDEX = 1e9;
          const container = viewport.container;
          container.style.position = "fixed";
          container.style.left = "0px";
          container.style.top = "0px";
          container.style.width = "100vw";
          container.style.height = "100vh";
          container.style.zIndex = String(CONTAINER_ZINDEX);
        }
      };
      BestFitResizeStrategy = class extends ImmersiveResizeStrategy {
        /**
         * Resize the viewport
         * @param viewport
         */
        resize(viewport) {
          const subContainer = viewport._subContainer;
          const windowAspectRatio = window.innerWidth / window.innerHeight;
          const viewportAspectRatio = viewport.aspectRatio;
          let width = 1, height = 1, left = "0px", top = "0px";
          if (viewportAspectRatio <= windowAspectRatio) {
            height = window.innerHeight;
            width = Math.round(height * viewportAspectRatio);
            width -= width % 2;
            left = `calc(50% - ${width >>> 1}px)`;
          } else {
            width = window.innerWidth;
            height = Math.round(width / viewportAspectRatio);
            height -= height % 2;
            top = `calc(50% - ${height >>> 1}px)`;
          }
          subContainer.style.position = "absolute";
          subContainer.style.left = left;
          subContainer.style.top = top;
          subContainer.style.width = width + "px";
          subContainer.style.height = height + "px";
          super.resize(viewport);
        }
      };
      StretchResizeStrategy = class extends ImmersiveResizeStrategy {
        /**
         * Resize the viewport
         * @param viewport
         */
        resize(viewport) {
          const subContainer = viewport._subContainer;
          subContainer.style.position = "absolute";
          subContainer.style.left = "0px";
          subContainer.style.top = "0px";
          subContainer.style.width = window.innerWidth + "px";
          subContainer.style.height = window.innerHeight + "px";
          super.resize(viewport);
        }
      };
      Viewport = class extends ViewportEventTarget {
        /**
         * Constructor
         * @param viewportSettings
         */
        constructor(viewportSettings) {
          const settings = Object.assign({}, DEFAULT_VIEWPORT_SETTINGS, viewportSettings);
          super();
          const guessedAspectRatio = window.innerWidth / window.innerHeight;
          const initialSize = Utils.resolution(settings.resolution, guessedAspectRatio);
          this._mediaSize = () => initialSize;
          this._resolution = settings.resolution;
          this._style = settings.style;
          this._containers = new ViewportContainers(settings.container);
          this._hud = new HUD(this._subContainer, settings.hudContainer);
          this._canvases = new ViewportCanvases(this._subContainer, initialSize, settings.canvas);
          this._resizer = new ViewportResizer(this);
          this._resizer.setStrategyByName(this._style);
          this._fullscreen = new ViewportFullscreenHelper(this);
          this._fullscreenButton = null;
          if (settings.fullscreenUI && this.fullscreenAvailable)
            this._fullscreenButton = new FullscreenButton(this);
        }
        /**
         * Viewport container
         */
        get container() {
          return this._containers.container;
        }
        /**
         * Viewport style
         */
        get style() {
          return this._style;
        }
        /**
         * Set viewport style
         */
        /*
        set style(value: ViewportStyle)
        {
            // note: the viewport style is independent of the session mode!
            if(value !== this._style) {
                this._resizer.setStrategyByName(value);
                this._style = value;
            }
        }
        */
        /**
         * HUD
         */
        get hud() {
          return this._hud;
        }
        /**
         * Resolution of the virtual scene
         */
        get resolution() {
          return this._resolution;
        }
        /**
         * Size in pixels of the drawing buffer of the canvas
         * on which the virtual scene will be drawn
         */
        get virtualSize() {
          return Utils.resolution(this._resolution, this.aspectRatio);
        }
        /**
         * Aspect ratio of the viewport
         */
        get aspectRatio() {
          const size = this._realSize;
          return size.width / size.height;
        }
        /**
         * Is the viewport currently being displayed in fullscreen mode?
         */
        get fullscreen() {
          return this._fullscreen.isActivated();
        }
        /**
         * Is the fullscreen mode available in this platform?
         */
        get fullscreenAvailable() {
          return this._fullscreen.isAvailable();
        }
        /**
         * The canvas on which the virtual scene will be drawn
         */
        get canvas() {
          return this._canvases.foregroundCanvas;
        }
        /**
         * The canvas on which the physical scene will be drawn
         * @internal
         */
        get _backgroundCanvas() {
          return this._canvases.backgroundCanvas;
        }
        /**
         * Size of the drawing buffer of the background canvas, in pixels
         * @internal
         */
        get _realSize() {
          return this._mediaSize();
        }
        /**
         * Sub-container of the viewport container
         * @internal
         */
        get _subContainer() {
          return this._containers.subContainer;
        }
        /**
         * Request fullscreen mode
         * @returns promise
         */
        requestFullscreen() {
          return this._fullscreen.request();
        }
        /**
         * Exit fullscreen mode
         * @returns promise
         */
        exitFullscreen() {
          return this._fullscreen.exit();
        }
        /**
         * Convert a position given in space units to a corresponding pixel
         * position in canvas space. Units in normalized space range from -1 to +1.
         * The center of the canvas is at (0,0). The top right corner is at (1,1).
         * The bottom left corner is at (-1,-1).
         * @param position in space units
         * @param space either "normalized" (default) or "adjusted"; @see PointerSpace
         * @returns an equivalent pixel position in canvas space
         */
        convertToPixels(position, space = "normalized") {
          const canvas = this.canvas;
          let px = position.x, py = position.y;
          if (space == "adjusted") {
            const a = canvas.width / canvas.height;
            if (a >= 1)
              py *= a;
            else
              px /= a;
          } else if (space != "normalized")
            throw new IllegalArgumentError(`Invalid space: "${space}"`);
          const x = 0.5 * (1 + px) * canvas.width;
          const y = 0.5 * (1 - py) * canvas.height;
          return new Vector2(x, y);
        }
        /**
         * Convert a pixel position given in canvas space to a corresponding
         * position in space units. This is the inverse of convertToPixels().
         * @param position in canvas space
         * @space either "normalized" (default) or "adjusted"; see @PointerSpace
         * @returns an equivalent position in space units
         */
        convertFromPixels(position, space = "normalized") {
          const canvas = this.canvas;
          let x = 2 * position.x / canvas.width - 1;
          let y = -2 * position.y / canvas.height + 1;
          if (space == "adjusted") {
            const a = canvas.width / canvas.height;
            if (a >= 1)
              y /= a;
            else
              x *= a;
          } else if (space != "normalized")
            throw new IllegalArgumentError(`Invalid space: "${space}"`);
          return new Vector2(x, y);
        }
        /**
         * Initialize the viewport (when the session starts)
         * @param getMediaSize
         * @param sessionMode
         * @internal
         */
        _init(getMediaSize, sessionMode) {
          if (sessionMode == "immersive") {
            if (this._style != "best-fit" && this._style != "stretch") {
              Utils.warning(`Invalid viewport style "${this._style}" for the "${sessionMode}" mode`);
              this._style = "best-fit";
              this._resizer.setStrategyByName(this._style);
            }
          } else if (sessionMode == "inline") {
            if (this._style != "inline") {
              Utils.warning(`Invalid viewport style "${this._style}" for the "${sessionMode}" mode`);
              this._style = "inline";
              this._resizer.setStrategyByName(this._style);
            }
          }
          this._mediaSize = getMediaSize;
          this._containers.init();
          this._hud._init(HUD_ZINDEX);
          this._canvases.init();
          this._resizer.init();
          this._fullscreen.init();
          this._fullscreenButton?.init();
        }
        /**
         * Release the viewport (when the session ends)
         * @internal
         */
        _release() {
          this._fullscreenButton?.release();
          this._fullscreen.release();
          this._resizer.release();
          this._canvases.release();
          this._hud._release();
          this._containers.release();
        }
      };
    }
  });

  // src/main.ts
  var import_speedy_vision28, AR;
  var init_main = __esm({
    "src/main.ts"() {
      "use strict";
      import_speedy_vision28 = __toESM(require_speedy_vision(), 1);
      init_settings2();
      init_session();
      init_tracker_factory();
      init_source_factory();
      init_viewport();
      init_vector2();
      init_vector3();
      init_utils();
      AR = class {
        /**
         * Start a new session
         * @param options
         * @returns a promise that resolves to a new session
         */
        static startSession(options) {
          return Session.instantiate(options);
        }
        /**
         * Checks if the engine can be run in the browser the client is using
         * @returns true if the engine is compatible with the browser
         */
        static isSupported() {
          return Session.isSupported();
        }
        /**
         * Engine version
         */
        static get version() {
          if (false)
            return "0.4.1-dev";
          else
            return "0.4.1";
        }
        /**
         * Speedy Vision
         */
        static get Speedy() {
          return import_speedy_vision28.default;
        }
        /**
         * Trackers
         */
        static get Tracker() {
          return TrackerFactory;
        }
        /**
         * Sources of data
         */
        static get Source() {
          return SourceFactory;
        }
        /**
         * Create a viewport
         * @param settings
         * @returns a new viewport with the specified settings
         */
        static Viewport(settings) {
          return new Viewport(settings);
        }
        /**
         * Create a new 2D vector
         * @param x x-coordinate
         * @param y y-coordinate
         * @returns a new 2D vector with the provided coordinates
         */
        static Vector2(x, y) {
          return new Vector2(x, y);
        }
        /**
         * Create a new 3D vector
         * @param x x-coordinate
         * @param y y-coordinate
         * @param z z-coordinate
         * @returns a new 3D vector with the provided coordinates
         */
        static Vector3(x, y, z) {
          return new Vector3(x, y, z);
        }
        /**
         * Global Settings
         */
        static get Settings() {
          return Settings;
        }
      };
      Object.freeze(AR);
      ((window2) => window2.Speedy = window2.Speedy || import_speedy_vision28.default)(window);
      Utils.log(
        `encantar.js version ${AR.version}. GPU-accelerated Augmented Reality for the web by Alexandre Martins. https://encantar.dev`
      );
    }
  });

  // src/__main.ts
  var require_main = __commonJS({
    "src/__main.ts"(exports, module) {
      init_main();
      module.exports = AR;
    }
  });
  return require_main();
})();
